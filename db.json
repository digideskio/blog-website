{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"themes/jacman/source/js/totop.js","path":"js/totop.js","modified":0},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","path":"js/jquery.qrcode-0.12.0.min.js","modified":0},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":0},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":0},{"_id":"themes/jacman/source/js/gallery.js","path":"js/gallery.js","modified":0},{"_id":"themes/jacman/source/img/scrollup.png","path":"img/scrollup.png","modified":0},{"_id":"themes/jacman/source/img/logo.svg","path":"img/logo.svg","modified":0},{"_id":"themes/jacman/source/img/logo.png","path":"img/logo.png","modified":0},{"_id":"themes/jacman/source/img/jacman.jpg","path":"img/jacman.jpg","modified":0},{"_id":"themes/jacman/source/img/favicon.ico","path":"img/favicon.ico","modified":0},{"_id":"themes/jacman/source/img/cc-zero.svg","path":"img/cc-zero.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by.svg","path":"img/cc-by.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-sa.svg","path":"img/cc-by-sa.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nd.svg","path":"img/cc-by-nd.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc.svg","path":"img/cc-by-nc.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","path":"img/cc-by-nc-sa.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","path":"img/cc-by-nc-nd.svg","modified":0},{"_id":"themes/jacman/source/img/banner.jpg","path":"img/banner.jpg","modified":0},{"_id":"themes/jacman/source/img/author.jpg","path":"img/author.jpg","modified":0},{"_id":"themes/jacman/source/font/fontdiao.woff","path":"font/fontdiao.woff","modified":0},{"_id":"themes/jacman/source/font/fontdiao.ttf","path":"font/fontdiao.ttf","modified":0},{"_id":"themes/jacman/source/font/fontdiao.svg","path":"font/fontdiao.svg","modified":0},{"_id":"themes/jacman/source/font/fontdiao.eot","path":"font/fontdiao.eot","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","path":"font/fontawesome-webfont.woff","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","path":"font/fontawesome-webfont.ttf","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","path":"font/fontawesome-webfont.svg","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","path":"font/fontawesome-webfont.eot","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","path":"font/coveredbyyourgrace-webfont.woff","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","path":"font/coveredbyyourgrace-webfont.ttf","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","path":"font/coveredbyyourgrace-webfont.svg","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","path":"font/coveredbyyourgrace-webfont.eot","modified":0},{"_id":"themes/jacman/source/font/FontAwesome.otf","path":"font/FontAwesome.otf","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0},{"_id":"themes/jacman/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0},{"_id":"themes/jacman/source/css/style.styl","path":"css/style.styl","modified":0},{"_id":"source/CNAME","path":"CNAME","modified":0}],"Cache":[{"_id":"source/CNAME","shasum":"b94100d6afddd9feaffb8707a02a31879ef7c06a","modified":1444729994828},{"_id":"source/404.html","shasum":"95e0296d25ff2d3216f38d624c2f069ea0020763","modified":1444708682099},{"_id":"source/_posts/java8/Java8 DSL.md","shasum":"6353f115a28c1834196075302a822087c734d56a","modified":1445321422795},{"_id":"source/_posts/java8/java8 lambda.md","shasum":"71fae9435f06bf60f96cdc0fdc413749fed583fd","modified":1445320643983},{"_id":"source/_posts/Bug库/技术CheckList.md","shasum":"f3b111a6c912022fcdbf2b29304a6b0a1002f623","modified":1446264485147},{"_id":"source/_posts/java8/java8 time.md","shasum":"fccba59966f9584c27b2d9cd21dbce9612197360","modified":1444963260785},{"_id":"source/_posts/Bug库/项目CheckList.md","shasum":"54ff88da6634b0b0c68b9f5f22208a2cd0d060ae","modified":1446263761730},{"_id":"source/_posts/java加密解密/Java加密.md","shasum":"775163efad1c260691c7eb93d88341a41b361e9c","modified":1444963321583},{"_id":"source/_posts/java8/java8 流.md","shasum":"8f35b6a47a5cef236bbffe1e3bf244217695834e","modified":1445307289843},{"_id":"source/_posts/java加密解密/消息摘要实现.md","shasum":"6279d16488f30e759a5ec8a1cf6b3a0a84116dde","modified":1444963324317},{"_id":"source/_posts/java加密解密/数字证书实现.md","shasum":"0f8c62b5664ed6420fc9b24e337cb21f2b84121f","modified":1444963328774},{"_id":"source/_posts/java加密解密/对称加密.md","shasum":"fbd47d519a51d0842118e0fcfde01d65a208a9b2","modified":1444963317630},{"_id":"source/_posts/java加密解密/辅助工具.md","shasum":"a0ea988e5bb98eeed2c8de9475a4eb6f99f97de2","modified":1444968364362},{"_id":"source/_posts/java基础/Java网络.md","shasum":"c3455dfb0276e8a71cdde16bb3269db5adf3c243","modified":1445305633987},{"_id":"source/_posts/java基础/java io.md","shasum":"c65b0b9e39cd26140ef617304910cad72373c4e6","modified":1444963375618},{"_id":"source/_posts/java加密解密/非对称加密实现.md","shasum":"2444bc8300d57de96c855266f61f59f3acff05e5","modified":1444963312462},{"_id":"source/_posts/java基础/估算java对象大小.md","shasum":"ff1573852157b6c0dfe711283aa43206261d3d65","modified":1444963379209},{"_id":"source/_posts/java基础/java集合.md","shasum":"ed3f4064cd324f1f166edf192bec2b2495929b3a","modified":1444963367730},{"_id":"source/_posts/jvm7/JVM 参数.md","shasum":"786e2043db241bfae8a07a62a068c6d513da06e0","modified":1444984754654},{"_id":"source/_posts/java基础/java 泛型.md","shasum":"877481089ad107011f4d56f22506b59682968649","modified":1444963373122},{"_id":"source/_posts/java基础/java_hook.md","shasum":"041f2a8826840edce3dbfea0455784a1bb5d2552","modified":1444963370644},{"_id":"source/_posts/jvm7/class文件格式.md","shasum":"72fef0e007ca5c65394c03b13b14d5c336c1f5bf","modified":1444963211253},{"_id":"source/_posts/jvm7/gc_log.md","shasum":"bd398bed7070691cfe4c2228642158d29ec6b376","modified":1444979099372},{"_id":"source/_posts/jvm7/JVM工具以及日志分析.md","shasum":"bafda14e90b4d64e33309f348c21ecb89c8307be","modified":1444980056581},{"_id":"source/_posts/jvm7/java虚拟机结构.md","shasum":"cb95e0823c4b1e8885614005242bfabefff74ca6","modified":1444963198493},{"_id":"source/_posts/jvm7/内存分配以及内存溢出.md","shasum":"e40ad918dd72d367355c3bbb2cfeef403d56682d","modified":1444979031882},{"_id":"source/_posts/jvm7/字节码指令.md","shasum":"621197cc85e3cc7bb455c098feda760e2428225d","modified":1444963173119},{"_id":"source/_posts/jvm7/垃圾收集.md","shasum":"3a8a90480a6b1f07439da8f4475d5a0815028a13","modified":1444963188846},{"_id":"source/_posts/工具/CachesExplained.md","shasum":"22e7aa9aad09d7d4fc6ab41cba3130af5d125eef","modified":1445331204794},{"_id":"source/_posts/jvm7/oql.md","shasum":"b55389cb7d1ea819a3d3a2a7b20afcd8db2cbe6b","modified":1444963191254},{"_id":"source/_posts/工具/DevOps.md","shasum":"a245352252bc929883a58806ea5a10608b1bb64b","modified":1445331297644},{"_id":"source/_posts/工具/Flick Ticket Server.md","shasum":"74d29cf42f465100a5b1bdd12913b6c492d7a313","modified":1444787667858},{"_id":"source/_posts/工具/Archiva.md","shasum":"115b4a1ab5f7fb2999f8a825b378c6bc72778d9c","modified":1444787682168},{"_id":"source/_posts/jvm7/类加载.md","shasum":"6ac22a721ef1bbd512f6e09d7194faddb242aefe","modified":1446201124355},{"_id":"source/_posts/工具/idea_indent.md","shasum":"7f683d6b6d651f3c678fd2aff7036067741dac69","modified":1444787652273},{"_id":"source/_posts/工具/MongoDB.md","shasum":"9a2525ba8033c987a92eb0b19e160f74cec00df5","modified":1444787627865},{"_id":"source/_posts/工具/linux命令.md","shasum":"c5e07d7c6508d4f6866082d98ff534943f57c81a","modified":1445306286821},{"_id":"source/_posts/工具/dropwizard.md","shasum":"bcc9b6c0d3b5a553c496fda0f704e5cf13fd63c6","modified":1444963120084},{"_id":"source/_posts/工具/logstash_config.md","shasum":"69a331283efa19771684a91a2ee011cdfeb39d69","modified":1444787643041},{"_id":"source/_posts/工具/maven.md","shasum":"e4a0d41ae6c7e33e7078647b82a98ef2b1508064","modified":1444787636932},{"_id":"source/_posts/工具/gitbook.md","shasum":"72aeb0e6e4d1be120d471ab59fda8c79d718a816","modified":1444787659890},{"_id":"source/_posts/工具/spring_boot.md","shasum":"dd6edd680220228e049e565c8dd232c68837292e","modified":1444787603392},{"_id":"source/_posts/工具/mycat.md","shasum":"b4deb4f88c4844f68afed0464e8c093ce6ea5d51","modified":1444787619460},{"_id":"source/_posts/工具/docker命令.md","shasum":"d2985a295f9e13850f67ad4579fc20d902557867","modified":1444787676338},{"_id":"source/_posts/工具/svn服务器搭建.md","shasum":"f63767ec85049a006c99ebdddd90d117a29d5ddb","modified":1445312670994},{"_id":"source/_posts/工具/vim.md","shasum":"0bee54a9d07e4ffc8ed0889f45c2787bdef54ef8","modified":1445304738750},{"_id":"source/_posts/工具/unity命令行使用.md","shasum":"cc0c1166f727ae97f86c6473e546efed35e1d4b8","modified":1444787592247},{"_id":"source/_posts/编程语言/2015-10-12-AWK.md","shasum":"fb9dc3588e7db85cddaaeb593cfb5afa8c8154cb","modified":1445303444562},{"_id":"source/_posts/编程语言/JavaScript.md","shasum":"2c0d4f31e075956b2d8f3a813e5403ac014820ec","modified":1445234553414},{"_id":"source/_posts/并发编程/1_1_双线程锁.md","shasum":"34e28e182e05ddb4d035a8f2b8d513161c518e99","modified":1444963292897},{"_id":"source/_posts/编程语言/Clojure.md","shasum":"2d89b0265693f3b43cf9afa769edcc0301a91817","modified":1445855548980},{"_id":"source/_posts/编程语言/sql.md","shasum":"895da8ead501744edcccfe4065136c9cabd01808","modified":1445853991684},{"_id":"source/_posts/编程语言/python.md","shasum":"00d966c6de6332a62f5f57f06d261f7b07369410","modified":1445303317524},{"_id":"source/_posts/编程语言/windows rust.md","shasum":"0cb82dd1a233d89344f6bc41c68931bf7e607835","modified":1444787519028},{"_id":"source/_posts/计算机基础/NUMA.md","shasum":"f79c241503d6b1c06bc3695b03cee8fe077472b4","modified":1446515412937},{"_id":"source/_posts/计算机基础/2015-10-19-数据链路层.md","shasum":"020079718339e7855e947a0203e6544d8c662383","modified":1445331263484},{"_id":"source/_posts/计算机基础/http.md","shasum":"a74de675c969beacb3cb5b228615818d5b6cdc83","modified":1444787720629},{"_id":"source/_posts/编程语言/haskell.md","shasum":"356b03e56120c4378c1963ed25930c3ac86826ac","modified":1444787549638},{"_id":"source/about/index.md","shasum":"d1842586d75bce421a755f8394b32ff1ca934ac5","modified":1444647250767},{"_id":"source/categories/bug库/index.md","shasum":"e83b76ded6cdf14f93122c9f1f6fe67f4283b20f","modified":1444959197842},{"_id":"source/categories/index.md","shasum":"3cfb4a49283ec2cc8c5eaca25b847508cd831635","modified":1444705338561},{"_id":"source/categories/java8/index.md","shasum":"e523c07ce8869c14c99a43188f6cbffa5a662115","modified":1444096162995},{"_id":"source/categories/java加密解密/index.md","shasum":"611e506b4bf392a93dd2f2aeb132d5fdd416c205","modified":1444963468307},{"_id":"source/categories/java基础/index.md","shasum":"0331807c0497dc65e382f1fada5378c51dd7c554","modified":1444096096475},{"_id":"source/categories/jvm7/index.md","shasum":"3bd94f405d9d096039171dd79960272bf91d4707","modified":1445219210181},{"_id":"source/categories/工具/index.md","shasum":"1aa5414b0c5b9c4ab1ad884b29df1dfd11cc0f9d","modified":1444124162706},{"_id":"source/categories/并发编程/index.md","shasum":"408e009204d00abb37ac73f4ead207d81b788dd0","modified":1444963458806},{"_id":"source/categories/编程语言/index.md","shasum":"4bb9b591c830feee28487201c88fda39d83e522b","modified":1444096113687},{"_id":"source/_posts/计算机基础/TCP.md","shasum":"c6265108e86c11f3edabdd0afe6d58866ac34ef1","modified":1445305620382},{"_id":"source/_posts/编程语言/groovy.md","shasum":"2c8fd5014d61ab97275918df63f5a558e08149e6","modified":1444787559726},{"_id":"source/_posts/编程语言/shell.md","shasum":"a86888964b1340b9b2fd4c55f11567bf51bf57ec","modified":1445236045993},{"_id":"source/categories/计算机基础/index.md","shasum":"3f248481d3528d23c0390539c30977a3ccbc4952","modified":1444096138477},{"_id":"source/_posts/计算机基础/io.md","shasum":"23dc1bb5b09647676998c45c2cdc4f0b0bfa502e","modified":1445854798873},{"_id":"themes/jacman/_config.yml","shasum":"a7ac90671bf5048a57de2457e6e8bdce63488ad3","modified":1445857896255},{"_id":"themes/jacman/languages/default.yml","shasum":"966be0b585cd3e3b7f0e485c896c24dfdfee423a","modified":1445857739412},{"_id":"themes/jacman/languages/zh-CN.yml","shasum":"6e1460594fa50394ac6f11fe9d39dc59478ddd0c","modified":1445857739412},{"_id":"themes/jacman/languages/zh-TW.yml","shasum":"0e7912c6505592a10efe2db1c994ccc3ebf91239","modified":1445857739413},{"_id":"themes/jacman/LICENSE","shasum":"d8780b41bab4b87bdd21eca444cae11af72617f4","modified":1445857739386},{"_id":"themes/jacman/README.md","shasum":"b5d265267ed9f44a5edf848033e5ac0491004bd0","modified":1445857739387},{"_id":"themes/jacman/README_zh.md","shasum":"9c818b2c1f8c216c439be6bc574469d1dc338c12","modified":1445857739411},{"_id":"themes/jacman/layout/_partial/after_footer.ejs","shasum":"7e406be944cb4ab7e02e05f37a1890f47d6bce39","modified":1445857739413},{"_id":"themes/jacman/layout/_partial/article_row.ejs","shasum":"2c1f1edfeaebaafe4265d58e0b8110e71673da40","modified":1445857739444},{"_id":"themes/jacman/layout/_partial/categories.ejs","shasum":"2b77ff6cbc8571cab27c3bdc4ad51a79510bbca2","modified":1445857739444},{"_id":"themes/jacman/layout/_partial/analytics.ejs","shasum":"5cb06f9d23b92815ff77766b894421e1037505f8","modified":1445857739414},{"_id":"themes/jacman/layout/_partial/archive.ejs","shasum":"90502fc2f5b0a5681a6c6588a9ed6ad297e32890","modified":1445857739414},{"_id":"themes/jacman/layout/_partial/article.ejs","shasum":"00c00b4a961ac1f7bc8ee688ce134fe0c454edc6","modified":1445857739414},{"_id":"themes/jacman/layout/_partial/head.ejs","shasum":"210bb4c1ec77d998dfd93baeb4e3a0b46a925cd1","modified":1445857739446},{"_id":"themes/jacman/layout/_partial/pagination.ejs","shasum":"6cf37f844f150af4bbe212610da61e5140317de9","modified":1445857739460},{"_id":"themes/jacman/layout/_partial/footer.ejs","shasum":"5e02117ed541872115386a0c0257d94a2b3b2bb1","modified":1445857739445},{"_id":"themes/jacman/layout/_partial/post/catetags.ejs","shasum":"20349dcde9942885d5eae1c302ef26b1b8484f3f","modified":1445857739462},{"_id":"themes/jacman/layout/_partial/post/comment.ejs","shasum":"9db7847461cf8b10a9cd5434deb690c6b26af6f1","modified":1445857739463},{"_id":"themes/jacman/layout/_partial/header.ejs","shasum":"795435cc84c46a18e4ac597435a81f66eb86b0c4","modified":1445857739447},{"_id":"themes/jacman/layout/_partial/post/gallery.ejs","shasum":"fc23ef9b5a412e05436f68ff47146b860d2d4225","modified":1445857739464},{"_id":"themes/jacman/layout/_partial/mathjax.ejs","shasum":"5636df1f2b6a8d02986d866e3824ec60430046e6","modified":1445857739458},{"_id":"themes/jacman/layout/_partial/post/header.ejs","shasum":"351e771b1b38244560fc52cf60d91263d3d63eef","modified":1445857739466},{"_id":"themes/jacman/layout/_partial/post/footer.ejs","shasum":"5b9f5ee6a2cc8bd557550bbdc1a03d237681114e","modified":1445857739464},{"_id":"themes/jacman/layout/_partial/post/article.ejs","shasum":"c01220f0af629f9e23bf125bdc1beef8afc206ef","modified":1445857739461},{"_id":"themes/jacman/layout/_partial/sidebar.ejs","shasum":"846d96ff73409b9a8b34f3cab691821096c03e1d","modified":1445857739470},{"_id":"themes/jacman/layout/_partial/tags.ejs","shasum":"c5c858742b29e6364da2e1d098e7d6cd8cef038f","modified":1445857739470},{"_id":"themes/jacman/layout/_partial/tinysou_search.ejs","shasum":"67a55a4d94cca2db11a2636f1f2c92c208688b14","modified":1445857739471},{"_id":"themes/jacman/layout/_partial/totop.ejs","shasum":"224d078ba1f2c33c52d5e867af71c5fe9f1bdf45","modified":1445857739472},{"_id":"themes/jacman/layout/_widget/archive.ejs","shasum":"b82d7fb0d1119738a9f9bb747d415e8c99e454ae","modified":1445857739473},{"_id":"themes/jacman/layout/_widget/category.ejs","shasum":"2c1b9ac7666d7d5b9aaf8f33588e10451c4b7841","modified":1445857739474},{"_id":"themes/jacman/layout/_widget/douban.ejs","shasum":"6dcb532d02325d2a9f5fb92831401552a5540aa8","modified":1445857739474},{"_id":"themes/jacman/layout/_widget/github-card.ejs","shasum":"c8a6fdb883be27f5e7daef6fa8899c17f51548a0","modified":1445857739475},{"_id":"themes/jacman/layout/_widget/links.ejs","shasum":"bd73be669ddc47e1daab38736d1cecc3f37662e2","modified":1445857739476},{"_id":"themes/jacman/layout/_widget/lofter.ejs","shasum":"51d4458ee96c1b1f7a4dde81e3b6a258b5c1efc1","modified":1444815552867},{"_id":"themes/jacman/layout/_widget/rss.ejs","shasum":"ebfb11bdd603cd6e4dcf3949cc52e38009615c25","modified":1445857739478},{"_id":"themes/jacman/layout/_widget/tag.ejs","shasum":"43b1c29fea51f849ec0bf85a6d91fe0507f01503","modified":1445857739478},{"_id":"themes/jacman/layout/_widget/tagcloud.ejs","shasum":"317d420f5448c7452290e37f0ed8516cb73f4068","modified":1445857739479},{"_id":"themes/jacman/layout/_widget/weibo.ejs","shasum":"ff7db098608ba48752964cc67a51a04965ea927e","modified":1445857739480},{"_id":"themes/jacman/layout/archive.ejs","shasum":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1445857739481},{"_id":"themes/jacman/layout/category.ejs","shasum":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1445857739482},{"_id":"themes/jacman/layout/index.ejs","shasum":"b832b280ec0a2b741e73a2300f219f0075c99278","modified":1445857739482},{"_id":"themes/jacman/layout/_partial/search.ejs","shasum":"732fcd909f6dac557629206dc7e93a7083cda084","modified":1445857739469},{"_id":"themes/jacman/layout/page.ejs","shasum":"bd6bbf2ea8e183bd835867ff617dc6366b56748c","modified":1445857739484},{"_id":"themes/jacman/layout/post.ejs","shasum":"3114134775bdde5a83cf14feb019606fa2b2b2be","modified":1445857739485},{"_id":"themes/jacman/layout/tag.ejs","shasum":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1445857739486},{"_id":"themes/jacman/scripts/fancybox.js","shasum":"4c130fc242cf9b59b5df6ca5eae3b14302311e8c","modified":1445857739487},{"_id":"themes/jacman/layout/_partial/post/jiathis.ejs","shasum":"12b7360326691ebf06bea5d7ee4d54c41f64e2ec","modified":1445857739467},{"_id":"themes/jacman/layout/layout.ejs","shasum":"ceeb2a7410b96b81310ed9b1279f62e953b0a6ca","modified":1445857739483},{"_id":"themes/jacman/source/css/_base/font.styl","shasum":"5699c270be7b28c5b2c36f453317ccd42789fd3d","modified":1445857739489},{"_id":"themes/jacman/source/css/_base/highlight/highlight.styl","shasum":"2aee0cdb80fce512cde66ad229b9e5ee42c0d7b4","modified":1445857739491},{"_id":"themes/jacman/source/css/_base/public.styl","shasum":"657ad4c267490bd3b9ac98b5f864ecddb7025586","modified":1445857739493},{"_id":"themes/jacman/source/css/_base/highlight/theme.styl","shasum":"d280f9ab32d7bf177adb5f7c858444cbfbac651a","modified":1445857739492},{"_id":"themes/jacman/source/css/_base/variable.styl","shasum":"0b7d517e12102a99be82bc1a9104bb6bfd4ca10b","modified":1445857739494},{"_id":"themes/jacman/source/css/_partial/article.styl","shasum":"0bcb684376fcbf4be42d1df5dd02c395760f7ffb","modified":1445857739495},{"_id":"themes/jacman/source/css/_partial/aside.styl","shasum":"4746783dc7993ac45d8a0e7a9d347bfe137111fe","modified":1445857739496},{"_id":"themes/jacman/layout/_partial/post/pagination.ejs","shasum":"091512e19cfcf5bde2a699b211f99874f26587ad","modified":1445857739468},{"_id":"themes/jacman/source/css/_partial/gallery.styl","shasum":"75843d727319b1d07ad4b8c2e969036ce0d4f362","modified":1445857739499},{"_id":"themes/jacman/source/css/_partial/helper.styl","shasum":"3ca7266a44240093143d0c55c74bb6daf579e298","modified":1445857739500},{"_id":"themes/jacman/source/css/_partial/duoshuo.styl","shasum":"3ec423b734639614fbd11ec2c3445d3a03f5231d","modified":1445857739498},{"_id":"themes/jacman/source/css/_partial/totop.styl","shasum":"b48360e757d501027b7dbe093859d03795476930","modified":1445857739501},{"_id":"themes/jacman/source/css/style.styl","shasum":"4610c477560086880acc1ba71c3a72e7c89ecdb7","modified":1445857739501},{"_id":"themes/jacman/source/fancybox/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1445857739502},{"_id":"themes/jacman/source/css/_partial/footer.styl","shasum":"0300d7d289eceb3933c1eebf38f8d10f425c1128","modified":1445857739499},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1445857739502},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1445857739503},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1445857739503},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1445857739504},{"_id":"themes/jacman/source/css/_partial/header.styl","shasum":"f1ae52a4f41d4cfdd66cb186b0329af904fead4f","modified":1445857739500},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1445857739504},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1445857739505},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","shasum":"4c9c395d705d22af7da06870d18f434e2a2eeaf9","modified":1445857739506},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","shasum":"6394c48092085788a8c0ef72670b0652006231a1","modified":1445857739505},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","shasum":"e14c32cc6823b81b2f758512f13ed8eb9ef2b454","modified":1445857739506},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","shasum":"2e54d51d21e68ebc4bb870f6e57d3bfb660d4f9c","modified":1445857739508},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","shasum":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1445857739507},{"_id":"themes/jacman/source/css/_partial/index.styl","shasum":"d5a3046587f42703224ac3b761e80baab35d4ccc","modified":1445857739501},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","shasum":"83cdfea43632b613771691a11f56f99d85fb6dbd","modified":1445857739507},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","shasum":"2da892a02778236b64076e5e8802ef0566e1d9e8","modified":1445857739509},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","shasum":"a17d0f10534303e40f210c506ebb8703fa23b7de","modified":1445857739511},{"_id":"themes/jacman/source/font/FontAwesome.otf","shasum":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1445857739510},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","shasum":"58193c802f307ec9bc9e586c0e8a13ebef45d2f8","modified":1445857739508},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","shasum":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e","modified":1445857739515},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","shasum":"194ccb4acf77a03dc25bcc174edb266143704fec","modified":1445857739515},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1445857739516},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","shasum":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1445857739519},{"_id":"themes/jacman/source/font/fontdiao.woff","shasum":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f","modified":1445857739524},{"_id":"themes/jacman/source/font/fontdiao.eot","shasum":"9544a0d7ba208989302bc4da5a184faeb0e883c9","modified":1445857739520},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1445858024427},{"_id":"themes/jacman/source/font/fontdiao.ttf","shasum":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab","modified":1445857739524},{"_id":"themes/jacman/source/img/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1445858024272},{"_id":"themes/jacman/source/img/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1445858024314},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1445858024292},{"_id":"themes/jacman/source/img/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1445858024332},{"_id":"themes/jacman/source/img/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1445858024351},{"_id":"themes/jacman/source/img/logo.png","shasum":"cfe9ece003e30801e82fc31336412b48fd7fdaa2","modified":1445858024420},{"_id":"themes/jacman/source/img/scrollup.png","shasum":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3","modified":1445857739534},{"_id":"themes/jacman/source/img/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1445858024388},{"_id":"themes/jacman/source/js/gallery.js","shasum":"735a714e54f0ac229f292a90df3a1f882904f6c7","modified":1445857739534},{"_id":"themes/jacman/source/img/logo.svg","shasum":"9ae38f7225c38624faeb7b74996efa9de7bf065b","modified":1445858024368},{"_id":"themes/jacman/source/img/favicon.ico","shasum":"4a605a4cc4691ad8b07ea9bc7f1a8212f1ee57cb","modified":1445858024373},{"_id":"themes/jacman/source/js/totop.js","shasum":"48648ec9c86e9ab491831e5a029e6f8864934149","modified":1445857739537},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1445857739519},{"_id":"themes/jacman/source/font/fontdiao.svg","shasum":"50e0247e9d39756843b7e4f720503b37bfb6154b","modified":1445857739523},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","shasum":"739808e56a56e10a03bc93d03eb55abd19590942","modified":1445857739514},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","shasum":"5f690e8588c8493eb9406aa68fbf1765aaff9476","modified":1445857739537},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","shasum":"28ef4346743a60c896a9ae492a544c0854904350","modified":1445857739536},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","shasum":"cd981db035ec1b6f502fca78fd394c5bd438aba1","modified":1445857739535},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","shasum":"a275426daefd3716c53561fad121d258a7f05b47","modified":1445857739518},{"_id":"themes/jacman/source/img/author.jpg","shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c","modified":1445858024407},{"_id":"themes/jacman/source/img/banner.jpg","shasum":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74","modified":1445857739528},{"_id":"themes/jacman/source/img/jacman.jpg","shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c","modified":1445858024437},{"_id":"public/js/totop.js","modified":1446515487653,"shasum":"cad23c5ea7163d1e5c05a0fd3ef9233469da10cb"},{"_id":"public/js/jquery.qrcode-0.12.0.min.js","modified":1446515487657,"shasum":"57c3987166a26415a71292162690e82c21e315ad"},{"_id":"public/js/jquery.imagesloaded.min.js","modified":1446515487659,"shasum":"4109837b1f6477bacc6b095a863b1b95b1b3693f"},{"_id":"public/js/jquery-2.0.3.min.js","modified":1446515487661,"shasum":"a0ae3697b0ab8c0e8bd3186c80db42abd6d97a8d"},{"_id":"public/js/gallery.js","modified":1446515487662,"shasum":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed"},{"_id":"public/img/scrollup.png","modified":1446515487666,"shasum":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3"},{"_id":"public/img/logo.svg","modified":1446515487670,"shasum":"9ae38f7225c38624faeb7b74996efa9de7bf065b"},{"_id":"public/img/logo.png","modified":1446515487672,"shasum":"cfe9ece003e30801e82fc31336412b48fd7fdaa2"},{"_id":"public/img/jacman.jpg","modified":1446515487674,"shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c"},{"_id":"public/img/favicon.ico","modified":1446515487720,"shasum":"4a605a4cc4691ad8b07ea9bc7f1a8212f1ee57cb"},{"_id":"public/img/cc-zero.svg","modified":1446515487724,"shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030"},{"_id":"public/img/cc-by.svg","modified":1446515487728,"shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e"},{"_id":"public/img/cc-by-sa.svg","modified":1446515487731,"shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e"},{"_id":"public/img/cc-by-nd.svg","modified":1446515487742,"shasum":"c563508ce9ced1e66948024ba1153400ac0e0621"},{"_id":"public/img/cc-by-nc.svg","modified":1446515487747,"shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7"},{"_id":"public/img/cc-by-nc-sa.svg","modified":1446515487751,"shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e"},{"_id":"public/img/cc-by-nc-nd.svg","modified":1446515487756,"shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564"},{"_id":"public/img/banner.jpg","modified":1446515487761,"shasum":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74"},{"_id":"public/img/author.jpg","modified":1446515487770,"shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c"},{"_id":"public/font/fontdiao.woff","modified":1446515487773,"shasum":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f"},{"_id":"public/font/fontdiao.ttf","modified":1446515487776,"shasum":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab"},{"_id":"public/font/fontdiao.svg","modified":1446515487779,"shasum":"50e0247e9d39756843b7e4f720503b37bfb6154b"},{"_id":"public/font/fontdiao.eot","modified":1446515487781,"shasum":"9544a0d7ba208989302bc4da5a184faeb0e883c9"},{"_id":"public/font/fontawesome-webfont.woff","modified":1446515487783,"shasum":"04c3bf56d87a0828935bd6b4aee859995f321693"},{"_id":"public/font/fontawesome-webfont.ttf","modified":1446515487786,"shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f"},{"_id":"public/font/fontawesome-webfont.svg","modified":1446515487789,"shasum":"a275426daefd3716c53561fad121d258a7f05b47"},{"_id":"public/font/fontawesome-webfont.eot","modified":1446515487792,"shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e"},{"_id":"public/font/coveredbyyourgrace-webfont.woff","modified":1446515487799,"shasum":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e"},{"_id":"public/font/coveredbyyourgrace-webfont.ttf","modified":1446515487802,"shasum":"194ccb4acf77a03dc25bcc174edb266143704fec"},{"_id":"public/font/coveredbyyourgrace-webfont.svg","modified":1446515487804,"shasum":"739808e56a56e10a03bc93d03eb55abd19590942"},{"_id":"public/font/coveredbyyourgrace-webfont.eot","modified":1446515487806,"shasum":"a17d0f10534303e40f210c506ebb8703fa23b7de"},{"_id":"public/font/FontAwesome.otf","modified":1446515487808,"shasum":"b5b4f9be85f91f10799e87a083da1d050f842734"},{"_id":"public/fancybox/jquery.fancybox.pack.js","modified":1446515487811,"shasum":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e"},{"_id":"public/fancybox/jquery.fancybox.js","modified":1446515487813,"shasum":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed"},{"_id":"public/fancybox/jquery.fancybox.css","modified":1446515487814,"shasum":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6"},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","modified":1446515487816,"shasum":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c"},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","modified":1446515487817,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","modified":1446515487818,"shasum":"294420f9ff20f4e3584d212b0c262a00a96ecdb3"},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","modified":1446515487819,"shasum":"dc3645529a4bf72983a39fa34c1eb9146e082019"},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","modified":1446515487821,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/fancybox/helpers/fancybox_buttons.png","modified":1446515487822,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/fancybox/fancybox_sprite@2x.png","modified":1446515487824,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/fancybox/fancybox_sprite.png","modified":1446515487825,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/fancybox/fancybox_overlay.png","modified":1446515487827,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/fancybox/fancybox_loading@2x.gif","modified":1446515487829,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/fancybox/fancybox_loading.gif","modified":1446515487831,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/fancybox/blank.gif","modified":1446515487832,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/css/style.css","modified":1446515488630,"shasum":"b1efa7168d3c9497d1904f599f5d4d6612ce6fd9"},{"_id":"public/CNAME","modified":1446515488906,"shasum":"b94100d6afddd9feaffb8707a02a31879ef7c06a"},{"_id":"public/404.html","modified":1446515488926,"shasum":"30f300502d9db856b0d1e2c5e48f0e99659b6f18"},{"_id":"public/categories/计算机基础/index.html","modified":1446515488952,"shasum":"70b7c25619f24ee56f2d759c9e5ea7e18b07767c"},{"_id":"public/categories/编程语言/index.html","modified":1446515488973,"shasum":"2c50a7edd980b6dc5ffa1a310033c93ef0621557"},{"_id":"public/categories/并发编程/index.html","modified":1446515488980,"shasum":"0ff85eacc1be6c68cc5015482f623a6148a130dd"},{"_id":"public/categories/工具/index.html","modified":1446515488990,"shasum":"c20ae410e64b6460bbfbae52fd52a26a2a0c5a8f"},{"_id":"public/categories/jvm7/index.html","modified":1446515488998,"shasum":"77dfebb59d2fbb43fd489dd7138c5e21f83c3bec"},{"_id":"public/categories/java基础/index.html","modified":1446515489008,"shasum":"118b1f27ad4bc013f41e69c518a2f38e46d7d467"},{"_id":"public/categories/java加密解密/index.html","modified":1446515489017,"shasum":"a8f990fa68a34ceb8d9aa864d08ed1305ba0bdb1"},{"_id":"public/categories/java8/index.html","modified":1446515489026,"shasum":"b1f3f909b2ad8ba23f54e283e34152d7c1d4ed0f"},{"_id":"public/categories/index.html","modified":1446515489039,"shasum":"f43785a99dd6e7bf0d1b92d6c3bc645078fcb52b"},{"_id":"public/categories/bug库/index.html","modified":1446515489050,"shasum":"b4245346765a6246e403799e29ab758146d37379"},{"_id":"public/about/index.html","modified":1446515489057,"shasum":"25a7e2417f4c3986437b59f5428a380f755dc01f"},{"_id":"public/2015/10/26/计算机基础/NUMA/index.html","modified":1446515489109,"shasum":"7224f7b2f74fbd122afa812a77fbdd8bd5efe01e"},{"_id":"public/2015/10/20/java8/Java8 DSL/index.html","modified":1446515489126,"shasum":"96c7c419b300bd580af8beccd9cb8f738f7ae391"},{"_id":"public/2015/10/15/Bug库/技术CheckList/index.html","modified":1446515489147,"shasum":"7279f8bac35191c68f0b1deced7bbeb83a2c6f78"},{"_id":"public/2015/10/15/工具/linux命令/index.html","modified":1446515489226,"shasum":"4bd1fb36b19903a65affa4e9fe914c81db8cd261"},{"_id":"public/2015/10/12/并发编程/1_1_双线程锁/index.html","modified":1446515489259,"shasum":"b95eb7631c423592855c45205b29d9028e12c10a"},{"_id":"public/2015/10/08/编程语言/sql/index.html","modified":1446515489313,"shasum":"0690a5d422fe29d594b6450c619cb1af97d488eb"},{"_id":"public/2015/10/08/编程语言/shell/index.html","modified":1446515489363,"shasum":"487deb8f5207c3b23c6bf5dbcbb2f0d2308a8faf"},{"_id":"public/2015/10/08/计算机基础/2015-10-19-数据链路层/index.html","modified":1446515489378,"shasum":"92d66f43d51d159f96166025dfa2550343d3fd96"},{"_id":"public/2015/10/08/编程语言/2015-10-12-AWK/index.html","modified":1446515489407,"shasum":"c37969bd50a59d48bcaa73a8896567a9e9c6d920"},{"_id":"public/2015/10/08/工具/vim/index.html","modified":1446515489427,"shasum":"d108e9c90fc665d0e40fb0438b3836f0ce45eb6f"},{"_id":"public/2015/10/08/工具/DevOps/index.html","modified":1446515489448,"shasum":"f1a2c77f0625f923aa188cd29642d144c59d91b6"},{"_id":"public/2015/10/08/工具/mycat/index.html","modified":1446515489474,"shasum":"7def77bbdf9300496a1279255d5eca3c8ce3cb20"},{"_id":"public/2015/10/08/编程语言/Clojure/index.html","modified":1446515489533,"shasum":"05accd05666d8d849c9f2726097e1018a9014c70"},{"_id":"public/2015/09/08/计算机基础/io/index.html","modified":1446515489705,"shasum":"8c6a7055c182077c248298387b549cc2c354f580"},{"_id":"public/2015/09/08/java8/java8 lambda/index.html","modified":1446515489906,"shasum":"e9ce50391eab85b4509842edf24c1d6f9696add1"},{"_id":"public/2015/09/08/java8/java8 time/index.html","modified":1446515489929,"shasum":"2da5a127d95542c711726797b18a4e763466cd86"},{"_id":"public/2015/09/08/工具/Archiva/index.html","modified":1446515489949,"shasum":"eafacba5716c3245a3054d578060b18b6c30a082"},{"_id":"public/2015/09/08/计算机基础/http/index.html","modified":1446515489969,"shasum":"d12c6ab3a6a9b12b77c36b06a72209705ca4de7e"},{"_id":"public/2015/09/08/java8/java8 流/index.html","modified":1446515490026,"shasum":"74b5cf27df3e8bcb46c8a0eb7aa524103e3ac67e"},{"_id":"public/2015/09/08/编程语言/JavaScript/index.html","modified":1446515490079,"shasum":"8979f6fa943394b9d63242803fd375459b719c75"},{"_id":"public/2015/09/08/计算机基础/TCP/index.html","modified":1446515490096,"shasum":"07cb739040ae4d7bfba2607ed55996eedf32cc45"},{"_id":"public/2015/08/08/工具/logstash_config/index.html","modified":1446515490116,"shasum":"13e801d49e0ac10bc7df0f08392deb034d33c920"},{"_id":"public/2015/08/08/编程语言/python/index.html","modified":1446515490174,"shasum":"ef2d22d13987f33dc5f9b000b22f23be024072ca"},{"_id":"public/2015/08/08/工具/idea_indent/index.html","modified":1446515490187,"shasum":"cdb44f20f84f9a68746ef00a1a8ed95ee69cf5b5"},{"_id":"public/2015/08/08/工具/unity命令行使用/index.html","modified":1446515490209,"shasum":"6e778bc62b81617d89ed20ca1b8f925c714f3fa3"},{"_id":"public/2015/07/05/Bug库/项目CheckList/index.html","modified":1446515490223,"shasum":"7f6292c4097e42d9b4259245ea72c5af1aaef43e"},{"_id":"public/2015/06/08/java基础/估算java对象大小/index.html","modified":1446515490238,"shasum":"9fedd2d4807fd146a36578e0842868faac267e53"},{"_id":"public/2015/06/08/java基础/java 泛型/index.html","modified":1446515490256,"shasum":"f1bb40f7e6cb4a3ff202c1583e54034056adef0f"},{"_id":"public/2015/06/08/工具/maven/index.html","modified":1446515490278,"shasum":"91f1cf28347194d70bd81d78d3d5fd7a1c170967"},{"_id":"public/2015/06/08/编程语言/windows rust/index.html","modified":1446515490300,"shasum":"224a8233457126df8894db3cbddaac137a1da93d"},{"_id":"public/2015/06/08/工具/docker命令/index.html","modified":1446515490331,"shasum":"9859cf14643e852bc7d974b47e8526cfcecb2193"},{"_id":"public/2015/05/08/工具/Flick Ticket Server/index.html","modified":1446515490353,"shasum":"bad68962fd980474192665ac72e8d9975293dea6"},{"_id":"public/2015/04/08/编程语言/haskell/index.html","modified":1446515490418,"shasum":"03ff5af2d56d0187b28df1bb4e4312816cfe2f38"},{"_id":"public/2015/04/08/工具/spring_boot/index.html","modified":1446515490453,"shasum":"d34ea63f54729ec79616a81668318dc494517ae5"},{"_id":"public/2015/04/08/工具/dropwizard/index.html","modified":1446515490492,"shasum":"03f2fac78f90681ec1ce4c0bd34c34db51a51ea1"},{"_id":"public/2015/03/08/java基础/java_hook/index.html","modified":1446515490525,"shasum":"bc25210a1b95620082b91c84009ea421894e9daf"},{"_id":"public/2015/03/08/工具/MongoDB/index.html","modified":1446515490594,"shasum":"78b9183ec8ff859a4d41bbb0dc6a184df348881d"},{"_id":"public/2014/12/08/java基础/java io/index.html","modified":1446515490677,"shasum":"6e9dad37d1dfcb84a3f55d6c86dab245e8e18009"},{"_id":"public/2014/11/08/java加密解密/非对称加密实现/index.html","modified":1446515490779,"shasum":"1a47039f55799720a4cfdd279bc0ceb773219141"},{"_id":"public/2014/11/08/java加密解密/辅助工具/index.html","modified":1446515490813,"shasum":"d040f626df76456a7109b6d0cc1f3372e282e686"},{"_id":"public/2014/11/08/java加密解密/消息摘要实现/index.html","modified":1446515490901,"shasum":"2e7f85d399350aa41e9a51ca596acacc011a677c"},{"_id":"public/2014/11/08/java加密解密/数字证书实现/index.html","modified":1446515490962,"shasum":"c03294160f3ba3a07f5697be2aaf50e793384379"},{"_id":"public/2014/11/08/java加密解密/对称加密/index.html","modified":1446515491045,"shasum":"e33ce17f7d2cb25b53358955fe7dccce710b42ce"},{"_id":"public/2014/11/08/java加密解密/Java加密/index.html","modified":1446515491065,"shasum":"7316ed845d6b898a46f76fc8aa60eab30f42d151"},{"_id":"public/2014/10/08/jvm7/垃圾收集/index.html","modified":1446515491090,"shasum":"788adc77d1fa806673aa18d73fa0fb02c97991f6"},{"_id":"public/2014/10/08/jvm7/内存分配以及内存溢出/index.html","modified":1446515491131,"shasum":"ced2c020acc66f6e903155c59c85c51128feec64"},{"_id":"public/2014/10/08/jvm7/oql/index.html","modified":1446515491150,"shasum":"12a075bea37bfb62a5e9d188e9ed7418cdc8c179"},{"_id":"public/2014/10/08/jvm7/java虚拟机结构/index.html","modified":1446515491175,"shasum":"8ec6572ee78d3ec1552e1aa5de92969078e5ea1b"},{"_id":"public/2014/10/08/jvm7/gc_log/index.html","modified":1446515491192,"shasum":"2a70bca8ab0ca6e13ccac0ebf04f26d65c38810b"},{"_id":"public/2014/10/08/jvm7/class文件格式/index.html","modified":1446515491225,"shasum":"c119c7d620607acefa9e872226b91544e065236d"},{"_id":"public/2014/10/08/jvm7/JVM工具以及日志分析/index.html","modified":1446515491252,"shasum":"836f58becb4764d7755043f75df7c2c18f5c37be"},{"_id":"public/2014/10/08/jvm7/JVM 参数/index.html","modified":1446515491273,"shasum":"27d03f2614ae88c9664507f880374ff45debb9c0"},{"_id":"public/2014/10/08/jvm7/类加载/index.html","modified":1446515491307,"shasum":"5c58d9bdfcd93fb0e54b889500c461d2eceee4a6"},{"_id":"public/2014/10/08/jvm7/字节码指令/index.html","modified":1446515491345,"shasum":"df5c4a896df28ea0e09bdf80bb06cf9fafa0dbaa"},{"_id":"public/2014/09/08/java基础/Java网络/index.html","modified":1446515491373,"shasum":"331cf521ae08c1ac20ca99cc7dfca3d99f630a79"},{"_id":"public/2014/09/08/工具/gitbook/index.html","modified":1446515491387,"shasum":"a570cd7516a52110cff255d78a72cf10eb5d4e32"},{"_id":"public/2014/06/08/java基础/java集合/index.html","modified":1446515491401,"shasum":"35aaf07416ff66c7ddc12dd73dc52271fb0e4f58"},{"_id":"public/2014/04/08/编程语言/groovy/index.html","modified":1446515491590,"shasum":"4b1249d6c530d46fc33fe59df87528d6436fab41"},{"_id":"public/2013/09/13/工具/CachesExplained/index.html","modified":1446515491637,"shasum":"8da0e1c7553f4a8bc6368f39f8c423c1cb066085"},{"_id":"public/2012/08/20/工具/svn服务器搭建/index.html","modified":1446515491651,"shasum":"c7945411dce269c48e391e3ef878e66d4c3bc44f"},{"_id":"public/categories/工具/page/2/index.html","modified":1446515491660,"shasum":"292f74ca4b989187bc01d5e3d7b0686e36b44587"},{"_id":"public/categories/Bug库/index.html","modified":1446515491665,"shasum":"dda4ab7d8d9c3b1a1edf81821ccaea31e9a03df0"},{"_id":"public/baidusitemap.xml","modified":1446515491667,"shasum":"be33a5b9412ac57a3c95932d6de62226b5f06ac0"},{"_id":"public/archives/index.html","modified":1446515491679,"shasum":"4621cf75ff8b8e66e16b74e8a9e46064d8e6609c"},{"_id":"public/archives/page/2/index.html","modified":1446515491695,"shasum":"bff58a6c4ee0095abe2c1a5f42d17e3f282c57aa"},{"_id":"public/archives/page/3/index.html","modified":1446515491705,"shasum":"303e98c670e2f51c2c1bbea5bc2e131cb3b0224e"},{"_id":"public/archives/page/4/index.html","modified":1446515491715,"shasum":"b311f87c408db570b5ce51458329eda90b897751"},{"_id":"public/archives/page/5/index.html","modified":1446515491725,"shasum":"fbd5c2814364454dfb9c9cfa14f01d14dcd8a435"},{"_id":"public/archives/page/6/index.html","modified":1446515491735,"shasum":"793e737d5d64d3367255941337cffd449e75a6b1"},{"_id":"public/archives/2012/index.html","modified":1446515491743,"shasum":"11594131d5a9bc2f50658c7ce054be9426a299b5"},{"_id":"public/archives/2012/08/index.html","modified":1446515491751,"shasum":"df1951c1de761986d09b2be748648b7460272b91"},{"_id":"public/archives/2013/index.html","modified":1446515491757,"shasum":"209fbe6ce3bd71da18e28df3dc34d093ca7c8567"},{"_id":"public/archives/2013/09/index.html","modified":1446515491763,"shasum":"daee31f744af6dcea9611b76418e56b736c318fa"},{"_id":"public/archives/2014/index.html","modified":1446515491773,"shasum":"6cd668167f10c38fd565a6531e09bf27fc948a14"},{"_id":"public/archives/2014/page/2/index.html","modified":1446515491809,"shasum":"794feb42ac498f83f455745391e5c3c42a79ad9c"},{"_id":"public/archives/2014/page/3/index.html","modified":1446515491817,"shasum":"173961171639e3e59165fa1fe307a2ff6141b4a1"},{"_id":"public/archives/2014/04/index.html","modified":1446515491827,"shasum":"8842351c9c6ee0169fe7cddbef8a73656bd1b7a2"},{"_id":"public/archives/2014/06/index.html","modified":1446515491834,"shasum":"f26a7fcbc3609b7d12f003f9ecc87ab13130e973"},{"_id":"public/archives/2014/09/index.html","modified":1446515491841,"shasum":"b550359b03c6925761984f42ca851918478da387"},{"_id":"public/archives/2014/10/index.html","modified":1446515491850,"shasum":"132ce17ea838a6f0ea86fb52c087baed8fd4ff6c"},{"_id":"public/archives/2014/11/index.html","modified":1446515491860,"shasum":"986113ee139de2e78bbbd133b6075fe14abfc00a"},{"_id":"public/archives/2014/12/index.html","modified":1446515491866,"shasum":"c91b1b763b688eb9e24f9319c13faadb38decabd"},{"_id":"public/archives/2015/index.html","modified":1446515491875,"shasum":"3cbcf5ae64a7a075dfba7ef48d3429af95218e28"},{"_id":"public/archives/2015/page/2/index.html","modified":1446515491885,"shasum":"f6c83e2cab37dbff5430181d520e53b19837da1c"},{"_id":"public/archives/2015/page/3/index.html","modified":1446515491894,"shasum":"58649bf4e35081b3bceb4ddccc037b98fcdc86a3"},{"_id":"public/archives/2015/page/4/index.html","modified":1446515491904,"shasum":"47157a4e2a37296bde365595207902baee349bb0"},{"_id":"public/archives/2015/03/index.html","modified":1446515491910,"shasum":"ca4e1f0eec22afd6a6e3fa107578449d17dc6248"},{"_id":"public/archives/2015/04/index.html","modified":1446515491917,"shasum":"5c28216c7ff31c940c254cdd0e2d173f6becf2f3"},{"_id":"public/archives/2015/05/index.html","modified":1446515491924,"shasum":"110cd5f759e70d6257f3354bc63dcadc664101f6"},{"_id":"public/archives/2015/06/index.html","modified":1446515491931,"shasum":"5263a2ca7cd117b398f48b6edcd2aa1b5d8e5efe"},{"_id":"public/archives/2015/07/index.html","modified":1446515491937,"shasum":"56a3bf9881cb1bef4bdf44abe91b8d82a9f19276"},{"_id":"public/archives/2015/08/index.html","modified":1446515491943,"shasum":"19d07080599fec0a8dbae2f535cba62e9935becd"},{"_id":"public/archives/2015/09/index.html","modified":1446515491953,"shasum":"e6fabfa79b9ebdbec060a4cc79f8e7296ef43329"},{"_id":"public/archives/2015/10/index.html","modified":1446515491963,"shasum":"493e10740bda02fbfbd45db4ed615d4eb4eac0a9"},{"_id":"public/archives/2015/10/page/2/index.html","modified":1446515491970,"shasum":"f0da063b923b8130f15014589a0cd4dbe61b5072"},{"_id":"public/index.html","modified":1446515491995,"shasum":"da50dbf8b40c6767859433b47a36e6131aeb1015"},{"_id":"public/page/2/index.html","modified":1446515492029,"shasum":"8bbc6ae96e06e327b95c7acacfc075859103c232"},{"_id":"public/page/3/index.html","modified":1446515492052,"shasum":"67be1d5174b215c5477dfbf569e2490414195dc2"},{"_id":"public/page/4/index.html","modified":1446515492079,"shasum":"85c5513de933e0918f1fbc840cdda155d0faa447"},{"_id":"public/page/5/index.html","modified":1446515492105,"shasum":"2584ca3b092d571beb5e806c8a888151bb7be6ab"},{"_id":"public/page/6/index.html","modified":1446515492133,"shasum":"0e727eeb39cad4664e74ce48e42731f4e1d8fe01"}],"Category":[{"name":"计算机基础","_id":"cigipyxqz000d0cufww9eeq0f"},{"name":"编程语言","_id":"cigipyxrd000o0cuf9ge6gf96"},{"name":"并发编程","_id":"cigipyxs000170cufe7o02999"},{"name":"工具","_id":"cigipyxs2001a0cuffx9nsurz"},{"name":"jvm7","_id":"cigipyxsy00290cufd2w26rwo"},{"name":"java基础","_id":"cigipyxtk002u0cuf4db0rui1"},{"name":"java加密解密","_id":"cigipyxtu00370cufx725ojkq"},{"name":"java8","_id":"cigipyxu4003k0cufp9aptpzn"},{"name":"Bug库","_id":"cigipyxuh003t0cufrmywi81h"}],"Data":[],"Page":[{"_content":"<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://www.gnim.wang\" homePageName=\"gnim.wang\"></script>","source":"404.html","raw":"<script type=\"text/javascript\" src=\"http://www.qq.com/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"http://www.gnim.wang\" homePageName=\"gnim.wang\"></script>","date":"2015-10-13T05:07:19.582Z","updated":"2015-10-13T03:58:02.099Z","path":"404.html","title":"","comments":1,"layout":"page","_id":"cigipyxq300000cuf0i6qczvw"},{"layout":"categories","title":"计算机基础","_content":"","source":"categories/计算机基础/index.md","raw":"layout: categories\ntitle: 计算机基础\n---","date":"2015-10-06T01:49:59.974Z","updated":"2015-10-06T01:48:58.477Z","path":"categories/计算机基础/index.html","comments":1,"_id":"cigipyxq800010cufz58u90yc"},{"layout":"categories","title":"编程语言","_content":"","source":"categories/编程语言/index.md","raw":"layout: categories\ntitle: 编程语言\n---\n","date":"2015-10-06T01:49:59.958Z","updated":"2015-10-06T01:48:33.687Z","path":"categories/编程语言/index.html","comments":1,"_id":"cigipyxq900020cufwlv5rwd9"},{"layout":"categories","title":"并发编程","_content":"","source":"categories/并发编程/index.md","raw":"layout: categories\ntitle:  并发编程\n---\n","date":"2015-10-16T02:45:33.110Z","updated":"2015-10-16T02:44:18.806Z","path":"categories/并发编程/index.html","comments":1,"_id":"cigipyxqa00030cuf5p8xulmm"},{"layout":"categories","title":"工具","_content":"","source":"categories/工具/index.md","raw":"layout: categories\ntitle: 工具\n---","date":"2015-10-06T09:57:30.015Z","updated":"2015-10-06T09:36:02.706Z","path":"categories/工具/index.html","comments":1,"_id":"cigipyxqb00040cufhfxdg9r7"},{"layout":"categories","title":"JVM7","_content":"","source":"categories/jvm7/index.md","raw":"layout: categories\ntitle: JVM7\n---\n","date":"2015-10-19T01:48:38.638Z","updated":"2015-10-19T01:46:50.181Z","path":"categories/jvm7/index.html","comments":1,"_id":"cigipyxqc00050cufwbagxt4h"},{"layout":"categories","title":"java","_content":"","source":"categories/java基础/index.md","raw":"layout: categories\ntitle: java\n---\n","date":"2015-10-16T02:45:33.109Z","updated":"2015-10-06T01:48:16.475Z","path":"categories/java基础/index.html","comments":1,"_id":"cigipyxqd00060cuf0sejni69"},{"layout":"categories","title":"java加密解密","_content":"","source":"categories/java加密解密/index.md","raw":"layout: categories\ntitle:  java加密解密\n---\n","date":"2015-10-16T02:45:33.108Z","updated":"2015-10-16T02:44:28.307Z","path":"categories/java加密解密/index.html","comments":1,"_id":"cigipyxqe00070cufllizp6hw"},{"layout":"tags","title":"java8","_content":"","source":"categories/java8/index.md","raw":"layout: tags\ntitle:  java8\n---\n","date":"2015-10-16T02:45:33.107Z","updated":"2015-10-06T01:49:22.995Z","path":"categories/java8/index.html","comments":1,"_id":"cigipyxqo00080cuf69b7u2e1"},{"layout":"categories","_content":"","source":"categories/index.md","raw":"layout: categories\n---\n","date":"2015-10-13T03:13:16.212Z","updated":"2015-10-13T03:02:18.561Z","path":"categories/index.html","title":"","comments":1,"_id":"cigipyxqq00090cuf6yetp7u5"},{"layout":"categories","title":"Bug库","_content":"","source":"categories/bug库/index.md","raw":"layout: categories\ntitle: Bug库\n---\n","date":"2015-10-16T02:45:33.106Z","updated":"2015-10-16T01:33:17.842Z","path":"categories/bug库/index.html","comments":1,"_id":"cigipyxqr000a0cuf0qj93j50"},{"title":"关于","_content":"","source":"about/index.md","raw":"title: 关于\n---\n","date":"2015-10-13T02:51:36.301Z","updated":"2015-10-12T10:54:10.767Z","path":"about/index.html","comments":1,"layout":"page","_id":"cigipyxqs000b0cufkbadnkcj"}],"Post":[{"date":"2015-09-07T16:00:00.000Z","title":"IO","_content":"# IO模型\n\n## IO概念\nlinux内核将内分分成内核区和用户区俩个区域：\n1. 用户区进程A向内核发起一个读文件的系统调用(进程A阻塞)\n2. linux在内核区生成一个文件句柄fd(该文件句柄指向了一个内核缓冲区)\n3. linux通过驱动程序向磁盘读取指定文件\n4. 驱动程序将读取到的数据存储在内核区的缓冲区内\n5. 当内核缓冲区的大小大于进程A设置的读取文件的大小时发生读就绪,内核缓冲区的数据刷新到用户区内\n\n## IO类型\n\n### 阻塞IO\n在进程空间中调用recvfrom,其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回,期间一直在等待.我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的.\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n这种情况下用户空间的进程不断地向内核空间轮询是否有数据到达,如果没有达到不进入阻塞(睡眠)而是直接返回一个错误.\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n这种操作效率是及其低下的,因为它把密集型IO操作变成了IO密集和计算密集的操作.\n\n### SIGIO\n首先开启套接口信号驱动I/O功能,并通过系统调用sigaction安装一个信号处理函数(此系统调用立即返回,进程继续工作,它是非阻塞的).当数据报准备好被读时,就为该进程生成一个SIGIO信号.随即可以在信号处理程序中调用recvfrom来读数据报,井通知主循环数据已准备好被处理中.也可以通知主循环,让它来读数据报.\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### IO复用\n在`select/poll`上注册多个`fd`, 然后`select/poll`顺序轮询所有的`fd`,如果轮询到某个`fd`读就绪或者写就绪就取出该`fd`进行读写数据,但是由于`select/poll`支持的`fd`数量有限而且是顺序扫描的,因此它的性能仍然会达不到要求. 于是`epoll`出现了,它是基于事件驱动方式,而不是顺序扫描,当有fd就绪时,立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n### windows的IOCP\n告知内核启动某个操作,并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们.这种模型与信号驱动模型的主要区别是：\n* 信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；\n* 异步I/O模型：由内核通知我们I/O操作何时完成.\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝.可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上,数据无需流经应用程序.本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销,然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能.\n\n\n### 传统方法数据传输\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换.在内部,发出 `sys_read()`(或等效内容)以从文件中读取数据.直接内存存取(`direct memory access`,DMA)引擎执行了第一次拷贝,它从磁盘中读取文件内容,然后将它们存储到一个内核地址空间缓存区中.\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区,read() 调用返回.该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换).现在数据被储存在用户地址空间缓冲区.\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换.数据被第三次拷贝,并被再次放置在内核地址空间缓冲区.但是这一次放置的缓冲区不同,该缓冲区与目标套接字相关联.\n4. `send()` 系统调用返回,结果导致了第四次的上下文切换.DMA 引擎将数据从内核缓冲区传到协议引擎,第四次拷贝独立地、异步地发生 .\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下.但是之所以引入中间内核缓冲区的目的是想提高性能.在读取方面使用中间内核缓冲区,可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时,充当 “预读高速缓存(readahead cache)” 的角色.这在所需数据量小于内核缓冲区大小时极大地提高了性能.在写入方面的中间缓冲区则可以让写入过程异步完成.\n\n不幸的是,如果所需数据量远大于内核缓冲区大小的话,这个方法本身可能成为一个性能瓶颈.数据在被最终传入到应用程序前,在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次.零拷贝通过消除这些冗余的数据拷贝而提高了性能.\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区.然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区.\n\n2. 数据的第三次复制发生在DMA引擎将数据从内核套接字缓冲区传到协议引擎时.改进的地方：我们将上下文切换的次数从四次减少到了两次,将数据复制的次数从四次减少到了三次(其中只有一次涉及到了CPU).但是这个代码尚未达到我们的零拷贝要求.如果底层网络接口卡支持收集操作的话,那么我们就可以进一步减少内核的数据复制.在Linux内核2.4及后期版本中,套接字缓冲区描述符就做了相应调整,以满足该需求.这种方法不仅可以减少多个上下文切换,还可以消除需要涉及CPU的重复的数据拷贝.对于用户方面,用法还是一样的,但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区.\nB. 数据未被拷贝到套接字缓冲区.取而代之的是,只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区.DMA 引擎直接把数据从内核缓冲区传输到协议引擎,从而消除了剩下的最后一次 CPU 拷贝.\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n\n\n## IO性能\n性能度量的几个指标\n\nLinux中怎么查看这几个指标\n\n结合当前主流的服务器的IO性能，给出Linux中磁盘达到瓶颈时的IO性能阀值（80%的极限性能）\n\n全SSD硬盘的IO阀值\n\n1万转机械磁盘的IO阀值","source":"_posts/计算机基础/io.md","raw":"category: 计算机基础\ndate: 2015-09-08\ntitle: IO\n---\n# IO模型\n\n## IO概念\nlinux内核将内分分成内核区和用户区俩个区域：\n1. 用户区进程A向内核发起一个读文件的系统调用(进程A阻塞)\n2. linux在内核区生成一个文件句柄fd(该文件句柄指向了一个内核缓冲区)\n3. linux通过驱动程序向磁盘读取指定文件\n4. 驱动程序将读取到的数据存储在内核区的缓冲区内\n5. 当内核缓冲区的大小大于进程A设置的读取文件的大小时发生读就绪,内核缓冲区的数据刷新到用户区内\n\n## IO类型\n\n### 阻塞IO\n在进程空间中调用recvfrom,其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回,期间一直在等待.我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的.\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n这种情况下用户空间的进程不断地向内核空间轮询是否有数据到达,如果没有达到不进入阻塞(睡眠)而是直接返回一个错误.\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n这种操作效率是及其低下的,因为它把密集型IO操作变成了IO密集和计算密集的操作.\n\n### SIGIO\n首先开启套接口信号驱动I/O功能,并通过系统调用sigaction安装一个信号处理函数(此系统调用立即返回,进程继续工作,它是非阻塞的).当数据报准备好被读时,就为该进程生成一个SIGIO信号.随即可以在信号处理程序中调用recvfrom来读数据报,井通知主循环数据已准备好被处理中.也可以通知主循环,让它来读数据报.\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### IO复用\n在`select/poll`上注册多个`fd`, 然后`select/poll`顺序轮询所有的`fd`,如果轮询到某个`fd`读就绪或者写就绪就取出该`fd`进行读写数据,但是由于`select/poll`支持的`fd`数量有限而且是顺序扫描的,因此它的性能仍然会达不到要求. 于是`epoll`出现了,它是基于事件驱动方式,而不是顺序扫描,当有fd就绪时,立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n### windows的IOCP\n告知内核启动某个操作,并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们.这种模型与信号驱动模型的主要区别是：\n* 信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；\n* 异步I/O模型：由内核通知我们I/O操作何时完成.\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝.可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上,数据无需流经应用程序.本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销,然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能.\n\n\n### 传统方法数据传输\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换.在内部,发出 `sys_read()`(或等效内容)以从文件中读取数据.直接内存存取(`direct memory access`,DMA)引擎执行了第一次拷贝,它从磁盘中读取文件内容,然后将它们存储到一个内核地址空间缓存区中.\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区,read() 调用返回.该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换).现在数据被储存在用户地址空间缓冲区.\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换.数据被第三次拷贝,并被再次放置在内核地址空间缓冲区.但是这一次放置的缓冲区不同,该缓冲区与目标套接字相关联.\n4. `send()` 系统调用返回,结果导致了第四次的上下文切换.DMA 引擎将数据从内核缓冲区传到协议引擎,第四次拷贝独立地、异步地发生 .\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下.但是之所以引入中间内核缓冲区的目的是想提高性能.在读取方面使用中间内核缓冲区,可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时,充当 “预读高速缓存(readahead cache)” 的角色.这在所需数据量小于内核缓冲区大小时极大地提高了性能.在写入方面的中间缓冲区则可以让写入过程异步完成.\n\n不幸的是,如果所需数据量远大于内核缓冲区大小的话,这个方法本身可能成为一个性能瓶颈.数据在被最终传入到应用程序前,在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次.零拷贝通过消除这些冗余的数据拷贝而提高了性能.\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区.然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区.\n\n2. 数据的第三次复制发生在DMA引擎将数据从内核套接字缓冲区传到协议引擎时.改进的地方：我们将上下文切换的次数从四次减少到了两次,将数据复制的次数从四次减少到了三次(其中只有一次涉及到了CPU).但是这个代码尚未达到我们的零拷贝要求.如果底层网络接口卡支持收集操作的话,那么我们就可以进一步减少内核的数据复制.在Linux内核2.4及后期版本中,套接字缓冲区描述符就做了相应调整,以满足该需求.这种方法不仅可以减少多个上下文切换,还可以消除需要涉及CPU的重复的数据拷贝.对于用户方面,用法还是一样的,但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区.\nB. 数据未被拷贝到套接字缓冲区.取而代之的是,只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区.DMA 引擎直接把数据从内核缓冲区传输到协议引擎,从而消除了剩下的最后一次 CPU 拷贝.\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n\n\n## IO性能\n性能度量的几个指标\n\nLinux中怎么查看这几个指标\n\n结合当前主流的服务器的IO性能，给出Linux中磁盘达到瓶颈时的IO性能阀值（80%的极限性能）\n\n全SSD硬盘的IO阀值\n\n1万转机械磁盘的IO阀值","slug":"计算机基础/io","published":1,"updated":"2015-10-26T10:19:58.873Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxqw000c0cuff6m35hsx"},{"date":"2015-09-07T16:00:00.000Z","title":"HTTP","_content":"# HTTP报文\n用于HTTP协议交互的信息称为HTTP报文. HTTP报文一般被空行(`CR+LF`)分割成报文首部和报文主体俩部分.\n\n## 请求报文\n* 请求行\t\n* 请求首部字段\n* 通用首部字段\n* 实体首部字段\n\n\n## 响应报文\n* 响应行\t\n* 响应首部字段\n* 通用首部字段\n* 实体首部字段\n\n## HTTP状态码\n\n### 2XX\n\n* 200 ok\n* 204 No Content. \n* ","source":"_posts/计算机基础/http.md","raw":"category: 计算机基础\ndate: 2015-09-08\ntitle: HTTP\n---\n# HTTP报文\n用于HTTP协议交互的信息称为HTTP报文. HTTP报文一般被空行(`CR+LF`)分割成报文首部和报文主体俩部分.\n\n## 请求报文\n* 请求行\t\n* 请求首部字段\n* 通用首部字段\n* 实体首部字段\n\n\n## 响应报文\n* 响应行\t\n* 响应首部字段\n* 通用首部字段\n* 实体首部字段\n\n## HTTP状态码\n\n### 2XX\n\n* 200 ok\n* 204 No Content. \n* ","slug":"计算机基础/http","published":1,"updated":"2015-10-14T01:55:20.629Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxr2000f0cuf34qrtk9q"},{"date":"2015-09-07T16:00:00.000Z","title":"TCP","_content":"\n# 连接管理\n\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/net/TCP_STATE2.jpg)\n## 三次握手\n* 第一次握手：建立连接时，客户端首先向服务端发送一个 SYN 包和一个随机序列号 A，客户端进入SYN_SENT状态，等待服务器确认；\n* 第二次握手：服务端收到后会回复客户端一个 SYN-ACK 包以及一个确认号（用于确认收到 SYN）A+1，同时再发送一个随机序列号 B，此时服务器进入SYN_RECV状态；\n* 第三次握手：客户端收到后会发送一个 ACK 包以及确认号（用于确认收到 SYN-ACK）B+1 和序列号 A+1 给服务端，此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。\n\n## 四次挥手\n1. 客户端执行`CLOSE`主动关闭,向服务器发送`FIN`数据报. 客户端进入`FIN WAIT1`状态\n2. 服务器收到客户端发送过来的`FIN`数据包执行被动关闭,同时向客户端响应`ACK`数据包,服务器进入`CLOSE WAIT`状态. 客户端收到服务端发送过来的`ACK`包后, 客户端进入`FIN WAIT2`状态.\n3. 紧接着服务器再发送一个`ACK`包,服务器进入`LAST ACK`状态. 服务器端就关闭了.\n4. 客户端收到`ACK`包后进入`TIME_WAIT`状态. 当客户端超时后也就执行关闭了.\n\n\n\nTCP端口状态：\n1. LISTENING状态: FTP服务启动后首先处于侦听（LISTENING）状态。\n2. ESTABLISHED状态: ESTABLISHED的意思是建立连接。表示两台机器正在通信。\n3. CLOSE_WAIT: 对方主动关闭连接或者网络异常导致连接中断，这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭\n4. TIME_WAIT: 我方主动调用close()断开连接，收到对方确认后状态变为TIME_WAIT。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期)，以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放，所以作为服务器，在可能的情况下，尽量不要主动断开连接，以减少TIME_WAIT状态造成的资源浪费。目前有一种避免TIME_WAIT资源浪费的方法，就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的，在某些情况下这个操作可能会带来错误。\n5. SYN_SENT状态:SYN_SENT状态表示请求连接，当你要访问其它的计算机的服务时首先要发个同步信号给该端口，此时状态为SYN_SENT，如果连接成功了就变为ESTABLISHED，此时SYN_SENT状态非常短暂。但如果发现SYN_SENT非常多且在向不同的机器发出，那你的机器可能中了冲击波或震荡波之类的病毒了。这类病毒为了感染别的计算机，它就要扫描别的计算机，在扫描的过程中对每个要扫描的计算机都要发出了同步请求，这也是出现许多SYN_SENT的原因。\n\n\n","source":"_posts/计算机基础/TCP.md","raw":"category: 计算机基础\ndate: 2015-09-08\ntitle: TCP\n---\n\n# 连接管理\n\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/net/TCP_STATE2.jpg)\n## 三次握手\n* 第一次握手：建立连接时，客户端首先向服务端发送一个 SYN 包和一个随机序列号 A，客户端进入SYN_SENT状态，等待服务器确认；\n* 第二次握手：服务端收到后会回复客户端一个 SYN-ACK 包以及一个确认号（用于确认收到 SYN）A+1，同时再发送一个随机序列号 B，此时服务器进入SYN_RECV状态；\n* 第三次握手：客户端收到后会发送一个 ACK 包以及确认号（用于确认收到 SYN-ACK）B+1 和序列号 A+1 给服务端，此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。\n\n## 四次挥手\n1. 客户端执行`CLOSE`主动关闭,向服务器发送`FIN`数据报. 客户端进入`FIN WAIT1`状态\n2. 服务器收到客户端发送过来的`FIN`数据包执行被动关闭,同时向客户端响应`ACK`数据包,服务器进入`CLOSE WAIT`状态. 客户端收到服务端发送过来的`ACK`包后, 客户端进入`FIN WAIT2`状态.\n3. 紧接着服务器再发送一个`ACK`包,服务器进入`LAST ACK`状态. 服务器端就关闭了.\n4. 客户端收到`ACK`包后进入`TIME_WAIT`状态. 当客户端超时后也就执行关闭了.\n\n\n\nTCP端口状态：\n1. LISTENING状态: FTP服务启动后首先处于侦听（LISTENING）状态。\n2. ESTABLISHED状态: ESTABLISHED的意思是建立连接。表示两台机器正在通信。\n3. CLOSE_WAIT: 对方主动关闭连接或者网络异常导致连接中断，这时我方的状态会变成CLOSE_WAIT 此时我方要调用close()来使得连接正确关闭\n4. TIME_WAIT: 我方主动调用close()断开连接，收到对方确认后状态变为TIME_WAIT。TCP协议规定TIME_WAIT状态会一直持续2MSL(即两倍的分段最大生存期)，以此来确保旧的连接状态不会对新连接产生影响。处于TIME_WAIT状态的连接占用的资源不会被内核释放，所以作为服务器，在可能的情况下，尽量不要主动断开连接，以减少TIME_WAIT状态造成的资源浪费。目前有一种避免TIME_WAIT资源浪费的方法，就是关闭socket的LINGER选项。但这种做法是TCP协议不推荐使用的，在某些情况下这个操作可能会带来错误。\n5. SYN_SENT状态:SYN_SENT状态表示请求连接，当你要访问其它的计算机的服务时首先要发个同步信号给该端口，此时状态为SYN_SENT，如果连接成功了就变为ESTABLISHED，此时SYN_SENT状态非常短暂。但如果发现SYN_SENT非常多且在向不同的机器发出，那你的机器可能中了冲击波或震荡波之类的病毒了。这类病毒为了感染别的计算机，它就要扫描别的计算机，在扫描的过程中对每个要扫描的计算机都要发出了同步请求，这也是出现许多SYN_SENT的原因。\n\n\n","slug":"计算机基础/TCP","published":1,"updated":"2015-10-20T01:47:00.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxr6000h0cufpocz8tcp"},{"date":"2015-10-25T16:00:00.000Z","title":"NUMA和RDMA","_content":"\n## 支持NUMA的CPU\n\n英特尔系列的\n* Nehalem和Tukwila系列之后的处理器\n* Xeon\n* 至强处理器 E5-2690 \n* i3、i5、i7\n\nHP系列的\n* Superdome\n* SGI的Altix 3000\n \nIBM的\n* p690\n* x440\n \nNEC\n* TX7\n\nAMD\n* Opteron\n\n\n## Linux中关于NUMA的命令\n* NUMACTL ：设定进程NUMA策略的命令行工具。\n* NUMASTAT ：获取NUMA内存访问统计信息的命令行工具\n\n开启NUMA\n```\nnumactl --cpunodebind=0 --membind=0 myapp\n```\n\n\n# JAVA中的NUMA\n`-XX:+UseNUMA`启用Numa, 默认情况下,JVM所占内存会随机的分配到不同的NUMA节点上,当cpu运算时可能会到不同的NUMA节点的告诉缓存上进行数据查找,降低系统速度,可使用numactl工具将JVM进程绑定到特定的NUMA节点上,只让其访问自己所在节点的内存.\n\n# NUMA用于MySQL\n调优的时候，有哪些关键配置项，需要注意什么\n\n* `numactl --interleave=all`\n* 在MySQL进程启动前，使用`sysctl -q -w vm.drop_caches=3`清空文件缓存所占用的空间\n* Innodb在启动时，就完成整个`Innodb_buffer_pool_size`的内存分配\n\n# RDMA\nRDMA 技术需要怎样的硬件，寻找一篇RDMA用于数据库或者Java的文章，对其性能和用法做简单的阐述。\n\nRDMA是一种网卡技术,采用该技术可以使一台计算机直接将信息放入另一台计算机的内存中。RDMA通过在网卡上将可靠传输协议固化于硬件,以及支持绕过内核的零拷贝网络这两种途径来达到这一目标。绕过内核使应用程序不必执行内核调用就可以向网卡发出命令。当一个应用程序执行RDMA读/写请求时,系统并不执行数据拷贝动作。这就减少了处理 网络通信时在内核空间和用户空间上下文切换的次数。RDMA请求的完成,或者完全在用户空间中进行,或者在应用程序希望进入睡眠直到完成信号出现的情况下 通过内核进行。\n\nRDMA实现：\n* 利用传统的网络硬件,以TCP/IP及以太网络标准来建立因特网\n* InfiniBand网络和实现虚拟接口架构的网络支持RDMA.\n\n采用RDMA来获取高性能的协议包括\n* Sockets Direct Protocol\n* SCSI RDMA Protocol（SRP）\n* Direct Access File System（DAFS）\n\n## Java 7 SDP\n在Solaris系统上只要有物理InfiniBand网卡，Java 7 SDP就可以立即工作。\n\nLinux则通过Open Fabrics Enterprise Distribution（OFED）包支持SDP。\n> 确认Linux版本有没有配置OFED设备驱动器，`egrep \"^[ \\t]+ib\" /proc/net/dev`可以使用该命令测试.\n\nJava只通过`java.net.Socket、java.net.ServerSocket、java.net.Datagram`对传输层进行抽象,通过`Java.net.InetAddress`对网络层进行抽象.只需要将JVM和InfiniBand操作系统设备和库进行设定,java就可以通过传输层抽象直接与物理层进行访问,从而绕过了网络层和数据链路层.\n\nSDP也能让Java具备非常强大的“零拷贝”,这个零拷贝并不是指的是`java.nio.channels.FileChannel`的`transferTo()`实现的零拷贝.而是直接使用原生的InfiniBand零拷贝协议实现。现在CPU不用将一个内存区域的数据拷贝到另一个内存区域。CPU可以继续处理其他任务，数据拷贝则由机器的另一部分并行处理，这样就提升了性能。此外，零拷贝操作减少了在用户空间和内核空间之间切换所消耗的时间。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/net/javasdp.jpg)\n\n### 配置JVM7支持SDP\nSDP配置文件是个文本文件，JVM启动时会从本地文件系统读取该文件。我们有俩种规则来定义：\n1. bind规则：只要TCP套接字绑定到与规则匹配的地址和端口，就会使用SDP协议进行传输。\n2. connect规则：没有绑定的TCP套接字尝试连接匹配规则的地址和端口时，就会使用SDP协议进行传输。\n第一个关键字用来表明规则是bind还是connect。第二部分指定主机名或IP地址。当指定为IP地址时，你也可以指定表示IP地址范围的前缀。第三部分即最后一个部分是端口号或端口号范围。\n```\n# 绑定到192.168.1.196主机所有端口使用SDP\nbind 192.168.1.196 *\n\n# 连接到192.168.2.*上的所有应用服务时都使用SDP\nconnect 192.168.2.0/24 1024-*\n```\n### 使用SDP的JVM7\n```\njava \\\n-Dcom.sun.sdp.conf=sdp.conf \\\n-Djava.net.preferIPv4Stack=true \\\nApplication.class\n```\n> 注意要指定网络格式为`IPv4Stack`。尽管Java 7和InfiniBand都支持IPv6网络格式，但Solaris和Linux都不支持两者之间的映射。所以启动支持SDP的Java 7 VM时，还是要使用基础、可靠的IPv4网络格式。\n\n## IO性能度量\niostat用于输出CPU和磁盘I/O相关的统计信息. \n\n* `-c` 仅显示CPU统计信息.与-d选项互斥.\n* `-d` 仅显示磁盘统计信息.与-c选项互斥.\n* `-k` 以K为单位显示每秒的磁盘请求数,默认单位块.\n* `-p device | ALL`  与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:`iostat -p hda` 或显示所有设备`iostat -p ALL`\n* `-t`    在输出数据时,打印搜集数据的时间.\n* `-V`    打印版本号和帮助信息.\n* `-x`    输出扩展信息.\n* \n```\n[root@cvs /]# iostat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月16日  _x86_64_        (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.67    0.00    0.21    0.38    0.00   97.74\n\nDevice:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\nsda              18.64        72.79       512.65  951732770 6702726216\n```\navg-cpu:  \n* `%user`: 在用户级别运行所使用的CPU的百分比.\n* `%nice`: nice操作所使用的CPU的百分比.\n* `%system`: 在系统级别(kernel)运行所使用CPU的百分比.\n* `%iowait`: CPU等待硬件I/O时,所占用CPU百分比.\n* `%steal`: \n* `%idle`: CPU空闲时间的百分比.\n           \n\nDevice:            \n* `tps`: 每秒钟发送到的I/O请求数.\n* `Blk_read/s`: 每秒读取的block数.\n* `Blk_wrtn/s`: 每秒写入的block数.\n* `Blk_read`: 读入的block总数.\n* `Blk_wrtn`: 写入的block总数.\n\n\n* `Blk_read` 读入块的当总数.\n* `Blk_wrtn` 写入块的总数.\n* `kB_read/s` 每秒从驱动器读入的数据量,单位为K.\n* `kB_wrtn/s` 每秒向驱动器写入的数据量,单位为K.\n* `kB_read` 读入的数据总量,单位为K.\n* `kB_wrtn` 写入的数据总量,单位为K.\n* `rrqm/s`  将读入请求合并后,每秒发送到设备的读入请求数.\n* `wrqm/s`  将写入请求合并后,每秒发送到设备的写入请求数.\n* `r/s`     每秒发送到设备的读入请求数.\n* `w/s`     每秒发送到设备的写入请求数.\n* `rsec/s`  每秒从设备读入的扇区数.\n* `wsec/s`  每秒向设备写入的扇区数.\n* `rkB/s`  每秒从设备读入的数据量,单位为K.\n* `wkB/s`  每秒向设备写入的数据量,单位为K.\n* `avgrq-sz`  发送到设备的请求的平均大小,单位是扇区.\n* `avgqu-sz` 发送到设备的请求的平均队列长度.\n* `await`  I/O请求平均执行时间.包括发送请求和执行的时间.单位是毫秒.\n* `svctm` 发送到设备的I/O请求的平均执行时间.单位是毫秒.\n* `%util`  在I/O请求发送到设备期间,占用CPU时间的百分比.用于显示设备的带宽利用率.当这个值接近100%时,表示设备带宽已经占满.\n\n### 全SSD硬盘的IO阀值\nSSD 硬盘传输速率取 500M/S\n```\n0.1ms + 0 + 4K/500MB = 0.1 + 0 + 0.008 = 0.108\n\nIOPS = 1/0.108 ms = 9259 IOPS\n```\n吞吐率 = `9259 * 4K = 37M / 500M = 7.4%`\n\n\n### 1万转机械磁盘的IO阀值\n1 万转机械磁盘传输速率取 200M/S\n```\n5ms + (60sec/10000RPM/2) + 4K/200MB = 5 + 3 + 0.02 = 8.02 IOPS = 1/8.02s ms = 125 IOPS\n```\n吞吐率 = `125 * 4K = 500K / 200M = 0.25%`","source":"_posts/计算机基础/NUMA.md","raw":"category: 计算机基础\ndate: 2015-10-26\ntitle: NUMA和RDMA \n---\n\n## 支持NUMA的CPU\n\n英特尔系列的\n* Nehalem和Tukwila系列之后的处理器\n* Xeon\n* 至强处理器 E5-2690 \n* i3、i5、i7\n\nHP系列的\n* Superdome\n* SGI的Altix 3000\n \nIBM的\n* p690\n* x440\n \nNEC\n* TX7\n\nAMD\n* Opteron\n\n\n## Linux中关于NUMA的命令\n* NUMACTL ：设定进程NUMA策略的命令行工具。\n* NUMASTAT ：获取NUMA内存访问统计信息的命令行工具\n\n开启NUMA\n```\nnumactl --cpunodebind=0 --membind=0 myapp\n```\n\n\n# JAVA中的NUMA\n`-XX:+UseNUMA`启用Numa, 默认情况下,JVM所占内存会随机的分配到不同的NUMA节点上,当cpu运算时可能会到不同的NUMA节点的告诉缓存上进行数据查找,降低系统速度,可使用numactl工具将JVM进程绑定到特定的NUMA节点上,只让其访问自己所在节点的内存.\n\n# NUMA用于MySQL\n调优的时候，有哪些关键配置项，需要注意什么\n\n* `numactl --interleave=all`\n* 在MySQL进程启动前，使用`sysctl -q -w vm.drop_caches=3`清空文件缓存所占用的空间\n* Innodb在启动时，就完成整个`Innodb_buffer_pool_size`的内存分配\n\n# RDMA\nRDMA 技术需要怎样的硬件，寻找一篇RDMA用于数据库或者Java的文章，对其性能和用法做简单的阐述。\n\nRDMA是一种网卡技术,采用该技术可以使一台计算机直接将信息放入另一台计算机的内存中。RDMA通过在网卡上将可靠传输协议固化于硬件,以及支持绕过内核的零拷贝网络这两种途径来达到这一目标。绕过内核使应用程序不必执行内核调用就可以向网卡发出命令。当一个应用程序执行RDMA读/写请求时,系统并不执行数据拷贝动作。这就减少了处理 网络通信时在内核空间和用户空间上下文切换的次数。RDMA请求的完成,或者完全在用户空间中进行,或者在应用程序希望进入睡眠直到完成信号出现的情况下 通过内核进行。\n\nRDMA实现：\n* 利用传统的网络硬件,以TCP/IP及以太网络标准来建立因特网\n* InfiniBand网络和实现虚拟接口架构的网络支持RDMA.\n\n采用RDMA来获取高性能的协议包括\n* Sockets Direct Protocol\n* SCSI RDMA Protocol（SRP）\n* Direct Access File System（DAFS）\n\n## Java 7 SDP\n在Solaris系统上只要有物理InfiniBand网卡，Java 7 SDP就可以立即工作。\n\nLinux则通过Open Fabrics Enterprise Distribution（OFED）包支持SDP。\n> 确认Linux版本有没有配置OFED设备驱动器，`egrep \"^[ \\t]+ib\" /proc/net/dev`可以使用该命令测试.\n\nJava只通过`java.net.Socket、java.net.ServerSocket、java.net.Datagram`对传输层进行抽象,通过`Java.net.InetAddress`对网络层进行抽象.只需要将JVM和InfiniBand操作系统设备和库进行设定,java就可以通过传输层抽象直接与物理层进行访问,从而绕过了网络层和数据链路层.\n\nSDP也能让Java具备非常强大的“零拷贝”,这个零拷贝并不是指的是`java.nio.channels.FileChannel`的`transferTo()`实现的零拷贝.而是直接使用原生的InfiniBand零拷贝协议实现。现在CPU不用将一个内存区域的数据拷贝到另一个内存区域。CPU可以继续处理其他任务，数据拷贝则由机器的另一部分并行处理，这样就提升了性能。此外，零拷贝操作减少了在用户空间和内核空间之间切换所消耗的时间。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/net/javasdp.jpg)\n\n### 配置JVM7支持SDP\nSDP配置文件是个文本文件，JVM启动时会从本地文件系统读取该文件。我们有俩种规则来定义：\n1. bind规则：只要TCP套接字绑定到与规则匹配的地址和端口，就会使用SDP协议进行传输。\n2. connect规则：没有绑定的TCP套接字尝试连接匹配规则的地址和端口时，就会使用SDP协议进行传输。\n第一个关键字用来表明规则是bind还是connect。第二部分指定主机名或IP地址。当指定为IP地址时，你也可以指定表示IP地址范围的前缀。第三部分即最后一个部分是端口号或端口号范围。\n```\n# 绑定到192.168.1.196主机所有端口使用SDP\nbind 192.168.1.196 *\n\n# 连接到192.168.2.*上的所有应用服务时都使用SDP\nconnect 192.168.2.0/24 1024-*\n```\n### 使用SDP的JVM7\n```\njava \\\n-Dcom.sun.sdp.conf=sdp.conf \\\n-Djava.net.preferIPv4Stack=true \\\nApplication.class\n```\n> 注意要指定网络格式为`IPv4Stack`。尽管Java 7和InfiniBand都支持IPv6网络格式，但Solaris和Linux都不支持两者之间的映射。所以启动支持SDP的Java 7 VM时，还是要使用基础、可靠的IPv4网络格式。\n\n## IO性能度量\niostat用于输出CPU和磁盘I/O相关的统计信息. \n\n* `-c` 仅显示CPU统计信息.与-d选项互斥.\n* `-d` 仅显示磁盘统计信息.与-c选项互斥.\n* `-k` 以K为单位显示每秒的磁盘请求数,默认单位块.\n* `-p device | ALL`  与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:`iostat -p hda` 或显示所有设备`iostat -p ALL`\n* `-t`    在输出数据时,打印搜集数据的时间.\n* `-V`    打印版本号和帮助信息.\n* `-x`    输出扩展信息.\n* \n```\n[root@cvs /]# iostat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月16日  _x86_64_        (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.67    0.00    0.21    0.38    0.00   97.74\n\nDevice:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\nsda              18.64        72.79       512.65  951732770 6702726216\n```\navg-cpu:  \n* `%user`: 在用户级别运行所使用的CPU的百分比.\n* `%nice`: nice操作所使用的CPU的百分比.\n* `%system`: 在系统级别(kernel)运行所使用CPU的百分比.\n* `%iowait`: CPU等待硬件I/O时,所占用CPU百分比.\n* `%steal`: \n* `%idle`: CPU空闲时间的百分比.\n           \n\nDevice:            \n* `tps`: 每秒钟发送到的I/O请求数.\n* `Blk_read/s`: 每秒读取的block数.\n* `Blk_wrtn/s`: 每秒写入的block数.\n* `Blk_read`: 读入的block总数.\n* `Blk_wrtn`: 写入的block总数.\n\n\n* `Blk_read` 读入块的当总数.\n* `Blk_wrtn` 写入块的总数.\n* `kB_read/s` 每秒从驱动器读入的数据量,单位为K.\n* `kB_wrtn/s` 每秒向驱动器写入的数据量,单位为K.\n* `kB_read` 读入的数据总量,单位为K.\n* `kB_wrtn` 写入的数据总量,单位为K.\n* `rrqm/s`  将读入请求合并后,每秒发送到设备的读入请求数.\n* `wrqm/s`  将写入请求合并后,每秒发送到设备的写入请求数.\n* `r/s`     每秒发送到设备的读入请求数.\n* `w/s`     每秒发送到设备的写入请求数.\n* `rsec/s`  每秒从设备读入的扇区数.\n* `wsec/s`  每秒向设备写入的扇区数.\n* `rkB/s`  每秒从设备读入的数据量,单位为K.\n* `wkB/s`  每秒向设备写入的数据量,单位为K.\n* `avgrq-sz`  发送到设备的请求的平均大小,单位是扇区.\n* `avgqu-sz` 发送到设备的请求的平均队列长度.\n* `await`  I/O请求平均执行时间.包括发送请求和执行的时间.单位是毫秒.\n* `svctm` 发送到设备的I/O请求的平均执行时间.单位是毫秒.\n* `%util`  在I/O请求发送到设备期间,占用CPU时间的百分比.用于显示设备的带宽利用率.当这个值接近100%时,表示设备带宽已经占满.\n\n### 全SSD硬盘的IO阀值\nSSD 硬盘传输速率取 500M/S\n```\n0.1ms + 0 + 4K/500MB = 0.1 + 0 + 0.008 = 0.108\n\nIOPS = 1/0.108 ms = 9259 IOPS\n```\n吞吐率 = `9259 * 4K = 37M / 500M = 7.4%`\n\n\n### 1万转机械磁盘的IO阀值\n1 万转机械磁盘传输速率取 200M/S\n```\n5ms + (60sec/10000RPM/2) + 4K/200MB = 5 + 3 + 0.02 = 8.02 IOPS = 1/8.02s ms = 125 IOPS\n```\n吞吐率 = `125 * 4K = 500K / 200M = 0.25%`","slug":"计算机基础/NUMA","published":1,"updated":"2015-11-03T01:50:12.937Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxr9000j0cuf6h9w6wxz"},{"date":"2015-10-07T16:00:00.000Z","title":"数据链路层","_content":"## 概念\n\n物理层负责将实际设备过程中的电压的高低,光的闪灭,电波的强弱新号等与二进制0,1进行转换. 而数据链路层则负责将0,1数据集合成帧块后进行传输.\n\n### 数据链路段\n数据链路段是指一个被分割的网络.\n\n### 网络拓扑\n网络的连接与构成的形态被称为网络拓扑\n* [总线型]()\n* [环形]()\n* [星形]()\n* [混合型]()\n\n## MAC地址\nMAC地址用于识别数据链路中的互联的节点. 不论哪种数据链路的网络(以太网,FDDI,ATM,无线LAN),他们彼此的MAC地址都是唯一的.\n\nMAC地址总长46位,一般用16进制表示.\n* 第一位:单播地址(0)/多播地址(1)\n* 第2位: 全局地址(0)/本地地址(1)\n* 第3-24位:由IEEE管理并保证各厂家不重复\n* 第25-48位:由厂商管理并保证产品之间不重复\n\n## 共享介质型网络\n共享介质型网络是指多个设备共享一个通信介质的网络.在这种方式下多个设备使用同一个载波信道进行发送和接受,基本上采用半双工通信.\n\n* 半双工: 在数据链路上同时只发送或者只接受的通信方式\n* 全双工: 在数据链路上同时即可以发送也可以接受数据的通信方式\n\n### 争用方式\n\n\n### 令牌传递方式\n\n## 非共享介质网络\n\n\n\n","source":"_posts/计算机基础/2015-10-19-数据链路层.md","raw":"category: 计算机基础\ndate: 2015-10-08\ntitle: 数据链路层\n---\n## 概念\n\n物理层负责将实际设备过程中的电压的高低,光的闪灭,电波的强弱新号等与二进制0,1进行转换. 而数据链路层则负责将0,1数据集合成帧块后进行传输.\n\n### 数据链路段\n数据链路段是指一个被分割的网络.\n\n### 网络拓扑\n网络的连接与构成的形态被称为网络拓扑\n* [总线型]()\n* [环形]()\n* [星形]()\n* [混合型]()\n\n## MAC地址\nMAC地址用于识别数据链路中的互联的节点. 不论哪种数据链路的网络(以太网,FDDI,ATM,无线LAN),他们彼此的MAC地址都是唯一的.\n\nMAC地址总长46位,一般用16进制表示.\n* 第一位:单播地址(0)/多播地址(1)\n* 第2位: 全局地址(0)/本地地址(1)\n* 第3-24位:由IEEE管理并保证各厂家不重复\n* 第25-48位:由厂商管理并保证产品之间不重复\n\n## 共享介质型网络\n共享介质型网络是指多个设备共享一个通信介质的网络.在这种方式下多个设备使用同一个载波信道进行发送和接受,基本上采用半双工通信.\n\n* 半双工: 在数据链路上同时只发送或者只接受的通信方式\n* 全双工: 在数据链路上同时即可以发送也可以接受数据的通信方式\n\n### 争用方式\n\n\n### 令牌传递方式\n\n## 非共享介质网络\n\n\n\n","slug":"计算机基础/2015-10-19-数据链路层","published":1,"updated":"2015-10-20T08:54:23.484Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrb000l0cuf52agev6s"},{"date":"2015-06-07T16:00:00.000Z","title":"在windows上搭建rust开发环境","_content":"在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","source":"_posts/编程语言/windows rust.md","raw":"category: 编程语言\ndate: 2015-06-08\ntitle: 在windows上搭建rust开发环境\n---\n在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","slug":"编程语言/windows rust","published":1,"updated":"2015-10-14T01:51:59.028Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrd000n0cufjhlv7wmy"},{"date":"2015-10-07T16:00:00.000Z","title":"数据库和SQL","_content":"\n# Mysql索引\n\n一般我们在创建索引的时候都要指定它的索引名字. 当然这个不是必须的.\n\n## 索引类型\n\n### 普通索引\n```sql\nCREATE INDEX idxName ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  INDEX (id)\n)\n```\n\n### 唯一索引\n与普通索引相比值唯一, 可以有空值\n```sql\nCREATE UNIQUE INDEX id ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  UNIQUE (id)\n)\n```\n\n### 主键索引\n与普通索引相比值唯一, 不可以有空值\n```sql\nCREATE TABLE t1 (\n  id int NOT NULL,\n  PRIMARY KEY (id)\n)\n```\n\n### 组合索引\n下面我们创建了一个唯一组合索引.\n```sql\nCREATE TABLE `t1` (\n  `id` int(11) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  UNIQUE KEY `idx` (`id`,`name`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n## 索引注意事项\n* 如果索引上出现`NULL`值(包含组合索引),那么这一行就不会被索引\n* 我们要尽可能的使用短索引(指定一个前缀长度),例如对varchar类型进行索引,它的长度是16个字符,但是前6个字符是固定的,那么我们指定前缀长度为6就好了\n* 尽量不要对索引进行`like`操作\n* 不要在索引列上使用`NOT IN`和`<>`操作\n\n# 连接数据库\n```\nmysql -h 主机地址 -u 用户名 －p 用户密码 （注:u与root可以不用加空格，其它也一样）\n```\n\n# 用户操作\n创建用户\n```\nCREATE USER 'username'@'host' IDENTIFIED BY 'password';\n```\n授权: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' \n```\n> privileges - 用户的操作权限,如SELECT,INSERT,UPDATE等.如果要授予所的权限则使用ALL;如果要授予该用户对所有数据库和表的相应操作权限则可用*表示, 如*.*. \n\n用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION; \n```\n设置与更改用户密码 \n```\nSET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword');\n```\n撤销用户权限 \n```\nREVOKE privilege ON databasename.tablename FROM 'username'@'host'; \n```\n删除用户 \n```\nDROP USER 'username'@'host';\n```\n\n# 数据库操作 \n* 显示数据库：`SHOW databases`; \n* 创建库：`CREATE DATABASE 库名`; \n* 删除库：`DROP DATABASE 库名`; \n* 使用库(选中库)：`USE 库名`; \n\n# 表操作\n* 显示数据表：`SHOW tables`\n* 显示表结构：`DESC 表名`\n* 删除表：`DROP TABLE 表名`; \n* 输入创建表的DDL语句 `SHOW CREATE TABLE 表名;`\n* 创建表：\n```sql\nCREATE TABLE  \n    USER  \n    (  \n        name VARCHAR(30) NOT NULL,  \n        id INT DEFAULT '0' NOT NULL,  \n        stu_id INT,  \n        phone VARCHAR(20),  \n        address VARCHAR(30) NOT NULL,  \n        age INT(4) NOT NULL,  \n        PRIMARY KEY (name),  \n        CONSTRAINT stu_id UNIQUE (stu_id)  \n    )  \n    ENGINE=InnoDB DEFAULT CHARSET=utf8;  \n```\n\n## 表数据操作\n* 清空表数据`truncate table 表名;`. truncate删除后不记录mysql日志，不可以恢复数据。相当于保留mysql表的结构，重新创建了这个表，所有的状态都相当于新表。\n* 清空表数据`delete from 表名`. delete的效果有点像将mysql表中所有记录一条一条删除到删完\n\n## 修改表结构\n* 修改列名`alter table 表名称 change 字段名称 字段名称`\n* 修改表名`alter table 表名称 rename 表名称`\n* 修改某个表的字段类型及指定为空或非空`alter table 表名称 change 字段名称字段名称 字段类型 [null/not null];`\n* 修改某个表的字段名称及指定为空或非空`alter table 表名称 change 字段原名称字段新名称 字段类型 [null/not null];`\n* 增加一个字段(一列)`alter table table_name add column column_name type default value;` type指该字段的类型,value指该字段的默认值\n* 更改一个字段名字(也可以改变类型和默认值)`alter table table_name change sorce_col_name dest_col_name type defaultvalue;` source_col_name指原来的字段名称,dest_col_name指改后的字段名称\n* 改变一个字段的默认值`alter table table_name alter column_name set default value;`\n* 改变一个字段的数据类型`alter table table_name change column column_name column_name type;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 删除字段`alter table form1 drop column 列名;`\n\n\n## 复制表\n* 含有主键等信息的完整表结构 `CREATE table 新表名 LIKE book;`\n* 只有表结构，没有主键等信息 `create table 新表名 select * from books;\n* 将旧表中的数据灌入新表 `INSERT INTO 新表 SELECT * FROM 旧表；` 注：新表必须已经存在\n\n## 导入导出数据库\n* 数据库某表的备份,在命令行中输入:`mysqldump -u root -p database_name table_name > bak_file_name`\n* 导出数据`select_statment into outfile”dest_file”;`\n* 导入数据`load data infile”file_name” into table table_name;`\n* 将两个表里的数据拼接后插入到另一个表里`insert into tx select t1.com1,concat(t1.com2,t2.com1) from t1,t2;`\n\n\n \n## 查询表\nmysql查询的五种子句 \n\n### where(条件查询)\n```\nSELECT * FROM t1 WHERE id > 100;\n```\n* 数值谓词:`>,=,<,<>,!=,!>,!<,=>,=<`\n* 字符串谓词：`=，like`\n* 日期谓词：`=` (`SELECT * from t1 WHERE create_time = '2011-04-08'`)\n\n\n### having（筛选）\n```\n\n```\n\n### group by（分组）\n```\nSELECT id FROM player GROUP BY vip;\n```\n\n### order by（排序）\n```\nSELECT id FROM player ORDER BY id;\n```\n\n### limit（限制结果数）\n查询前n条记录\n```\nSELECT id FROM player LIMIT 10;\n```\n查询后n条记录\n\n\n# 事务\n事务（Transaction）是是一个操作序列，它构成了并发执行的基本单元。事务的提出主要是为了解决并发情况下保持数据一致性。\n\n数据库事务具有ACID特性,即\n* 原子性： 原子性体现在对事务的修改,要么全部执行要么都不执行\n* 一致性： 保持数据的一致性,例如整数类型的数据大小不能溢出,字符型数据长度不能超过规定范围，保证数据的完整性.\n* 隔离性： 如果数据库并发执行A,B俩个事务,那么在A事务执行完之前对B事务是不可见的,也就是说,B事务是看不见A事务的中间状态的.\n* 持久性： 事务完成后,它对数据库的影响是永久的,即使数据库出现异常也是如此.\n\n\n隔离级别\n* `Read Uncommitted`: 读取未提交的数据,即其他事务已经提交修改但还未提交的数据(这是最低的隔离级别)\n* `Read Committed`: 读取已经提交的数据,但是在一个事务中,对同一个项,前后俩次读取的结果可能不同.\n* `Repetable Read`: 可重复读取,在一个事务中,对同一个项,确保前后俩次读取的结果一样\n* `Serializable`: 可序列话,即数据库的事务是可串行执行的,就像一个事务执行的时候没有别的事务同时在执行\n我们使用下面的语句来改变数据库的隔离级别\n```sql\nSET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE\n```\n1. 不带`SESSION、GLOBAL`的SET命令,只对下一个事务有效\n2. `SET SESSION` 为当前会话设置隔离模式\n3. `SET GLOBAL`为以后新建的所有MYSQL连接设置隔离模式（当前连接不包括在内）\n\n读写异常\n* `Lost Update`: 俩个事务并发修改同一个数据,A事务提交成功,B事务提交失败回滚后,A事务的修改都可能会丢失\n* `Dirty Reads`: A事务读取了B事务更新却没有提交的数据\n* `Non-Repeatable Reads`: 一个事务对同一个数据项的多次读取可能得到不同的结果\n* `Second Lost Updates`:俩个事务并发修改同一个数据, B事务可能会覆盖掉A事务的修改\n* `Phantom Reads`: A事务进行前后俩次查询,但是在查询过程中出现了B事务向其中插入数据,那么A事务可能读取到未出现的数据\n\n隔离级别与读写异常的关系\n```\n    LU  DR  NRR  SLU  PR\nRU  N   Y   Y    Y    Y\nRC  N   N   Y    Y    Y\nRR  N   N   N   N     Y\nS   N   N   N   N     N\n```\n\n## 事务语句\n* 开始事物：`BEGIN TRANSACTION`\n* 提交事物：`COMMIT TRANSACTION`\n* 回滚事务：`ROLLBACK TRANSACTION`\n\n```sql\n# 开启一个事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(1);\n# 提交事务\nCOMMIT;\n\n# 开启事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(2);\n# 回滚刚才的事务\nROLLBACK;\n```\n\n\n## 并发控制\n\n### 锁\n\n### 写时复制\n\n### 多版本并发控制\n\nMysql InnoDB存储引擎,InnoDB对每一行维护了俩个隐含的列,一列用于存储行被修改的时间,另一列存储每一行被删除的时间.\n> 这里的时间并不是绝对时间,而是与时间对应的数据库系统的版本号,每当一个事务开始时,InnoDB都会给这个事务分配一个递增的版本号,所以版本号也可以被任务是事务好.对于每一行的查询语句,InnoDB都会把这个查询语句的版本号同这个查询雨具遇到的行的版本号进行对比,然后结合不同的事务隔离级别来决定是否返回改行.\n\n下面以SELECT,DELETE,INSERT,UPDATE为例:\n#### SELECT\n只有同时满足下面俩个条件的行才能被返回:\n1. 行的版本号小于等于该事务的版本号\n2. 行的删除版本号要么没有定义,要么大于等于事务的版本号\n如果行的修改或者删除版本号大于事务号,说明行是被该食物后面启动的事务修改或者删除的 \n\n\n#### DELETE\nInnoDB直接把该行的删除版本号设置为当前的事务号,相当于标记为删除而不是物理删除\n\n#### INSERT\n对于新插入的行,行的修改版本号更新为该事务的事务号\n\n#### UPDATE\n更新行的时候,InnoDB会把原来的行复制一份,并把当前的事务号作为改行的修改版本号\n","source":"_posts/编程语言/sql.md","raw":"category: 编程语言\ndate: 2015-10-08\ntitle: 数据库和SQL\n---\n\n# Mysql索引\n\n一般我们在创建索引的时候都要指定它的索引名字. 当然这个不是必须的.\n\n## 索引类型\n\n### 普通索引\n```sql\nCREATE INDEX idxName ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  INDEX (id)\n)\n```\n\n### 唯一索引\n与普通索引相比值唯一, 可以有空值\n```sql\nCREATE UNIQUE INDEX id ON db1.idtable(id);\n\nCREATE TABLE t1 (\n  id int NOT NULL,\n  UNIQUE (id)\n)\n```\n\n### 主键索引\n与普通索引相比值唯一, 不可以有空值\n```sql\nCREATE TABLE t1 (\n  id int NOT NULL,\n  PRIMARY KEY (id)\n)\n```\n\n### 组合索引\n下面我们创建了一个唯一组合索引.\n```sql\nCREATE TABLE `t1` (\n  `id` int(11) NOT NULL,\n  `name` varchar(16) NOT NULL,\n  UNIQUE KEY `idx` (`id`,`name`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8\n```\n\n## 索引注意事项\n* 如果索引上出现`NULL`值(包含组合索引),那么这一行就不会被索引\n* 我们要尽可能的使用短索引(指定一个前缀长度),例如对varchar类型进行索引,它的长度是16个字符,但是前6个字符是固定的,那么我们指定前缀长度为6就好了\n* 尽量不要对索引进行`like`操作\n* 不要在索引列上使用`NOT IN`和`<>`操作\n\n# 连接数据库\n```\nmysql -h 主机地址 -u 用户名 －p 用户密码 （注:u与root可以不用加空格，其它也一样）\n```\n\n# 用户操作\n创建用户\n```\nCREATE USER 'username'@'host' IDENTIFIED BY 'password';\n```\n授权: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' \n```\n> privileges - 用户的操作权限,如SELECT,INSERT,UPDATE等.如果要授予所的权限则使用ALL;如果要授予该用户对所有数据库和表的相应操作权限则可用*表示, 如*.*. \n\n用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令: \n```\nGRANT privileges ON databasename.tablename TO 'username'@'host' WITH GRANT OPTION; \n```\n设置与更改用户密码 \n```\nSET PASSWORD FOR 'username'@'host' = PASSWORD('newpassword');\n```\n撤销用户权限 \n```\nREVOKE privilege ON databasename.tablename FROM 'username'@'host'; \n```\n删除用户 \n```\nDROP USER 'username'@'host';\n```\n\n# 数据库操作 \n* 显示数据库：`SHOW databases`; \n* 创建库：`CREATE DATABASE 库名`; \n* 删除库：`DROP DATABASE 库名`; \n* 使用库(选中库)：`USE 库名`; \n\n# 表操作\n* 显示数据表：`SHOW tables`\n* 显示表结构：`DESC 表名`\n* 删除表：`DROP TABLE 表名`; \n* 输入创建表的DDL语句 `SHOW CREATE TABLE 表名;`\n* 创建表：\n```sql\nCREATE TABLE  \n    USER  \n    (  \n        name VARCHAR(30) NOT NULL,  \n        id INT DEFAULT '0' NOT NULL,  \n        stu_id INT,  \n        phone VARCHAR(20),  \n        address VARCHAR(30) NOT NULL,  \n        age INT(4) NOT NULL,  \n        PRIMARY KEY (name),  \n        CONSTRAINT stu_id UNIQUE (stu_id)  \n    )  \n    ENGINE=InnoDB DEFAULT CHARSET=utf8;  \n```\n\n## 表数据操作\n* 清空表数据`truncate table 表名;`. truncate删除后不记录mysql日志，不可以恢复数据。相当于保留mysql表的结构，重新创建了这个表，所有的状态都相当于新表。\n* 清空表数据`delete from 表名`. delete的效果有点像将mysql表中所有记录一条一条删除到删完\n\n## 修改表结构\n* 修改列名`alter table 表名称 change 字段名称 字段名称`\n* 修改表名`alter table 表名称 rename 表名称`\n* 修改某个表的字段类型及指定为空或非空`alter table 表名称 change 字段名称字段名称 字段类型 [null/not null];`\n* 修改某个表的字段名称及指定为空或非空`alter table 表名称 change 字段原名称字段新名称 字段类型 [null/not null];`\n* 增加一个字段(一列)`alter table table_name add column column_name type default value;` type指该字段的类型,value指该字段的默认值\n* 更改一个字段名字(也可以改变类型和默认值)`alter table table_name change sorce_col_name dest_col_name type defaultvalue;` source_col_name指原来的字段名称,dest_col_name指改后的字段名称\n* 改变一个字段的默认值`alter table table_name alter column_name set default value;`\n* 改变一个字段的数据类型`alter table table_name change column column_name column_name type;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 向一个表中增加一个列做为主键`alter table table_name add column column_name type auto_increment PRIMARYKEY;`\n* 删除字段`alter table form1 drop column 列名;`\n\n\n## 复制表\n* 含有主键等信息的完整表结构 `CREATE table 新表名 LIKE book;`\n* 只有表结构，没有主键等信息 `create table 新表名 select * from books;\n* 将旧表中的数据灌入新表 `INSERT INTO 新表 SELECT * FROM 旧表；` 注：新表必须已经存在\n\n## 导入导出数据库\n* 数据库某表的备份,在命令行中输入:`mysqldump -u root -p database_name table_name > bak_file_name`\n* 导出数据`select_statment into outfile”dest_file”;`\n* 导入数据`load data infile”file_name” into table table_name;`\n* 将两个表里的数据拼接后插入到另一个表里`insert into tx select t1.com1,concat(t1.com2,t2.com1) from t1,t2;`\n\n\n \n## 查询表\nmysql查询的五种子句 \n\n### where(条件查询)\n```\nSELECT * FROM t1 WHERE id > 100;\n```\n* 数值谓词:`>,=,<,<>,!=,!>,!<,=>,=<`\n* 字符串谓词：`=，like`\n* 日期谓词：`=` (`SELECT * from t1 WHERE create_time = '2011-04-08'`)\n\n\n### having（筛选）\n```\n\n```\n\n### group by（分组）\n```\nSELECT id FROM player GROUP BY vip;\n```\n\n### order by（排序）\n```\nSELECT id FROM player ORDER BY id;\n```\n\n### limit（限制结果数）\n查询前n条记录\n```\nSELECT id FROM player LIMIT 10;\n```\n查询后n条记录\n\n\n# 事务\n事务（Transaction）是是一个操作序列，它构成了并发执行的基本单元。事务的提出主要是为了解决并发情况下保持数据一致性。\n\n数据库事务具有ACID特性,即\n* 原子性： 原子性体现在对事务的修改,要么全部执行要么都不执行\n* 一致性： 保持数据的一致性,例如整数类型的数据大小不能溢出,字符型数据长度不能超过规定范围，保证数据的完整性.\n* 隔离性： 如果数据库并发执行A,B俩个事务,那么在A事务执行完之前对B事务是不可见的,也就是说,B事务是看不见A事务的中间状态的.\n* 持久性： 事务完成后,它对数据库的影响是永久的,即使数据库出现异常也是如此.\n\n\n隔离级别\n* `Read Uncommitted`: 读取未提交的数据,即其他事务已经提交修改但还未提交的数据(这是最低的隔离级别)\n* `Read Committed`: 读取已经提交的数据,但是在一个事务中,对同一个项,前后俩次读取的结果可能不同.\n* `Repetable Read`: 可重复读取,在一个事务中,对同一个项,确保前后俩次读取的结果一样\n* `Serializable`: 可序列话,即数据库的事务是可串行执行的,就像一个事务执行的时候没有别的事务同时在执行\n我们使用下面的语句来改变数据库的隔离级别\n```sql\nSET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE\n```\n1. 不带`SESSION、GLOBAL`的SET命令,只对下一个事务有效\n2. `SET SESSION` 为当前会话设置隔离模式\n3. `SET GLOBAL`为以后新建的所有MYSQL连接设置隔离模式（当前连接不包括在内）\n\n读写异常\n* `Lost Update`: 俩个事务并发修改同一个数据,A事务提交成功,B事务提交失败回滚后,A事务的修改都可能会丢失\n* `Dirty Reads`: A事务读取了B事务更新却没有提交的数据\n* `Non-Repeatable Reads`: 一个事务对同一个数据项的多次读取可能得到不同的结果\n* `Second Lost Updates`:俩个事务并发修改同一个数据, B事务可能会覆盖掉A事务的修改\n* `Phantom Reads`: A事务进行前后俩次查询,但是在查询过程中出现了B事务向其中插入数据,那么A事务可能读取到未出现的数据\n\n隔离级别与读写异常的关系\n```\n    LU  DR  NRR  SLU  PR\nRU  N   Y   Y    Y    Y\nRC  N   N   Y    Y    Y\nRR  N   N   N   N     Y\nS   N   N   N   N     N\n```\n\n## 事务语句\n* 开始事物：`BEGIN TRANSACTION`\n* 提交事物：`COMMIT TRANSACTION`\n* 回滚事务：`ROLLBACK TRANSACTION`\n\n```sql\n# 开启一个事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(1);\n# 提交事务\nCOMMIT;\n\n# 开启事务\nSTART TRANSACTION;\nINSERT INTO db1.`t1`(id) VALUES(2);\n# 回滚刚才的事务\nROLLBACK;\n```\n\n\n## 并发控制\n\n### 锁\n\n### 写时复制\n\n### 多版本并发控制\n\nMysql InnoDB存储引擎,InnoDB对每一行维护了俩个隐含的列,一列用于存储行被修改的时间,另一列存储每一行被删除的时间.\n> 这里的时间并不是绝对时间,而是与时间对应的数据库系统的版本号,每当一个事务开始时,InnoDB都会给这个事务分配一个递增的版本号,所以版本号也可以被任务是事务好.对于每一行的查询语句,InnoDB都会把这个查询语句的版本号同这个查询雨具遇到的行的版本号进行对比,然后结合不同的事务隔离级别来决定是否返回改行.\n\n下面以SELECT,DELETE,INSERT,UPDATE为例:\n#### SELECT\n只有同时满足下面俩个条件的行才能被返回:\n1. 行的版本号小于等于该事务的版本号\n2. 行的删除版本号要么没有定义,要么大于等于事务的版本号\n如果行的修改或者删除版本号大于事务号,说明行是被该食物后面启动的事务修改或者删除的 \n\n\n#### DELETE\nInnoDB直接把该行的删除版本号设置为当前的事务号,相当于标记为删除而不是物理删除\n\n#### INSERT\n对于新插入的行,行的修改版本号更新为该事务的事务号\n\n#### UPDATE\n更新行的时候,InnoDB会把原来的行复制一份,并把当前的事务号作为改行的修改版本号\n","slug":"编程语言/sql","published":1,"updated":"2015-10-26T10:06:31.684Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrf000q0cufoyk496l8"},{"date":"2015-10-07T16:00:00.000Z","title":"Shell","_content":"每个shell脚本文件第一行都要指定使用哪个shell,我们默认使用`#!/bin/bash`\n\n# 变量\nbash变量分为\n* 局部变量: 脚本或命令中定义，仅在当前shell实例中有效\n* 环境变量: 所有的脚本和shell中都可以访问的变量\n* 预定义变量\n\n## 变量类型\n运行shell时，会同时存在三种变量：\n* 局部变量： 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。\n* 环境变量：所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。\n* shell变量：shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行\n\n## 变量声明\n```shell\nv1=123\n```\n在上面的声明语法中我们需要注意以下几点\n* `=`左右不能用空格\n* 变量的默认类型是字符串\n* 该变量对当前以及子shell都有效\n\n### declare声明\nTODO\n\n## 变量引用\n我们通过使用`$`或者`${}`符号可以引用一个变量\n```shell\nv=1\necho $v\necho ${v}\n```\n\n## 只读变量\n`readonly` 命令可以将变量定义为只读变量\n```shell\nreadonly myUrl\n```\n\n## 删除变量\n```shell\nunset  myUrl\n```\n\n## 特殊变量\n* `$0`:\t当前脚本的文件名\n* `$n`:\t传递给脚本或函数的参数。(第一个参数是$1，第二个参数是$2)\n* `$#`:\t传递给脚本或函数的参数个数。\n* `$*`:\t传递给脚本或函数的所有参数。\n* `$@`:\t传递给脚本或函数的所有参数。被双引号(\" \")包含时，与 $* 稍有不同\n* `$?`:\t上个命令的退出状态，或函数的返回值。\n* `$$`:\t当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。\n\n## 数组\n\n### 数组定义\n一对括号表示是数组，数组元素用“空格”符号分割开。\n```shell\narray=(1 2 3 4 5)\n```\n\n### 数组长度\n```shell\n${#数组名[@或*]} : 可以得到数组长度\n${#array[@]}\n```\n\n### 索引数组成员\n`${数组名[下标]}` : 下标是从0开始 (下标是：*或者@ 得到整个数组内容)\n```shell\n${array[2]}\n```\n\n### 数组成员赋值\n`数组名[下标]`: 进行数组元素引用，如果下标不存在，自动添加新一个数组元素\n```shell\narray[1]=100\n```\n\n### 删除数组\n`unset 数组[下标]`：删除下标相应的元素，不带下标，则删掉整个数组。\n```shell\nunset array[1]\n```\n\n### 数组分片\n`${数组名[@或*]:起始位置:长度}`： 切片数组，返回一个用“空格”分割元素的字符串\n> 如果加上`()`，将得到切片数组\n```shell\nc=(${array[@]:1:4})\n```\n\n### 数组替换\n`${数组名[@或*]/查找字符/替换字符}`: 该操作不会改变原先数组内容\n```shell\n${array[@]/old/new}\n```\n\n# 运算符\n\n## 算术运算符\n我们可以使用`expr`, `let`, `(())`, `[]`等四种方式进行算术运算\n* `+`:\t加法\t`(($a + $b))` \n* `-\t`:\t减法`(($a - $b))` \n* `*`:\t乘法\t`(($a \\* $b))`\n* `/`:\t除法\t`(($b / $a))` \n* `%`:\t取余\t`(($b % $a))` \n* `=`:\t赋值\t`a=$b`\n* `==`:\t相等。用于比较两个数字，相同则返回 true。\t`[ $a == $b ]` 返回 false。\n* `!=`:\t不相等。用于比较两个数字，不相同则返回 true。\t`[ $a != $b ]` 返回 true。\n\n## 关系运算符\n关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n* `-eq`\t检测两个数是否相等，相等返回 true。\t`[ $a -eq $b ]` 返回 true。\n* `-ne`\t检测两个数是否相等，不相等返回 true。\t`[ $a -ne $b ]` 返回 true。\n* `-gt`\t检测左边的数是否大于右边的，如果是，则返回 true。\t`[ $a -gt $b ]` 返回 false。\n* `-lt`\t检测左边的数是否小于右边的，如果是，则返回 true。\t`[ $a -lt $b ]` 返回 true。\n* `-ge`\t检测左边的数是否大等于右边的，如果是，则返回 true。\t`[ $a -ge $b ]` 返回 false。\n* `-le`\t检测左边的数是否小于等于右边的，如果是，则返回 true。\t`[ $a -le $b ]` 返回 true。\n\n## 逻辑运算符\n* `!`\t非运算，表达式为 true 则返回 false，否则返回 true。\t`[ ! false ]` 返回 true。\n* `-o`\t或运算，有一个表达式为 true 则返回 true。\t`[ $a -lt 20 -o $b -gt 100 ]` 返回 true。\n* `-a`\t与运算，两个表达式都为 true 才返回 true。\t`[ $a -lt 20 -a $b -gt 100 ]` 返回 false。\n\n## 字符串运算符\n* `=`\t检测两个字符串是否相等，相等返回 true。\t`[ $a = $b ]` 返回 false。\n* `!=`\t检测两个字符串是否相等，不相等返回 true。\t`[ $a != $b ]` 返回 true。\n* `-z`\t检测字符串长度是否为0，为0返回 true。\t`[ -z $a `] 返回 false。\n* `-n`\t检测字符串长度是否为0，不为0返回 true。\t`[ -z $a `] 返回 true。\n* `str`\t检测字符串是否为空，不为空返回 true。\t`[ $a `] 返回 true。\n\n## 文件测试运算符\n* `-b` 文件是否是块设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-c` 文件是否是字符设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-d` 文件是否是目录，如果是，则返回 true。\t`[ -d $file `] 返回 false。\n* `-f` 文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。\t`[ -f $file `] 返回 true。\n* `-g` 文件是否设置了 SGID 位，如果是，则返回 true。\t`[ -g $file `] 返回 false。\n* `-k` 文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。\t`[ -k $file `] 返回 false。\n* `-p` 文件是否是具名管道，如果是，则返回 true。\t`[ -p $file `] 返回 false。\n* `-u` 文件是否设置了 SUID 位，如果是，则返回 true。\t`[ -u $file `] 返回 false。\n* `-r` 文件是否可读，如果是，则返回 true。\t`[ -r $file `] 返回 true。\n* `-w` 文件是否可写，如果是，则返回 true。\t`[ -w $file `] 返回 true。\n* `-x` 文件是否可执行，如果是，则返回 true。\t`[ -x $file `] 返回 true。\n* `-s` 文件是否为空（文件大小是否大于0），不为空返回 true。\t`[ -s $file `] 返回 true。\n* `-e` 文件（包括目录）是否存在，如果是，则返回 true。\t`[ -e $file `] 返回 true。\n\n# 流程控制\nshell流程控制包含：\n* if\n* while\n* until\n* case\n* for\n\n同样的shell也支持`break`和`continue`\n\n##  if else\n\n### if \n语法格式\n```shell\nif condition\nthen\n    command1 \n    command2\n    ...\n    commandN \nfi\n```\n示例\n```shell\n#!/bin/bash\nv=123\nif [ -b $txt ];   \nthen\n        echo \"ok\";\nfi\n```\n我们一定要注意if前后的空格\n\n### if else\n```\nif condition\nthen\n    command1 \n    command2\n    ...\n    commandN\nelse\n    command\nfi\n```\n\n### if else-if else\n```\nif condition1\nthen\n    command1\nelif condition2\n    command2\nelse\n    commandN\nfi\n```\n\n## case \n case语句为多选择语句\n```shell\ncase 值 in\n模式1)\n    command1\n    command2\n    ...\n    commandN\n    ;;\n模式2）\n    command1\n    command2\n    ...\n    commandN\n    ;;\nesac\n```\n示例\n```shell\n\n#!/bin/bash\n\nfor i in 1 2 3 4 5;\ndo\n        case $i in\n                1)  echo '你选择了 1'\n                ;;\n                2)  echo '你选择了 2'\n                ;;\n                3)  echo '你选择了 3'\n                ;;\n                4)  echo '你选择了 4'\n                ;;\n                *)  echo '你没有输入 1 到 4 之间的数字'\n                ;;\n                esac\ndone\n```\n\n## for \n```shell\nfor var in item1 item2 ... itemN\ndo\n    command1\n    command2\n    ...\n    commandN\ndone\n```\n示例\n```shell\n#!/bin/bash\n\nfor i in 1 2 3 4;\ndo\n        echo $i\ndone\n```\n\n## while \n```shell\nwhile condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nwhile(( $i<=5 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n## until \nuntil循环执行一系列命令直至条件为真时停止。\n```shell\nuntil condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nuntil(( $i>3 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n# 函数\n调用函数不需要加`()`\n```shell\nvi=123546789\nf() {\n\techo $vi\n}\nf\n```\n\n## 带参数的函数\n参数名是固定的`$n`, 如果参数大于10的话就需要`${10}`\n```shell\nf() {\necho $1\n}\nf 789\n```\n\n## 函数的返回值\n函数返回值在调用该函数后通过 `$?` 来获得\n```shell\nf() {\necho $1\n}\nf 789\necho $?\n```\n如果不写`return`, 则直接返回0\n```shell\nf() {\necho $1\nreturn 569\n}\nf 789\necho $?\n```\n","source":"_posts/编程语言/shell.md","raw":"category: 编程语言\ndate: 2015-10-08\ntitle: Shell\n---\n每个shell脚本文件第一行都要指定使用哪个shell,我们默认使用`#!/bin/bash`\n\n# 变量\nbash变量分为\n* 局部变量: 脚本或命令中定义，仅在当前shell实例中有效\n* 环境变量: 所有的脚本和shell中都可以访问的变量\n* 预定义变量\n\n## 变量类型\n运行shell时，会同时存在三种变量：\n* 局部变量： 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。\n* 环境变量：所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。\n* shell变量：shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行\n\n## 变量声明\n```shell\nv1=123\n```\n在上面的声明语法中我们需要注意以下几点\n* `=`左右不能用空格\n* 变量的默认类型是字符串\n* 该变量对当前以及子shell都有效\n\n### declare声明\nTODO\n\n## 变量引用\n我们通过使用`$`或者`${}`符号可以引用一个变量\n```shell\nv=1\necho $v\necho ${v}\n```\n\n## 只读变量\n`readonly` 命令可以将变量定义为只读变量\n```shell\nreadonly myUrl\n```\n\n## 删除变量\n```shell\nunset  myUrl\n```\n\n## 特殊变量\n* `$0`:\t当前脚本的文件名\n* `$n`:\t传递给脚本或函数的参数。(第一个参数是$1，第二个参数是$2)\n* `$#`:\t传递给脚本或函数的参数个数。\n* `$*`:\t传递给脚本或函数的所有参数。\n* `$@`:\t传递给脚本或函数的所有参数。被双引号(\" \")包含时，与 $* 稍有不同\n* `$?`:\t上个命令的退出状态，或函数的返回值。\n* `$$`:\t当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。\n\n## 数组\n\n### 数组定义\n一对括号表示是数组，数组元素用“空格”符号分割开。\n```shell\narray=(1 2 3 4 5)\n```\n\n### 数组长度\n```shell\n${#数组名[@或*]} : 可以得到数组长度\n${#array[@]}\n```\n\n### 索引数组成员\n`${数组名[下标]}` : 下标是从0开始 (下标是：*或者@ 得到整个数组内容)\n```shell\n${array[2]}\n```\n\n### 数组成员赋值\n`数组名[下标]`: 进行数组元素引用，如果下标不存在，自动添加新一个数组元素\n```shell\narray[1]=100\n```\n\n### 删除数组\n`unset 数组[下标]`：删除下标相应的元素，不带下标，则删掉整个数组。\n```shell\nunset array[1]\n```\n\n### 数组分片\n`${数组名[@或*]:起始位置:长度}`： 切片数组，返回一个用“空格”分割元素的字符串\n> 如果加上`()`，将得到切片数组\n```shell\nc=(${array[@]:1:4})\n```\n\n### 数组替换\n`${数组名[@或*]/查找字符/替换字符}`: 该操作不会改变原先数组内容\n```shell\n${array[@]/old/new}\n```\n\n# 运算符\n\n## 算术运算符\n我们可以使用`expr`, `let`, `(())`, `[]`等四种方式进行算术运算\n* `+`:\t加法\t`(($a + $b))` \n* `-\t`:\t减法`(($a - $b))` \n* `*`:\t乘法\t`(($a \\* $b))`\n* `/`:\t除法\t`(($b / $a))` \n* `%`:\t取余\t`(($b % $a))` \n* `=`:\t赋值\t`a=$b`\n* `==`:\t相等。用于比较两个数字，相同则返回 true。\t`[ $a == $b ]` 返回 false。\n* `!=`:\t不相等。用于比较两个数字，不相同则返回 true。\t`[ $a != $b ]` 返回 true。\n\n## 关系运算符\n关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n* `-eq`\t检测两个数是否相等，相等返回 true。\t`[ $a -eq $b ]` 返回 true。\n* `-ne`\t检测两个数是否相等，不相等返回 true。\t`[ $a -ne $b ]` 返回 true。\n* `-gt`\t检测左边的数是否大于右边的，如果是，则返回 true。\t`[ $a -gt $b ]` 返回 false。\n* `-lt`\t检测左边的数是否小于右边的，如果是，则返回 true。\t`[ $a -lt $b ]` 返回 true。\n* `-ge`\t检测左边的数是否大等于右边的，如果是，则返回 true。\t`[ $a -ge $b ]` 返回 false。\n* `-le`\t检测左边的数是否小于等于右边的，如果是，则返回 true。\t`[ $a -le $b ]` 返回 true。\n\n## 逻辑运算符\n* `!`\t非运算，表达式为 true 则返回 false，否则返回 true。\t`[ ! false ]` 返回 true。\n* `-o`\t或运算，有一个表达式为 true 则返回 true。\t`[ $a -lt 20 -o $b -gt 100 ]` 返回 true。\n* `-a`\t与运算，两个表达式都为 true 才返回 true。\t`[ $a -lt 20 -a $b -gt 100 ]` 返回 false。\n\n## 字符串运算符\n* `=`\t检测两个字符串是否相等，相等返回 true。\t`[ $a = $b ]` 返回 false。\n* `!=`\t检测两个字符串是否相等，不相等返回 true。\t`[ $a != $b ]` 返回 true。\n* `-z`\t检测字符串长度是否为0，为0返回 true。\t`[ -z $a `] 返回 false。\n* `-n`\t检测字符串长度是否为0，不为0返回 true。\t`[ -z $a `] 返回 true。\n* `str`\t检测字符串是否为空，不为空返回 true。\t`[ $a `] 返回 true。\n\n## 文件测试运算符\n* `-b` 文件是否是块设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-c` 文件是否是字符设备文件，如果是，则返回 true。\t`[ -b $file `] 返回 false。\n* `-d` 文件是否是目录，如果是，则返回 true。\t`[ -d $file `] 返回 false。\n* `-f` 文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。\t`[ -f $file `] 返回 true。\n* `-g` 文件是否设置了 SGID 位，如果是，则返回 true。\t`[ -g $file `] 返回 false。\n* `-k` 文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。\t`[ -k $file `] 返回 false。\n* `-p` 文件是否是具名管道，如果是，则返回 true。\t`[ -p $file `] 返回 false。\n* `-u` 文件是否设置了 SUID 位，如果是，则返回 true。\t`[ -u $file `] 返回 false。\n* `-r` 文件是否可读，如果是，则返回 true。\t`[ -r $file `] 返回 true。\n* `-w` 文件是否可写，如果是，则返回 true。\t`[ -w $file `] 返回 true。\n* `-x` 文件是否可执行，如果是，则返回 true。\t`[ -x $file `] 返回 true。\n* `-s` 文件是否为空（文件大小是否大于0），不为空返回 true。\t`[ -s $file `] 返回 true。\n* `-e` 文件（包括目录）是否存在，如果是，则返回 true。\t`[ -e $file `] 返回 true。\n\n# 流程控制\nshell流程控制包含：\n* if\n* while\n* until\n* case\n* for\n\n同样的shell也支持`break`和`continue`\n\n##  if else\n\n### if \n语法格式\n```shell\nif condition\nthen\n    command1 \n    command2\n    ...\n    commandN \nfi\n```\n示例\n```shell\n#!/bin/bash\nv=123\nif [ -b $txt ];   \nthen\n        echo \"ok\";\nfi\n```\n我们一定要注意if前后的空格\n\n### if else\n```\nif condition\nthen\n    command1 \n    command2\n    ...\n    commandN\nelse\n    command\nfi\n```\n\n### if else-if else\n```\nif condition1\nthen\n    command1\nelif condition2\n    command2\nelse\n    commandN\nfi\n```\n\n## case \n case语句为多选择语句\n```shell\ncase 值 in\n模式1)\n    command1\n    command2\n    ...\n    commandN\n    ;;\n模式2）\n    command1\n    command2\n    ...\n    commandN\n    ;;\nesac\n```\n示例\n```shell\n\n#!/bin/bash\n\nfor i in 1 2 3 4 5;\ndo\n        case $i in\n                1)  echo '你选择了 1'\n                ;;\n                2)  echo '你选择了 2'\n                ;;\n                3)  echo '你选择了 3'\n                ;;\n                4)  echo '你选择了 4'\n                ;;\n                *)  echo '你没有输入 1 到 4 之间的数字'\n                ;;\n                esac\ndone\n```\n\n## for \n```shell\nfor var in item1 item2 ... itemN\ndo\n    command1\n    command2\n    ...\n    commandN\ndone\n```\n示例\n```shell\n#!/bin/bash\n\nfor i in 1 2 3 4;\ndo\n        echo $i\ndone\n```\n\n## while \n```shell\nwhile condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nwhile(( $i<=5 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n## until \nuntil循环执行一系列命令直至条件为真时停止。\n```shell\nuntil condition\ndo\n    command\ndone\n```\n示例\n```shell\n#!/bin/bash\n\ni=1\nuntil(( $i>3 ))\ndo\n        echo $i\n        ((i++))\ndone\n```\n\n# 函数\n调用函数不需要加`()`\n```shell\nvi=123546789\nf() {\n\techo $vi\n}\nf\n```\n\n## 带参数的函数\n参数名是固定的`$n`, 如果参数大于10的话就需要`${10}`\n```shell\nf() {\necho $1\n}\nf 789\n```\n\n## 函数的返回值\n函数返回值在调用该函数后通过 `$?` 来获得\n```shell\nf() {\necho $1\n}\nf 789\necho $?\n```\n如果不写`return`, 则直接返回0\n```shell\nf() {\necho $1\nreturn 569\n}\nf 789\necho $?\n```\n","slug":"编程语言/shell","published":1,"updated":"2015-10-19T06:27:25.993Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrh000s0cufo72frwtl"},{"date":"2015-08-07T16:00:00.000Z","title":"PYTHON2","_content":"\n# 字符串\n* `capitalize(...)` : Python capitalize()将字符串的第一个字母变成大写,其他字母变小写。`print \"abc\".capitalize()`\n\n* `center(...)` : 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串。默认填充字符为空格。`print \"abc\".center(10, \"1\")`结果为`111abc1111`\n··\n* `count(...)` : 用于统计字符串里某个字符出现的次数。可选参数为在字符串搜索的开始与结束位置。`\"abcdefg\".count(\"c\", 2, 4)`结果为`1`\n\n* `encode(...)` : encoding 指定的编码格式编码字符串。errors参数可以指定不同的错误处理方案。`S.encode(encoding='utf-8', errors='strict') -> bytes` \n\n* `endswith(...)` : 用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False。可选参数\"start\"与\"end\"为检索字符串的开始与结束位置。`\"abcdefg\".endswith(\"d\", 2, 4)`结果为true\n\n* `expandtabs(...)` : `S.expandtabs(tabsize=8) -> str` 把字符串中的 tab 符号('\\t')转为空格，默认的空格数 tabsize 是 8。\n\n* `find(...)` : `S.find(sub[, start[, end]]) -> int` 检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。\n\n* `rfind(...)` : `S.rfind(sub[, start[, end]]) -> int` 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。\n\n* `format(...)` : `\"abcd{0}fg\".format(\"sdf\")` {0}被替换成sdf\n\n* `index(...)` : `S.index(sub[, start[, end]]) -> int`检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。\n\n* `rindex(...)` : `S.rindex(sub[, start[, end]]) -> int` 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。\n\n* `isalnum(...)` : `S.isalnum() -> bool` 判断字符串是否包含字母数字。\n\n* `isalpha(...)` : `S.isalpha() -> bool` 检测字符串是否只由字母组成。\n\n* `isdecimal(...)` : `S.isdecimal() -> bool` 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。\n\n* `isdigit(...)` : `S.isdigit() -> bool` 检测字符串是否只由数字组成。\n\n* `islower(...)` : `S.islower() -> bool` 检测字符串是否由小写字母组成。\n\n* `isnumeric(...)` : `S.isnumeric() -> bool` 检查是否只有数字字符组成的字符串。这种方法目前只对unicode对象。\n\n* `isspace(...)` : `S.isspace() -> bool` 是否只由空格组成。\n\n* `istitle(...)` : `S.istitle() -> bool` 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。\n\n* `isupper(...)` : `S.isupper() -> bool` 检测字符串中所有的字母是否都为大写。\n\n* `join(...)` : `S.join(iterable) -> str` 用于将序列中的元素以指定的字符连接生成一个新的字符串。\n\n* `ljust(...)` : `S.ljust(width[, fillchar]) -> str` 返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。\n\n* `rjust(...)` : `S.rjust(width[, fillchar]) -> str` 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。\n\n* `lower(...)` : `S.lower() -> str` 转换字符串中所有大写字符为小写。\n\n* `lstrip(...)` : `S.lstrip([chars]) -> str` 用于截掉字符串左边的空格或指定字符。\n\n* `partition(...)` : `S.partition(sep) -> (head, sep, tail)` Search for the separator sep in S, and return the part before it,the separator itself, and the part after it.  If the separator is not found, return S and two empty strings.\n\n* `rpartition(...)` : `S.rpartition(sep) -> (head, sep, tail)` 类似于 partition()函数,不过是从右边开始查找.\n\n* `replace(...)` : `S.replace(old, new[, count]) -> str` 把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。\n\n* `split(...)` : `S.split(sep=None, maxsplit=-1) -> list of strings` 通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串. 另外参考`rsplit(...)`\n\n* `splitlines(...)` : `S.splitlines([keepends]) -> list of strings` 返回一个字符串的所有行，可选包括换行符列表(如果num提供，则为true)\n\n* `startswith(...)` : `S.startswith(prefix[, start[, end]]) -> bool` 用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。\n\n* `strip(...)` : `S.strip([chars]) -> str` 用于移除字符串头尾指定的字符（默认为空格）。\n\n* `rstrip(...)` : `S.rstrip([chars]) -> str` 删除 string 字符串末尾的指定字符（默认为空格）.\n\n* `swapcase(...)` : `S.swapcase() -> str` 用于对字符串的大小写字母进行转换。\n\n* `title(...)` : `S.title() -> str` 返回\"标题化\"的字符串,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())。\n\n* `translate(...)` : `S.translate(table) -> str` 根据参数table给出的表(包含 256 个字符)转换字符串的字符, 要过滤掉的字符放到 del 参数中。\n\n* `upper(...)` : `S.upper() -> str` 将字符串中的小写字母转为大写字母。\n\n* `zfill(...)` : `S.zfill(width) -> str` 返回指定长度的字符串，原字符串右对齐，前面填充0。\n\n# 内置数据结构\n\n## 列表\n* 声明一个列表 `list = [123, \"ad\"]`\n* 索引第一个元素 `list[0]`\n* 在尾部添加一个元素 `list.append(2.56)`\n* 对第一个元素重新赋值 `list[0] = \"0\"`\n* 获取列表长度 `len(list)`\n* 删除第一个元素 `del list[0]`\n\n\n\n## 元组\n元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组\n```python\ntumple = (123, \"adf\")\nprint(tumple[0])\nprint(len(tumple))\n```\n\n## 字典\n```python\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nprint(map)\nprint(len(map))\nprint(map[\"key1\"])\ndel map[\"key1\"]\nprint(map)\n\nfor key in map:\n    print(key + \"   \" + map[key])\nif \"key2\" in map:\n    print(\"map contains key2\")\n\nhelp(dict)\n```\n\n## 序列\n序列的两个主要特点是索引操作符和切片操作符\n```python\nshoplist = ['apple', 'mango', 'carrot', 'banana']\n\nprint('Item 0 is', shoplist[0])\nprint('Item -1 is', shoplist[-1])\n\n# Slicing on a list\nprint('Item 1 to 3 is', shoplist[1:3])\nprint('Item 2 to end is', shoplist[2:])\nprint('Item 1 to -1 is', shoplist[1:-1])\nprint('Item start to end is', shoplist[:])\n\n# Slicing on a string\nname = 'swaroop'\nprint('characters 1 to 3 is', name[1:3])\nprint('characters 2 to end is', name[2:])\nprint('characters 1 to -1 is', name[1:-1])\nprint('characters start to end is', name[:])\n```\n\n\n# 文件\n```python\nf = open(name, [mode], [size])\n```\n* name: 文件名\n* mode: 打开方式\n* size: 操作的字节数\n\n## mode值:\n* `r`: 只读方式打开(文件必须存在)\n* `w`: 只写方式打开(文件不存在创建文件,文件存在清空文件)\n* `a`: 追加方式打开(文件不存在创建文件)\n* `r+/w+`: 读写方式打开\n* `a+`: 读写方式打开\n* `rb,wb,ab,rb+,wb+,ab+`: 二进制方式打开\n\n> 注意:如果我们使用非二进制模式输出时`\\n(0A)`会被自动替换为`\\r\\n(0D 0A)`,因此在文件输出时,我们要注意这个问题.\n\n## f对象常用方法\n* `read([size])` : 读取文件(size有值则读取size个字节),如果不填写size则读取全部\n* `readline([size])` : 每次读取一行(size值为当前行的长度,但是如果每次读取不完的话,下次再调用readline时会继续在当前行读取)\n* `readlines([size])` : 读取多行,返回每一行组成的列表. 如果不填写size则读取全部内容(不推荐使用这种方式读取所有行)\n* `write(str)` : 将字符串直接写入文件中\n* `writelines(lines)`: 将字符串或者字符串列表写入文件中.\n* `close()`: 关闭文件操作\n\n我们可以使用for循环遍历整个文件\n```python\nfile = open(\"demo.txt\")\nfor line in file:\n\tprint(line)\n```\n\n## OS模块文件操作\n```\nfd = os.open(filename, flag, [mode])\n```\nfilename和mode我们通过上面的描述都知道了,现在我们看一下flag属性值(文件打开方式)\n* os.O_CREAT : 创建文件\n* os.O_RDONLY : 只读方式打开\n* os.O_WRONLY : 只写方式打开\n* os.O_RDWR : 读写方式打开\n\n示例\n```python\nfd = os.open(\"test.txt\", os.O_CREAT | os.O_RDWR)\nos.write(fd, \"helloworld\")\n```\n\n## 中文乱码\n写入文件时,如果输出中文,我们经常会遇到乱码的问题.只需要在python文件顶部加上以下内容就可以了\n```\n#-*- coding=utf-8 -*-\n```\n\n# 控制流\n## if\n```python\ntmp = 0\nif tmp > 0 :\n    print(\">\")\nelif tmp < 0 :\n    print(\"<\")\nelse :\n    print(\"=\")\n```\n\n## while\n```python\ntmp = 0\nwhile tmp < 3 :\n    print(tmp)\n    tmp +=1\nelse :\n    print(\"over\")\n```\n\n## for\n```python\nfor i in [0,1,2,3,4]:\n    print(i)\n\n    if i > 2 :\n        break\n    else :\n        continue\n\nelse:\n    print('loop over')\n```\n\n# 函数\n\n## 定义一个不带参数的函数\n```python\n# 定义一个不带参数的函数\ndef printHelloworld():\n    print(\"hello world\")\n\n# 调用函数\nprintHelloworld()\n```\n\n## 定义一个带参数的函数\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n## 函数中的局部变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    value = saywhat\n    print(value)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n当在函数内部修改了局部变量之后,并不会影响脚本中的变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nstr = \"hello world\"\nprintHelloworld(str)\nprint(str)\n```\n\n## 使用global语句\n```python\n# 定义一个带参数的函数\ndef printHelloworld():\n    global saywhat # 此处不可进行初始化\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nprintHelloworld()\nprint(saywhat)\n```\n\n## 默认参数值\n我们也可以给函数参数指定默认值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str + \" \" + str1 + \" \" + str2)\n\n# 调用函数\nprintHelloworld(\"123\", str2=\"789\")\n```\n\n## 可变参数\npython函数也可以接受不定参数\n```python\ndef f(*args):\n\tprint(args)\n\nf(1)\nf(1, 2)\n```\n输出为\n```\n(1,)\n(1, 2)\n```\n\n## return返回值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str)\n    if str1==\"str1 value\" :\n        return \"nil value\"\n    print(str1)\n    print(str2)\n\n# 调用函数\nresult = printHelloworld(\"123\", str2=\"789\")\nprint(result)\n\nresult = printHelloworld(\"123\", str1=\"789\")\nprint(result)\n```\n\n## 高阶函数\n如果函数A里的参数或者返回值是另一个函数,那么函数A就是高阶函数.\n```python\ndef add5(v1):\n\treturn v1 + 5;\n\ndef add(v1, v2, add5):\n\treturn add5(v1) + add5(v2)\n\nprint(add(2, 4, add5))\n```\n\n### 内置高阶函数\n#### map()函数\n它接受一个函数和一个列表,然后遍历列表中的每个元素作用在函数参数中\n```python\nprint(map(add5, [1, 2, 3]))\n\n// 结果为\n[6, 7, 8]\n```\n#### reduce()函数\n```python\n\n```\n\n#### filter\n```python\n\n```\n\n## 闭包\n在2.7版本中必须要如下声明一个闭包\n```python\ndef outerF():\n\tcount = [10]\n\tdef innerF():\n\t\tprint(count[0])\n\t\tcount[0] = 20\n\treturn innerF\n\nf = outerF()\nf()\nf()\n```\n\n## 匿名函数\npython通过lambda表达式完成匿名函数\n```python\ndef nonameF(f, v1):\n\treturn f(v1)\n\nvalue = nonameF(lambda x: x + 1, 5)\nprint(value)\n```\n不过python只是有限的支持匿名函数, 匿名函数只能是一个表达式,而且不能拥有return,表达式的结果就是返回值\n\n## 偏函数\n偏函数就是通过`functools.partial`函数将函数A中的参数指定一个值然后返回一个新的函数\n```python\nimport functools\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfb = functools.partial(fa, var2=2, var3=3)\n\nfa(1, 2, 3)\nfb(1)\n```\n最后我们看到了相同的结果\n\n## 重定义\n我们可以对一个已经存在的函数重新定义行为\n```\ndef f(*args):\n\tprint(args)\n\n\nf = lambda : 15\nprint(f())\n\nn = f\n\ndef f():\n\treturn 20\n\nprint(n())\nprint(f())\n```\n从这一点可以验证在python中函数也是对象.\n\n## 装饰器\n装饰器本质上就是一个高阶函数，它接收一个函数作为参数，然后，返回一个新函数。\n\npython通过`@`语法内置实现装饰器\n```python\ndef fb(f):\n\tprint(\"fb\")\n\treturn f\n\n@fb\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfa(1, 2, 3)\n```\n上面这个例子每次在调用`fa`方法时都会输出一个`fb`字符串\n\n# 模块\n模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。\n\n## 使用`sys`模块\n```python\nimport sys\n\nfor argv in sys.argv :\n    print(argv)\n```\n\n使用`from..import..`, `import`可以使用`*`\n```python\nfrom sys import argv\n\nfor argvtmp in argv :\n    print(argvtmp)\n```\n\n模块的name,下面的语法输出当前模块的name\n```python\nprint(__name__)\n```\n\n## 自定义模块\n* 建立`mymodule.py`文件\n```python\n# Filename: mymodule.py\n\ndef printModuleName():\n    print(__name__)\n```\n* 建立`test_mymodule.py`文件\n```python\nimport mymodule\n\nmymodule.printModuleName()\n```\n1. 需要注意的是`mymodule.py`文件的`Filename`必须和文件名相同\n2. 如果`module`的name是`__main__`说明这个module是由用户启动的\n\n# 面向对象\n\n## self\n类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称`self`\n```python\n\n```\n\n## 创建一个类\n```python\nclass Person:\n    pass\n\np = Person()\nprint p\n```\n\n## 对象的方法\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n\np = Person()\np.run()\n```\n\n### __init__方法\n`__init__`方法在类的一个对象被建立时，马上运行\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"init\")\n\np = Person()\np.run()\n```\n\n### __del__方法\n```python\nclass Person:\n    def __init__(self):\n        print(\"init\")\n    def __del__(self):\n        print(\"__destory__\")\n\np = Person()\n```\n\n### 变量\n* 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。\n\n* 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。\n\n```python\nclass Father:\n    age = 0\n\nfather = Father()\nfather.age = 10\nFather.age = 20\nprint(father.age)\nprint(Father.age)\n```\n\n### 权限控制\n对象的属性(变量和方法)如果名字以`__`开头则不能被外部访问,但是如果名称构成形式为`__xxx__`则被称为特殊属性,是可以被外界访问的.\n\n## 继承\n```python\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n\nclass Son(Father):\n    pass\n\nson = Son()\nprint(son.name)\nson.run()\n\n```\n\n### `__init__`, `__del__`在继承中的使用\nPython不会自动调用父类的constructor\n```python\nclass Mother:\n    pass\n\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"Father init\")\n    def __del__(self):\n        print(\"Father del\")\n\nclass Son(Father, Mother):\n    def __init__(self):\n        print(\"Son init\")\n    def __del__(self):\n        print(\"Son del\")\n\nson = Son()\nprint(son.name)\nson.run()\n```\n\n# json\n使用`dump()`方法将对象序列化成json,然后使用`load()`将字符串反序列化成对象\n```python\n#-*- coding=utf-8 -*-\nimport json\n\nlist = [123, \"ad\"]\nlistJson = json.dumps(list)\nlistR = json.loads(listJson)\nprint \"列表序列化 : \" + listJson\nprint \"列表反序列化 : \" + str(listR[0])\n\ntumple = (123, \"adf\")\ntumpleJson = json.dumps(tumple)\ntumpleR = json.loads(tumpleJson)\nprint \"元组序列化 : \" + tumpleJson\nprint \"元组反序列化 : \" + str(tumpleR[1])\n\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nmapJson = json.dumps(map)\nmapR = json.loads(mapJson)\nprint \"字典序列化 : \" + mapJson\nprint \"字典反序列化 : \" + str(mapR[\"key1\"])\n\nseq = ['apple', 'mango', 'carrot', 'banana']\nseqJson = json.dumps(seq)\nseqR = json.loads(seqJson)\nprint \"序列序列化 : \" + seqJson\nprint \"序列反序列化 : \" + str(seqR[1])\n\n\ntype tumpleR[1]\ntype mapR[\"key1\"]\ntype seqR[1]\n\n```\n ","source":"_posts/编程语言/python.md","raw":"category: 编程语言\ndate: 2015-08-08\ntitle: PYTHON2\n---\n\n# 字符串\n* `capitalize(...)` : Python capitalize()将字符串的第一个字母变成大写,其他字母变小写。`print \"abc\".capitalize()`\n\n* `center(...)` : 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串。默认填充字符为空格。`print \"abc\".center(10, \"1\")`结果为`111abc1111`\n··\n* `count(...)` : 用于统计字符串里某个字符出现的次数。可选参数为在字符串搜索的开始与结束位置。`\"abcdefg\".count(\"c\", 2, 4)`结果为`1`\n\n* `encode(...)` : encoding 指定的编码格式编码字符串。errors参数可以指定不同的错误处理方案。`S.encode(encoding='utf-8', errors='strict') -> bytes` \n\n* `endswith(...)` : 用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False。可选参数\"start\"与\"end\"为检索字符串的开始与结束位置。`\"abcdefg\".endswith(\"d\", 2, 4)`结果为true\n\n* `expandtabs(...)` : `S.expandtabs(tabsize=8) -> str` 把字符串中的 tab 符号('\\t')转为空格，默认的空格数 tabsize 是 8。\n\n* `find(...)` : `S.find(sub[, start[, end]]) -> int` 检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。\n\n* `rfind(...)` : `S.rfind(sub[, start[, end]]) -> int` 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。\n\n* `format(...)` : `\"abcd{0}fg\".format(\"sdf\")` {0}被替换成sdf\n\n* `index(...)` : `S.index(sub[, start[, end]]) -> int`检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。\n\n* `rindex(...)` : `S.rindex(sub[, start[, end]]) -> int` 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。\n\n* `isalnum(...)` : `S.isalnum() -> bool` 判断字符串是否包含字母数字。\n\n* `isalpha(...)` : `S.isalpha() -> bool` 检测字符串是否只由字母组成。\n\n* `isdecimal(...)` : `S.isdecimal() -> bool` 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。\n\n* `isdigit(...)` : `S.isdigit() -> bool` 检测字符串是否只由数字组成。\n\n* `islower(...)` : `S.islower() -> bool` 检测字符串是否由小写字母组成。\n\n* `isnumeric(...)` : `S.isnumeric() -> bool` 检查是否只有数字字符组成的字符串。这种方法目前只对unicode对象。\n\n* `isspace(...)` : `S.isspace() -> bool` 是否只由空格组成。\n\n* `istitle(...)` : `S.istitle() -> bool` 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。\n\n* `isupper(...)` : `S.isupper() -> bool` 检测字符串中所有的字母是否都为大写。\n\n* `join(...)` : `S.join(iterable) -> str` 用于将序列中的元素以指定的字符连接生成一个新的字符串。\n\n* `ljust(...)` : `S.ljust(width[, fillchar]) -> str` 返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。\n\n* `rjust(...)` : `S.rjust(width[, fillchar]) -> str` 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。\n\n* `lower(...)` : `S.lower() -> str` 转换字符串中所有大写字符为小写。\n\n* `lstrip(...)` : `S.lstrip([chars]) -> str` 用于截掉字符串左边的空格或指定字符。\n\n* `partition(...)` : `S.partition(sep) -> (head, sep, tail)` Search for the separator sep in S, and return the part before it,the separator itself, and the part after it.  If the separator is not found, return S and two empty strings.\n\n* `rpartition(...)` : `S.rpartition(sep) -> (head, sep, tail)` 类似于 partition()函数,不过是从右边开始查找.\n\n* `replace(...)` : `S.replace(old, new[, count]) -> str` 把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。\n\n* `split(...)` : `S.split(sep=None, maxsplit=-1) -> list of strings` 通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串. 另外参考`rsplit(...)`\n\n* `splitlines(...)` : `S.splitlines([keepends]) -> list of strings` 返回一个字符串的所有行，可选包括换行符列表(如果num提供，则为true)\n\n* `startswith(...)` : `S.startswith(prefix[, start[, end]]) -> bool` 用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。\n\n* `strip(...)` : `S.strip([chars]) -> str` 用于移除字符串头尾指定的字符（默认为空格）。\n\n* `rstrip(...)` : `S.rstrip([chars]) -> str` 删除 string 字符串末尾的指定字符（默认为空格）.\n\n* `swapcase(...)` : `S.swapcase() -> str` 用于对字符串的大小写字母进行转换。\n\n* `title(...)` : `S.title() -> str` 返回\"标题化\"的字符串,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())。\n\n* `translate(...)` : `S.translate(table) -> str` 根据参数table给出的表(包含 256 个字符)转换字符串的字符, 要过滤掉的字符放到 del 参数中。\n\n* `upper(...)` : `S.upper() -> str` 将字符串中的小写字母转为大写字母。\n\n* `zfill(...)` : `S.zfill(width) -> str` 返回指定长度的字符串，原字符串右对齐，前面填充0。\n\n# 内置数据结构\n\n## 列表\n* 声明一个列表 `list = [123, \"ad\"]`\n* 索引第一个元素 `list[0]`\n* 在尾部添加一个元素 `list.append(2.56)`\n* 对第一个元素重新赋值 `list[0] = \"0\"`\n* 获取列表长度 `len(list)`\n* 删除第一个元素 `del list[0]`\n\n\n\n## 元组\n元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组\n```python\ntumple = (123, \"adf\")\nprint(tumple[0])\nprint(len(tumple))\n```\n\n## 字典\n```python\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nprint(map)\nprint(len(map))\nprint(map[\"key1\"])\ndel map[\"key1\"]\nprint(map)\n\nfor key in map:\n    print(key + \"   \" + map[key])\nif \"key2\" in map:\n    print(\"map contains key2\")\n\nhelp(dict)\n```\n\n## 序列\n序列的两个主要特点是索引操作符和切片操作符\n```python\nshoplist = ['apple', 'mango', 'carrot', 'banana']\n\nprint('Item 0 is', shoplist[0])\nprint('Item -1 is', shoplist[-1])\n\n# Slicing on a list\nprint('Item 1 to 3 is', shoplist[1:3])\nprint('Item 2 to end is', shoplist[2:])\nprint('Item 1 to -1 is', shoplist[1:-1])\nprint('Item start to end is', shoplist[:])\n\n# Slicing on a string\nname = 'swaroop'\nprint('characters 1 to 3 is', name[1:3])\nprint('characters 2 to end is', name[2:])\nprint('characters 1 to -1 is', name[1:-1])\nprint('characters start to end is', name[:])\n```\n\n\n# 文件\n```python\nf = open(name, [mode], [size])\n```\n* name: 文件名\n* mode: 打开方式\n* size: 操作的字节数\n\n## mode值:\n* `r`: 只读方式打开(文件必须存在)\n* `w`: 只写方式打开(文件不存在创建文件,文件存在清空文件)\n* `a`: 追加方式打开(文件不存在创建文件)\n* `r+/w+`: 读写方式打开\n* `a+`: 读写方式打开\n* `rb,wb,ab,rb+,wb+,ab+`: 二进制方式打开\n\n> 注意:如果我们使用非二进制模式输出时`\\n(0A)`会被自动替换为`\\r\\n(0D 0A)`,因此在文件输出时,我们要注意这个问题.\n\n## f对象常用方法\n* `read([size])` : 读取文件(size有值则读取size个字节),如果不填写size则读取全部\n* `readline([size])` : 每次读取一行(size值为当前行的长度,但是如果每次读取不完的话,下次再调用readline时会继续在当前行读取)\n* `readlines([size])` : 读取多行,返回每一行组成的列表. 如果不填写size则读取全部内容(不推荐使用这种方式读取所有行)\n* `write(str)` : 将字符串直接写入文件中\n* `writelines(lines)`: 将字符串或者字符串列表写入文件中.\n* `close()`: 关闭文件操作\n\n我们可以使用for循环遍历整个文件\n```python\nfile = open(\"demo.txt\")\nfor line in file:\n\tprint(line)\n```\n\n## OS模块文件操作\n```\nfd = os.open(filename, flag, [mode])\n```\nfilename和mode我们通过上面的描述都知道了,现在我们看一下flag属性值(文件打开方式)\n* os.O_CREAT : 创建文件\n* os.O_RDONLY : 只读方式打开\n* os.O_WRONLY : 只写方式打开\n* os.O_RDWR : 读写方式打开\n\n示例\n```python\nfd = os.open(\"test.txt\", os.O_CREAT | os.O_RDWR)\nos.write(fd, \"helloworld\")\n```\n\n## 中文乱码\n写入文件时,如果输出中文,我们经常会遇到乱码的问题.只需要在python文件顶部加上以下内容就可以了\n```\n#-*- coding=utf-8 -*-\n```\n\n# 控制流\n## if\n```python\ntmp = 0\nif tmp > 0 :\n    print(\">\")\nelif tmp < 0 :\n    print(\"<\")\nelse :\n    print(\"=\")\n```\n\n## while\n```python\ntmp = 0\nwhile tmp < 3 :\n    print(tmp)\n    tmp +=1\nelse :\n    print(\"over\")\n```\n\n## for\n```python\nfor i in [0,1,2,3,4]:\n    print(i)\n\n    if i > 2 :\n        break\n    else :\n        continue\n\nelse:\n    print('loop over')\n```\n\n# 函数\n\n## 定义一个不带参数的函数\n```python\n# 定义一个不带参数的函数\ndef printHelloworld():\n    print(\"hello world\")\n\n# 调用函数\nprintHelloworld()\n```\n\n## 定义一个带参数的函数\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n## 函数中的局部变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    value = saywhat\n    print(value)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n当在函数内部修改了局部变量之后,并不会影响脚本中的变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nstr = \"hello world\"\nprintHelloworld(str)\nprint(str)\n```\n\n## 使用global语句\n```python\n# 定义一个带参数的函数\ndef printHelloworld():\n    global saywhat # 此处不可进行初始化\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nprintHelloworld()\nprint(saywhat)\n```\n\n## 默认参数值\n我们也可以给函数参数指定默认值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str + \" \" + str1 + \" \" + str2)\n\n# 调用函数\nprintHelloworld(\"123\", str2=\"789\")\n```\n\n## 可变参数\npython函数也可以接受不定参数\n```python\ndef f(*args):\n\tprint(args)\n\nf(1)\nf(1, 2)\n```\n输出为\n```\n(1,)\n(1, 2)\n```\n\n## return返回值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str)\n    if str1==\"str1 value\" :\n        return \"nil value\"\n    print(str1)\n    print(str2)\n\n# 调用函数\nresult = printHelloworld(\"123\", str2=\"789\")\nprint(result)\n\nresult = printHelloworld(\"123\", str1=\"789\")\nprint(result)\n```\n\n## 高阶函数\n如果函数A里的参数或者返回值是另一个函数,那么函数A就是高阶函数.\n```python\ndef add5(v1):\n\treturn v1 + 5;\n\ndef add(v1, v2, add5):\n\treturn add5(v1) + add5(v2)\n\nprint(add(2, 4, add5))\n```\n\n### 内置高阶函数\n#### map()函数\n它接受一个函数和一个列表,然后遍历列表中的每个元素作用在函数参数中\n```python\nprint(map(add5, [1, 2, 3]))\n\n// 结果为\n[6, 7, 8]\n```\n#### reduce()函数\n```python\n\n```\n\n#### filter\n```python\n\n```\n\n## 闭包\n在2.7版本中必须要如下声明一个闭包\n```python\ndef outerF():\n\tcount = [10]\n\tdef innerF():\n\t\tprint(count[0])\n\t\tcount[0] = 20\n\treturn innerF\n\nf = outerF()\nf()\nf()\n```\n\n## 匿名函数\npython通过lambda表达式完成匿名函数\n```python\ndef nonameF(f, v1):\n\treturn f(v1)\n\nvalue = nonameF(lambda x: x + 1, 5)\nprint(value)\n```\n不过python只是有限的支持匿名函数, 匿名函数只能是一个表达式,而且不能拥有return,表达式的结果就是返回值\n\n## 偏函数\n偏函数就是通过`functools.partial`函数将函数A中的参数指定一个值然后返回一个新的函数\n```python\nimport functools\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfb = functools.partial(fa, var2=2, var3=3)\n\nfa(1, 2, 3)\nfb(1)\n```\n最后我们看到了相同的结果\n\n## 重定义\n我们可以对一个已经存在的函数重新定义行为\n```\ndef f(*args):\n\tprint(args)\n\n\nf = lambda : 15\nprint(f())\n\nn = f\n\ndef f():\n\treturn 20\n\nprint(n())\nprint(f())\n```\n从这一点可以验证在python中函数也是对象.\n\n## 装饰器\n装饰器本质上就是一个高阶函数，它接收一个函数作为参数，然后，返回一个新函数。\n\npython通过`@`语法内置实现装饰器\n```python\ndef fb(f):\n\tprint(\"fb\")\n\treturn f\n\n@fb\ndef fa(var1, var2, var3):\n\tprint(var1 + var2 + var3)\n\nfa(1, 2, 3)\n```\n上面这个例子每次在调用`fa`方法时都会输出一个`fb`字符串\n\n# 模块\n模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。\n\n## 使用`sys`模块\n```python\nimport sys\n\nfor argv in sys.argv :\n    print(argv)\n```\n\n使用`from..import..`, `import`可以使用`*`\n```python\nfrom sys import argv\n\nfor argvtmp in argv :\n    print(argvtmp)\n```\n\n模块的name,下面的语法输出当前模块的name\n```python\nprint(__name__)\n```\n\n## 自定义模块\n* 建立`mymodule.py`文件\n```python\n# Filename: mymodule.py\n\ndef printModuleName():\n    print(__name__)\n```\n* 建立`test_mymodule.py`文件\n```python\nimport mymodule\n\nmymodule.printModuleName()\n```\n1. 需要注意的是`mymodule.py`文件的`Filename`必须和文件名相同\n2. 如果`module`的name是`__main__`说明这个module是由用户启动的\n\n# 面向对象\n\n## self\n类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称`self`\n```python\n\n```\n\n## 创建一个类\n```python\nclass Person:\n    pass\n\np = Person()\nprint p\n```\n\n## 对象的方法\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n\np = Person()\np.run()\n```\n\n### __init__方法\n`__init__`方法在类的一个对象被建立时，马上运行\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"init\")\n\np = Person()\np.run()\n```\n\n### __del__方法\n```python\nclass Person:\n    def __init__(self):\n        print(\"init\")\n    def __del__(self):\n        print(\"__destory__\")\n\np = Person()\n```\n\n### 变量\n* 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。\n\n* 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。\n\n```python\nclass Father:\n    age = 0\n\nfather = Father()\nfather.age = 10\nFather.age = 20\nprint(father.age)\nprint(Father.age)\n```\n\n### 权限控制\n对象的属性(变量和方法)如果名字以`__`开头则不能被外部访问,但是如果名称构成形式为`__xxx__`则被称为特殊属性,是可以被外界访问的.\n\n## 继承\n```python\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n\nclass Son(Father):\n    pass\n\nson = Son()\nprint(son.name)\nson.run()\n\n```\n\n### `__init__`, `__del__`在继承中的使用\nPython不会自动调用父类的constructor\n```python\nclass Mother:\n    pass\n\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"Father init\")\n    def __del__(self):\n        print(\"Father del\")\n\nclass Son(Father, Mother):\n    def __init__(self):\n        print(\"Son init\")\n    def __del__(self):\n        print(\"Son del\")\n\nson = Son()\nprint(son.name)\nson.run()\n```\n\n# json\n使用`dump()`方法将对象序列化成json,然后使用`load()`将字符串反序列化成对象\n```python\n#-*- coding=utf-8 -*-\nimport json\n\nlist = [123, \"ad\"]\nlistJson = json.dumps(list)\nlistR = json.loads(listJson)\nprint \"列表序列化 : \" + listJson\nprint \"列表反序列化 : \" + str(listR[0])\n\ntumple = (123, \"adf\")\ntumpleJson = json.dumps(tumple)\ntumpleR = json.loads(tumpleJson)\nprint \"元组序列化 : \" + tumpleJson\nprint \"元组反序列化 : \" + str(tumpleR[1])\n\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nmapJson = json.dumps(map)\nmapR = json.loads(mapJson)\nprint \"字典序列化 : \" + mapJson\nprint \"字典反序列化 : \" + str(mapR[\"key1\"])\n\nseq = ['apple', 'mango', 'carrot', 'banana']\nseqJson = json.dumps(seq)\nseqR = json.loads(seqJson)\nprint \"序列序列化 : \" + seqJson\nprint \"序列反序列化 : \" + str(seqR[1])\n\n\ntype tumpleR[1]\ntype mapR[\"key1\"]\ntype seqR[1]\n\n```\n ","slug":"编程语言/python","published":1,"updated":"2015-10-20T01:08:37.524Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxri000u0cufu1pvrjxr"},{"date":"2015-04-07T16:00:00.000Z","title":"haskell","_content":"\n#类型系统\n\n## 数据类型\n在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.\n在Haskell中所有的数据类型都必须首字母都必须大写.\n\n在GHCI中我们可以通过`::t`命令来查看一个数据类型或者函数类型.\n\n我们可以通过下面的语法声明一个数据\n```\nvar :: 数据类型\nvar = 数据初始值\n```\n或者我们可以将这俩行并为一行\n```\nvar = 数据初始值 :: 数据类型\n```\n\n### Bool类型\n\n我们声明一个bool类型的数据,并将其初始化为`True`\n```haskell\ntrue = True :: Bool\n```\n\n\n### Char类型\n\n单字符类型\n```haskell\nchar = 'a' :: Char\n\nchar = '\\100' :: Char\n\nchar = '\\n' :: Char\n```\n\n### Int类型\n有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`-2^31~2^31-1`\n```haskell\nint = -1 :: Int\n```\n\n### Word类型\n有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`0~2^32-1`\n```haskell\nimport Data.Word\n\nword = 1 :: Word\n```\n\n### Integer类型\n任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关.\n\n当数据不指明类型时,Integer是整数的默认类型\n```haskell\ninteger = 199999 :: Integer\n```\n\n### Float类型\n单精度浮点小数\n```haskell\nfloat = 1.1 :: Float\n```\n\n### Double类型\n双精度浮点小数\n```haskell\ndouble = 1.11111 :: Double\n```\n\n### Rational类型\n有理数类型\n```haskell\nrational = 1 / 500 :: Rational\n```\n\n### String类型\n`String`的类型为`[Char]`\n```haskell\nstring = \"char array\" :: String\n```\n\n### 元组类型\n元祖用`(,)`表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组).\n\n一旦确定了元件的个数和元件的类型,那他们就是不可再变的.\n```haskell\ntuple = (123, \"abc\") :: (Int, [Char])\n```\n\n### 列表类型\n列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变.\n```haskell\nlist = [123, 8, 9] :: [Int]\n```\n\n#### 拼接列表\n采用`x:xs`的形式进行拼接列表, `x`代表一个元素, `xs`代表一个列表.\n```haskell\nlist = [123, 8, 9]\n\nnewList = 1 : list\n```\n\n#### 多维列表\n\n```haskell\nmulList = [[]]  -- 列表中套有一个列表,类似于2维数组\n\nmulList = [[[]]]\n```\n\n## 类型别名\n我们可以使用`type`关键字将复杂类型起一个简单的名字\n\n```haskell\ntype NewType = (Int, Int)\n```\n\n接下来我们就可以使用这个类型了\n```haskell\npoint :: NewType\npoint = (1, 2)\n```\n\n`type`关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型.\n\n\n## 类型类\n\n\n## Eq\n```haskell\n\n```\n\n## Ord\n```haskell\n\n```\n\n## Enum\n```haskell\n\n```\n\n## Bounded\n```haskell\n\n```\n\n## Num\n```haskell\n\n```\n\n## Show\n```haskell\n\n```\n\n\n# 表达式\n## 条件表达式\n\n```haskell\nisOne :: Int -> Bool\nisOne arg =\n    if arg == 1 then True\n    else False\n```\n\n## 情况分析表达式\n与`switch case`类似,只不过情况分析表达式没有`break`, 使用`_`作为通配符.\n```haskell\nmonth :: Int -> Int\nmonth n = case n of\n    1 -> 31\n    2 -> 28\n    12 -> 31\n    _ -> error \"error\"\n```\n\n## 守卫表达式\n\n```haskell\nabs :: Num a => a -> a\nabs n | n > 0 = n\n      | otherwise = -n\n```\n\n## 匹配模式表达式\n\n```haskell\nmonth :: Int -> Int\nmonth 1 = 31\nmonth 2 = 28\nmonth 3 = 21\nmonth 12 = 31\nmonth _ = error \"error\"\n```\n\n# 运算符\n```\n优先级9 : !!, .\n优先级8 : ^, ^^, **\n优先级7 : *, /, div,   mod, rem, quot\n优先级6 : +, -\n优先级5 : :, ++\n优先级4 : ==, /=, <, <=, >, >=,     elem, notElem\n优先级3 : &&\n优先级2 : ||\n优先级1 : >>, >>=\n优先级0 : $, $!, $!!seq\n```\n> 凡是英文运算符,其前后都必须带有`标点\n\n# 函数\n我们采用如下格式定义一个函数\n```\n函数名 :: 参数1的类型 -> 参数2的类型 -> ... -> 结果类型 (1)\n函数名 参数1 参数2 ... = 函数体                         (2)\n```\n1. 定义函数签名\n2. 定义函数\n\n下面我们举例出多种函数定义变体形式:\n\n### 带有类型类的函数定义\n\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n### 带有多个类型的函数定义\n\n```haskell\nadd :: (Show t, Int t) => t -> t -> t\nadd x y = x + y\n```\n\n#### 不带有类型类的函数定义\n```haskell\nadd :: Int -> Int -> Int\nadd x y = x + y\n```\n\n#### 函数定义\n```haskell\nadd x y = x + y :: Int\n```\n\n#### 类型自动推断的函数定义\n```haskell\nadd x y = x + y\n```\n\n#### 函数后跟'\n在函数名后加一个`'`,与原函数这代表着俩个函数.\n```haskell\nadd' :: Num t => t -> t -> t\nadd' x y = x + y\n\nadd :: Num t => t -> t -> t\nadd x y = x + y\n\n```\n\n## 函数类型\n### 柯里化函数\n当调用一个N参数的函数时, 传递M个参数(N < M),那么该参数返回的结果也是一个函数.这个过程称为柯里化.\n\n但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用.\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n当我们只向`add`函数传递一个参数`5`的时候,我们会得到下面一个这样子的函数:\n```haskell\nadd 5 y = 5 + y\n\n函数类型为:\nadd :: Num t => t -> t\n```\n\n### 偏函数\n如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数.\n\n\n### 非柯里化函数\n非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数.\n```haskell\nadd :: Num t => (t ,t) -> t\nadd (x, y) = x + y\n```\n\n### 多态函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n### 重载类型函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n## lambada\n\n## 参数绑定\n### let...in...\n`let`里定义的部分会在函数体中进行替换\n#### 替换表达式\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c =\n    let p = (a + b + c) / 2\n    in sqrt (p * (p - a) * (p - b) * (p - c))\n```\n#### 替换多个表达式\n```haskell\n\n```\n#### 替换函数\n```haskell\n\n```\n\n### where\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c = sqrt (p * (p - a) * (p - b) * (p - c))\n    where p = (a + b + c) / 2\n```\n\n#### 常用函数\n* 恒值函数id\n\n```haskell\n\n```\n* 常数函数const\n\n```haskell\n\n```\n* 参数反置函数flip\n\n```haskell\n\n```\n* 错误函数error\n\n```haskell\n\n```\n* undifine函数\n\n```haskell\n\n```\n* min/max函数\n\n```haskell\n\n```\n\n## 内置函数\n#### 列表函数\n* null\n\n```haskell\n\n```\n* length\n\n```haskell\n\n```\n* !!\n\n```haskell\n\n```\n* reverse\n\n```haskell\n\n```\n* head\n\n```haskell\n\n```\n* last\n\n```haskell\n\n```\n* tail\n\n```haskell\n\n```\n* init\n\n```haskell\n\n```\n* map\n\n\n```haskell\n\n```\n* filter\n\n```haskell\n\n```\n* take\n\n```haskell\n\n```\n* drop\n\n```haskell\n\n```\n* span\n\n```haskell\n\n```\n* break\n\n```haskell\n\n```\n* takeWhile\n\n```haskell\n\n```\n* dropWhile\n\n```haskell\n\n```\n* spiltAt\n\n```haskell\n\n```\n* repeat\n\n```haskell\n\n```\n* replicate\n\n```haskell\n\n```\n* any\n\n```haskell\n\n```\n* all\n\n```haskell\n\n```\n* elem\n\n```haskell\n\n```\n* notelem\n\n```haskell\n\n```\n* iterate\n\n```haskell\n\n```\n* until\n\n```haskell\n\n```\n* zip\n\n```haskell\n\n```\n* concat\n\n```haskell\n\n```\n* concatMap\n\n```haskell\n\n```\n\n#### 字符串\n* show\n\n```haskell\n\n```\n* read\n\n```haskell\n\n```\n* lines\n\n```haskell\n\n```\n* unlines\n\n```haskell\n\n```\n* word\n\n```haskell\n\n```\n* unword\n\n```haskell\n\n```\n\n\n#### 字符库\n* Data.char\n\n```haskell\n\n```\n\n#### 位函数库\n* Data.Bits\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n","source":"_posts/编程语言/haskell.md","raw":"category: 编程语言\ndate: 2015-04-08\ntitle: haskell\n---\n\n#类型系统\n\n## 数据类型\n在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.\n在Haskell中所有的数据类型都必须首字母都必须大写.\n\n在GHCI中我们可以通过`::t`命令来查看一个数据类型或者函数类型.\n\n我们可以通过下面的语法声明一个数据\n```\nvar :: 数据类型\nvar = 数据初始值\n```\n或者我们可以将这俩行并为一行\n```\nvar = 数据初始值 :: 数据类型\n```\n\n### Bool类型\n\n我们声明一个bool类型的数据,并将其初始化为`True`\n```haskell\ntrue = True :: Bool\n```\n\n\n### Char类型\n\n单字符类型\n```haskell\nchar = 'a' :: Char\n\nchar = '\\100' :: Char\n\nchar = '\\n' :: Char\n```\n\n### Int类型\n有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`-2^31~2^31-1`\n```haskell\nint = -1 :: Int\n```\n\n### Word类型\n有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`0~2^32-1`\n```haskell\nimport Data.Word\n\nword = 1 :: Word\n```\n\n### Integer类型\n任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关.\n\n当数据不指明类型时,Integer是整数的默认类型\n```haskell\ninteger = 199999 :: Integer\n```\n\n### Float类型\n单精度浮点小数\n```haskell\nfloat = 1.1 :: Float\n```\n\n### Double类型\n双精度浮点小数\n```haskell\ndouble = 1.11111 :: Double\n```\n\n### Rational类型\n有理数类型\n```haskell\nrational = 1 / 500 :: Rational\n```\n\n### String类型\n`String`的类型为`[Char]`\n```haskell\nstring = \"char array\" :: String\n```\n\n### 元组类型\n元祖用`(,)`表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组).\n\n一旦确定了元件的个数和元件的类型,那他们就是不可再变的.\n```haskell\ntuple = (123, \"abc\") :: (Int, [Char])\n```\n\n### 列表类型\n列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变.\n```haskell\nlist = [123, 8, 9] :: [Int]\n```\n\n#### 拼接列表\n采用`x:xs`的形式进行拼接列表, `x`代表一个元素, `xs`代表一个列表.\n```haskell\nlist = [123, 8, 9]\n\nnewList = 1 : list\n```\n\n#### 多维列表\n\n```haskell\nmulList = [[]]  -- 列表中套有一个列表,类似于2维数组\n\nmulList = [[[]]]\n```\n\n## 类型别名\n我们可以使用`type`关键字将复杂类型起一个简单的名字\n\n```haskell\ntype NewType = (Int, Int)\n```\n\n接下来我们就可以使用这个类型了\n```haskell\npoint :: NewType\npoint = (1, 2)\n```\n\n`type`关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型.\n\n\n## 类型类\n\n\n## Eq\n```haskell\n\n```\n\n## Ord\n```haskell\n\n```\n\n## Enum\n```haskell\n\n```\n\n## Bounded\n```haskell\n\n```\n\n## Num\n```haskell\n\n```\n\n## Show\n```haskell\n\n```\n\n\n# 表达式\n## 条件表达式\n\n```haskell\nisOne :: Int -> Bool\nisOne arg =\n    if arg == 1 then True\n    else False\n```\n\n## 情况分析表达式\n与`switch case`类似,只不过情况分析表达式没有`break`, 使用`_`作为通配符.\n```haskell\nmonth :: Int -> Int\nmonth n = case n of\n    1 -> 31\n    2 -> 28\n    12 -> 31\n    _ -> error \"error\"\n```\n\n## 守卫表达式\n\n```haskell\nabs :: Num a => a -> a\nabs n | n > 0 = n\n      | otherwise = -n\n```\n\n## 匹配模式表达式\n\n```haskell\nmonth :: Int -> Int\nmonth 1 = 31\nmonth 2 = 28\nmonth 3 = 21\nmonth 12 = 31\nmonth _ = error \"error\"\n```\n\n# 运算符\n```\n优先级9 : !!, .\n优先级8 : ^, ^^, **\n优先级7 : *, /, div,   mod, rem, quot\n优先级6 : +, -\n优先级5 : :, ++\n优先级4 : ==, /=, <, <=, >, >=,     elem, notElem\n优先级3 : &&\n优先级2 : ||\n优先级1 : >>, >>=\n优先级0 : $, $!, $!!seq\n```\n> 凡是英文运算符,其前后都必须带有`标点\n\n# 函数\n我们采用如下格式定义一个函数\n```\n函数名 :: 参数1的类型 -> 参数2的类型 -> ... -> 结果类型 (1)\n函数名 参数1 参数2 ... = 函数体                         (2)\n```\n1. 定义函数签名\n2. 定义函数\n\n下面我们举例出多种函数定义变体形式:\n\n### 带有类型类的函数定义\n\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n### 带有多个类型的函数定义\n\n```haskell\nadd :: (Show t, Int t) => t -> t -> t\nadd x y = x + y\n```\n\n#### 不带有类型类的函数定义\n```haskell\nadd :: Int -> Int -> Int\nadd x y = x + y\n```\n\n#### 函数定义\n```haskell\nadd x y = x + y :: Int\n```\n\n#### 类型自动推断的函数定义\n```haskell\nadd x y = x + y\n```\n\n#### 函数后跟'\n在函数名后加一个`'`,与原函数这代表着俩个函数.\n```haskell\nadd' :: Num t => t -> t -> t\nadd' x y = x + y\n\nadd :: Num t => t -> t -> t\nadd x y = x + y\n\n```\n\n## 函数类型\n### 柯里化函数\n当调用一个N参数的函数时, 传递M个参数(N < M),那么该参数返回的结果也是一个函数.这个过程称为柯里化.\n\n但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用.\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n当我们只向`add`函数传递一个参数`5`的时候,我们会得到下面一个这样子的函数:\n```haskell\nadd 5 y = 5 + y\n\n函数类型为:\nadd :: Num t => t -> t\n```\n\n### 偏函数\n如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数.\n\n\n### 非柯里化函数\n非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数.\n```haskell\nadd :: Num t => (t ,t) -> t\nadd (x, y) = x + y\n```\n\n### 多态函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n### 重载类型函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n## lambada\n\n## 参数绑定\n### let...in...\n`let`里定义的部分会在函数体中进行替换\n#### 替换表达式\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c =\n    let p = (a + b + c) / 2\n    in sqrt (p * (p - a) * (p - b) * (p - c))\n```\n#### 替换多个表达式\n```haskell\n\n```\n#### 替换函数\n```haskell\n\n```\n\n### where\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c = sqrt (p * (p - a) * (p - b) * (p - c))\n    where p = (a + b + c) / 2\n```\n\n#### 常用函数\n* 恒值函数id\n\n```haskell\n\n```\n* 常数函数const\n\n```haskell\n\n```\n* 参数反置函数flip\n\n```haskell\n\n```\n* 错误函数error\n\n```haskell\n\n```\n* undifine函数\n\n```haskell\n\n```\n* min/max函数\n\n```haskell\n\n```\n\n## 内置函数\n#### 列表函数\n* null\n\n```haskell\n\n```\n* length\n\n```haskell\n\n```\n* !!\n\n```haskell\n\n```\n* reverse\n\n```haskell\n\n```\n* head\n\n```haskell\n\n```\n* last\n\n```haskell\n\n```\n* tail\n\n```haskell\n\n```\n* init\n\n```haskell\n\n```\n* map\n\n\n```haskell\n\n```\n* filter\n\n```haskell\n\n```\n* take\n\n```haskell\n\n```\n* drop\n\n```haskell\n\n```\n* span\n\n```haskell\n\n```\n* break\n\n```haskell\n\n```\n* takeWhile\n\n```haskell\n\n```\n* dropWhile\n\n```haskell\n\n```\n* spiltAt\n\n```haskell\n\n```\n* repeat\n\n```haskell\n\n```\n* replicate\n\n```haskell\n\n```\n* any\n\n```haskell\n\n```\n* all\n\n```haskell\n\n```\n* elem\n\n```haskell\n\n```\n* notelem\n\n```haskell\n\n```\n* iterate\n\n```haskell\n\n```\n* until\n\n```haskell\n\n```\n* zip\n\n```haskell\n\n```\n* concat\n\n```haskell\n\n```\n* concatMap\n\n```haskell\n\n```\n\n#### 字符串\n* show\n\n```haskell\n\n```\n* read\n\n```haskell\n\n```\n* lines\n\n```haskell\n\n```\n* unlines\n\n```haskell\n\n```\n* word\n\n```haskell\n\n```\n* unword\n\n```haskell\n\n```\n\n\n#### 字符库\n* Data.char\n\n```haskell\n\n```\n\n#### 位函数库\n* Data.Bits\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n","slug":"编程语言/haskell","published":1,"updated":"2015-10-14T01:52:29.638Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrn000w0cufnbcyfvvy"},{"date":"2014-04-07T16:00:00.000Z","title":"groovy","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\n# 注释\n## 单行注释\n想要使用单行注释, 使用`//`就可以了.  本行中`//`后续的内容都会被认为是注释的一部分\n```groovy\n// a standalone single line comment\nprintln \"hello\" // a comment till the end of the line\n```\n\n## 多行注释\n多行注释从`/*`开始, 直到`*/`结束(跨行也包含在内)\n```groovy\n/* a standalone multiline comment\nspanning two lines */\nprintln \"hello\" /* a multiline comment starting\nat the end of a statement */\nprintln 1 /* one */ + 2 /* two */\n```\n### GroovyDoc 注释\n`GroovyDoc` 注释也是多行的, 但是它是以`/**`开始, `*/`结束定义的.\n这种注释一般用于以下情况：\n* 类型定义(包含 classes, interfaces, enums, annotations)\n* 字段和属性定义\n* 方法定义\n\n```groovy\n/**\n  * A Class description\n  */\n class Person {\n     /** the name of the person */\n     String name\n\n     /**\n      * Creates a greeting method for a certain person.\n      *\n      * @param otherPerson the person to greet\n      * @return ag reeting message\n      */\n     String greet(String otherPerson) {\n        \"Hello ${otherPerson}\"\n     }\n }\n```\n\n## Shebang line\n除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了`groovy`,并且在`PATH`里进行了配置)\n\n```groovy\n#!/usr/bin/env groovy\nprintln \"Hello from the shebang line\"\n```\n`#`字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误.\n\n# 标识符\n\n## 普通标识符\n\n标识符以一个`字母`或者`$`或者`_`开始, 不能以数字打头.\n如果以字母打头,他们在下列范围内\n\n* 'a' to 'z' (lowercase ascii letter)\n* 'A' to 'Z' (uppercase ascii letter)\n* '\\u00C0' to '\\u00D6'\n* '\\u00D8' to '\\u00F6'\n* '\\u00F8' to '\\u00FF'\n* '\\u0100' to '\\uFFFE'\n\n剩下的字符就可以包含字母或者数字了.  下面列举了一些合法的标识符：\n```groovy\ndef name\ndef item3\ndef with_underscore\ndef $dollarStart\n```\n下面是一些非法的标识符\n```groovy\ndef 3tier\ndef a+b\ndef a#b\n```\n`.`后面的关键字也是合法的标识符\n```groovy\nfoo.as\nfoo.assert\nfoo.break\nfoo.case\nfoo.catch\n```\n\n## 带引号的标识符\n\n带引号的标识符出现在`.\\`. 例如`person.name`表达式中的`name`部分能通过这俩种方式引起来`person.\"name\"`或者`person.\\'name'`. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号,\n```groovy\ndef map = [:]\n\nmap.\"an identifier with a space and double quotes\" = \"ALLOWED\"\nmap.'with-dash-signs-and-single-quotes' = \"ALLOWED\"\n\nassert map.\"an identifier with a space and double quotes\" == \"ALLOWED\"\nassert map.'with-dash-signs-and-single-quotes' == \"ALLOWED\"\n```\n\n正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的\n```groovy\nmap.'single quote'\nmap.\"double quote\"\nmap.'''triple single quote'''\nmap.\"\"\"triple double quote\"\"\"\nmap./slashy string/\nmap.$/dollar slashy string/$\n```\n\nstrings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier:\n```groovy\ndef firstname = \"Homer\"\nmap.\"Simson-${firstname}\" = \"Homer Simson\"\n\nassert map.'Simson-Homer' == \"Homer Simson\"\n```\n\n# 字符串\nText literals are represented in the form of chain of characters called strings. Groovy lets you instantiate `java.lang.String` objects, as well as GStrings (`groovy.lang.GString`) which are also called interpolated strings in other programming languages.\n\n在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化`java.lang.String`,像  GStrings (`groovy.lang.GString`)那样, (GString还被称为插值字符串)\n\n## 单引号字符\nSingle quoted strings are a series of characters surrounded by single quotes:\n\n单引号字符串是通过单引号括起来的一列字符\n```groovy\n'a single quoted string'\n```\nSingle quoted strings are plain `java.lang.String` and don’t support interpolation.\n\n单引号字符和`java.lang.String`是同一个东西, 同时它也不允许插值的出现\n## 字符串连接\n\nGroovy里所有的字符串都可以通过 `+` 连接起来\n```groovy\nassert 'ab' == 'a' + 'b'\n```\n\n## 三重单引号字符串\n\n三重单引号字符串 是通过三个单引号 包围起来的字符序列.\n```groovy\n'''a triple single quoted string'''\n```\n三重单引号字符串就是纯`java.lang.String` 而且不允许插值.\n三重单引号字符串可以多行赋值.\n```groovy\ndef aMultilineString = '''line one\nline two\nline three'''\n```\n\n如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用`String#stripIndent()` 去除掉缩进. `String#stripMargin()`方法会通过分割符从字符串的开头\n```groovy\ndef startingAndEndingWithANewline = '''\nline one\nline two\nline three\n'''\n```\n\n你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash:\n```groovy\ndef strippedFirstNewline = '''\\\nline one\nline two\nline three\n'''\n\nassert !strippedFirstNewline.startsWith('\\n')\n```\n\n### 更换特殊字符\n\n可以通过`\\`字符在`''`继续引用`'`\n```groovy\n'an escaped single quote: \\' needs a backslash'\n```\n\n当然也可以通过`\\`来引用它自身\n```groovy\n'an escaped escape character: \\\\ needs a double backslash'\n```\n\n还有一些其他的特殊字符需要`\\`来引用\n```groovy\nEscape sequence\tCharacter\n'\\t'\ttabulation\n'\\b'\tbackspace\n'\\n'\tnewline\n'\\r'\tcarriage return\n'\\f'\tformfeed\n'\\\\'\tbackslash\n'\\''\tsingle quote (for single quoted and triple single quoted strings)\n'\\\"'\tdouble quote (for double quoted and triple double quoted strings)\n```\n### Unicode 转义序列\n\n有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如`backslash`, 在u后跟4个16进制数字即可.\n\n```groovy\n'The Euro currency symbol: \\u20AC'\n```\n## 双引号包含的 string\n\n通过双引号包括起来的字符串\n```groovy\n\"a double quoted string\"\n```\nTo escape a double quote, you can use the backslash character: \"A double quote: \\\"\".\n\n当双引号字符串内没有插值(${})的时候, 那它就等同于`java.lang.String`, 当有插值的时候那么双引号字符串就是`groovy.lang.GString`的实例\n\n### String 插值\n\n任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过`${}` 或者 `$`来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式`toString()`方法,通过传递一个String参数.\n\n下面的例子展示的是字符串里的占位符定位本地变量\n```groovy\ndef name = 'Guillaume' // a plain string\ndef greeting = \"Hello ${name}\"\n\nassert greeting.toString() == 'Hello Guillaume'\n```\n\n但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式\n\n```groovy\ndef sum = \"The sum of 2 and 3 equals ${2 + 3}\"\nassert sum.toString() == 'The sum of 2 and 3 equals 5'\n```\n\n其实并不是只有表达式允许出现在`${}`表达式里. Statements 同样可以在`${}` 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在`${}`里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如`\"The sum of 1 and 2 is equal to ${def a = 1; def b = 2; a + b}\"` 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.\n除了` ${}`占位符之外, 我们也可以使用`$`标记前缀点缀表达式：\n\n```groovy\ndef person = [name: 'Guillaume', age: 36]\nassert \"$person.name is $person.age years old\" == 'Guillaume is 36 years old'\n```\n但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.\n下面给出了一个定义成数字形式的变量.\n```groovy\ndef number = 3.14\n```\n\n下面的 statement 将会抛出一个`groovy.lang.MissingPropertyException` 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性.\n```groovy\nshouldFail(MissingPropertyException) {\n    println \"$number.toString()\"\n}\n```\n你可以理解成解析器会将`\"$number.toString()\"` 解释成 `\"${number.toString}()\"`.如果你想要在GString中避免`$`或者`${}` 称为插值的话,只需要在它们前面加上`\\`即可.\n\n```groovy\nassert '${name}' == \"\\${name}\"\n```\n### 特殊插值形式-闭包表达式\n\n到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时`${→}`,这个表达式实际上就是一个闭包表达式.\n\n```groovy\ndef sParameterLessClosure = \"1 + 2 == ${-> 3}\" (1)\nassert sParameterLessClosure == '1 + 2 == 3'\n\ndef sOneParamClosure = \"1 + 2 == ${ w -> w << 3}\" (2)\nassert sOneParamClosure == '1 + 2 == 3'\n```\n1. 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参\n2. 上例中,闭包中使用了一个`java.io.StringWriter argument`参数, 我们可以使用`<<`操作符添加内容.不论任何情况, 占位符都被嵌入了闭包.\n\n上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算:\n\n```groovy\ndef number = 1 (1)\ndef eagerGString = \"value == ${number}\"\ndef lazyGString = \"value == ${ -> number }\"\n\nassert eagerGString == \"value == 1\" (2)\nassert lazyGString ==  \"value == 1\" (3)\n\nnumber = 2 (4)\nassert eagerGString == \"value == 1\" (5)\nassert lazyGString ==  \"value == 2\" (6)\n```\n1\tWe define a number variable containing 1 that we then interpolate within two GStrings, as an expression in eagerGString and as a closure in lazyGString.\n2\tWe expect the resulting string to contain the same string value of 1 for eagerGString.\n3\tSimilarily for lazyGString\n4\tThen we change the value of the variable to a new number\n5\tWith a plain interpolated expression, the value was actually bound at the time of creation of the GString.\n6\tBut with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value.\nAn embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed.\n\n1. 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中,\n2. 我们希望eagerGString 产生的字符串包含着相同的值 1\n3. 同样我们也希望lazyGString 产生的字符串包含着相同的值 1\n4. 然后我们将number改变一个值.\n5.\n6.\n\n### Inteoperability with Java\n当一个方法(不管是在Java还是在Groovy中定义的)带有一个`java.lang.String`参数, 但我们传递一个`groovy.lang.GString instance`实例, GString会自动调用toString()方法.\n\n```groovy\nString takeString(String message) {         (4)\n    assert message instanceof String        (5)\n    return message\n}\n\ndef message = \"The message is ${'hello'}\"   (1)\nassert message instanceof GString           (2)\n\ndef result = takeString(message)            (3)\nassert result instanceof String\nassert result == 'The message is hello'\n```\n1. 首先我们创建一个GString变量\n2. 然后我们检查一下声明的变量是否是GString的实例\n3. 接着我们向一个方法(参数为String类型)传递GString类型变量\n4. takeString()显式地指出了它唯一的参数为String\n5. 我们再次验证所需的参数是String 而不是GString\n\n\n### GString and String hashCodes\n\n尽管插值字符串能被用来代替`Java strings`, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是`immutable`, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的.\n\n```groovy\nassert \"one: ${1}\".hashCode() != \"one: 1\".hashCode()\n```\n\nGString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString.\n```groovy\ndef key = \"a\"\ndef m = [\"${key}\": \"letter ${key}\"]     (1)\n\nassert m[\"a\"] == null                   (2)\n```\n1. map使用一对键值被创建了出来,其key是GString类型\n2. 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode\n\n## Triple double quoted string\n\n三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样)\n```groovy\ndef name = 'Groovy'\ndef template = \"\"\"\n    Dear Mr ${name},\n\n    You're the winner of the lottery!\n\n    Yours sincerly,\n\n    Dave\n\"\"\"\n\nassert template.toString().contains('Groovy')\n```\n\n在三重双引号字符串中,不管是双引号还是单引号都不需要escaped\n\n## Slashy string\n除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的.\n\n```groovy\ndef fooPattern = /.*foo.*/\nassert fooPattern == '.*foo.*'\n```\n\n只有在`/ slashes`中需要使用\\ 来escaped\n```groovy\ndef escapeSlash = /The character \\/ is a forward slash/\nassert escapeSlash == 'The character / is a forward slash'\n```\n\nSlashy字符串也可以是多行的\n```groovy\ndef multilineSlashy = /one\n    two\n    three/\n\nassert multilineSlashy.contains('\\n')\n```\n\nSlashy字符串也可以插值形式出现(像GString一样)\n```groovy\ndef color = 'blue'\ndef interpolatedSlashy = /a ${color} car/\n\nassert interpolatedSlashy == 'a blue car'\n```\n\n下面有一些常识方面的东西需要你知道：\n`//`不会被解释为空Slashy字符串,这代表着行注释.\n\n```groovy\nassert '' == //\n```\n\n## Dollar slashy string\n\nDollar slashy字符串 通过`$/``/$` 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义\n```groovy\ndef name = \"Guillaume\"\ndef date = \"April, 1st\"\n\ndef dollarSlashy = $/\n    Hello $name,\n    today we're ${date}.\n\n    $ dollar sign\n    $$ escaped dollar sign\n    \\ backslash\n    / forward slash\n    $/ escaped forward slash\n    $/$ escaped dollar slashy string delimiter\n/$\n\nassert [\n    'Guillaume',\n    'April, 1st',\n    '$ dollar sign',\n    '$ escaped dollar sign',\n    '\\\\ backslash',\n    '/ forward slash',\n        '$/ escaped forward slash',\n        '/$ escaped dollar slashy string delimiter'\n\n        ].each { dollarSlashy.contains(it) }\n```\n\n## Characters\n\n不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量\n```groovy\nchar c1 = 'A' (1)\nassert c1 instanceof Character\n\ndef c2 = 'B' as char (2)\nassert c2 instanceof Character\n\ndef c3 = (char)'C' (3)\nassert c3 instanceof Character\n```\n1. 通过指定char类型来显式地声明一个character变量\n2. 通过操作符强制转换类型\n3. 通过强制转换成指定类型\n\n# Numbers\n\nGroovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现)\n\n## Integral literals\n\nThe integral literal types are the same as in Java:\n\n证书类型变量和Java里的一样\n\n* byte\n* char\n* short\n* int\n* long\n* java.lang.BigInteger\n\nYou can create integral numbers of those types with the following declarations:\n\n可以通过以下声明方式创建整数类型变量\n```groovy\n// primitive types\nbyte  b = 1\nchar  c = 2\nshort s = 3\nint   i = 4\nlong  l = 5\n\n// infinite precision\nBigInteger bi =  6\n```\n如果使用`def`关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型\n```groovy\ndef a = 1\nassert a instanceof Integer\n\n// Integer.MAX_VALUE\ndef b = 2147483647\nassert b instanceof Integer\n\n// Integer.MAX_VALUE + 1\ndef c = 2147483648\nassert c instanceof Long\n\n// Long.MAX_VALUE\ndef d = 9223372036854775807\nassert d instanceof Long\n\n// Long.MAX_VALUE + 1\ndef e = 9223372036854775808\nassert e instanceof BigInteger\n```\nAs well as for negative numbers:\n```groovy\ndef na = -1\nassert na instanceof Integer\n\n// Integer.MIN_VALUE\ndef nb = -2147483648\nassert nb instanceof Integer\n\n// Integer.MIN_VALUE - 1\ndef nc = -2147483649\nassert nc instanceof Long\n\n// Long.MIN_VALUE\ndef nd = -9223372036854775808\nassert nd instanceof Long\n\n// Long.MIN_VALUE - 1\ndef ne = -9223372036854775809\nassert ne instanceof BigInteger\n```\n\n### Alternative non-base 10 representations\n\n#### Binary literal\n\n在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据.\n```groovy\nint xInt = 0b10101111\nassert xInt == 175\n\nshort xShort = 0b11001001\nassert xShort == 201 as short\n\nbyte xByte = 0b11\nassert xByte == 3 as byte\n\nlong xLong = 0b101101101101\nassert xLong == 2925l\n\nBigInteger xBigInteger = 0b111100100001\nassert xBigInteger == 3873g\n\nint xNegativeInt = -0b10101111\nassert xNegativeInt == -175\n```\n#### Octal literal\n\n8进制的电话,只需要开头是0后跟要表示的8进制数即可.\n```groovy\nint xInt = 077\nassert xInt == 63\n\nshort xShort = 011\nassert xShort == 9 as short\n\nbyte xByte = 032\nassert xByte == 26 as byte\n\nlong xLong = 0246\nassert xLong == 166l\n\nBigInteger xBigInteger = 01111\nassert xBigInteger == 585g\n\nint xNegativeInt = -077\nassert xNegativeInt == -63\n```\n#### Hexadecimal literal\n\nHexadecimal numbers are specified in the typical format of 0x followed by hex digits.\n\n16进制的电话,只需要开头是0x后跟要表示的16进制数即可.\n```groovy\n\nint xInt = 0x77\nassert xInt == 119\n\nshort xShort = 0xaa\nassert xShort == 170 as short\n\nbyte xByte = 0x3a\nassert xByte == 58 as byte\n\nlong xLong = 0xffff\nassert xLong == 65535l\n\nBigInteger xBigInteger = 0xaaaa\nassert xBigInteger == 43690g\n\nDouble xDouble = new Double('0x1.0p0')\nassert xDouble == 1.0d\n\nint xNegativeInt = -0x77\nassert xNegativeInt == -119\n```\n\n## Decimal literals\n\n小数字面量和在java 里一样\n* float\n* double\n* java.lang.BigDecimal\n\n可以通过下面的方式创建小数类型的number\n```groovy\n// primitive types\nfloat  f = 1.234\ndouble d = 2.345\n\n// infinite precision\nBigDecimal bd =  3.456\n```\nDecimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent:\n\n\n```groovy\nassert 1e3  ==  1_000.0\nassert 2E4  == 20_000.0\nassert 3e+1 ==     30.0\nassert 4E-2 ==      0.04\nassert 5e-1 ==      0.5\n```\nConveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types.\n\nDecimal numbers can’t be represented using a binary, octal or hexadecimal representation.\n\n\n## Underscore in literals\n\nWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups:\n\n\n```groovy\nlong creditCardNumber = 1234_5678_9012_3456L\nlong socialSecurityNumbers = 999_99_9999L\ndouble monetaryAmount = 12_345_132.12\nlong hexBytes = 0xFF_EC_DE_5E\nlong hexWords = 0xFFEC_DE5E\nlong maxLong = 0x7fff_ffff_ffff_ffffL\nlong alsoMaxLong = 9_223_372_036_854_775_807L\nlong bytes = 0b11010010_01101001_10010100_10010010\n```\n\n## Number type suffixes\n\n我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制)\n```java\nType\t\t\tSuffix\nBigInteger\t\tG or g\nLong\t\t\tL or l\nInteger\t\t\tI or i\nBigDecimal\t\tG or g\nDouble\t\t\tD or d\nFloat\t\t\tF or f\n```\n```groovy\nassert 42I == new Integer('42')\nassert 42i == new Integer('42') // lowercase i more readable\nassert 123L == new Long(\"123\") // uppercase L more readable\nassert 2147483648 == new Long('2147483648') // Long type used, value too large for an Integer\nassert 456G == new BigInteger('456')\nassert 456g == new BigInteger('456')\nassert 123.45 == new BigDecimal('123.45') // default BigDecimal type used\nassert 1.200065D == new Double('1.200065')\nassert 1.234F == new Float('1.234')\nassert 1.23E23D == new Double('1.23E23')\nassert 0b1111L.class == Long // binary\nassert 0xFFi.class == Integer // hexadecimal\nassert 034G.class == BigInteger // octal\n```\n## Math operations\n\n尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型\n\n* byte, char, short 和 int 之间的二进制计算返回的是int类型\n* byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型\n* BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型\n* float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型\n* 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型.\n\nThe following table summarizes those rules:\n```groovy\n\n```\n\n由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字.\n\n### The case of the division operator\n\nThe division operators / (and /= for division and assignment) produce a double result if either operand is a float or double, and a BigDecimal result otherwise (when both operands are any combination of an integral type short, char, byte, int, long, BigInteger or BigDecimal).\n\nBigDecimal division is performed with the divide() method if the division is exact (ie. yielding a result that can be represented within the bounds of the same precision and scale), or using a MathContext with a precision of the maximum of the two operands' precision plus an extra precision of 10, and a scale of the maximum of 10 and the maximum of the operands' scale.\n\nFor integer division like in Java, you should use the intdiv() method, as Groovy doesn’t provide a dedicated integer division operator symbol.\n\n除法操作符`/`(和`/=`)会得到一个double类型的结果,\n\n### The case of the power operator\n\nGroovy 里有一种强大的操作符`**`, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型\n\n#### 如果exponent为小数类型\n```java\n1. 如果结果能表示为Integer类型,那就返回Integer类型\n2. 否则如果结果能表示为Long类型,那就返回Long类型\n3. 否则的话就返回Double\n```\n\n#### 如果exponent为整数类型\n```\n1. 如果exponent负数负数, 那就返回Integer, Long 或者Double,\n2. 如果exponent是正数或者0, 那就要根据base来判断了\n\tA. 如果base是 BigDecimal, 那就返回BigDecimal类型\n\tB. 如果base是 BigInteger, 那就返回BigInteger类型\n\tC. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger\n\tD. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger\n```\n\n#### 示例\n```groovy\n// base and exponent are ints and the result can be represented by an Integer\nassert    2    **   3    instanceof Integer    //  8\nassert   10    **   9    instanceof Integer    //  1_000_000_000\n\n// the base is a long, so fit the result in a Long\n// (although it could have fit in an Integer)\nassert    5L   **   2    instanceof Long       //  25\n\n// the result can't be represented as an Integer or Long, so return a BigInteger\nassert  100    **  10    instanceof BigInteger //  10e20\nassert 1234    ** 123    instanceof BigInteger //  170515806212727042875...\n\n// the base is a BigDecimal and the exponent a negative int\n// but the result can be represented as an Integer\nassert    0.5  **  -2    instanceof Integer    //  4\n\n// the base is an int, and the exponent a negative float\n// but again, the result can be represented as an Integer\nassert    1    **  -0.3f instanceof Integer    //  1\n\n// the base is an int, and the exponent a negative int\n// but the result will be calculated as a Double\n// (both base and exponent are actually converted to doubles)\nassert   10    **  -1    instanceof Double     //  0.1\n\n// the base is a BigDecimal, and the exponent is an int, so return a BigDecimal\nassert    1.2  **  10    instanceof BigDecimal //  6.1917364224\n\n// the base is a float or double, and the exponent is an int\n// but the result can only be represented as a Double value\nassert    3.4f **   5    instanceof Double     //  454.35430372146965\nassert    5.6d **   2    instanceof Double     //  31.359999999999996\n\n// the exponent is a decimal value\n// and the result can only be represented as a Double value\nassert    7.8  **   1.9  instanceof Double     //  49.542708423868476\nassert    2    **   0.1f instanceof Double     //  1.0717734636432956\n```\n\n\n# Booleans\nBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false.\n```groovy\ndef myBooleanVariable = true\nboolean untypedBooleanVar = false\nbooleanField = true\n```\ntrue and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators.\n\nIn addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.\n\n\n# IO\n## 读文件\n作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line ->\n    println line\n}\n```\n\n`eachLine`方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量:\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line, nb ->\n    println \"Line $nb: $line\"\n}\n```\n无论由于什么原因, 当`eachLine`中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效.\n\n例如, 某种情况你使用了`Reader`, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭.\n```groovy\ndef count = 0, MAXSIZE = 3\nnew File(baseDir,\"haiku.txt\").withReader { reader ->\n    while (reader.readLine()) {\n        if (++count > MAXSIZE) {\n            throw new RuntimeException('Haiku should only have 3 verses')\n        }\n    }\n}\n```\n\n如果你想要把文本文件中每一行都放进一个list中, 你可以这么做:\n```groovy\ndef list = new File(baseDir, 'haiku.txt').collect {it}\n```\n\n或者你想利用操作符将文件中每一行都添加到一个数组中:\n```groovy\ndef array = new File(baseDir, 'haiku.txt') as String[]\n```\n\n下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里:\n```groovy\nbyte[] contents = file.bytes\n```\n\n如下例,我们轻松地获得了一个输入流.\n```groovy\ndef is = new File(baseDir,'haiku.txt').newInputStream()\n// do something ...\nis.close()\n```\n\n上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法`withInputStream`, 这个方法可以帮我们自动的关闭输入流.\n```groovy\nnew File(baseDir,'haiku.txt').withInputStream { stream ->\n    // do something ...\n}\n```\n\n## 写文件\n\n有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件\n```groovy\nnew File(baseDir,'haiku.txt').withWriter('utf-8') { writer ->\n    writer.writeLine 'Into the ancient pond'\n    writer.writeLine 'A frog jumps'\n    writer.writeLine 'Water’s sound!'\n}\n```\n\n但对于一个要求很简单的需求来说,我们可以使用`<<`向文件中写\n```groovy\nnew File(baseDir,'haiku.txt') << '''Into the ancient pond\nA frog jumps\nWater’s sound!'''\n```\n\n当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节:\n```groovy\nfile.bytes = [66,22,11]\n```\n\n当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流.\n```groovy\ndef os = new File(baseDir,'data.bin').newOutputStream()\n// do something ...\nos.close()\n```\n\n同`newInputStream`一样,`newOutputStream`同样需要手动关闭, ok,你大概想到了`withOutputStream`:\n```groovy\nnew File(baseDir,'data.bin').withOutputStream { stream ->\n    // do something ...\n}\n```\n\n## 遍历文件\n\n在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作:\n```groovy\ndir.eachFile { file ->                      (1)\n    println file.name\n}\ndir.eachFileMatch(~/.*\\.txt/) { file ->     (2)\n    println file.name\n}\n```\n\n1. 在目录下的每个文件上执行闭包操作.\n2. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作.\n\n也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用`eachFileRecurse`\n```groovy\ndir.eachFileRecurse { file ->                      (1)\n    println file.name\n}\n\ndir.eachFileRecurse(FileType.FILES) { file ->      (2)\n    println file.name\n}\n```\n1. 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作\n2. 对目录里进行递归查找,但是只查找文件.\n\n```groovy\ndir.traverse { file ->\n    if (file.directory && file.name=='bin') {\n        FileVisitResult.TERMINATE                   (1)\n    } else {\n        println file.name\n        FileVisitResult.CONTINUE                    (2)\n    }\n\n}\n```\n1. 如果找到的文件是目录,且它的名字是\"dir\", 则停止遍历\n2.  打印出文件的名字,接着遍历\n\n## 序列化\n\n在java中会使用`java.io.DataOutputStream` 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化:\n```groovy\nboolean b = true\nString message = 'Hello from Groovy'\n// Serialize data into a file\nfile.withDataOutputStream { out ->\n    out.writeBoolean(b)\n    out.writeUTF(message)\n}\n// ...\n// Then read it back\nfile.withDataInputStream { input ->\n    assert input.readBoolean() == b\n    assert input.readUTF() == message\n}\n```\n\n同样,如果这个数据实例了序列化接口`Serializable`, 你可以使用 object output stream将整个数据序列化到文件:\n```groovy\nPerson p = new Person(name:'Bob', age:76)\n// Serialize data into a file\nfile.withObjectOutputStream { out ->\n    out.writeObject(p)\n}\n// ...\n// Then read it back\nfile.withObjectInputStream { input ->\n    def p2 = input.readObject()\n    assert p2.name == p.name\n    assert p2.age == p.age\n}\n```\n\n## 执行命令\n\n前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令.\n\nGroovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的`execute()`. 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令.\n```groovy\ndef process = \"ls -l\".execute()             (1)\nprintln \"Found text ${process.text}\"        (2)\n```\n1. 在外部过程(external process)执行ls命令\n2. 获得命令的输出,并输出\n\n`execute()`方法返回一个`java.lang.Process`实例, 随后选择一种输出流`in/out/err`, 同时检查`exit`值,查看是否命令执行完毕.\n\n下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出.\n```groovy\n            def process = \"ls -l\".execute()             (1)\n            process.in.eachLine { line ->               (2)\n                println line                            (3)\n            }\n            assert process instanceof Process\n        }\n    }\n\n    void testProcessConsumeOutput() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                File file = null\n                def tmpDir = b.tmp {\n                    file = 'foo.tmp'('foo')\n                }\n                assert file.exists()\n                def p = \"rm -f foo.tmp\".execute([], tmpDir)\n                p.consumeProcessOutput()\n                p.waitFor()\n                assert !file.exists()\n            }\n\n        }\n    }\n\n    void testProcessPipe() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                def proc1, proc2, proc3, proc4\n                proc1 = 'ls'.execute()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc1 | proc2 | proc3 | proc4\n                proc4.waitFor()\n                if (proc4.exitValue()) {\n                    println proc4.err.text\n                } else {\n                    println proc4.text\n                }\n\n                def sout = new StringBuilder()\n                def serr = new StringBuilder()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc4.consumeProcessOutput(sout, serr)\n                proc2 | proc3 | proc4\n                [proc2, proc3].each { it.consumeProcessErrorStream(serr) }\n                proc2.withWriter { writer ->\n                    writer << 'testfile.groovy'\n                }\n                proc4.waitForOrKill(1000)\n                println \"Standard output: $sout\"\n                println \"Standard error: $serr\"\n            }\n        }\n    }\n\n    public static class Person implements Serializable {\n        String name\n        int age\n    }\n}\n```\n\n1\texecutes the ls command in an external process\n2\tfor each line of the input stream of the process\n3\tprint the line\n1. 在外部进程中执行ls命令\n2.\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input).\n\n\nRemember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write:\n\n```groovy\ndef process = \"dir\".execute()\nprintln \"${process.text}\"\n```\n\n接着你会收到一个异常`IOException`,异常信息为`Cannot run program \"dir\": CreateProcess error=2`,系统找不到指定的文件.\n\n这是因为`dir`是内建于`windows shell(cmd.ext)`, 想要使用那个命令,你要像下面这个样操作:\n```groovy\ndef process = \"cmd /c dir\".execute()\nprintln \"${process.text}\"\n```\n\n还有,因为上述的功能是在内部使用的`java.lang.Process`, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的:\n\n> Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\nBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier.\n\n现在演示一下,如何输出进程里所有的输出(包括error stream).\n```groovy\ndef p = \"rm -f foo.tmp\".execute([], tmpDir)\np.consumeProcessOutput()\np.waitFor()\n```\n\n`consumeProcessOutput`仍然有很多对`StringBuffer`, `InputStream`, `OutputStream`等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 [GDK API for java.lang.Process](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Process.html)\n\n另外, `pipeTo`命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例:\n\n```groovy\nproc1 = 'ls'.execute()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc1 | proc2 | proc3 | proc4\nproc4.waitFor()\nif (proc4.exitValue()) {\n    println proc4.err.text\n} else {\n    println proc4.text\n}\n```\nConsuming errors\n```groovy\ndef sout = new StringBuilder()\ndef serr = new StringBuilder()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc4.consumeProcessOutput(sout, serr)\nproc2 | proc3 | proc4\n[proc2, proc3].each { it.consumeProcessErrorStream(serr) }\nproc2.withWriter { writer ->\n    writer << 'testfile.groovy'\n}\nproc4.waitForOrKill(1000)\nprintln \"Standard output: $sout\"\nprintln \"Standard error: $serr\"\n```\n\n# 集合\n\nGroovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法.\n## Lists\n\nGroovy使用了一种被`[]`括起来,值通过`,`分割的语法 定义list. Groovy list 采用的是 JDK里`java.util.List`的实现, 因为它自身并没有定义自己的集合类.\nGroovy list 的默认实现是`java.util.ArrayList`, 在后面我们可以看到其他形式的list\n\n```groovy\ndef numbers = [1, 2, 3]         (1)\n\nassert numbers instanceof List  (2)\nassert numbers.size() == 3      (3)\n```\n\n1. 我们定义了一个Number类型的List,然后将这个list分配给一个变量\n2. 判断list是 Java’s `java.util.List` interface 的实例\n3. list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素\n\n在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样：\n```groovy\ndef heterogeneous = [1, \"a\", true]  (1)\n```\n1. 我们定义了一个包含有number,string,boolean 三个类型的list\n\n在上面我们提到过, list实际上是`java.util.ArrayList`实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现\n```groovy\ndef arrayList = [1, 2, 3]\nassert arrayList instanceof java.util.ArrayList\n\ndef linkedList = [2, 3, 4] as LinkedList    (1)\nassert linkedList instanceof java.util.LinkedList\n\nLinkedList otherLinked = [3, 4, 5]          (2)\nassert otherLinked instanceof java.util.LinkedList\n```\n1. 我们使用操作符强制将类型显式地声明为`java.util.LinkedList`\n2. 我们使用显式声明方式, 将list声明为`java.util.LinkedList`\n\n我们可以通过`[]`下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用`<<`操作符向list里追加元素\n```groovy\ndef letters = ['a', 'b', 'c', 'd']\n\nassert letters[0] == 'a'     (1)\nassert letters[1] == 'b'\n\nassert letters[-1] == 'd'    (2)\nassert letters[-2] == 'c'\n\nletters[2] = 'C'             (3)\nassert letters[2] == 'C'\n\nletters << 'e'               (4)\nassert letters[ 4] == 'e'\nassert letters[-1] == 'e'\n\nassert letters[1, 3] == ['b', 'd']         (5)\nassert letters[2..4] == ['C', 'd', 'e']    (6)\n```\n\n1. 访问第一个元素(从这可以看出,list的下标是从0开始的)\n2. 通过-1 下标访问list中的最后一个元素.\n3. 使用下标对list中第三个元素重新赋值\n4. 使用`<<`向list尾部添加一个元素\n5. 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list\n6. 使用值域符来访问list中一定范围内的值.\n\n由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list\n```groovy\ndef multi = [[0, 1], [2, 3]]     (1)\nassert multi[1][0] == 2          (2)\n```\n\n1. 定义了一个包含Number类型list的list\n2. 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素)\n\n### List literals\n\n你可以像下面这样创建集合, 注意`[]`是空集合表达式.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.get(2) == 7\nassert list[2] == 7\nassert list instanceof java.util.List\n\ndef emptyList = []\nassert emptyList.size() == 0\nemptyList.add(5)\nassert emptyList.size() == 1\n```groovy\n\n每一个list表达式都是实现自`java.util.List`\n\n当然list也可以指定其具体的实现类型\n```groovy\ndef list1 = ['a', 'b', 'c']\n//construct a new list, seeded with the same items as in list1\ndef list2 = new ArrayList<String>(list1)\n\nassert list2 == list1 // == checks that each corresponding element is the same\n\n// clone() can also be called\ndef list3 = list1.clone()\nassert list3 == list1\n```\n\nlist本质上是一个有序的对象集合.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.size() == 4\nassert list.getClass() == ArrayList     // the specific kind of list being used\n\nassert list[2] == 7                     // indexing starts at 0\nassert list.getAt(2) == 7               // equivalent method to subscript operator []\nassert list.get(2) == 7                 // alternative method\n\nlist[2] = 9\nassert list == [5, 6, 9, 8,]           // trailing comma OK\n\nlist.putAt(2, 10)                       // equivalent method to [] when value being changed\nassert list == [5, 6, 10, 8]\nassert list.set(2, 11) == 10            // alternative method that returns old value\nassert list == [5, 6, 11, 8]\n\nassert ['a', 1, 'a', 'a', 2.5, 2.5f, 2.5d, 'hello', 7g, null, 9 as byte]\n//objects can be of different types; duplicates allowed\n\nassert [1, 2, 3, 4, 5][-1] == 5             // use negative indices to count from the end\nassert [1, 2, 3, 4, 5][-2] == 4\nassert [1, 2, 3, 4, 5].getAt(-2) == 4       // getAt() available with negative index...\ntry {\n    [1, 2, 3, 4, 5].get(-2)                 // but negative index not allowed with get()\n    assert false\n} catch (e) {\n    assert e instanceof ArrayIndexOutOfBoundsException\n}\n```\n\n### List as a boolean expression\n\nlist还可以计算出boolean表达式.\n```groovy\nassert ![]             // an empty list evaluates as false\n\n//all other lists, irrespective of contents, evaluate as true\nassert [1] && ['a'] && [0] && [0.0] && [false] && [null]\n```\n\n### Iterating on a list\n\n可以通过`each`, `eachWithIndex`遍历整个集合.\n```groovy\n[1, 2, 3].each {\n    println \"Item: $it\" // `it` is an implicit parameter corresponding to the current element\n}\n['a', 'b', 'c'].eachWithIndex { it, i -> // `it` is the current element, while `i` is the index\n    println \"$i: $it\"\n}\n```\n\n在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过`collect`方法实现.\n```groovy\nassert [1, 2, 3].collect { it * 2 } == [2, 4, 6]\n\n// shortcut syntax instead of collect\nassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect { it.multiply(2) }\n\ndef list = [0]\n// it is possible to give `collect` the list which collects the elements\nassert [1, 2, 3].collect(list) { it * 2 } == [0, 2, 4, 6]\nassert list == [0, 2, 4, 6]\n```\n\n### Manipulating lists\n\n#### Filtering and searching\n\n[Groovy development kit](http://www.groovy-lang.org/gdk.html)提供了许多强大有趣的方法用来强化标准集合:\n\n```groovy\nassert [1, 2, 3].find { it > 1 } == 2           // find 1st element matching criteria\nassert [1, 2, 3].findAll { it > 1 } == [2, 3]   // find all elements matching critieria\nassert ['a', 'b', 'c', 'd', 'e'].findIndexOf {      // find index of 1st element matching criteria\n    it in ['c', 'e', 'g']\n} == 2\n\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('c') == 2  // index returned\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('z') == -1 // index -1 means value not in list\nassert ['a', 'b', 'c', 'd', 'c'].lastIndexOf('c') == 4\n\nassert [1, 2, 3].every { it < 5 }               // returns true if all elements match the predicate\nassert ![1, 2, 3].every { it < 3 }\nassert [1, 2, 3].any { it > 2 }                 // returns true if any element matches the predicate\nassert ![1, 2, 3].any { it > 3 }\n\nassert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() method\nassert ['a', 'b', 'c', 'd', 'e'].sum {\n    it == 'a' ? 1 : it == 'b' ? 2 : it == 'c' ? 3 : it == 'd' ? 4 : it == 'e' ? 5 : 0\n    // custom value to use in sum\n} == 15\nassert ['a', 'b', 'c', 'd', 'e'].sum { ((char) it) - ((char) 'a') } == 10\nassert ['a', 'b', 'c', 'd', 'e'].sum() == 'abcde'\nassert [['a', 'b'], ['c', 'd']].sum() == ['a', 'b', 'c', 'd']\n\n// an initial value can be provided\nassert [].sum(1000) == 1000\nassert [1, 2, 3].sum(1000) == 1006\n\nassert [1, 2, 3].join('-') == '1-2-3'           // String joining\nassert [1, 2, 3].inject('counting: ') {\n    str, item -> str + item                     // reduce operation\n} == 'counting: 123'\nassert [1, 2, 3].inject(0) { count, item ->\n    count + item\n} == 6\n```\n\n下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子:\n```groovy\ndef list = [9, 4, 2, 10, 5]\nassert list.max() == 10\nassert list.min() == 2\n\n// we can also compare single characters, as anything comparable\nassert ['x', 'y', 'a', 'z'].min() == 'a'\n\n// we can use a closure to specify the sorting behaviour\ndef list2 = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list2.max { it.size() } == 'xyzuvw'\nassert list2.min { it.size() } == 'z'\n```\n\n在闭包里,你还可以自定义一个比较规则.\n```groovy\nComparator mc = { a, b -> a == b ? 0 : (a < b ? -1 : 1) }\n\ndef list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list.max(mc) == 11\nassert list.min(mc) == -13\n\nComparator mc2 = { a, b -> a == b ? 0 : (Math.abs(a) < Math.abs(b)) ? -1 : 1 }\n\n\nassert list.max(mc2) == -13\nassert list.min(mc2) == -1\n\nassert list.max { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -13\nassert list.min { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -1\n```\n\n#### Adding or removing elements\n\n我们可以使用`[]`去声明一个新的空list, 然后使用`<<`向list追加元素\n```groovy\ndef list = []\nassert list.empty\n\nlist << 5\nassert list.size() == 1\n\nlist << 7 << 'i' << 11\nassert list == [5, 7, 'i', 11]\n\nlist << ['m', 'o']\nassert list == [5, 7, 'i', 11, ['m', 'o']]\n\n//first item in chain of << is target list\nassert ([1, 2] << 3 << [4, 5] << 6) == [1, 2, 3, [4, 5], 6]\n\n//using leftShift is equivalent to using <<\nassert ([1, 2, 3] << 4) == ([1, 2, 3].leftShift(4))\n```groovy\nWe can add to a list in many ways:\n```groovy\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]\n// equivalent to calling the `plus` method\nassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]\n\ndef a = [1, 2, 3]\na += 4      // creates a new list and assigns it to `a`\na += [5, 6]\nassert a == [1, 2, 3, 4, 5, 6]\n\nassert [1, *[222, 333], 456] == [1, 222, 333, 456]\nassert [*[1, 2, 3]] == [1, 2, 3]\nassert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ndef list = [1, 2]\nlist.add(3)\nlist.addAll([5, 4])\nassert list == [1, 2, 3, 5, 4]\n\nlist = [1, 2]\nlist.add(1, 3) // add 3 just before index 1\nassert list == [1, 3, 2]\n\nlist.addAll(2, [5, 4]) //add [5,4] just before index 2\nassert list == [1, 3, 5, 4, 2]\n\nlist = ['a', 'b', 'z', 'e', 'u', 'v', 'g']\nlist[8] = 'x' // the [] operator is growing the list as needed\n// nulls inserted if required\nassert list == ['a', 'b', 'z', 'e', 'u', 'v', 'g', null, 'x']\n```\n\n在list中`+`的语义并没有发生变化,这是何等的重要啊~~~ 与`<<`相比, `+`会创建一个新的list,  但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题.\n\n`Groovy development kit`同样提供了很多便捷的方式从list里删除元素:\n```groovy\nassert ['a','b','c','b','b'] - 'c' == ['a','b','b','b']\nassert ['a','b','c','b','b'] - 'b' == ['a','c']\nassert ['a','b','c','b','b'] - ['b','c'] == ['a']\n\ndef list = [1,2,3,4,3,2,1]\nlist -= 3           // creates a new list by removing `3` from the original one\nassert list == [1,2,4,2,1]\nassert ( list -= [2,4] ) == [1,1]\n```\n同样,你也能通过索引的方式从list里删除元素.\n```groovy\ndef list = [1,2,3,4,5,6,2,2,1]\nassert list.remove(2) == 3          // remove the third element, and return it\nassert list == [1,2,4,5,6,2,2,1]\n```\n假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用`remove`方法.\n```groovy\ndef list= ['a','b','c','b','b']\nassert list.remove('c')             // remove 'c', and return true because element removed\nassert list.remove('b')             // remove first 'b', and return true because element removed\n\nassert ! list.remove('z')           // return false because no elements removed\nassert list == ['a','b','b']\n```\n如果你想要将list清空的话,只需要调用`clear`方法即可\n```groovy\ndef list= ['a',2,'c',4]\nlist.clear()\nassert list == []\n```\n\n#### Set operations\n\n`Groovy development kit`还包含很多逻辑运算的方法\n```groovy\nassert 'a' in ['a','b','c']             // returns true if an element belongs to the list\nassert ['a','b','c'].contains('a')      // equivalent to the `contains` method in Java\nassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are found\n\nassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some value\nassert [1,2,3,3,3,3,4,5].count {\n    it%2==0                             // count the number of elements which match the predicate\n} == 2\n\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]\n\nassert [1,2,3].disjoint( [4,6,9] )\nassert ![1,2,3].disjoint( [2,4,6] )\n```\n\n#### Sorting\n\nGroovy还提供了很多使用闭包比较器的排序操作\n```groovy\nassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]\n\ndef list = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list.sort {\n    it.size()\n} == ['z', 'abc', '321', 'Hello', 'xyzuvw']\n\ndef list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list2.sort { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } ==\n        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\nComparator mc = { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 }\n\n// JDK 8+ only\n// list2.sort(mc)\n// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\ndef list3 = [6, -3, 9, 2, -7, 1, 5]\n\nCollections.sort(list3)\nassert list3 == [-7, -3, 1, 2, 5, 6, 9]\n\nCollections.sort(list3, mc)\nassert list3 == [1, 2, -3, 5, 6, -7, 9]\n```\n\n#### Duplicating elements\n\n`roovy development kit`还通过重载操作符的方式, 内部提供了一些方法进行list元素复制.\n```groovy\nassert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]\nassert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]\nassert Collections.nCopies(3, 'b') == ['b', 'b', 'b']\n\n// nCopies from the JDK has different semantics than multiply for lists\nassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2]\n```\n\n## Arrays\n\nGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型\n```groovy\nString[] arrStr = ['Ananas', 'Banana', 'Kiwi']  (1)\n\nassert arrStr instanceof String[]    (2)\nassert !(arrStr instanceof List)\n\ndef numArr = [1, 2, 3] as int[]      (3)\n\nassert numArr instanceof int[]       (4)\nassert numArr.size() == 3\n```\n\n1. 使用显式变量类型定义了一个字符串数组\n2. 断言刚才创建的数组是否是string类型\n3. 使用操作符定义一个int数组\n4. 断言刚才创建的数组是否是int类型\n\n我们也可以创建出一个多维数组\n```groovy\ndef matrix3 = new Integer[3][3]         (1)\nassert matrix3.size() == 3\n\nInteger[][] matrix2                     (2)\nmatrix2 = [[1, 2], [3, 4]]\nassert matrix2 instanceof Integer[][]\n```\n1. 我们指定了新数组的边界\n2. 当然我们也可以不指定它的边界\n\n访问数组元素和访问list元素的方式相同\n```groovy\nString[] names = ['Cédric', 'Guillaume', 'Jochen', 'Paul']\nassert names[0] == 'Cédric'     (1)\n\nnames[2] = 'Blackdrag'          (2)\nassert names[2] == 'Blackdrag'\n```\n1\tRetrieve the first element of the array\n2\tSet the value of the third element of the array to a new value\n1. 检索数组中第一个元素\n2. 对数组中第三个元素重新赋值\n\nGroovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包\n\n## Maps\n有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被`[]`括起来, 通过`,`分割键值对, 键值通过`:`分割\n```groovy\ndef colors = [red: '#FF0000', green: '#00FF00', blue: '#0000FF']   (1)\n\nassert colors['red'] == '#FF0000'    (2)\nassert colors.green  == '#00FF00'    (3)\n\ncolors['pink'] = '#FF00FF'           (4)\ncolors.yellow  = '#FFFF00'           (5)\n\nassert colors.pink == '#FF00FF'\nassert colors['yellow'] == '#FFFF00'\n\nassert colors instanceof java.util.LinkedHashMap\n```\n\n1. 我们定义了一个string类型的代表颜色名字的数组,\n2. 然后使用下标来检索map中是否包含red这个key\n3. 我们还可以直接使用`.`来索引到某个key\n4. 我们可以使用下标向map中添加一个新的键值对\n5. 我们也可以使用`.`添加一个新的键值对\n\nGroovy创建的map类型默认的是`java.util.LinkedHashMap`\n\n当你想要访问一个不存在的key时：\n```groovy\nassert colors.unknown == null\n```\n你将检索出一个null的结果\n\n在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key：\n\n```groovy\ndef numbers = [1: 'one', 2: 'two']\n\nassert numbers[1] == 'one'\n```\n\n我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key：\n\n```groovy\ndef key = 'name'\ndef person = [key: 'Guillaume']      (1)\n\nassert !person.containsKey('name')   (2)\nassert person.containsKey('key')     (3)\n```\n1. 与`\\'Guillaume'` 关联的key实际上是`\"key\"`这个字符串, 而不是这个key的引用值`'name'`\n2. map中不包含`'name'`key\n3. 取而代之的是map中包含一个`\"key\"`的字符串\n\n你可以向map中传递一个引号字符串作为key,例如`[\"name\": \"Guillaume\"]`.\n\n```groovy\nperson = [(key): 'Guillaume']        (1)\n\nassert person.containsKey('name')    (2)\nassert !person.containsKey('key')    (3)\n```\n1\tThis time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key\n2\tThe map does contain the name key\n3\tBut the map doesn’t contain the key key as before\n1.\n2.\n3.\n\n### Map literals\n\n在Groovy中可以使用`[:]` 创建一个map.\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.get('name') == 'Gromit'\nassert map.get('id') == 1234\nassert map['name'] == 'Gromit'\nassert map['id'] == 1234\nassert map instanceof java.util.Map\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.put(\"foo\", 5)\nassert emptyMap.size() == 1\nassert emptyMap.get(\"foo\") == 5\n```\n\nMap的key默认是`string`, 例如`[a:1]`等同于`['a':1]`. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量a`put`进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用`()`key进行转义了.\n```groovy\ndef a = 'Bob'\ndef ages = [a: 43]\nassert ages['Bob'] == null // `Bob` is not found\nassert ages['a'] == 43     // because `a` is a literal!\n\nages = [(a): 43]            // now we escape `a` by using parenthesis\nassert ages['Bob'] == 43   // and the value is found!\n```\n\n通过下面的方式你可以轻松克隆一个map\n```groovy\ndef map = [\n        simple : 123,\n        complex: [a: 1, b: 2]\n]\ndef map2 = map.clone()\nassert map2.get('simple') == map.get('simple')\nassert map2.get('complex') == map.get('complex')\nmap2.get('complex').put('c', 3)\nassert map.get('complex').get('c') == 3\n```\n\n### Map property notation\n\nMaps和beans也是非常相像的, 所以你可以对map使用`get/set`操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key.\n\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.name == 'Gromit'     // can be used instead of map.get('Gromit')\nassert map.id == 1234\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.foo = 5\nassert emptyMap.size() == 1\nassert emptyMap.foo == 5\n```\n\n注意:`map.foo`总是会在map中查找key`foo`. 这意味着,\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.class == null\nassert map.get('class') == null\nassert map.getClass() == LinkedHashMap // this is probably what you want\n\nmap = [1      : 'a',\n       (true) : 'p',\n       (false): 'q',\n       (null) : 'x',\n       'null' : 'z']\nassert map.containsKey(1) // 1 is not an identifier so used as is\nassert map.true == null\nassert map.false == null\nassert map.get(true) == 'p'\nassert map.get(false) == 'q'\nassert map.null == 'z'\nassert map.get(null) == 'x'\n```\n\n### Iterating on maps\n\n`Groovy development kit`还提供了`eachWithIndex`方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的.\n```groovy\ndef map = [\n        Bob  : 42,\n        Alice: 54,\n        Max  : 33\n]\n\n// `entry` is a map entry\nmap.each { entry ->\n    println \"Name: $entry.key Age: $entry.value\"\n}\n\n// `entry` is a map entry, `i` the index in the map\nmap.eachWithIndex { entry, i ->\n    println \"$i - Name: $entry.key Age: $entry.value\"\n}\n\n// Alternatively you can use key and value directly\nmap.each { key, value ->\n    println \"Name: $key Age: $value\"\n}\n\n// Key, value and i as the index in the map\nmap.eachWithIndex { key, value, i ->\n    println \"$i - Name: $key Age: $value\"\n}\n```\n\n### Manipulating maps\n\n#### Adding or removing elements\n\n向map中添加元素你可以使用`put`方法, `下标`, `putAll`方法.\n```groovy\ndef defaults = [1: 'a', 2: 'b', 3: 'c', 4: 'd']\ndef overrides = [2: 'z', 5: 'x', 13: 'x']\n\ndef result = new LinkedHashMap(defaults)\nresult.put(15, 't')\nresult[17] = 'u'\nresult.putAll(overrides)\nassert result == [1: 'a', 2: 'z', 3: 'c', 4: 'd', 5: 'x', 13: 'x', 15: 't', 17: 'u']\n```\n\n如果想要删除map中全部的元素,可以使用`clear`方法.\n```groovy\ndef m = [1:'a', 2:'b']\nassert m.get(1) == 'a'\nm.clear()\nassert m == [:]\n```\n\n通过map字面量标记创建的map会使用`object`的`equals`方法和`hashcode`方法.\n\n还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样.\n```groovy\ndef key = 'some key'\ndef map = [:]\ndef gstringKey = \"${key.toUpperCase()}\"\nmap.put(gstringKey,'value')\nassert map.get('SOME KEY') == null\n```\n\n#### Keys, values and entries\n\n我们可以在视图中inspect`keys, values, and entries`\n```groovy\ndef map = [1:'a', 2:'b', 3:'c']\n\ndef entries = map.entrySet()\nentries.each { entry ->\n  assert entry.key in [1,2,3]\n  assert entry.value in ['a','b','c']\n}\n\ndef keys = map.keySet()\nassert keys == [1,2,3] as Set\n```\n\nMutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values.\n\n\n#### Filtering and searching\n\nThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists:\n\n```groovy\ndef people = [\n    1: [name:'Bob', age: 32, gender: 'M'],\n    2: [name:'Johnny', age: 36, gender: 'M'],\n    3: [name:'Claire', age: 21, gender: 'F'],\n    4: [name:'Amy', age: 54, gender:'F']\n]\n\ndef bob = people.find { it.value.name == 'Bob' } // find a single entry\ndef females = people.findAll { it.value.gender == 'F' }\n\n// both return entries, but you can use collect to retrieve the ages for example\ndef ageOfBob = bob.value.age\ndef agesOfFemales = females.collect {\n    it.value.age\n}\n\nassert ageOfBob == 32\nassert agesOfFemales == [21,54]\n\n// but you could also use a key/pair value as the parameters of the closures\ndef agesOfMales = people.findAll { id, person ->\n    person.gender == 'M'\n}.collect { id, person ->\n    person.age\n}\nassert agesOfMales == [32, 36]\n\n// `every` returns true if all entries match the predicate\nassert people.every { id, person ->\n    person.age > 18\n}\n\n// `any` returns true if any entry matches the predicate\n\nassert people.any { id, person ->\n    person.age == 54\n}\n```\n\n#### Grouping\n\nWe can group a list into a map using some criteria:\n\n```groovy\nassert ['a', 7, 'b', [2, 3]].groupBy {\n    it.class\n} == [(String)   : ['a', 'b'],\n      (Integer)  : [7],\n      (ArrayList): [[2, 3]]\n]\n\nassert [\n        [name: 'Clark', city: 'London'], [name: 'Sharma', city: 'London'],\n        [name: 'Maradona', city: 'LA'], [name: 'Zhang', city: 'HK'],\n        [name: 'Ali', city: 'HK'], [name: 'Liu', city: 'HK'],\n].groupBy { it.city } == [\n        London: [[name: 'Clark', city: 'London'],\n                 [name: 'Sharma', city: 'London']],\n        LA    : [[name: 'Maradona', city: 'LA']],\n        HK    : [[name: 'Zhang', city: 'HK'],\n                 [name: 'Ali', city: 'HK'],\n                 [name: 'Liu', city: 'HK']],\n]\n```\n\n## Ranges\n\nRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List.\n\nRanges defined with the .. notation are inclusive (that is the list contains the from and to value).\n\nRanges defined with the ..< notation are half-open, they include the first value but not the last value.\n\n```groovy\n// an inclusive range\ndef range = 5..8\nassert range.size() == 4\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert range.contains(8)\n\n// lets use a half-open range\nrange = 5..<8\nassert range.size() == 3\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert !range.contains(8)\n\n//get the end points of the range without using indexes\nrange = 1..10\nassert range.from == 1\nassert range.to == 10\n```\n\nNote that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value.\n\nRanges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:\n\n# Parsing and producing JSON\n\nGroovy 原生支持Groovy对象和JSON之间的转换. `groovy.json`包内的类用于JSON的序列化和解析功能\n\n# JsonSlurper\n\n`JsonSlurper`用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如`maps</code>, `lists</code>, 或者其他原生基本类型 `Integer</code>, `Double</code>, `Boolean</code>, `String`。\n\n这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如`parseText</code>, `parseFile` 等.下面这个例子中我们使用了 `parseText` 方法, 它会解析一个JSON字符串, 然后递归地将它转换成`list</code>, `map`结构. 一些其他的`parse*</code> 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样.\n\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"name\": \"John Doe\" } /* some comment */')\n\nassert object instanceof Map\nassert object.name == 'John Doe'\n```\n\n需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. `JsonSlurper`根据[ECMA-404 JSON Interchange Standard](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)定义来解析JSON, 同时支持JavaScript的注释和时间类型.\n\n除了支持maps之外, `JsonSlurper` 还支持将JSON数组解析成list的功能\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\nJSON标准上只支持下面这些原生数据类型：`string</code>, `number</code>, `object</code>, `true</code>, `false</code>, `null</code>. `JsonSlurper` 将那些JSON类型转换成Groovy类型.\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText '''\n    { \"simple\": 123,\n      \"fraction\": 123.66,\n      \"exponential\": 123e12\n    }'''\n\nassert object instanceof Map\nassert object.simple.class == Integer\nassert object.fraction.class == BigDecimal\nassert object.exponential.class == BigDecimal\n```\n\n`JsonSlurper` 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上`JsonSlurper`的结果遵循`GPath`表达式. `GPath`是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如`XmlSlurper`支持`XML` 就是其中一个例子)\n\n如果想要了解更多的内容, 你可以直接去[GPath expressions](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#gpath_expressions)看一看.\n下面给出了JSON类型与Groovy数据类型之间的对应关系.\n```groovy\nJSON\t\t\tGroovy\nstring\t\t\tjava.lang.String\nnumber\t\t\tjava.lang.BigDecimal or java.lang.Integer\nobject\t\t\tjava.util.LinkedHashMap\narray\t\t\tjava.util.ArrayList\ntrue\t\t\ttrue\nfalse\t\t\tfalse\nnull\t\t\tnull\ndate\t\t\tjava.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format\n```\n\n如果JSON中的一个值是`null</code>, `JsonSlurper`支持它转换成Groovy中的`null</code>.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。\n\n## Parser Variants\n\nGroovy 有多个`JsonSlurper` 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介:\n\n`JsonParserCharArray` 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as \"chopping\") and operates on them.\n\n\n* `JsonFastParser`解析器是`JsonParserCharArray`解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. `JsonFastParser`解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. `JsonFastParser`采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用`JsonFastParser</code>, 那么给你的建议是保持`JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制.\n\n* `JsonParserLax` 是`JsonFastParser`的一个变种实现. 它与`JsonFastParser` 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar</code>. 例如,在下面例子中它支持不带引号的字符串注释.\n\n`JsonParserUsingCharacterSource` 用于解析非常大的文件. 它使用一种称为<code>\"character windowing\"</code>的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定\n\n`JsonSlurper`的默认实现是 `JsonParserCharArray</code>.  `JsonParserType`包含了解析器种类的枚举类型:\n\n```groovy\nImplementation\t\t\t\t\tConstant\nJsonParserCharArray\t\t\t\tJsonParserType#CHAR_BUFFER\nJsonFastParser\t\t\t\t\tJsonParserType#INDEX_OVERLAY\nJsonParserLax\t\t\t\t\tJsonParserType#LAX\nJsonParserUsingCharacterSource\tJsonParserType#CHARACTER_SOURCE\n```\n\n如果想要改变解析器的实现也非常简单, 只需要通过调用`JsonSlurper#setType()</code>方法给`JsonParserType`设置上不同的值就可以了\n\n```groovy\ndef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\n## JsonOutput\n\n`JsonOutput`用于将Groovy对象序列化成JSON字符串. \n\n`JsonOutput` 重载了`toJson`静态方法. 每个不同的`toJson`方法都会接受一个不同的参数类型. \n\n`toJson`方法返回的是一个包含JSOn格式的字符串\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n```\n\n`JsonOutput`不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs</code>(一种比较老的Groovy对象)\n```groovy\nclass Person { String name }\n\ndef json = JsonOutput.toJson([ new Person(name: 'John'), new Person(name: 'Max') ])\n\nassert json == '[{\"name\":\"John\"},{\"name\":\"Max\"}]'\n```\n\n刚才那个例子中, JSON输出默认没有进行pretty输出. 因此`JsonSlurper`还提供了`prettyPrint`方法\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n\nassert JsonOutput.prettyPrint(json) == '''\\\n{\n    \"name\": \"John Doe\",\n    \"age\": 42\n}'''.stripIndent()\n```\n\n`prettyPrint`方法只接受一个String类型的字符串, 它不能和`JsonOutput`里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances.\n\n在Groovy中还可以使用`JsonBuilder</code>, `StreamingJsonBuilder`方式创建JSON. 这俩个构建起都提供了一个`DSL</code>, 当构建器生成一个JSON的时候,可以制定一个对象图.\n\n\n```groovy\n// an inclusive range\ndef range = 'a'..'d'\nassert range.size() == 4\nassert range.get(2) == 'c'\nassert range[2] == 'c'\nassert range instanceof java.util.List\nassert range.contains('a')\nassert range.contains('d')\nassert !range.contains('e')\n```\n\nYou can iterate on a range using a classic for loop:\n\n```groovy\nfor (i in 1..10) {\n    println \"Hello ${i}\"\n}\n```\n\nbut alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method:\n\n```groovy\n(1..10).each { i ->\n    println \"Hello ${i}\"\n}\n```\n\nRanges can be also used in the switch statement:\n\n```\nswitch (years) {\n    case 1..10: interestRate = 0.076; break;\n    case 11..25: interestRate = 0.052; break;\n    default: interestRate = 0.037;\n}\n```\n\n# Syntax enhancements for collections\n\n## GPath support\n\nThanks to the support of property notation for both lists and maps, Groovy provides syntactic sugar making it really easy to deal with nested collections, as illustrated in the following examples:\n\n```groovy\ndef listOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22]]\nassert listOfMaps.a == [11, 21] //GPath notation\nassert listOfMaps*.a == [11, 21] //spread dot notation\n\nlistOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22], null]\nassert listOfMaps*.a == [11, 21, null] // caters for null values\nassert listOfMaps*.a == listOfMaps.collect { it?.a } //equivalent notation\n// But this will only collect non-null values\nassert listOfMaps.a == [11,21]\n```\n\n## Spread operator\n\nThe spread operator can be used to \"inline\" a collection into another. It is syntactic sugar which often avoids calls to putAll and facilitates the realization of one-liners:\n\n```groovy\nassert [ 'z': 900,\n         *: ['a': 100, 'b': 200], 'a': 300] == ['a': 300, 'b': 200, 'z': 900]\n//spread map notation in map definition\nassert [*: [3: 3, *: [5: 5]], 7: 7] == [3: 3, 5: 5, 7: 7]\n\ndef f = { [1: 'u', 2: 'v', 3: 'w'] }\nassert [*: f(), 10: 'zz'] == [1: 'u', 10: 'zz', 2: 'v', 3: 'w']\n//spread map notation in function arguments\nf = { map -> map.c }\nassert f(*: ['a': 10, 'b': 20, 'c': 30], 'e': 50) == 30\n\nf = { m, i, j, k -> [m, i, j, k] }\n//using spread map notation with mixed unnamed and named arguments\nassert f('e': 100, *[4, 5], *: ['a': 10, 'b': 20, 'c': 30], 6) ==\n        [[\"e\": 100, \"b\": 20, \"c\": 30, \"a\": 10], 4, 5, 6]\n```\n\n### 2.4.3. The star-dot `*.' operator\n\nThe \"star-dot\" operator is a shortcut operator allowing you to call a method or a property on all elements of a collection:\n\n```groovy\nassert [1, 3, 5] == ['a', 'few', 'words']*.size()\n\nclass Person {\n    String name\n    int age\n}\ndef persons = [new Person(name:'Hugo', age:17), new Person(name:'Sandra',age:19)]\nassert [17, 19] == persons*.age\n```\n\n## Slicing with the subscript operator\n\nYou can index into lists, arrays, maps using the subscript expression. It is interesting that strings are considered as special kinds of collections in that context:\n\n```groovy\ndef text = 'nice cheese gromit!'\ndef x = text[2]\n\nassert x == 'c'\nassert x.class == String\n\ndef sub = text[5..10]\nassert sub == 'cheese'\n\ndef list = [10, 11, 12, 13]\ndef answer = list[2,3]\nassert answer == [12,13]\n```\n\nNotice that you can use ranges to extract part of a collection:\n\n```groovy\nlist = 100..200\nsub = list[1, 3, 20..25, 33]\nassert sub == [101, 103, 120, 121, 122, 123, 124, 125, 133]\n```\n\nThe subscript operator can be used to update an existing collection (for collection type which are not immutable):\n\n```groovy\nlist = ['a','x','x','d']\nlist[1..2] = ['b','c']\nassert list == ['a','b','c','d']\n```\n\nIt is worth noting that negative indices are allowed, to extract more easily from the end of a collection:\n\nYou can use negative indices to count from the end of the List, array, String etc.\n\n```groovy\ntext = \"nice cheese gromit!\"\nx = text[-1]\nassert x == \"!\"\n\ndef name = text[-7..-2]\nassert name == \"gromit\"\n```\n\nEventually, if you use a backwards range (the starting index is greater than the end index), then the answer is reversed.\n\n```groovy\ntext = \"nice cheese gromit!\"\nname = text[3..1]\nassert name == \"eci\"\n```\n\n# Scripting Ant tasks\n\n虽然`Ant`只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用`build.xml`文件或者`Jelly`脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程.\n\nGroovy提供了一个辅助类`AntBuilder`帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们.\n\n`AntBuilder`通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息.\n```groovy\ndef ant = new AntBuilder()          \nant.echo('hello from Ant!')        \n```\n\n1. 创建一个`AntBuilder`实例\n2. 执行`AntBuilder`实例的echo task\n\n假设,现在你需要创建一个ZIP文件：\n```groovy\ndef ant = new AntBuilder()\nant.zip(destfile: 'sources.zip', basedir: 'src')\n```\n\n在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过`AntBuilder`拷贝一组文件.\n```groovy\n// lets just call one task\nant.echo(\"hello\")\n\n// here is an example of a block of Ant inside GroovyMarkup\nant.sequential {\n    echo(\"inside sequential\")\n    def myDir = \"target/AntTest/\"\n    mkdir(dir: myDir)\n    copy(todir: myDir) {\n        fileset(dir: \"src/test\") {\n            include(name: \"**/*.groovy\")\n        }\n    }\n    echo(\"done\")\n}\n\n// now lets do some normal Groovy again\ndef file = new File(ant.project.baseDir,\"target/AntTest/groovy/util/AntTest.groovy\")\nassert file.exists()\n```\n\n下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配.\n```groovy\n// lets create a scanner of filesets\ndef scanner = ant.fileScanner {\n    fileset(dir:\"src/test\") {\n        include(name:\"**/Ant*.groovy\")\n    }\n}\n\n// now lets iterate over\ndef found = false\nfor (f in scanner) {\n    println(\"Found file $f\")\n    found = true\n    assert f instanceof File\n    assert f.name.endsWith(\".groovy\")\n}\nassert found\n```\n\nOr execute a JUnit test:\n\n下面我们执行JUnit\n```groovy\n// lets create a scanner of filesets\nant.junit {\n    test(name:'groovy.util.SomethingThatDoesNotExist')\n}\n```\n\n现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件.\n```groovy\nant.echo(file:'Temp.java', '''\n    class Temp {\n        public static void main(String[] args) {\n            System.out.println(\"Hello\");\n        }\n    }\n''')\nant.javac(srcdir:'.', includes:'Temp.java', fork:'true')\nant.java(classpath:'.', classname:'Temp', fork:'true')\nant.echo('Done')\n```\n\n需要提及的是, `AntBuilder`是内嵌于`Gradle`中的. 你可以像在Groovy中那样, 在`Gradle`使用`AntBuilder`","source":"_posts/编程语言/groovy.md","raw":"category: 编程语言\ndate: 2014-04-08\ntitle: groovy\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\n# 注释\n## 单行注释\n想要使用单行注释, 使用`//`就可以了.  本行中`//`后续的内容都会被认为是注释的一部分\n```groovy\n// a standalone single line comment\nprintln \"hello\" // a comment till the end of the line\n```\n\n## 多行注释\n多行注释从`/*`开始, 直到`*/`结束(跨行也包含在内)\n```groovy\n/* a standalone multiline comment\nspanning two lines */\nprintln \"hello\" /* a multiline comment starting\nat the end of a statement */\nprintln 1 /* one */ + 2 /* two */\n```\n### GroovyDoc 注释\n`GroovyDoc` 注释也是多行的, 但是它是以`/**`开始, `*/`结束定义的.\n这种注释一般用于以下情况：\n* 类型定义(包含 classes, interfaces, enums, annotations)\n* 字段和属性定义\n* 方法定义\n\n```groovy\n/**\n  * A Class description\n  */\n class Person {\n     /** the name of the person */\n     String name\n\n     /**\n      * Creates a greeting method for a certain person.\n      *\n      * @param otherPerson the person to greet\n      * @return ag reeting message\n      */\n     String greet(String otherPerson) {\n        \"Hello ${otherPerson}\"\n     }\n }\n```\n\n## Shebang line\n除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了`groovy`,并且在`PATH`里进行了配置)\n\n```groovy\n#!/usr/bin/env groovy\nprintln \"Hello from the shebang line\"\n```\n`#`字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误.\n\n# 标识符\n\n## 普通标识符\n\n标识符以一个`字母`或者`$`或者`_`开始, 不能以数字打头.\n如果以字母打头,他们在下列范围内\n\n* 'a' to 'z' (lowercase ascii letter)\n* 'A' to 'Z' (uppercase ascii letter)\n* '\\u00C0' to '\\u00D6'\n* '\\u00D8' to '\\u00F6'\n* '\\u00F8' to '\\u00FF'\n* '\\u0100' to '\\uFFFE'\n\n剩下的字符就可以包含字母或者数字了.  下面列举了一些合法的标识符：\n```groovy\ndef name\ndef item3\ndef with_underscore\ndef $dollarStart\n```\n下面是一些非法的标识符\n```groovy\ndef 3tier\ndef a+b\ndef a#b\n```\n`.`后面的关键字也是合法的标识符\n```groovy\nfoo.as\nfoo.assert\nfoo.break\nfoo.case\nfoo.catch\n```\n\n## 带引号的标识符\n\n带引号的标识符出现在`.\\`. 例如`person.name`表达式中的`name`部分能通过这俩种方式引起来`person.\"name\"`或者`person.\\'name'`. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号,\n```groovy\ndef map = [:]\n\nmap.\"an identifier with a space and double quotes\" = \"ALLOWED\"\nmap.'with-dash-signs-and-single-quotes' = \"ALLOWED\"\n\nassert map.\"an identifier with a space and double quotes\" == \"ALLOWED\"\nassert map.'with-dash-signs-and-single-quotes' == \"ALLOWED\"\n```\n\n正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的\n```groovy\nmap.'single quote'\nmap.\"double quote\"\nmap.'''triple single quote'''\nmap.\"\"\"triple double quote\"\"\"\nmap./slashy string/\nmap.$/dollar slashy string/$\n```\n\nstrings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier:\n```groovy\ndef firstname = \"Homer\"\nmap.\"Simson-${firstname}\" = \"Homer Simson\"\n\nassert map.'Simson-Homer' == \"Homer Simson\"\n```\n\n# 字符串\nText literals are represented in the form of chain of characters called strings. Groovy lets you instantiate `java.lang.String` objects, as well as GStrings (`groovy.lang.GString`) which are also called interpolated strings in other programming languages.\n\n在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化`java.lang.String`,像  GStrings (`groovy.lang.GString`)那样, (GString还被称为插值字符串)\n\n## 单引号字符\nSingle quoted strings are a series of characters surrounded by single quotes:\n\n单引号字符串是通过单引号括起来的一列字符\n```groovy\n'a single quoted string'\n```\nSingle quoted strings are plain `java.lang.String` and don’t support interpolation.\n\n单引号字符和`java.lang.String`是同一个东西, 同时它也不允许插值的出现\n## 字符串连接\n\nGroovy里所有的字符串都可以通过 `+` 连接起来\n```groovy\nassert 'ab' == 'a' + 'b'\n```\n\n## 三重单引号字符串\n\n三重单引号字符串 是通过三个单引号 包围起来的字符序列.\n```groovy\n'''a triple single quoted string'''\n```\n三重单引号字符串就是纯`java.lang.String` 而且不允许插值.\n三重单引号字符串可以多行赋值.\n```groovy\ndef aMultilineString = '''line one\nline two\nline three'''\n```\n\n如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用`String#stripIndent()` 去除掉缩进. `String#stripMargin()`方法会通过分割符从字符串的开头\n```groovy\ndef startingAndEndingWithANewline = '''\nline one\nline two\nline three\n'''\n```\n\n你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash:\n```groovy\ndef strippedFirstNewline = '''\\\nline one\nline two\nline three\n'''\n\nassert !strippedFirstNewline.startsWith('\\n')\n```\n\n### 更换特殊字符\n\n可以通过`\\`字符在`''`继续引用`'`\n```groovy\n'an escaped single quote: \\' needs a backslash'\n```\n\n当然也可以通过`\\`来引用它自身\n```groovy\n'an escaped escape character: \\\\ needs a double backslash'\n```\n\n还有一些其他的特殊字符需要`\\`来引用\n```groovy\nEscape sequence\tCharacter\n'\\t'\ttabulation\n'\\b'\tbackspace\n'\\n'\tnewline\n'\\r'\tcarriage return\n'\\f'\tformfeed\n'\\\\'\tbackslash\n'\\''\tsingle quote (for single quoted and triple single quoted strings)\n'\\\"'\tdouble quote (for double quoted and triple double quoted strings)\n```\n### Unicode 转义序列\n\n有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如`backslash`, 在u后跟4个16进制数字即可.\n\n```groovy\n'The Euro currency symbol: \\u20AC'\n```\n## 双引号包含的 string\n\n通过双引号包括起来的字符串\n```groovy\n\"a double quoted string\"\n```\nTo escape a double quote, you can use the backslash character: \"A double quote: \\\"\".\n\n当双引号字符串内没有插值(${})的时候, 那它就等同于`java.lang.String`, 当有插值的时候那么双引号字符串就是`groovy.lang.GString`的实例\n\n### String 插值\n\n任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过`${}` 或者 `$`来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式`toString()`方法,通过传递一个String参数.\n\n下面的例子展示的是字符串里的占位符定位本地变量\n```groovy\ndef name = 'Guillaume' // a plain string\ndef greeting = \"Hello ${name}\"\n\nassert greeting.toString() == 'Hello Guillaume'\n```\n\n但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式\n\n```groovy\ndef sum = \"The sum of 2 and 3 equals ${2 + 3}\"\nassert sum.toString() == 'The sum of 2 and 3 equals 5'\n```\n\n其实并不是只有表达式允许出现在`${}`表达式里. Statements 同样可以在`${}` 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在`${}`里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如`\"The sum of 1 and 2 is equal to ${def a = 1; def b = 2; a + b}\"` 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.\n除了` ${}`占位符之外, 我们也可以使用`$`标记前缀点缀表达式：\n\n```groovy\ndef person = [name: 'Guillaume', age: 36]\nassert \"$person.name is $person.age years old\" == 'Guillaume is 36 years old'\n```\n但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.\n下面给出了一个定义成数字形式的变量.\n```groovy\ndef number = 3.14\n```\n\n下面的 statement 将会抛出一个`groovy.lang.MissingPropertyException` 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性.\n```groovy\nshouldFail(MissingPropertyException) {\n    println \"$number.toString()\"\n}\n```\n你可以理解成解析器会将`\"$number.toString()\"` 解释成 `\"${number.toString}()\"`.如果你想要在GString中避免`$`或者`${}` 称为插值的话,只需要在它们前面加上`\\`即可.\n\n```groovy\nassert '${name}' == \"\\${name}\"\n```\n### 特殊插值形式-闭包表达式\n\n到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时`${→}`,这个表达式实际上就是一个闭包表达式.\n\n```groovy\ndef sParameterLessClosure = \"1 + 2 == ${-> 3}\" (1)\nassert sParameterLessClosure == '1 + 2 == 3'\n\ndef sOneParamClosure = \"1 + 2 == ${ w -> w << 3}\" (2)\nassert sOneParamClosure == '1 + 2 == 3'\n```\n1. 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参\n2. 上例中,闭包中使用了一个`java.io.StringWriter argument`参数, 我们可以使用`<<`操作符添加内容.不论任何情况, 占位符都被嵌入了闭包.\n\n上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算:\n\n```groovy\ndef number = 1 (1)\ndef eagerGString = \"value == ${number}\"\ndef lazyGString = \"value == ${ -> number }\"\n\nassert eagerGString == \"value == 1\" (2)\nassert lazyGString ==  \"value == 1\" (3)\n\nnumber = 2 (4)\nassert eagerGString == \"value == 1\" (5)\nassert lazyGString ==  \"value == 2\" (6)\n```\n1\tWe define a number variable containing 1 that we then interpolate within two GStrings, as an expression in eagerGString and as a closure in lazyGString.\n2\tWe expect the resulting string to contain the same string value of 1 for eagerGString.\n3\tSimilarily for lazyGString\n4\tThen we change the value of the variable to a new number\n5\tWith a plain interpolated expression, the value was actually bound at the time of creation of the GString.\n6\tBut with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value.\nAn embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed.\n\n1. 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中,\n2. 我们希望eagerGString 产生的字符串包含着相同的值 1\n3. 同样我们也希望lazyGString 产生的字符串包含着相同的值 1\n4. 然后我们将number改变一个值.\n5.\n6.\n\n### Inteoperability with Java\n当一个方法(不管是在Java还是在Groovy中定义的)带有一个`java.lang.String`参数, 但我们传递一个`groovy.lang.GString instance`实例, GString会自动调用toString()方法.\n\n```groovy\nString takeString(String message) {         (4)\n    assert message instanceof String        (5)\n    return message\n}\n\ndef message = \"The message is ${'hello'}\"   (1)\nassert message instanceof GString           (2)\n\ndef result = takeString(message)            (3)\nassert result instanceof String\nassert result == 'The message is hello'\n```\n1. 首先我们创建一个GString变量\n2. 然后我们检查一下声明的变量是否是GString的实例\n3. 接着我们向一个方法(参数为String类型)传递GString类型变量\n4. takeString()显式地指出了它唯一的参数为String\n5. 我们再次验证所需的参数是String 而不是GString\n\n\n### GString and String hashCodes\n\n尽管插值字符串能被用来代替`Java strings`, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是`immutable`, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的.\n\n```groovy\nassert \"one: ${1}\".hashCode() != \"one: 1\".hashCode()\n```\n\nGString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString.\n```groovy\ndef key = \"a\"\ndef m = [\"${key}\": \"letter ${key}\"]     (1)\n\nassert m[\"a\"] == null                   (2)\n```\n1. map使用一对键值被创建了出来,其key是GString类型\n2. 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode\n\n## Triple double quoted string\n\n三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样)\n```groovy\ndef name = 'Groovy'\ndef template = \"\"\"\n    Dear Mr ${name},\n\n    You're the winner of the lottery!\n\n    Yours sincerly,\n\n    Dave\n\"\"\"\n\nassert template.toString().contains('Groovy')\n```\n\n在三重双引号字符串中,不管是双引号还是单引号都不需要escaped\n\n## Slashy string\n除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的.\n\n```groovy\ndef fooPattern = /.*foo.*/\nassert fooPattern == '.*foo.*'\n```\n\n只有在`/ slashes`中需要使用\\ 来escaped\n```groovy\ndef escapeSlash = /The character \\/ is a forward slash/\nassert escapeSlash == 'The character / is a forward slash'\n```\n\nSlashy字符串也可以是多行的\n```groovy\ndef multilineSlashy = /one\n    two\n    three/\n\nassert multilineSlashy.contains('\\n')\n```\n\nSlashy字符串也可以插值形式出现(像GString一样)\n```groovy\ndef color = 'blue'\ndef interpolatedSlashy = /a ${color} car/\n\nassert interpolatedSlashy == 'a blue car'\n```\n\n下面有一些常识方面的东西需要你知道：\n`//`不会被解释为空Slashy字符串,这代表着行注释.\n\n```groovy\nassert '' == //\n```\n\n## Dollar slashy string\n\nDollar slashy字符串 通过`$/``/$` 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义\n```groovy\ndef name = \"Guillaume\"\ndef date = \"April, 1st\"\n\ndef dollarSlashy = $/\n    Hello $name,\n    today we're ${date}.\n\n    $ dollar sign\n    $$ escaped dollar sign\n    \\ backslash\n    / forward slash\n    $/ escaped forward slash\n    $/$ escaped dollar slashy string delimiter\n/$\n\nassert [\n    'Guillaume',\n    'April, 1st',\n    '$ dollar sign',\n    '$ escaped dollar sign',\n    '\\\\ backslash',\n    '/ forward slash',\n        '$/ escaped forward slash',\n        '/$ escaped dollar slashy string delimiter'\n\n        ].each { dollarSlashy.contains(it) }\n```\n\n## Characters\n\n不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量\n```groovy\nchar c1 = 'A' (1)\nassert c1 instanceof Character\n\ndef c2 = 'B' as char (2)\nassert c2 instanceof Character\n\ndef c3 = (char)'C' (3)\nassert c3 instanceof Character\n```\n1. 通过指定char类型来显式地声明一个character变量\n2. 通过操作符强制转换类型\n3. 通过强制转换成指定类型\n\n# Numbers\n\nGroovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现)\n\n## Integral literals\n\nThe integral literal types are the same as in Java:\n\n证书类型变量和Java里的一样\n\n* byte\n* char\n* short\n* int\n* long\n* java.lang.BigInteger\n\nYou can create integral numbers of those types with the following declarations:\n\n可以通过以下声明方式创建整数类型变量\n```groovy\n// primitive types\nbyte  b = 1\nchar  c = 2\nshort s = 3\nint   i = 4\nlong  l = 5\n\n// infinite precision\nBigInteger bi =  6\n```\n如果使用`def`关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型\n```groovy\ndef a = 1\nassert a instanceof Integer\n\n// Integer.MAX_VALUE\ndef b = 2147483647\nassert b instanceof Integer\n\n// Integer.MAX_VALUE + 1\ndef c = 2147483648\nassert c instanceof Long\n\n// Long.MAX_VALUE\ndef d = 9223372036854775807\nassert d instanceof Long\n\n// Long.MAX_VALUE + 1\ndef e = 9223372036854775808\nassert e instanceof BigInteger\n```\nAs well as for negative numbers:\n```groovy\ndef na = -1\nassert na instanceof Integer\n\n// Integer.MIN_VALUE\ndef nb = -2147483648\nassert nb instanceof Integer\n\n// Integer.MIN_VALUE - 1\ndef nc = -2147483649\nassert nc instanceof Long\n\n// Long.MIN_VALUE\ndef nd = -9223372036854775808\nassert nd instanceof Long\n\n// Long.MIN_VALUE - 1\ndef ne = -9223372036854775809\nassert ne instanceof BigInteger\n```\n\n### Alternative non-base 10 representations\n\n#### Binary literal\n\n在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据.\n```groovy\nint xInt = 0b10101111\nassert xInt == 175\n\nshort xShort = 0b11001001\nassert xShort == 201 as short\n\nbyte xByte = 0b11\nassert xByte == 3 as byte\n\nlong xLong = 0b101101101101\nassert xLong == 2925l\n\nBigInteger xBigInteger = 0b111100100001\nassert xBigInteger == 3873g\n\nint xNegativeInt = -0b10101111\nassert xNegativeInt == -175\n```\n#### Octal literal\n\n8进制的电话,只需要开头是0后跟要表示的8进制数即可.\n```groovy\nint xInt = 077\nassert xInt == 63\n\nshort xShort = 011\nassert xShort == 9 as short\n\nbyte xByte = 032\nassert xByte == 26 as byte\n\nlong xLong = 0246\nassert xLong == 166l\n\nBigInteger xBigInteger = 01111\nassert xBigInteger == 585g\n\nint xNegativeInt = -077\nassert xNegativeInt == -63\n```\n#### Hexadecimal literal\n\nHexadecimal numbers are specified in the typical format of 0x followed by hex digits.\n\n16进制的电话,只需要开头是0x后跟要表示的16进制数即可.\n```groovy\n\nint xInt = 0x77\nassert xInt == 119\n\nshort xShort = 0xaa\nassert xShort == 170 as short\n\nbyte xByte = 0x3a\nassert xByte == 58 as byte\n\nlong xLong = 0xffff\nassert xLong == 65535l\n\nBigInteger xBigInteger = 0xaaaa\nassert xBigInteger == 43690g\n\nDouble xDouble = new Double('0x1.0p0')\nassert xDouble == 1.0d\n\nint xNegativeInt = -0x77\nassert xNegativeInt == -119\n```\n\n## Decimal literals\n\n小数字面量和在java 里一样\n* float\n* double\n* java.lang.BigDecimal\n\n可以通过下面的方式创建小数类型的number\n```groovy\n// primitive types\nfloat  f = 1.234\ndouble d = 2.345\n\n// infinite precision\nBigDecimal bd =  3.456\n```\nDecimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent:\n\n\n```groovy\nassert 1e3  ==  1_000.0\nassert 2E4  == 20_000.0\nassert 3e+1 ==     30.0\nassert 4E-2 ==      0.04\nassert 5e-1 ==      0.5\n```\nConveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types.\n\nDecimal numbers can’t be represented using a binary, octal or hexadecimal representation.\n\n\n## Underscore in literals\n\nWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups:\n\n\n```groovy\nlong creditCardNumber = 1234_5678_9012_3456L\nlong socialSecurityNumbers = 999_99_9999L\ndouble monetaryAmount = 12_345_132.12\nlong hexBytes = 0xFF_EC_DE_5E\nlong hexWords = 0xFFEC_DE5E\nlong maxLong = 0x7fff_ffff_ffff_ffffL\nlong alsoMaxLong = 9_223_372_036_854_775_807L\nlong bytes = 0b11010010_01101001_10010100_10010010\n```\n\n## Number type suffixes\n\n我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制)\n```java\nType\t\t\tSuffix\nBigInteger\t\tG or g\nLong\t\t\tL or l\nInteger\t\t\tI or i\nBigDecimal\t\tG or g\nDouble\t\t\tD or d\nFloat\t\t\tF or f\n```\n```groovy\nassert 42I == new Integer('42')\nassert 42i == new Integer('42') // lowercase i more readable\nassert 123L == new Long(\"123\") // uppercase L more readable\nassert 2147483648 == new Long('2147483648') // Long type used, value too large for an Integer\nassert 456G == new BigInteger('456')\nassert 456g == new BigInteger('456')\nassert 123.45 == new BigDecimal('123.45') // default BigDecimal type used\nassert 1.200065D == new Double('1.200065')\nassert 1.234F == new Float('1.234')\nassert 1.23E23D == new Double('1.23E23')\nassert 0b1111L.class == Long // binary\nassert 0xFFi.class == Integer // hexadecimal\nassert 034G.class == BigInteger // octal\n```\n## Math operations\n\n尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型\n\n* byte, char, short 和 int 之间的二进制计算返回的是int类型\n* byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型\n* BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型\n* float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型\n* 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型.\n\nThe following table summarizes those rules:\n```groovy\n\n```\n\n由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字.\n\n### The case of the division operator\n\nThe division operators / (and /= for division and assignment) produce a double result if either operand is a float or double, and a BigDecimal result otherwise (when both operands are any combination of an integral type short, char, byte, int, long, BigInteger or BigDecimal).\n\nBigDecimal division is performed with the divide() method if the division is exact (ie. yielding a result that can be represented within the bounds of the same precision and scale), or using a MathContext with a precision of the maximum of the two operands' precision plus an extra precision of 10, and a scale of the maximum of 10 and the maximum of the operands' scale.\n\nFor integer division like in Java, you should use the intdiv() method, as Groovy doesn’t provide a dedicated integer division operator symbol.\n\n除法操作符`/`(和`/=`)会得到一个double类型的结果,\n\n### The case of the power operator\n\nGroovy 里有一种强大的操作符`**`, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型\n\n#### 如果exponent为小数类型\n```java\n1. 如果结果能表示为Integer类型,那就返回Integer类型\n2. 否则如果结果能表示为Long类型,那就返回Long类型\n3. 否则的话就返回Double\n```\n\n#### 如果exponent为整数类型\n```\n1. 如果exponent负数负数, 那就返回Integer, Long 或者Double,\n2. 如果exponent是正数或者0, 那就要根据base来判断了\n\tA. 如果base是 BigDecimal, 那就返回BigDecimal类型\n\tB. 如果base是 BigInteger, 那就返回BigInteger类型\n\tC. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger\n\tD. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger\n```\n\n#### 示例\n```groovy\n// base and exponent are ints and the result can be represented by an Integer\nassert    2    **   3    instanceof Integer    //  8\nassert   10    **   9    instanceof Integer    //  1_000_000_000\n\n// the base is a long, so fit the result in a Long\n// (although it could have fit in an Integer)\nassert    5L   **   2    instanceof Long       //  25\n\n// the result can't be represented as an Integer or Long, so return a BigInteger\nassert  100    **  10    instanceof BigInteger //  10e20\nassert 1234    ** 123    instanceof BigInteger //  170515806212727042875...\n\n// the base is a BigDecimal and the exponent a negative int\n// but the result can be represented as an Integer\nassert    0.5  **  -2    instanceof Integer    //  4\n\n// the base is an int, and the exponent a negative float\n// but again, the result can be represented as an Integer\nassert    1    **  -0.3f instanceof Integer    //  1\n\n// the base is an int, and the exponent a negative int\n// but the result will be calculated as a Double\n// (both base and exponent are actually converted to doubles)\nassert   10    **  -1    instanceof Double     //  0.1\n\n// the base is a BigDecimal, and the exponent is an int, so return a BigDecimal\nassert    1.2  **  10    instanceof BigDecimal //  6.1917364224\n\n// the base is a float or double, and the exponent is an int\n// but the result can only be represented as a Double value\nassert    3.4f **   5    instanceof Double     //  454.35430372146965\nassert    5.6d **   2    instanceof Double     //  31.359999999999996\n\n// the exponent is a decimal value\n// and the result can only be represented as a Double value\nassert    7.8  **   1.9  instanceof Double     //  49.542708423868476\nassert    2    **   0.1f instanceof Double     //  1.0717734636432956\n```\n\n\n# Booleans\nBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false.\n```groovy\ndef myBooleanVariable = true\nboolean untypedBooleanVar = false\nbooleanField = true\n```\ntrue and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators.\n\nIn addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.\n\n\n# IO\n## 读文件\n作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line ->\n    println line\n}\n```\n\n`eachLine`方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量:\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line, nb ->\n    println \"Line $nb: $line\"\n}\n```\n无论由于什么原因, 当`eachLine`中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效.\n\n例如, 某种情况你使用了`Reader`, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭.\n```groovy\ndef count = 0, MAXSIZE = 3\nnew File(baseDir,\"haiku.txt\").withReader { reader ->\n    while (reader.readLine()) {\n        if (++count > MAXSIZE) {\n            throw new RuntimeException('Haiku should only have 3 verses')\n        }\n    }\n}\n```\n\n如果你想要把文本文件中每一行都放进一个list中, 你可以这么做:\n```groovy\ndef list = new File(baseDir, 'haiku.txt').collect {it}\n```\n\n或者你想利用操作符将文件中每一行都添加到一个数组中:\n```groovy\ndef array = new File(baseDir, 'haiku.txt') as String[]\n```\n\n下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里:\n```groovy\nbyte[] contents = file.bytes\n```\n\n如下例,我们轻松地获得了一个输入流.\n```groovy\ndef is = new File(baseDir,'haiku.txt').newInputStream()\n// do something ...\nis.close()\n```\n\n上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法`withInputStream`, 这个方法可以帮我们自动的关闭输入流.\n```groovy\nnew File(baseDir,'haiku.txt').withInputStream { stream ->\n    // do something ...\n}\n```\n\n## 写文件\n\n有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件\n```groovy\nnew File(baseDir,'haiku.txt').withWriter('utf-8') { writer ->\n    writer.writeLine 'Into the ancient pond'\n    writer.writeLine 'A frog jumps'\n    writer.writeLine 'Water’s sound!'\n}\n```\n\n但对于一个要求很简单的需求来说,我们可以使用`<<`向文件中写\n```groovy\nnew File(baseDir,'haiku.txt') << '''Into the ancient pond\nA frog jumps\nWater’s sound!'''\n```\n\n当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节:\n```groovy\nfile.bytes = [66,22,11]\n```\n\n当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流.\n```groovy\ndef os = new File(baseDir,'data.bin').newOutputStream()\n// do something ...\nos.close()\n```\n\n同`newInputStream`一样,`newOutputStream`同样需要手动关闭, ok,你大概想到了`withOutputStream`:\n```groovy\nnew File(baseDir,'data.bin').withOutputStream { stream ->\n    // do something ...\n}\n```\n\n## 遍历文件\n\n在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作:\n```groovy\ndir.eachFile { file ->                      (1)\n    println file.name\n}\ndir.eachFileMatch(~/.*\\.txt/) { file ->     (2)\n    println file.name\n}\n```\n\n1. 在目录下的每个文件上执行闭包操作.\n2. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作.\n\n也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用`eachFileRecurse`\n```groovy\ndir.eachFileRecurse { file ->                      (1)\n    println file.name\n}\n\ndir.eachFileRecurse(FileType.FILES) { file ->      (2)\n    println file.name\n}\n```\n1. 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作\n2. 对目录里进行递归查找,但是只查找文件.\n\n```groovy\ndir.traverse { file ->\n    if (file.directory && file.name=='bin') {\n        FileVisitResult.TERMINATE                   (1)\n    } else {\n        println file.name\n        FileVisitResult.CONTINUE                    (2)\n    }\n\n}\n```\n1. 如果找到的文件是目录,且它的名字是\"dir\", 则停止遍历\n2.  打印出文件的名字,接着遍历\n\n## 序列化\n\n在java中会使用`java.io.DataOutputStream` 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化:\n```groovy\nboolean b = true\nString message = 'Hello from Groovy'\n// Serialize data into a file\nfile.withDataOutputStream { out ->\n    out.writeBoolean(b)\n    out.writeUTF(message)\n}\n// ...\n// Then read it back\nfile.withDataInputStream { input ->\n    assert input.readBoolean() == b\n    assert input.readUTF() == message\n}\n```\n\n同样,如果这个数据实例了序列化接口`Serializable`, 你可以使用 object output stream将整个数据序列化到文件:\n```groovy\nPerson p = new Person(name:'Bob', age:76)\n// Serialize data into a file\nfile.withObjectOutputStream { out ->\n    out.writeObject(p)\n}\n// ...\n// Then read it back\nfile.withObjectInputStream { input ->\n    def p2 = input.readObject()\n    assert p2.name == p.name\n    assert p2.age == p.age\n}\n```\n\n## 执行命令\n\n前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令.\n\nGroovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的`execute()`. 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令.\n```groovy\ndef process = \"ls -l\".execute()             (1)\nprintln \"Found text ${process.text}\"        (2)\n```\n1. 在外部过程(external process)执行ls命令\n2. 获得命令的输出,并输出\n\n`execute()`方法返回一个`java.lang.Process`实例, 随后选择一种输出流`in/out/err`, 同时检查`exit`值,查看是否命令执行完毕.\n\n下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出.\n```groovy\n            def process = \"ls -l\".execute()             (1)\n            process.in.eachLine { line ->               (2)\n                println line                            (3)\n            }\n            assert process instanceof Process\n        }\n    }\n\n    void testProcessConsumeOutput() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                File file = null\n                def tmpDir = b.tmp {\n                    file = 'foo.tmp'('foo')\n                }\n                assert file.exists()\n                def p = \"rm -f foo.tmp\".execute([], tmpDir)\n                p.consumeProcessOutput()\n                p.waitFor()\n                assert !file.exists()\n            }\n\n        }\n    }\n\n    void testProcessPipe() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                def proc1, proc2, proc3, proc4\n                proc1 = 'ls'.execute()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc1 | proc2 | proc3 | proc4\n                proc4.waitFor()\n                if (proc4.exitValue()) {\n                    println proc4.err.text\n                } else {\n                    println proc4.text\n                }\n\n                def sout = new StringBuilder()\n                def serr = new StringBuilder()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc4.consumeProcessOutput(sout, serr)\n                proc2 | proc3 | proc4\n                [proc2, proc3].each { it.consumeProcessErrorStream(serr) }\n                proc2.withWriter { writer ->\n                    writer << 'testfile.groovy'\n                }\n                proc4.waitForOrKill(1000)\n                println \"Standard output: $sout\"\n                println \"Standard error: $serr\"\n            }\n        }\n    }\n\n    public static class Person implements Serializable {\n        String name\n        int age\n    }\n}\n```\n\n1\texecutes the ls command in an external process\n2\tfor each line of the input stream of the process\n3\tprint the line\n1. 在外部进程中执行ls命令\n2.\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input).\n\n\nRemember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write:\n\n```groovy\ndef process = \"dir\".execute()\nprintln \"${process.text}\"\n```\n\n接着你会收到一个异常`IOException`,异常信息为`Cannot run program \"dir\": CreateProcess error=2`,系统找不到指定的文件.\n\n这是因为`dir`是内建于`windows shell(cmd.ext)`, 想要使用那个命令,你要像下面这个样操作:\n```groovy\ndef process = \"cmd /c dir\".execute()\nprintln \"${process.text}\"\n```\n\n还有,因为上述的功能是在内部使用的`java.lang.Process`, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的:\n\n> Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\nBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier.\n\n现在演示一下,如何输出进程里所有的输出(包括error stream).\n```groovy\ndef p = \"rm -f foo.tmp\".execute([], tmpDir)\np.consumeProcessOutput()\np.waitFor()\n```\n\n`consumeProcessOutput`仍然有很多对`StringBuffer`, `InputStream`, `OutputStream`等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 [GDK API for java.lang.Process](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Process.html)\n\n另外, `pipeTo`命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例:\n\n```groovy\nproc1 = 'ls'.execute()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc1 | proc2 | proc3 | proc4\nproc4.waitFor()\nif (proc4.exitValue()) {\n    println proc4.err.text\n} else {\n    println proc4.text\n}\n```\nConsuming errors\n```groovy\ndef sout = new StringBuilder()\ndef serr = new StringBuilder()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc4.consumeProcessOutput(sout, serr)\nproc2 | proc3 | proc4\n[proc2, proc3].each { it.consumeProcessErrorStream(serr) }\nproc2.withWriter { writer ->\n    writer << 'testfile.groovy'\n}\nproc4.waitForOrKill(1000)\nprintln \"Standard output: $sout\"\nprintln \"Standard error: $serr\"\n```\n\n# 集合\n\nGroovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法.\n## Lists\n\nGroovy使用了一种被`[]`括起来,值通过`,`分割的语法 定义list. Groovy list 采用的是 JDK里`java.util.List`的实现, 因为它自身并没有定义自己的集合类.\nGroovy list 的默认实现是`java.util.ArrayList`, 在后面我们可以看到其他形式的list\n\n```groovy\ndef numbers = [1, 2, 3]         (1)\n\nassert numbers instanceof List  (2)\nassert numbers.size() == 3      (3)\n```\n\n1. 我们定义了一个Number类型的List,然后将这个list分配给一个变量\n2. 判断list是 Java’s `java.util.List` interface 的实例\n3. list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素\n\n在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样：\n```groovy\ndef heterogeneous = [1, \"a\", true]  (1)\n```\n1. 我们定义了一个包含有number,string,boolean 三个类型的list\n\n在上面我们提到过, list实际上是`java.util.ArrayList`实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现\n```groovy\ndef arrayList = [1, 2, 3]\nassert arrayList instanceof java.util.ArrayList\n\ndef linkedList = [2, 3, 4] as LinkedList    (1)\nassert linkedList instanceof java.util.LinkedList\n\nLinkedList otherLinked = [3, 4, 5]          (2)\nassert otherLinked instanceof java.util.LinkedList\n```\n1. 我们使用操作符强制将类型显式地声明为`java.util.LinkedList`\n2. 我们使用显式声明方式, 将list声明为`java.util.LinkedList`\n\n我们可以通过`[]`下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用`<<`操作符向list里追加元素\n```groovy\ndef letters = ['a', 'b', 'c', 'd']\n\nassert letters[0] == 'a'     (1)\nassert letters[1] == 'b'\n\nassert letters[-1] == 'd'    (2)\nassert letters[-2] == 'c'\n\nletters[2] = 'C'             (3)\nassert letters[2] == 'C'\n\nletters << 'e'               (4)\nassert letters[ 4] == 'e'\nassert letters[-1] == 'e'\n\nassert letters[1, 3] == ['b', 'd']         (5)\nassert letters[2..4] == ['C', 'd', 'e']    (6)\n```\n\n1. 访问第一个元素(从这可以看出,list的下标是从0开始的)\n2. 通过-1 下标访问list中的最后一个元素.\n3. 使用下标对list中第三个元素重新赋值\n4. 使用`<<`向list尾部添加一个元素\n5. 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list\n6. 使用值域符来访问list中一定范围内的值.\n\n由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list\n```groovy\ndef multi = [[0, 1], [2, 3]]     (1)\nassert multi[1][0] == 2          (2)\n```\n\n1. 定义了一个包含Number类型list的list\n2. 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素)\n\n### List literals\n\n你可以像下面这样创建集合, 注意`[]`是空集合表达式.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.get(2) == 7\nassert list[2] == 7\nassert list instanceof java.util.List\n\ndef emptyList = []\nassert emptyList.size() == 0\nemptyList.add(5)\nassert emptyList.size() == 1\n```groovy\n\n每一个list表达式都是实现自`java.util.List`\n\n当然list也可以指定其具体的实现类型\n```groovy\ndef list1 = ['a', 'b', 'c']\n//construct a new list, seeded with the same items as in list1\ndef list2 = new ArrayList<String>(list1)\n\nassert list2 == list1 // == checks that each corresponding element is the same\n\n// clone() can also be called\ndef list3 = list1.clone()\nassert list3 == list1\n```\n\nlist本质上是一个有序的对象集合.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.size() == 4\nassert list.getClass() == ArrayList     // the specific kind of list being used\n\nassert list[2] == 7                     // indexing starts at 0\nassert list.getAt(2) == 7               // equivalent method to subscript operator []\nassert list.get(2) == 7                 // alternative method\n\nlist[2] = 9\nassert list == [5, 6, 9, 8,]           // trailing comma OK\n\nlist.putAt(2, 10)                       // equivalent method to [] when value being changed\nassert list == [5, 6, 10, 8]\nassert list.set(2, 11) == 10            // alternative method that returns old value\nassert list == [5, 6, 11, 8]\n\nassert ['a', 1, 'a', 'a', 2.5, 2.5f, 2.5d, 'hello', 7g, null, 9 as byte]\n//objects can be of different types; duplicates allowed\n\nassert [1, 2, 3, 4, 5][-1] == 5             // use negative indices to count from the end\nassert [1, 2, 3, 4, 5][-2] == 4\nassert [1, 2, 3, 4, 5].getAt(-2) == 4       // getAt() available with negative index...\ntry {\n    [1, 2, 3, 4, 5].get(-2)                 // but negative index not allowed with get()\n    assert false\n} catch (e) {\n    assert e instanceof ArrayIndexOutOfBoundsException\n}\n```\n\n### List as a boolean expression\n\nlist还可以计算出boolean表达式.\n```groovy\nassert ![]             // an empty list evaluates as false\n\n//all other lists, irrespective of contents, evaluate as true\nassert [1] && ['a'] && [0] && [0.0] && [false] && [null]\n```\n\n### Iterating on a list\n\n可以通过`each`, `eachWithIndex`遍历整个集合.\n```groovy\n[1, 2, 3].each {\n    println \"Item: $it\" // `it` is an implicit parameter corresponding to the current element\n}\n['a', 'b', 'c'].eachWithIndex { it, i -> // `it` is the current element, while `i` is the index\n    println \"$i: $it\"\n}\n```\n\n在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过`collect`方法实现.\n```groovy\nassert [1, 2, 3].collect { it * 2 } == [2, 4, 6]\n\n// shortcut syntax instead of collect\nassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect { it.multiply(2) }\n\ndef list = [0]\n// it is possible to give `collect` the list which collects the elements\nassert [1, 2, 3].collect(list) { it * 2 } == [0, 2, 4, 6]\nassert list == [0, 2, 4, 6]\n```\n\n### Manipulating lists\n\n#### Filtering and searching\n\n[Groovy development kit](http://www.groovy-lang.org/gdk.html)提供了许多强大有趣的方法用来强化标准集合:\n\n```groovy\nassert [1, 2, 3].find { it > 1 } == 2           // find 1st element matching criteria\nassert [1, 2, 3].findAll { it > 1 } == [2, 3]   // find all elements matching critieria\nassert ['a', 'b', 'c', 'd', 'e'].findIndexOf {      // find index of 1st element matching criteria\n    it in ['c', 'e', 'g']\n} == 2\n\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('c') == 2  // index returned\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('z') == -1 // index -1 means value not in list\nassert ['a', 'b', 'c', 'd', 'c'].lastIndexOf('c') == 4\n\nassert [1, 2, 3].every { it < 5 }               // returns true if all elements match the predicate\nassert ![1, 2, 3].every { it < 3 }\nassert [1, 2, 3].any { it > 2 }                 // returns true if any element matches the predicate\nassert ![1, 2, 3].any { it > 3 }\n\nassert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() method\nassert ['a', 'b', 'c', 'd', 'e'].sum {\n    it == 'a' ? 1 : it == 'b' ? 2 : it == 'c' ? 3 : it == 'd' ? 4 : it == 'e' ? 5 : 0\n    // custom value to use in sum\n} == 15\nassert ['a', 'b', 'c', 'd', 'e'].sum { ((char) it) - ((char) 'a') } == 10\nassert ['a', 'b', 'c', 'd', 'e'].sum() == 'abcde'\nassert [['a', 'b'], ['c', 'd']].sum() == ['a', 'b', 'c', 'd']\n\n// an initial value can be provided\nassert [].sum(1000) == 1000\nassert [1, 2, 3].sum(1000) == 1006\n\nassert [1, 2, 3].join('-') == '1-2-3'           // String joining\nassert [1, 2, 3].inject('counting: ') {\n    str, item -> str + item                     // reduce operation\n} == 'counting: 123'\nassert [1, 2, 3].inject(0) { count, item ->\n    count + item\n} == 6\n```\n\n下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子:\n```groovy\ndef list = [9, 4, 2, 10, 5]\nassert list.max() == 10\nassert list.min() == 2\n\n// we can also compare single characters, as anything comparable\nassert ['x', 'y', 'a', 'z'].min() == 'a'\n\n// we can use a closure to specify the sorting behaviour\ndef list2 = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list2.max { it.size() } == 'xyzuvw'\nassert list2.min { it.size() } == 'z'\n```\n\n在闭包里,你还可以自定义一个比较规则.\n```groovy\nComparator mc = { a, b -> a == b ? 0 : (a < b ? -1 : 1) }\n\ndef list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list.max(mc) == 11\nassert list.min(mc) == -13\n\nComparator mc2 = { a, b -> a == b ? 0 : (Math.abs(a) < Math.abs(b)) ? -1 : 1 }\n\n\nassert list.max(mc2) == -13\nassert list.min(mc2) == -1\n\nassert list.max { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -13\nassert list.min { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -1\n```\n\n#### Adding or removing elements\n\n我们可以使用`[]`去声明一个新的空list, 然后使用`<<`向list追加元素\n```groovy\ndef list = []\nassert list.empty\n\nlist << 5\nassert list.size() == 1\n\nlist << 7 << 'i' << 11\nassert list == [5, 7, 'i', 11]\n\nlist << ['m', 'o']\nassert list == [5, 7, 'i', 11, ['m', 'o']]\n\n//first item in chain of << is target list\nassert ([1, 2] << 3 << [4, 5] << 6) == [1, 2, 3, [4, 5], 6]\n\n//using leftShift is equivalent to using <<\nassert ([1, 2, 3] << 4) == ([1, 2, 3].leftShift(4))\n```groovy\nWe can add to a list in many ways:\n```groovy\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]\n// equivalent to calling the `plus` method\nassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]\n\ndef a = [1, 2, 3]\na += 4      // creates a new list and assigns it to `a`\na += [5, 6]\nassert a == [1, 2, 3, 4, 5, 6]\n\nassert [1, *[222, 333], 456] == [1, 222, 333, 456]\nassert [*[1, 2, 3]] == [1, 2, 3]\nassert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ndef list = [1, 2]\nlist.add(3)\nlist.addAll([5, 4])\nassert list == [1, 2, 3, 5, 4]\n\nlist = [1, 2]\nlist.add(1, 3) // add 3 just before index 1\nassert list == [1, 3, 2]\n\nlist.addAll(2, [5, 4]) //add [5,4] just before index 2\nassert list == [1, 3, 5, 4, 2]\n\nlist = ['a', 'b', 'z', 'e', 'u', 'v', 'g']\nlist[8] = 'x' // the [] operator is growing the list as needed\n// nulls inserted if required\nassert list == ['a', 'b', 'z', 'e', 'u', 'v', 'g', null, 'x']\n```\n\n在list中`+`的语义并没有发生变化,这是何等的重要啊~~~ 与`<<`相比, `+`会创建一个新的list,  但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题.\n\n`Groovy development kit`同样提供了很多便捷的方式从list里删除元素:\n```groovy\nassert ['a','b','c','b','b'] - 'c' == ['a','b','b','b']\nassert ['a','b','c','b','b'] - 'b' == ['a','c']\nassert ['a','b','c','b','b'] - ['b','c'] == ['a']\n\ndef list = [1,2,3,4,3,2,1]\nlist -= 3           // creates a new list by removing `3` from the original one\nassert list == [1,2,4,2,1]\nassert ( list -= [2,4] ) == [1,1]\n```\n同样,你也能通过索引的方式从list里删除元素.\n```groovy\ndef list = [1,2,3,4,5,6,2,2,1]\nassert list.remove(2) == 3          // remove the third element, and return it\nassert list == [1,2,4,5,6,2,2,1]\n```\n假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用`remove`方法.\n```groovy\ndef list= ['a','b','c','b','b']\nassert list.remove('c')             // remove 'c', and return true because element removed\nassert list.remove('b')             // remove first 'b', and return true because element removed\n\nassert ! list.remove('z')           // return false because no elements removed\nassert list == ['a','b','b']\n```\n如果你想要将list清空的话,只需要调用`clear`方法即可\n```groovy\ndef list= ['a',2,'c',4]\nlist.clear()\nassert list == []\n```\n\n#### Set operations\n\n`Groovy development kit`还包含很多逻辑运算的方法\n```groovy\nassert 'a' in ['a','b','c']             // returns true if an element belongs to the list\nassert ['a','b','c'].contains('a')      // equivalent to the `contains` method in Java\nassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are found\n\nassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some value\nassert [1,2,3,3,3,3,4,5].count {\n    it%2==0                             // count the number of elements which match the predicate\n} == 2\n\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]\n\nassert [1,2,3].disjoint( [4,6,9] )\nassert ![1,2,3].disjoint( [2,4,6] )\n```\n\n#### Sorting\n\nGroovy还提供了很多使用闭包比较器的排序操作\n```groovy\nassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]\n\ndef list = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list.sort {\n    it.size()\n} == ['z', 'abc', '321', 'Hello', 'xyzuvw']\n\ndef list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list2.sort { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } ==\n        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\nComparator mc = { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 }\n\n// JDK 8+ only\n// list2.sort(mc)\n// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\ndef list3 = [6, -3, 9, 2, -7, 1, 5]\n\nCollections.sort(list3)\nassert list3 == [-7, -3, 1, 2, 5, 6, 9]\n\nCollections.sort(list3, mc)\nassert list3 == [1, 2, -3, 5, 6, -7, 9]\n```\n\n#### Duplicating elements\n\n`roovy development kit`还通过重载操作符的方式, 内部提供了一些方法进行list元素复制.\n```groovy\nassert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]\nassert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]\nassert Collections.nCopies(3, 'b') == ['b', 'b', 'b']\n\n// nCopies from the JDK has different semantics than multiply for lists\nassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2]\n```\n\n## Arrays\n\nGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型\n```groovy\nString[] arrStr = ['Ananas', 'Banana', 'Kiwi']  (1)\n\nassert arrStr instanceof String[]    (2)\nassert !(arrStr instanceof List)\n\ndef numArr = [1, 2, 3] as int[]      (3)\n\nassert numArr instanceof int[]       (4)\nassert numArr.size() == 3\n```\n\n1. 使用显式变量类型定义了一个字符串数组\n2. 断言刚才创建的数组是否是string类型\n3. 使用操作符定义一个int数组\n4. 断言刚才创建的数组是否是int类型\n\n我们也可以创建出一个多维数组\n```groovy\ndef matrix3 = new Integer[3][3]         (1)\nassert matrix3.size() == 3\n\nInteger[][] matrix2                     (2)\nmatrix2 = [[1, 2], [3, 4]]\nassert matrix2 instanceof Integer[][]\n```\n1. 我们指定了新数组的边界\n2. 当然我们也可以不指定它的边界\n\n访问数组元素和访问list元素的方式相同\n```groovy\nString[] names = ['Cédric', 'Guillaume', 'Jochen', 'Paul']\nassert names[0] == 'Cédric'     (1)\n\nnames[2] = 'Blackdrag'          (2)\nassert names[2] == 'Blackdrag'\n```\n1\tRetrieve the first element of the array\n2\tSet the value of the third element of the array to a new value\n1. 检索数组中第一个元素\n2. 对数组中第三个元素重新赋值\n\nGroovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包\n\n## Maps\n有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被`[]`括起来, 通过`,`分割键值对, 键值通过`:`分割\n```groovy\ndef colors = [red: '#FF0000', green: '#00FF00', blue: '#0000FF']   (1)\n\nassert colors['red'] == '#FF0000'    (2)\nassert colors.green  == '#00FF00'    (3)\n\ncolors['pink'] = '#FF00FF'           (4)\ncolors.yellow  = '#FFFF00'           (5)\n\nassert colors.pink == '#FF00FF'\nassert colors['yellow'] == '#FFFF00'\n\nassert colors instanceof java.util.LinkedHashMap\n```\n\n1. 我们定义了一个string类型的代表颜色名字的数组,\n2. 然后使用下标来检索map中是否包含red这个key\n3. 我们还可以直接使用`.`来索引到某个key\n4. 我们可以使用下标向map中添加一个新的键值对\n5. 我们也可以使用`.`添加一个新的键值对\n\nGroovy创建的map类型默认的是`java.util.LinkedHashMap`\n\n当你想要访问一个不存在的key时：\n```groovy\nassert colors.unknown == null\n```\n你将检索出一个null的结果\n\n在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key：\n\n```groovy\ndef numbers = [1: 'one', 2: 'two']\n\nassert numbers[1] == 'one'\n```\n\n我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key：\n\n```groovy\ndef key = 'name'\ndef person = [key: 'Guillaume']      (1)\n\nassert !person.containsKey('name')   (2)\nassert person.containsKey('key')     (3)\n```\n1. 与`\\'Guillaume'` 关联的key实际上是`\"key\"`这个字符串, 而不是这个key的引用值`'name'`\n2. map中不包含`'name'`key\n3. 取而代之的是map中包含一个`\"key\"`的字符串\n\n你可以向map中传递一个引号字符串作为key,例如`[\"name\": \"Guillaume\"]`.\n\n```groovy\nperson = [(key): 'Guillaume']        (1)\n\nassert person.containsKey('name')    (2)\nassert !person.containsKey('key')    (3)\n```\n1\tThis time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key\n2\tThe map does contain the name key\n3\tBut the map doesn’t contain the key key as before\n1.\n2.\n3.\n\n### Map literals\n\n在Groovy中可以使用`[:]` 创建一个map.\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.get('name') == 'Gromit'\nassert map.get('id') == 1234\nassert map['name'] == 'Gromit'\nassert map['id'] == 1234\nassert map instanceof java.util.Map\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.put(\"foo\", 5)\nassert emptyMap.size() == 1\nassert emptyMap.get(\"foo\") == 5\n```\n\nMap的key默认是`string`, 例如`[a:1]`等同于`['a':1]`. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量a`put`进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用`()`key进行转义了.\n```groovy\ndef a = 'Bob'\ndef ages = [a: 43]\nassert ages['Bob'] == null // `Bob` is not found\nassert ages['a'] == 43     // because `a` is a literal!\n\nages = [(a): 43]            // now we escape `a` by using parenthesis\nassert ages['Bob'] == 43   // and the value is found!\n```\n\n通过下面的方式你可以轻松克隆一个map\n```groovy\ndef map = [\n        simple : 123,\n        complex: [a: 1, b: 2]\n]\ndef map2 = map.clone()\nassert map2.get('simple') == map.get('simple')\nassert map2.get('complex') == map.get('complex')\nmap2.get('complex').put('c', 3)\nassert map.get('complex').get('c') == 3\n```\n\n### Map property notation\n\nMaps和beans也是非常相像的, 所以你可以对map使用`get/set`操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key.\n\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.name == 'Gromit'     // can be used instead of map.get('Gromit')\nassert map.id == 1234\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.foo = 5\nassert emptyMap.size() == 1\nassert emptyMap.foo == 5\n```\n\n注意:`map.foo`总是会在map中查找key`foo`. 这意味着,\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.class == null\nassert map.get('class') == null\nassert map.getClass() == LinkedHashMap // this is probably what you want\n\nmap = [1      : 'a',\n       (true) : 'p',\n       (false): 'q',\n       (null) : 'x',\n       'null' : 'z']\nassert map.containsKey(1) // 1 is not an identifier so used as is\nassert map.true == null\nassert map.false == null\nassert map.get(true) == 'p'\nassert map.get(false) == 'q'\nassert map.null == 'z'\nassert map.get(null) == 'x'\n```\n\n### Iterating on maps\n\n`Groovy development kit`还提供了`eachWithIndex`方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的.\n```groovy\ndef map = [\n        Bob  : 42,\n        Alice: 54,\n        Max  : 33\n]\n\n// `entry` is a map entry\nmap.each { entry ->\n    println \"Name: $entry.key Age: $entry.value\"\n}\n\n// `entry` is a map entry, `i` the index in the map\nmap.eachWithIndex { entry, i ->\n    println \"$i - Name: $entry.key Age: $entry.value\"\n}\n\n// Alternatively you can use key and value directly\nmap.each { key, value ->\n    println \"Name: $key Age: $value\"\n}\n\n// Key, value and i as the index in the map\nmap.eachWithIndex { key, value, i ->\n    println \"$i - Name: $key Age: $value\"\n}\n```\n\n### Manipulating maps\n\n#### Adding or removing elements\n\n向map中添加元素你可以使用`put`方法, `下标`, `putAll`方法.\n```groovy\ndef defaults = [1: 'a', 2: 'b', 3: 'c', 4: 'd']\ndef overrides = [2: 'z', 5: 'x', 13: 'x']\n\ndef result = new LinkedHashMap(defaults)\nresult.put(15, 't')\nresult[17] = 'u'\nresult.putAll(overrides)\nassert result == [1: 'a', 2: 'z', 3: 'c', 4: 'd', 5: 'x', 13: 'x', 15: 't', 17: 'u']\n```\n\n如果想要删除map中全部的元素,可以使用`clear`方法.\n```groovy\ndef m = [1:'a', 2:'b']\nassert m.get(1) == 'a'\nm.clear()\nassert m == [:]\n```\n\n通过map字面量标记创建的map会使用`object`的`equals`方法和`hashcode`方法.\n\n还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样.\n```groovy\ndef key = 'some key'\ndef map = [:]\ndef gstringKey = \"${key.toUpperCase()}\"\nmap.put(gstringKey,'value')\nassert map.get('SOME KEY') == null\n```\n\n#### Keys, values and entries\n\n我们可以在视图中inspect`keys, values, and entries`\n```groovy\ndef map = [1:'a', 2:'b', 3:'c']\n\ndef entries = map.entrySet()\nentries.each { entry ->\n  assert entry.key in [1,2,3]\n  assert entry.value in ['a','b','c']\n}\n\ndef keys = map.keySet()\nassert keys == [1,2,3] as Set\n```\n\nMutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values.\n\n\n#### Filtering and searching\n\nThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists:\n\n```groovy\ndef people = [\n    1: [name:'Bob', age: 32, gender: 'M'],\n    2: [name:'Johnny', age: 36, gender: 'M'],\n    3: [name:'Claire', age: 21, gender: 'F'],\n    4: [name:'Amy', age: 54, gender:'F']\n]\n\ndef bob = people.find { it.value.name == 'Bob' } // find a single entry\ndef females = people.findAll { it.value.gender == 'F' }\n\n// both return entries, but you can use collect to retrieve the ages for example\ndef ageOfBob = bob.value.age\ndef agesOfFemales = females.collect {\n    it.value.age\n}\n\nassert ageOfBob == 32\nassert agesOfFemales == [21,54]\n\n// but you could also use a key/pair value as the parameters of the closures\ndef agesOfMales = people.findAll { id, person ->\n    person.gender == 'M'\n}.collect { id, person ->\n    person.age\n}\nassert agesOfMales == [32, 36]\n\n// `every` returns true if all entries match the predicate\nassert people.every { id, person ->\n    person.age > 18\n}\n\n// `any` returns true if any entry matches the predicate\n\nassert people.any { id, person ->\n    person.age == 54\n}\n```\n\n#### Grouping\n\nWe can group a list into a map using some criteria:\n\n```groovy\nassert ['a', 7, 'b', [2, 3]].groupBy {\n    it.class\n} == [(String)   : ['a', 'b'],\n      (Integer)  : [7],\n      (ArrayList): [[2, 3]]\n]\n\nassert [\n        [name: 'Clark', city: 'London'], [name: 'Sharma', city: 'London'],\n        [name: 'Maradona', city: 'LA'], [name: 'Zhang', city: 'HK'],\n        [name: 'Ali', city: 'HK'], [name: 'Liu', city: 'HK'],\n].groupBy { it.city } == [\n        London: [[name: 'Clark', city: 'London'],\n                 [name: 'Sharma', city: 'London']],\n        LA    : [[name: 'Maradona', city: 'LA']],\n        HK    : [[name: 'Zhang', city: 'HK'],\n                 [name: 'Ali', city: 'HK'],\n                 [name: 'Liu', city: 'HK']],\n]\n```\n\n## Ranges\n\nRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List.\n\nRanges defined with the .. notation are inclusive (that is the list contains the from and to value).\n\nRanges defined with the ..< notation are half-open, they include the first value but not the last value.\n\n```groovy\n// an inclusive range\ndef range = 5..8\nassert range.size() == 4\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert range.contains(8)\n\n// lets use a half-open range\nrange = 5..<8\nassert range.size() == 3\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert !range.contains(8)\n\n//get the end points of the range without using indexes\nrange = 1..10\nassert range.from == 1\nassert range.to == 10\n```\n\nNote that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value.\n\nRanges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:\n\n# Parsing and producing JSON\n\nGroovy 原生支持Groovy对象和JSON之间的转换. `groovy.json`包内的类用于JSON的序列化和解析功能\n\n# JsonSlurper\n\n`JsonSlurper`用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如`maps</code>, `lists</code>, 或者其他原生基本类型 `Integer</code>, `Double</code>, `Boolean</code>, `String`。\n\n这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如`parseText</code>, `parseFile` 等.下面这个例子中我们使用了 `parseText` 方法, 它会解析一个JSON字符串, 然后递归地将它转换成`list</code>, `map`结构. 一些其他的`parse*</code> 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样.\n\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"name\": \"John Doe\" } /* some comment */')\n\nassert object instanceof Map\nassert object.name == 'John Doe'\n```\n\n需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. `JsonSlurper`根据[ECMA-404 JSON Interchange Standard](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)定义来解析JSON, 同时支持JavaScript的注释和时间类型.\n\n除了支持maps之外, `JsonSlurper` 还支持将JSON数组解析成list的功能\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\nJSON标准上只支持下面这些原生数据类型：`string</code>, `number</code>, `object</code>, `true</code>, `false</code>, `null</code>. `JsonSlurper` 将那些JSON类型转换成Groovy类型.\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText '''\n    { \"simple\": 123,\n      \"fraction\": 123.66,\n      \"exponential\": 123e12\n    }'''\n\nassert object instanceof Map\nassert object.simple.class == Integer\nassert object.fraction.class == BigDecimal\nassert object.exponential.class == BigDecimal\n```\n\n`JsonSlurper` 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上`JsonSlurper`的结果遵循`GPath`表达式. `GPath`是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如`XmlSlurper`支持`XML` 就是其中一个例子)\n\n如果想要了解更多的内容, 你可以直接去[GPath expressions](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#gpath_expressions)看一看.\n下面给出了JSON类型与Groovy数据类型之间的对应关系.\n```groovy\nJSON\t\t\tGroovy\nstring\t\t\tjava.lang.String\nnumber\t\t\tjava.lang.BigDecimal or java.lang.Integer\nobject\t\t\tjava.util.LinkedHashMap\narray\t\t\tjava.util.ArrayList\ntrue\t\t\ttrue\nfalse\t\t\tfalse\nnull\t\t\tnull\ndate\t\t\tjava.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format\n```\n\n如果JSON中的一个值是`null</code>, `JsonSlurper`支持它转换成Groovy中的`null</code>.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。\n\n## Parser Variants\n\nGroovy 有多个`JsonSlurper` 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介:\n\n`JsonParserCharArray` 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as \"chopping\") and operates on them.\n\n\n* `JsonFastParser`解析器是`JsonParserCharArray`解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. `JsonFastParser`解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. `JsonFastParser`采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用`JsonFastParser</code>, 那么给你的建议是保持`JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制.\n\n* `JsonParserLax` 是`JsonFastParser`的一个变种实现. 它与`JsonFastParser` 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar</code>. 例如,在下面例子中它支持不带引号的字符串注释.\n\n`JsonParserUsingCharacterSource` 用于解析非常大的文件. 它使用一种称为<code>\"character windowing\"</code>的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定\n\n`JsonSlurper`的默认实现是 `JsonParserCharArray</code>.  `JsonParserType`包含了解析器种类的枚举类型:\n\n```groovy\nImplementation\t\t\t\t\tConstant\nJsonParserCharArray\t\t\t\tJsonParserType#CHAR_BUFFER\nJsonFastParser\t\t\t\t\tJsonParserType#INDEX_OVERLAY\nJsonParserLax\t\t\t\t\tJsonParserType#LAX\nJsonParserUsingCharacterSource\tJsonParserType#CHARACTER_SOURCE\n```\n\n如果想要改变解析器的实现也非常简单, 只需要通过调用`JsonSlurper#setType()</code>方法给`JsonParserType`设置上不同的值就可以了\n\n```groovy\ndef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\n## JsonOutput\n\n`JsonOutput`用于将Groovy对象序列化成JSON字符串. \n\n`JsonOutput` 重载了`toJson`静态方法. 每个不同的`toJson`方法都会接受一个不同的参数类型. \n\n`toJson`方法返回的是一个包含JSOn格式的字符串\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n```\n\n`JsonOutput`不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs</code>(一种比较老的Groovy对象)\n```groovy\nclass Person { String name }\n\ndef json = JsonOutput.toJson([ new Person(name: 'John'), new Person(name: 'Max') ])\n\nassert json == '[{\"name\":\"John\"},{\"name\":\"Max\"}]'\n```\n\n刚才那个例子中, JSON输出默认没有进行pretty输出. 因此`JsonSlurper`还提供了`prettyPrint`方法\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n\nassert JsonOutput.prettyPrint(json) == '''\\\n{\n    \"name\": \"John Doe\",\n    \"age\": 42\n}'''.stripIndent()\n```\n\n`prettyPrint`方法只接受一个String类型的字符串, 它不能和`JsonOutput`里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances.\n\n在Groovy中还可以使用`JsonBuilder</code>, `StreamingJsonBuilder`方式创建JSON. 这俩个构建起都提供了一个`DSL</code>, 当构建器生成一个JSON的时候,可以制定一个对象图.\n\n\n```groovy\n// an inclusive range\ndef range = 'a'..'d'\nassert range.size() == 4\nassert range.get(2) == 'c'\nassert range[2] == 'c'\nassert range instanceof java.util.List\nassert range.contains('a')\nassert range.contains('d')\nassert !range.contains('e')\n```\n\nYou can iterate on a range using a classic for loop:\n\n```groovy\nfor (i in 1..10) {\n    println \"Hello ${i}\"\n}\n```\n\nbut alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method:\n\n```groovy\n(1..10).each { i ->\n    println \"Hello ${i}\"\n}\n```\n\nRanges can be also used in the switch statement:\n\n```\nswitch (years) {\n    case 1..10: interestRate = 0.076; break;\n    case 11..25: interestRate = 0.052; break;\n    default: interestRate = 0.037;\n}\n```\n\n# Syntax enhancements for collections\n\n## GPath support\n\nThanks to the support of property notation for both lists and maps, Groovy provides syntactic sugar making it really easy to deal with nested collections, as illustrated in the following examples:\n\n```groovy\ndef listOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22]]\nassert listOfMaps.a == [11, 21] //GPath notation\nassert listOfMaps*.a == [11, 21] //spread dot notation\n\nlistOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22], null]\nassert listOfMaps*.a == [11, 21, null] // caters for null values\nassert listOfMaps*.a == listOfMaps.collect { it?.a } //equivalent notation\n// But this will only collect non-null values\nassert listOfMaps.a == [11,21]\n```\n\n## Spread operator\n\nThe spread operator can be used to \"inline\" a collection into another. It is syntactic sugar which often avoids calls to putAll and facilitates the realization of one-liners:\n\n```groovy\nassert [ 'z': 900,\n         *: ['a': 100, 'b': 200], 'a': 300] == ['a': 300, 'b': 200, 'z': 900]\n//spread map notation in map definition\nassert [*: [3: 3, *: [5: 5]], 7: 7] == [3: 3, 5: 5, 7: 7]\n\ndef f = { [1: 'u', 2: 'v', 3: 'w'] }\nassert [*: f(), 10: 'zz'] == [1: 'u', 10: 'zz', 2: 'v', 3: 'w']\n//spread map notation in function arguments\nf = { map -> map.c }\nassert f(*: ['a': 10, 'b': 20, 'c': 30], 'e': 50) == 30\n\nf = { m, i, j, k -> [m, i, j, k] }\n//using spread map notation with mixed unnamed and named arguments\nassert f('e': 100, *[4, 5], *: ['a': 10, 'b': 20, 'c': 30], 6) ==\n        [[\"e\": 100, \"b\": 20, \"c\": 30, \"a\": 10], 4, 5, 6]\n```\n\n### 2.4.3. The star-dot `*.' operator\n\nThe \"star-dot\" operator is a shortcut operator allowing you to call a method or a property on all elements of a collection:\n\n```groovy\nassert [1, 3, 5] == ['a', 'few', 'words']*.size()\n\nclass Person {\n    String name\n    int age\n}\ndef persons = [new Person(name:'Hugo', age:17), new Person(name:'Sandra',age:19)]\nassert [17, 19] == persons*.age\n```\n\n## Slicing with the subscript operator\n\nYou can index into lists, arrays, maps using the subscript expression. It is interesting that strings are considered as special kinds of collections in that context:\n\n```groovy\ndef text = 'nice cheese gromit!'\ndef x = text[2]\n\nassert x == 'c'\nassert x.class == String\n\ndef sub = text[5..10]\nassert sub == 'cheese'\n\ndef list = [10, 11, 12, 13]\ndef answer = list[2,3]\nassert answer == [12,13]\n```\n\nNotice that you can use ranges to extract part of a collection:\n\n```groovy\nlist = 100..200\nsub = list[1, 3, 20..25, 33]\nassert sub == [101, 103, 120, 121, 122, 123, 124, 125, 133]\n```\n\nThe subscript operator can be used to update an existing collection (for collection type which are not immutable):\n\n```groovy\nlist = ['a','x','x','d']\nlist[1..2] = ['b','c']\nassert list == ['a','b','c','d']\n```\n\nIt is worth noting that negative indices are allowed, to extract more easily from the end of a collection:\n\nYou can use negative indices to count from the end of the List, array, String etc.\n\n```groovy\ntext = \"nice cheese gromit!\"\nx = text[-1]\nassert x == \"!\"\n\ndef name = text[-7..-2]\nassert name == \"gromit\"\n```\n\nEventually, if you use a backwards range (the starting index is greater than the end index), then the answer is reversed.\n\n```groovy\ntext = \"nice cheese gromit!\"\nname = text[3..1]\nassert name == \"eci\"\n```\n\n# Scripting Ant tasks\n\n虽然`Ant`只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用`build.xml`文件或者`Jelly`脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程.\n\nGroovy提供了一个辅助类`AntBuilder`帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们.\n\n`AntBuilder`通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息.\n```groovy\ndef ant = new AntBuilder()          \nant.echo('hello from Ant!')        \n```\n\n1. 创建一个`AntBuilder`实例\n2. 执行`AntBuilder`实例的echo task\n\n假设,现在你需要创建一个ZIP文件：\n```groovy\ndef ant = new AntBuilder()\nant.zip(destfile: 'sources.zip', basedir: 'src')\n```\n\n在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过`AntBuilder`拷贝一组文件.\n```groovy\n// lets just call one task\nant.echo(\"hello\")\n\n// here is an example of a block of Ant inside GroovyMarkup\nant.sequential {\n    echo(\"inside sequential\")\n    def myDir = \"target/AntTest/\"\n    mkdir(dir: myDir)\n    copy(todir: myDir) {\n        fileset(dir: \"src/test\") {\n            include(name: \"**/*.groovy\")\n        }\n    }\n    echo(\"done\")\n}\n\n// now lets do some normal Groovy again\ndef file = new File(ant.project.baseDir,\"target/AntTest/groovy/util/AntTest.groovy\")\nassert file.exists()\n```\n\n下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配.\n```groovy\n// lets create a scanner of filesets\ndef scanner = ant.fileScanner {\n    fileset(dir:\"src/test\") {\n        include(name:\"**/Ant*.groovy\")\n    }\n}\n\n// now lets iterate over\ndef found = false\nfor (f in scanner) {\n    println(\"Found file $f\")\n    found = true\n    assert f instanceof File\n    assert f.name.endsWith(\".groovy\")\n}\nassert found\n```\n\nOr execute a JUnit test:\n\n下面我们执行JUnit\n```groovy\n// lets create a scanner of filesets\nant.junit {\n    test(name:'groovy.util.SomethingThatDoesNotExist')\n}\n```\n\n现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件.\n```groovy\nant.echo(file:'Temp.java', '''\n    class Temp {\n        public static void main(String[] args) {\n            System.out.println(\"Hello\");\n        }\n    }\n''')\nant.javac(srcdir:'.', includes:'Temp.java', fork:'true')\nant.java(classpath:'.', classname:'Temp', fork:'true')\nant.echo('Done')\n```\n\n需要提及的是, `AntBuilder`是内嵌于`Gradle`中的. 你可以像在Groovy中那样, 在`Gradle`使用`AntBuilder`","slug":"编程语言/groovy","published":1,"updated":"2015-10-14T01:52:39.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrr000y0cufynuy64q4"},{"date":"2015-09-07T16:00:00.000Z","title":"JavaScript","_content":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\n# 数据类型\n## 数字\nJavaScript只有一个数字类型,它在内部被表示为64位的浮点数. 它没有分离出整数类型,因此1和1.0的值是相同的\n\nNaN是一个数值，它表示一个不能产生正常结果的运算结果。NaN不等于任何值，包括它自己。可以使用函数isNaN来检测NaN。\n\n## 字符串\n字符串可以由一对单引号或者一对双引号构成，可以包含0到多个字符。`\\`是转义字符。JavaScript采用Unicode16作为字符集，因此所有的字符都是16位的。\n\n字符串有一个length属性，可以获得字符串长度。\n\n字符串同样也是不可变的。一旦字符串被创建出来就无法改变它。我们同+链接其他字符串创建一个新的字符串。俩个包含着相同字符且字符顺序也相同的字符被认为是同一个字符串。`===`进行字符串判断。\n\n# 变量\n我们通过 `var`关键字来声明一个变量\n\n## 函数私有变量\nJavaScript通过函数管理作用域。在函数内部声明的变量只在这个函数内部可用，而在函数外面不可用。\n\n## 全局变量\n每个JavaScript环境有一个全局对象，当你在任意的函数外面使用this的时候可以访问到。你创建的每一个全局变量都成了这个全局对象的属性。\n\n# 控制流程\n\n我们可以通过条件语句(if和switch),循环语句（while，for和do）强制跳转语句（break,return，throw）和函数调用来改变执行序列。\n\n## if\n进行if判断时，下列值被作为假：\n* false\n* null\n* 空字符串 `''`\n* 数字0\n* 数字NaN\n\n## switch\n其表达式的值和case条件进行匹配。表达式可以是字符串或者数字。case表达式不一定必须是常量\n```javascript\nswitch (num)\n{\n\tcase 1:\n\t  x=\"输入正确\";\n\t  break;\n\tdefault:\n\t  x=\"输入错误\";\n}\n```\n\n## while\n```javascript\nwhile (i<5)\n{\n\tsum += i;\n}\n```\n\n## for\n```javascript\nfor (var i = 0; i<5; i++)\n{\n\tsum += i;\n}\n```\nfor...in\n```javascript\nvar array = [1, 2]\nfor (i in array)\n{\n\tsum += i;\n}\n```\n\n# 对象\nJavaScript的简单数据类型包括数字，字符串，布尔值，null值和undefined值，其他值都是对象(数组，函数都是对象)。 数字，字符串和布尔值虽然拥有方法，但他们是不可变的，因此不能称他们为对象。JavaScript中的对象是可变的键控集合。\n\n对象是属性的容器，每个属性都有名字和值。\n* 属性名：包括空串在内的任意字符串。如果字符串不是JavaScript保留的关键字切是合法的标识符则可以不必使用双引号。\n* 属性值：包括undefined值之外的任何值\n\n但是JavaScript里的对象是无类型的。\n\nJavaScript包含一种原型链特性,允许对象继承另一个对象的属性.正确的使用它能减少对象初始化时小号的时间和内存.\n\n## 对象字面量\n包围在一对花括号中的0~N个键值对即为对象字面量。\n```javascript\nvar empoty = {};\n\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n}\n```\n对象字面量还可以嵌套使用\n\n```javascript\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n\tchengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n}\n```\n\n## 检索对象里的值\n我们可以使用`[]`括住一个字符串表达式来索引某个值\n```javascript\nxiaoming[\"name\"]\n```\n如果该字符串是一个合法的标识符且不是保留关键字，那么也可以使用`.`进行索引\n```javascript\nxiaoming.name\n```\n如果我们索引`hair`这个属性的话,会得到一个`undefined`值,因此我们也可以使用`||`指定一个默认值\n```javascript\nxiaoming.hair || \"red\"\n```\n这样我们获得的结果就是`red`这个字符串,可是如果我们向一个`undefined`值继续索引的话会得到一个`TypeError`异常,我们可以使用`&&`来避免\n```javascript\nxiaoming.cars && xiaoming.cars.changcheng\n```\n我们通过这种方式获得小明拥有的汽车中长城汽车的属性值.\n\n## 更新对象的值\n我们可以通过`=`对对象进行赋值.\n```javascript\nxiaoming.name = \"zhangxiaoming\"\n\n// 或者赋值某个新的对象\nxiaoming.chengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n```\n\n## 引用对象\n对象通过引用来传递\n\n```javascript\nvar chengji = xiaoming.chengji\n```\n\n## 创建对象\n\n### Object 模式\n```javascript\nvar o1 = {};//字面量的表现形式\nvar o2 = new Object;\nvar o3 = new Object();\nvar o4 = new Object(null);\nvar o5 = new Object(undefined);\nvar o6 = Object.create(Object.prototype);//等价于 var o = {};//即以 Object.prototype 对象为一个原型模板,新建一个以这个原型模板为原型的对象\n// 区别\nvar o7 = Object.create(null);//创建一个原型为 null 的对象\n```\n\n### 构造器模式\n```javascript\nfunction Car(sColor){\n    this.color = sColor;      \n}\n\nvar car = new Car(\"red\");\n```\n\n\n## 原型链\n每个对象都会连接到一个原型对象,并且从中继承属性. 对象字面量会连接到`Object.prototype`\n\n需要指出的是原型连接在对象更新时是不起作用的(如果我们对某个对象做出改变是不会触及该对象的原型).原型连接只有在索引值的时候才会被用到.\n\n### 委托\n如果我们尝试去索引某个对象A的值,但该对象没有此属性名,那么JavaScript会试着从A的原型B中进行查找,如果B中也没有的话,会继续向B的原型C中查找,一直找到`Object.prototype`,如果都没有找到那么值就是`undefined`.\n\n### 指定对象的原型\n```javascript\n\n```\n\n## 反射\n我们可以使用typeof来观察我们的对象中是否包含某个属性\n```javascript\ntypeof xiaoming.name  // 值为string\ntypeof xiaoming.address  // 值为undefined\n```\n这样我们可以通过`undefined`来判断某个对象中是否包含某个值,但是有一点需要说明的是`typeof`也会在原型链进行索引判断。\n\n那么我们可以使用`hasOwnProperty`方法进行判断，它不对原型链进行检查同时它的返回值只有布尔值\n```javascript\nxiaoming.hasOwnProperty(\"address\")  // 值为false\n```\n\n## 删除\ndelete运算符可以用来删除对象的属性.它不会触及原型链中的任何对象. 如果我们自定义的对象属性覆盖了原型中的属性,我们可以通过删除对象的属性而让原型中的属性显露出来\n\n\n# 函数\n\nJavaScript中函数就是对象。函数对象连接到Function.prototype(该原型连接到Object.prototype).\n* 每个函数对象在创建时也随配一个prototype属性,它的值是一个拥有constructor属性且值为该函数的对象（这和连接到Function.prototype全完不同）.\n* 因为函数是对象,所以函数可以保存在变量,对象和数组中. 函数可以当做参数传递给其他函数,函数也可以再返回给函数.而且因为函数是对象,函数还可以拥有方法\n* 一个函数总会有一个返回值,如果没有指定返回值则返回undefined(如果函数调用前加上了new前缀,且返回的不是一个对象,则返回this)\n\n## 函数字面量\n我们定义一个函数字面量\n```JavaScript\nvar add = function(a, b) {\n\treturn a + b;\n}\n```\n上面这个函数字面量是通过将一个匿名函数赋值给一个变量.\n\n函数字面量可以出现在任何允许表达式出现的地方. 函数可以被定义在其他函数中. 可以作为函数参数或者函数返回值出现。函数甚至拥有自己的作用域(就像变量有自己的作用域一样)\n\n每声明一个函数实际是创建了一个Function 实例,上面的函数等价于\n```javascript\nvar Add = new Function(\"a\",\"b\",\"a + b;\");\n\nvar add = new Add(1, 2);\n```\n\n## 闭包\n内部函数可以访问自己内部的参数和变量还可以访问嵌套在父函数的参数和变量。通过函数字面量创建的函数对象包含了一个连接到外部上下文的连接，这杯称为闭包(每个函数在创建时会附加俩个隐藏属性：函数的上下文和实现函数行为的代码).\n\n\n## 函数调用\n当调用函数时除了显示地向其传递的参数,每个函数还会接受俩个附加参数`this`, `arguments`. 当实际参数大于形式参数时,多余的参数会被忽略,而当实际参数小于形式,参数时缺少的参数会被赋值为undefined.\n\n下面会介绍四种调用模式,每种调用模式对`this`参数的初始化是不一样的.\n\n### 方法调用模式\n当一个函数作为一个对象的属性时,我们称其为方法.方法里的this参数被被绑定到该对象上.\n```javascript\nvar obj = {\n\tvalue : 1;\n\taddOne : function() {\n\t\tthis.value += 1;\n\t}\n};\n\nobj.addOne();\n```\n\n### 函数调用模式\n当一个函数并非一个对象属性时,那么它就被当做是一个函数来调用\n```javascript\nfunction add(a, b) {\n\treturn a + b;\n}\n\nc = add(1, 2);\n```\n这种模式下this被绑定到全局对象上\n\n### 构造器调用模式\n\n\n一个函数如果创建的目的就是希望集合new关键字来使用,那么它就是构造器函数\n\n如果在一个函数前面带上一个new来调用,实际上会创建一个连接到该函数prototype成员的新对象,同时this也会绑定到那个新对象上.\n```javascript\nvar Quo = function(string) {\n\tthis.status = string;\n}\n\nQuo.prototype.get_status = function() {\n\treturn this.status;\n}\n\nvar myQuo = new Quo(\"hello\");\n```\n\n### Apply调用模式\nJavaScript的函数可以拥有方法,apply方法可以让我们构建一个参数数组传递给调用函数. apply方法接受俩个参数`this`和参数数组.\n```javascript\nvar add = function(a, b) {\n\treturn a + b;\n}\n\nvar argus = [3, 4];\nvar sum = add.apply(null, argus);\n```\n\n## arguments数组\n在函数内部我们可以通过arguments数组变量访问所有的实际参数\n```javascript\nvar add = function () {\n\tvar sum = 0;\n\tfor(i = 0; i < arguments.length; i += 1) {\n\t\tsum += argements[i];\n\t}\n};\n\nvar sum = add(1, 2, 3, 4, 5);\n```\n\n## 异常\nthrow语句中断函数的执行,它应该抛出一个exception对象,这个对象包含一个`name`和`message`属性(你也可以添加额外的属性).\n\n我们使用try catch来捕获异常 \n```javascript\nvar add = function(a, b) {\n\tif(arguments.length < 2) {\n\t\tthrow {\n\t\t\t\tname: \"arguments error\",\n\t\t\t\tmessage: \"need more arguments\"\n\t\t\t}\n\t}\n}\n\nvar tryAdd = function(a, b) {\n\ttry {\n\t\treturn add(a, b);\n\t} catch(e) {\n\n\t}\n}\n\ntryAdd(1, 2, 3);\n```\n\n## 作用域\n代码块是包在一对花括号中的一组语句，JavaScript中的代码块不会创建新的作用域.但是函数确实是有其自己的作用域的,但是在函数内部定义的变量在整个函数体的任意位置都是可见的,因此变量应该被定义在函数的头部。\n\n作用域的好处是内部函数可以访问定义在他们的外部函数的参数和变量(除了this和arguments)\n\n## 闭包\n当我们在函数A中定义了函数B,函数B引用了函数A中的变量I,当函数A执行完毕,函数B作为返回值继续被执行时,函数A的变量I是仍然可以被访问的,这就是闭包.\n```javascript\nvar f1 = function() {\n\tvar id = 1132;\n\treturn {\n\t\tadd: function() {\n\t\t\treturn id += 1;\n\t\t}\n\n\t}\n}\n\nvar if1 = fi();\nvar id = if1.add(); // 结果是1133\n```\n简而言之呢,闭包的特性是保存了创建它时的上下文信息.\n\n## 模块\n我们可以使用函数和闭包来构造模块. 模块是一个提供接口却隐藏状态与实现的函数或者对象.\n\n模块的一般形式是：一个定义了私有变量和函数的函数,利用闭包创建可以访问私有变量和函数的特权函数,最后返回这个特权函数,或者将他们保存到一个可访问到的地方.\n\n\n\n## 柯里化\n函数也是值,我们可以像往常操作值那样去操作函数, 将函数作为一个变量.\n```javascript\nvar f = function(a, b, c) {\n\n}\n\nvar f1 = function() {\n\treturn p(1);\n} \n\nvar c = f1();\n```\n上面就实现了函数的柯里化\n\n\n\n## 普通函数\n\n```JavaScript\nfunction add(a, b) {\n\treturn a + b;\n}\n```\n","source":"_posts/编程语言/JavaScript.md","raw":"category: 编程语言\ndate: 2015-09-08\ntitle: JavaScript\n---\nJavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的.\n\n# 数据类型\n## 数字\nJavaScript只有一个数字类型,它在内部被表示为64位的浮点数. 它没有分离出整数类型,因此1和1.0的值是相同的\n\nNaN是一个数值，它表示一个不能产生正常结果的运算结果。NaN不等于任何值，包括它自己。可以使用函数isNaN来检测NaN。\n\n## 字符串\n字符串可以由一对单引号或者一对双引号构成，可以包含0到多个字符。`\\`是转义字符。JavaScript采用Unicode16作为字符集，因此所有的字符都是16位的。\n\n字符串有一个length属性，可以获得字符串长度。\n\n字符串同样也是不可变的。一旦字符串被创建出来就无法改变它。我们同+链接其他字符串创建一个新的字符串。俩个包含着相同字符且字符顺序也相同的字符被认为是同一个字符串。`===`进行字符串判断。\n\n# 变量\n我们通过 `var`关键字来声明一个变量\n\n## 函数私有变量\nJavaScript通过函数管理作用域。在函数内部声明的变量只在这个函数内部可用，而在函数外面不可用。\n\n## 全局变量\n每个JavaScript环境有一个全局对象，当你在任意的函数外面使用this的时候可以访问到。你创建的每一个全局变量都成了这个全局对象的属性。\n\n# 控制流程\n\n我们可以通过条件语句(if和switch),循环语句（while，for和do）强制跳转语句（break,return，throw）和函数调用来改变执行序列。\n\n## if\n进行if判断时，下列值被作为假：\n* false\n* null\n* 空字符串 `''`\n* 数字0\n* 数字NaN\n\n## switch\n其表达式的值和case条件进行匹配。表达式可以是字符串或者数字。case表达式不一定必须是常量\n```javascript\nswitch (num)\n{\n\tcase 1:\n\t  x=\"输入正确\";\n\t  break;\n\tdefault:\n\t  x=\"输入错误\";\n}\n```\n\n## while\n```javascript\nwhile (i<5)\n{\n\tsum += i;\n}\n```\n\n## for\n```javascript\nfor (var i = 0; i<5; i++)\n{\n\tsum += i;\n}\n```\nfor...in\n```javascript\nvar array = [1, 2]\nfor (i in array)\n{\n\tsum += i;\n}\n```\n\n# 对象\nJavaScript的简单数据类型包括数字，字符串，布尔值，null值和undefined值，其他值都是对象(数组，函数都是对象)。 数字，字符串和布尔值虽然拥有方法，但他们是不可变的，因此不能称他们为对象。JavaScript中的对象是可变的键控集合。\n\n对象是属性的容器，每个属性都有名字和值。\n* 属性名：包括空串在内的任意字符串。如果字符串不是JavaScript保留的关键字切是合法的标识符则可以不必使用双引号。\n* 属性值：包括undefined值之外的任何值\n\n但是JavaScript里的对象是无类型的。\n\nJavaScript包含一种原型链特性,允许对象继承另一个对象的属性.正确的使用它能减少对象初始化时小号的时间和内存.\n\n## 对象字面量\n包围在一对花括号中的0~N个键值对即为对象字面量。\n```javascript\nvar empoty = {};\n\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n}\n```\n对象字面量还可以嵌套使用\n\n```javascript\nvar xiaoming = {\n\tname : \"小明\",\n\tage  : 18\n\tchengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n}\n```\n\n## 检索对象里的值\n我们可以使用`[]`括住一个字符串表达式来索引某个值\n```javascript\nxiaoming[\"name\"]\n```\n如果该字符串是一个合法的标识符且不是保留关键字，那么也可以使用`.`进行索引\n```javascript\nxiaoming.name\n```\n如果我们索引`hair`这个属性的话,会得到一个`undefined`值,因此我们也可以使用`||`指定一个默认值\n```javascript\nxiaoming.hair || \"red\"\n```\n这样我们获得的结果就是`red`这个字符串,可是如果我们向一个`undefined`值继续索引的话会得到一个`TypeError`异常,我们可以使用`&&`来避免\n```javascript\nxiaoming.cars && xiaoming.cars.changcheng\n```\n我们通过这种方式获得小明拥有的汽车中长城汽车的属性值.\n\n## 更新对象的值\n我们可以通过`=`对对象进行赋值.\n```javascript\nxiaoming.name = \"zhangxiaoming\"\n\n// 或者赋值某个新的对象\nxiaoming.chengji: {\n\t\tyuwen: 99,\n\t\tshuxu: 100\n\t}\n```\n\n## 引用对象\n对象通过引用来传递\n\n```javascript\nvar chengji = xiaoming.chengji\n```\n\n## 创建对象\n\n### Object 模式\n```javascript\nvar o1 = {};//字面量的表现形式\nvar o2 = new Object;\nvar o3 = new Object();\nvar o4 = new Object(null);\nvar o5 = new Object(undefined);\nvar o6 = Object.create(Object.prototype);//等价于 var o = {};//即以 Object.prototype 对象为一个原型模板,新建一个以这个原型模板为原型的对象\n// 区别\nvar o7 = Object.create(null);//创建一个原型为 null 的对象\n```\n\n### 构造器模式\n```javascript\nfunction Car(sColor){\n    this.color = sColor;      \n}\n\nvar car = new Car(\"red\");\n```\n\n\n## 原型链\n每个对象都会连接到一个原型对象,并且从中继承属性. 对象字面量会连接到`Object.prototype`\n\n需要指出的是原型连接在对象更新时是不起作用的(如果我们对某个对象做出改变是不会触及该对象的原型).原型连接只有在索引值的时候才会被用到.\n\n### 委托\n如果我们尝试去索引某个对象A的值,但该对象没有此属性名,那么JavaScript会试着从A的原型B中进行查找,如果B中也没有的话,会继续向B的原型C中查找,一直找到`Object.prototype`,如果都没有找到那么值就是`undefined`.\n\n### 指定对象的原型\n```javascript\n\n```\n\n## 反射\n我们可以使用typeof来观察我们的对象中是否包含某个属性\n```javascript\ntypeof xiaoming.name  // 值为string\ntypeof xiaoming.address  // 值为undefined\n```\n这样我们可以通过`undefined`来判断某个对象中是否包含某个值,但是有一点需要说明的是`typeof`也会在原型链进行索引判断。\n\n那么我们可以使用`hasOwnProperty`方法进行判断，它不对原型链进行检查同时它的返回值只有布尔值\n```javascript\nxiaoming.hasOwnProperty(\"address\")  // 值为false\n```\n\n## 删除\ndelete运算符可以用来删除对象的属性.它不会触及原型链中的任何对象. 如果我们自定义的对象属性覆盖了原型中的属性,我们可以通过删除对象的属性而让原型中的属性显露出来\n\n\n# 函数\n\nJavaScript中函数就是对象。函数对象连接到Function.prototype(该原型连接到Object.prototype).\n* 每个函数对象在创建时也随配一个prototype属性,它的值是一个拥有constructor属性且值为该函数的对象（这和连接到Function.prototype全完不同）.\n* 因为函数是对象,所以函数可以保存在变量,对象和数组中. 函数可以当做参数传递给其他函数,函数也可以再返回给函数.而且因为函数是对象,函数还可以拥有方法\n* 一个函数总会有一个返回值,如果没有指定返回值则返回undefined(如果函数调用前加上了new前缀,且返回的不是一个对象,则返回this)\n\n## 函数字面量\n我们定义一个函数字面量\n```JavaScript\nvar add = function(a, b) {\n\treturn a + b;\n}\n```\n上面这个函数字面量是通过将一个匿名函数赋值给一个变量.\n\n函数字面量可以出现在任何允许表达式出现的地方. 函数可以被定义在其他函数中. 可以作为函数参数或者函数返回值出现。函数甚至拥有自己的作用域(就像变量有自己的作用域一样)\n\n每声明一个函数实际是创建了一个Function 实例,上面的函数等价于\n```javascript\nvar Add = new Function(\"a\",\"b\",\"a + b;\");\n\nvar add = new Add(1, 2);\n```\n\n## 闭包\n内部函数可以访问自己内部的参数和变量还可以访问嵌套在父函数的参数和变量。通过函数字面量创建的函数对象包含了一个连接到外部上下文的连接，这杯称为闭包(每个函数在创建时会附加俩个隐藏属性：函数的上下文和实现函数行为的代码).\n\n\n## 函数调用\n当调用函数时除了显示地向其传递的参数,每个函数还会接受俩个附加参数`this`, `arguments`. 当实际参数大于形式参数时,多余的参数会被忽略,而当实际参数小于形式,参数时缺少的参数会被赋值为undefined.\n\n下面会介绍四种调用模式,每种调用模式对`this`参数的初始化是不一样的.\n\n### 方法调用模式\n当一个函数作为一个对象的属性时,我们称其为方法.方法里的this参数被被绑定到该对象上.\n```javascript\nvar obj = {\n\tvalue : 1;\n\taddOne : function() {\n\t\tthis.value += 1;\n\t}\n};\n\nobj.addOne();\n```\n\n### 函数调用模式\n当一个函数并非一个对象属性时,那么它就被当做是一个函数来调用\n```javascript\nfunction add(a, b) {\n\treturn a + b;\n}\n\nc = add(1, 2);\n```\n这种模式下this被绑定到全局对象上\n\n### 构造器调用模式\n\n\n一个函数如果创建的目的就是希望集合new关键字来使用,那么它就是构造器函数\n\n如果在一个函数前面带上一个new来调用,实际上会创建一个连接到该函数prototype成员的新对象,同时this也会绑定到那个新对象上.\n```javascript\nvar Quo = function(string) {\n\tthis.status = string;\n}\n\nQuo.prototype.get_status = function() {\n\treturn this.status;\n}\n\nvar myQuo = new Quo(\"hello\");\n```\n\n### Apply调用模式\nJavaScript的函数可以拥有方法,apply方法可以让我们构建一个参数数组传递给调用函数. apply方法接受俩个参数`this`和参数数组.\n```javascript\nvar add = function(a, b) {\n\treturn a + b;\n}\n\nvar argus = [3, 4];\nvar sum = add.apply(null, argus);\n```\n\n## arguments数组\n在函数内部我们可以通过arguments数组变量访问所有的实际参数\n```javascript\nvar add = function () {\n\tvar sum = 0;\n\tfor(i = 0; i < arguments.length; i += 1) {\n\t\tsum += argements[i];\n\t}\n};\n\nvar sum = add(1, 2, 3, 4, 5);\n```\n\n## 异常\nthrow语句中断函数的执行,它应该抛出一个exception对象,这个对象包含一个`name`和`message`属性(你也可以添加额外的属性).\n\n我们使用try catch来捕获异常 \n```javascript\nvar add = function(a, b) {\n\tif(arguments.length < 2) {\n\t\tthrow {\n\t\t\t\tname: \"arguments error\",\n\t\t\t\tmessage: \"need more arguments\"\n\t\t\t}\n\t}\n}\n\nvar tryAdd = function(a, b) {\n\ttry {\n\t\treturn add(a, b);\n\t} catch(e) {\n\n\t}\n}\n\ntryAdd(1, 2, 3);\n```\n\n## 作用域\n代码块是包在一对花括号中的一组语句，JavaScript中的代码块不会创建新的作用域.但是函数确实是有其自己的作用域的,但是在函数内部定义的变量在整个函数体的任意位置都是可见的,因此变量应该被定义在函数的头部。\n\n作用域的好处是内部函数可以访问定义在他们的外部函数的参数和变量(除了this和arguments)\n\n## 闭包\n当我们在函数A中定义了函数B,函数B引用了函数A中的变量I,当函数A执行完毕,函数B作为返回值继续被执行时,函数A的变量I是仍然可以被访问的,这就是闭包.\n```javascript\nvar f1 = function() {\n\tvar id = 1132;\n\treturn {\n\t\tadd: function() {\n\t\t\treturn id += 1;\n\t\t}\n\n\t}\n}\n\nvar if1 = fi();\nvar id = if1.add(); // 结果是1133\n```\n简而言之呢,闭包的特性是保存了创建它时的上下文信息.\n\n## 模块\n我们可以使用函数和闭包来构造模块. 模块是一个提供接口却隐藏状态与实现的函数或者对象.\n\n模块的一般形式是：一个定义了私有变量和函数的函数,利用闭包创建可以访问私有变量和函数的特权函数,最后返回这个特权函数,或者将他们保存到一个可访问到的地方.\n\n\n\n## 柯里化\n函数也是值,我们可以像往常操作值那样去操作函数, 将函数作为一个变量.\n```javascript\nvar f = function(a, b, c) {\n\n}\n\nvar f1 = function() {\n\treturn p(1);\n} \n\nvar c = f1();\n```\n上面就实现了函数的柯里化\n\n\n\n## 普通函数\n\n```JavaScript\nfunction add(a, b) {\n\treturn a + b;\n}\n```\n","slug":"编程语言/JavaScript","published":1,"updated":"2015-10-19T06:02:33.414Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrs00100cufpv2imt5q"},{"date":"2015-10-07T16:00:00.000Z","title":"Clojure","_content":"\n\n[Clojure入门教程](http://xumingming.sinaapp.com/302/clojure-functional-programming-for-the-jvm-clojure-tutorial)学习笔记.\n\n开发环境基于[IntelliJ IDEA 14 La Clojure](http://plugins.jetbrains.com/plugin/?id=4050)插件.\n\n## Clojure数据类型\n* 布尔值\n* 浮点数\n* 字符串\n* 分数\n\n\n\n## Clojure操作\nClojure里面的每个操作被实现成以下三种形式的一种: \n* 函数(function), \n* 宏(macro)\n* special form. \n\n### 函数\ndefn 宏用来定义一个函数。它的参数包括一个函数名字，一个可选的注释字符串，参数列表，然后一个方法体。而函数的返回值则是方法体里面最后一个表达式的值。所有的函数都会返回一个值， 只是有的返回的值是nil。\n\n通过宏defn- 定义的函数是私有的. 这意味着它们只在定义它们的名字空间里面可见. 其它一些类似定义私有函数/宏的还有：defmacro- 和defstruct- (在clojure.contrib.def里面)\n\n#### 定义函数\n```clojure\n(defn printHello ;定义函数名\n  \"println hello\" ;注释\n  [name]  ; 参数\n  (println \"hello\") ; 方法体\n\n  )\n\n(printHello \"\") ;调用函数\n```\n需要注意的是,调用函数时,如果参数声明了,则必须加上参数\n\n还有个有趣的特性是,我们可以在声明一个函数时, 添加多个参数列表以及与之对应的方法体.只要各个参数列表的参数数量不一致就可以了.\n```clojure\n(defn printHello\n  \"println hello\"\n\n  ([v] (println \"hello\" v))\n\n  ([] (println \"hello\"))\n\n  )\n\n(printHello)\n(printHello \"world\")\n```\n\n\n##### 匿名函数\n我们可以通过`fn`或者`#(...)`定义匿名函数\n\nfn 定义的匿名函数可以包含任意个数的表达式\n```clojure\nuser=> (map (fn [num] (+ num 1)) [1 2 3])\n(2 3 4)\n```\n\n`#(...)`定义的匿名函数则只能包含一个表达式，如果你想包含多个表达式，那么把它用do包起来\n```clojure\nuser=> (map #(+ % 1) [1 2 3])\n(2 3 4)\n```\n`%`代表参数,如果有多个参数可以使用`%1`, `%2`等.\n\n#### 函数重载\nClojure虽然只能根据参数个数进行重载,使用multimethods技术可以实现任意类型的重载。\n\nmultimethod使用宏`defmulti`和`defmethod`进行定义.\n* `defmulti` :参数包括一个方法名以及一个dispatch函数，这个dispatch函数的返回值会被用来选择到底调用哪个重载的函数\n* `defmethod`: 参数则包括方法名，dispatch的值， 参数列表以及方法体\n```clojure\n(defmulti printOne class)\n(defmethod printOne Number [arg] (println \"print \" arg))\n(defmethod printOne String [arg] (println \"print \" arg))\n(defmethod printOne :default [arg] (println \"print defult\"))\n(printOne 12)\n(printOne \"cde\")\n(printOne false)\n```\n\n\n#### 函数参数占位符\n`_`可以用来做函数的占位符 \n```clojure\n(defn call1 [n1] (println n1))\n(defn call2 [n1 n2] (println n1 n2))\n(defn call3 [n1 _] (println n1))\n(call1 1)\n(call2 2 3)\n(call3 3 4)\n```\n占位符的作用是表示这个位置有一个参数,但是我并不会使用它. 这种参数在回调函数里比较有用.\n```clojure\n(defn call2 [n1 n2] (println n1 n2))\n(defn call3 [n1 _] (println n1))\n(defn caller [call n](call n n))\n(caller call2 2)\n(caller call3 3)\n```\n\n#### 高阶函数\n##### complement\n接受一个函数作为参数，如果这个参数返回值是true， 那么它就返回false, 相当于一个取反的操作\n```clojure\n\n```\n\n##### comp\ncomp把任意多个函数组合成一个，前面一个函数的返回值作为后面一个函数的参数\n```clojure\n\n```\n\n##### partial\npartial 函数创建一个新的函数 — 通过给旧的函数制定一个初始值， 然后再调用原来的函数\n```clojure\n\n```\n\n##### memoize\n函数接受一个参数，它的作用就是给原来的函数加一个缓存，所以如果同样的参数被调用了两次， 那么它就直接从缓存里面返回缓存了的结果\n```clojure\n\n```\n\n##### time\n```clojure\n\n```\n\n#### 宏\n\n\n\n\n\n#### special form\nClojure支持以下几种special form\n\n##### def\n通过`def`来定义一个全局binding(还可以给他一个`root value`, 该值在所有线程里都是可见的).\n```clojure\n(def n 19)\n(print n)\n```\n\n##### var\n```clojure\n\n```\n\n##### do\n```clojure\n\n```\n\n\n##### dot (‘.’)\n```clojure\n\n```\n\n\n##### finally\n```clojure\n\n```\n\n\n##### fn\n```clojure\n\n```\n\n##### if\n```clojure\n\n```\n\n##### let\nlet 这个special form 创建局限于一个 当前form的bindings. 它的第一个参数是一个vector, 里面包含名字-表达式的对子。表达式的值会被解析然后赋给左边的名字。这些binding可以在这个vector后面的表达式里面使用。这些binding还可以被多次赋值以改变它们的值，let命令剩下的参数是一些利用这个binding来进行计算的一些表达式。注意：如果这些表达式里面有调用别的函数，那么这个函数是无法利用let创建的这个binding的。\n```clojure\n\n```\n\n##### loop\n```clojure\n\n```\n\n##### monitor-enter\n```clojure\n\n```\n\n##### monitor-exit\n```clojure\n\n```\n\n##### new\n```clojure\n\n```\n\n##### quote\n```clojure\n\n```\n\n##### recur\n```clojure\n\n```\n\n##### set!\n```clojure\n\n```\n\n##### try catch throw\n```clojure\n\n```\n\n\n\n## 安全共享数据\nClojure提供三种方法来安全地共享可修改的数据。所有三种方法的实现方式都是持有一个可以开遍的引用指向一个不可改变的数据。\n\n* 它们都可以指向任意类型的对象。\n* 都可以利用函数deref 以及宏@ 来读取它所指向的对象。\n* 它们都支持验证函数，这些函数在它们所指向的值发生变化的时候自动调用。如果新值是合法的值，那么验证函数简单的返回true, 如果新值是不合法的，那么要么返回false， 要么抛出一个异常。如果只是简单地返回了false, 那么一个IllegalStateException 异常会被抛出，并且带着提示信息： \"Invalid reference state\" 。\n* 如果是Agents的话，它们还支持watchers。如果被监听的引用的值发生了变化，那么Agent会得到通知， 详情见 \"Agents\" 一节。\n\n### binding\nClojure不支持变量但是支持`binding`。`binding`跟变量有点像，但是在被赋值之前是不允许改的，bingding类型有：\n* 全局binding: 通过`def`来定义一个全局binding\n* 线程本地(thread local)binding:\n* 函数内的本地binding:函数的参数是只在这个函数内可见的本地binding。\n* 表达式内部的binding:\n\n### vars\nVars数据被所有线程root binding, 并且每个线程线程对其有自己线程本地(thread-local)值的一种引用类型。这个类型是不是线程安全的,因为每个线程都有对其线程本地的拷贝,那么当A线程对值进行修改时,可能B线程会优先对其进行修改,但是这是B的修改对A是不可见的.\n\n创建\n```clojure\n(def name initial-value) ;如果不设置值的话,则默认是'unbound'\n```\n修改值\n```clojure\n(def name new-value) 可以赋新的值 \n(alter-var-root (var name) update-fn args) 自动设置新值\n(set! name new-value) 在一个binding form 里满设置一个新的、线程本地的值\n```\n创建线程本地binding\n```\n(binding [name expression] body)\n(set! name expression) ;\n```\n\n### Refs \nRefs是用来协调对于一个或者多个binding的并发修改的。这个协调机制是利用Software Transactional Memory (STM)来实现的。 \n\nRefs指定在一个事务里面修改。执行事务的代码要包在`dosync`体内,当在一个事务里面对值进行修改，被改的其实是一个私有的、线程内的、直到事务提交才会被别的线程看到的一快内存。当事务结束的时候如果没有抛出异常的话,事务会正常提交. 如果在提交时发现已经有其他的线程修改了该值,那么事务会从头再重新执行一边.\n\n要在事务里面执行的代码一定要是没有副作用的，这一点非常重要，因为前面提到的，事务可能会跟别的事务事务冲突，然后重试， 如果有副作用的话，那么出来的结果就不对了。不过要执行有副作用的代码也是可能的， 可以把这个方法调用包装给Agent, 然后这个方法会被hold住直到事务成功提交，然后执行一次。如果事务失败那么就不会执行。\n\n创建\n```clojure\n(def name (ref initial-value)) ;ref函数创建了一个 Ref 对象\n```\n\n如果你要赋的新值是基于旧的值的话，那么就需要三个步骤了：\n1. deference 这个 Ref 来获得它的旧值\n2. 计算新值\n3. 设置新值\n\n下面的alter函数和commite函数都完成了这三个操作,要赋的新的值是基于旧的值计算出来的时候, 那么我们鼓励使用alter 和commute 而不是ref-set.\n```clojure\n(ref-set ref new-value) 必须在dosync里面调用 \n(alter ref update-fn arguments) 必须在dosync里面调用\n(commute ref update-fn arguments) 必须在dosync 里面调用\n```\n* alter:用来操作那些必须以特定顺序进行的修改.如果alter 试图修改的 Ref 在当前事务开始之后被别的事务改变了，那么当前事务会进行重试\n* commite:操作那些修改顺序不是很重要,可以同时进行的修改.如果alter 试图修改的 Ref 在当前事务开始之后被别的事务改变了，commute 不会进行重试。它会以事务内的当前值进行计算。\n\ndosync宏\n```clojure\n(dosync\n  (ref-set name new-value)\n )\n```\n\n#### Validation函数\n他验证所有赋给Ref的值是数字。\n\n### Atoms \nAtoms 提供了一种比使用Refs&STM更简单的更新当个值的方法。它不受事务的影响\n\n\n创建\n```clojure\n(def my-atom (atom initial-value))\n```\n\n有三个函数可以修改一个Atom的值：\n#### reset! \n接受两个参数：要设值的Atom以及新值。它设置新的值，而不管你旧的值是什么。\n```clojure\n(reset! atom new-value) \n```\n\n#### compare-and-set! \n接受三个参数：要被修改的Atom, 上次读取时候的值，新的值。 这个函数在设置新值之前会去读Atom现在的值。如果与上次读的时候的值相等， 那么设置新值并返回true, 否则不设置新值， 返回false\n```clojure\n(compare-and-set! atom current-value new-value)\n```\n\n#### swap!: \n接受一个要修改的 Atom, 一个计算Atom新值的函数以及一些额外的参数(如果需要的话)。这个计算Atom新的值的函数会以这个Atom以及一些额外的参数做为输入。swap！函数实际上是对compare-and-set!函数的一个封装，但是有一个显著的不同。 它首先把Atom的当前值存入一个变量，然后调用计算新值的函数来计算新值， 然后再调用compare-and-set!函数来赋值。如果赋值成功的话，那就结束了。如果赋值不成功的话， 那么它会重复这个过程，一直到赋值成功为止\n```clojure\n(swap! atom update-fn arguments)\n```\n\n### Agents \nAgents 是用把一些事情放到另外一个线程来做 -- 一般来说不需要事务控制的。它们对于修改一个单个对象的值(也就是Agent的值)来说很方便。这个值是通过在另外的一个thread上面运行一个“action”来修改的。一个action是一个函数， 这个函数接受Agent的当前值以及一些其它参数。 Only one action at a time will be run on a given Agent在任意一个时间点一个Agent实例上面只能运行一个action.\n\n\n创建\n```clojure\n(def my-agent (agent initial-value))\n```\n\n有俩个个函数可以修改一个Agent的值：\n#### send\nend 函数把一个 action 分配给一个 Agent， 并且马上返回而不做任何等待。 这个action会在另外一个线程(一般是由一个线程池提供的)上面单独运行。 当这个action运行结束之后，返回值会被设置给这个Agent。\n\nsend 使用一个 \"固定大小的\" 线程吃 (java.util.concurrent.Executors里面的newFixedThreadPool ) ， 线程的个数是机器的处理器的个数加2。如果所有的线程都被占用，那么你如果要运行新的action， 那你就要等了\n```clojure\n(send agent update-fn arguments) \n```\n\n#### send-off\nsend-off 函数也类似只是线程来自另外一个线程吃。\n\nsend-off 使用的是 \"cached thread pool\" (java.util.concurrent.Executors里面的?newCachedThreadPool) ， 这个线程池里面的线程的个数是按照需要来分配的。\n```clojure \n(send-off agent update-fn arguments)\n```\n\n\n## 流程控制\n\n\n## 调用java\n\n\n## 谓词\nClojure 提供了很多函数来充当谓词的功能 — 测试条件是否成立\n\n### 测试对象类型谓词\n* `class?`\n* `coll?`\n* `decimal?`\n* `delay?`\n* `float?`\n* `fn?`\n* `instance?`\n* `integer?`\n* `isa?`\n* `keyword?`\n* `list?`\n* `macro?`\n* `map?`\n* `number?`\n* `seq?`\n* `set?`\n* `string?` \n* `vector?`\n\n### 测试两个值关系\n* `<`\n* `<=`\n* `=`\n* `not=`\n* `==`\n* `>`\n* `>=`\n* `compare`\n* `distinct?` \n* `identical?`\n\n### 测试逻辑关系\n* `and`\n* `or`\n* `not`\n* `true?`\n* `false?` \n* `nil?`\n\n\n### 测试集合\n* `empty?`\n* `not-empty`\n* `every?`\n* `not-every?`\n* `some?` \n* `not-any?`\n\n### 测试数字的谓词有\n* `even?`\n* `neg?`\n* `odd?`\n* `pos?` \n* `zero?`\n\n\n\n## Clojure集合\n所有的clojure集合有以下三个特性\n* 不可修改的:集合产生之后，不能从集合里面删除一个元素，也往集合里面添加一个元素\n* 异源的\n* 持久的\n\nClojure提供这些集合类型:\n* list\n* vector\n* set\n* map\n\n### list\nLists是一个有序的元素的集合\n\nlist有多种定义方式\n* `(def stooges (list \"Moe\" \"Larry\" \"Curly\"))`\n* `(def stooges (quote (\"Moe\" \"Larry\" \"Curly\")))`\n* `(def stooges '(\"Moe\" \"Larry\" \"Curly\"))`\n\n\n### Vectors\nVectors也是一种有序的集合。这种集合对于从最后面删除一个元素，或者获取最后面一个元素是非常高效的(O(1))。这意味着对于向vector里面添加元素使用conj被使用cons更高效。Vector对于以索引的方式访问某个元素（用nth命令）或者修改某个元素(用assoc)来说非常的高效。函数定义的时候指定参数列表用的就是vector。\n\n创建有多种定义方式\n* `(def stooges (vector \"Moe\" \"Larry\" \"Curly\"))`\n* `(def stooges [\"Moe\" \"Larry\" \"Curly\"])`\n\n### Sets\n一个包含不重复元素的集合。当我们要求集合里面的元素不可以重复，并且我们不要求集合里面的元素保持它们添加时候的顺序，那么sets是比较适合的。 Clojure 支持两种不同的set： 排序的和不排序的。如果添加到set里面的元素相互之间不能比较大小，那么一个ClassCastException 异常会被抛出来。\n\n创建有多种定义方式\n* (def stooges (hash-set \"Moe\" \"Larry\" \"Curly\"))\n* (def stooges #{\"Moe\" \"Larry\" \"Curly\"})  \n* (def stooges (sorted-set \"Moe\" \"Larry\" \"Curly\"))\n\n### Maps\nMaps 保存从key到value的a对应关系 \n\n创建有多种定义方式\n* (def popsicle-map (hash-map :red :cherry, :green :apple, :purple :grape))\n* (def popsicle-map {:red :cherry, :green :apple, :purple :grape}) ; same as previous\n* (def popsicle-map (sorted-map :red :cherry, :green :apple, :purple :grape))\n  \n\n### 集合函数:\n\n#### count\n统计集合里面的元素个数\n```clojure\nuser=> (count [19 \"yellow\" true])\n3\n```\n\n#### conj\n添加一个元素到集合里面去\n```clojure\n\n```\n\n#### reverse \n把集合里面的元素反转\n```clojure\nuser=> (reverse [1 2 3])\n(3 2 1)\n```\n\n#### map \n对一个给定的集合里面的每一个元素调用一个指定的方法，然后这些方法的所有返回值构成一个新的集合（LazySeq）返回\n```clojure\nuser=> (map #(+ % 1) [1 2 3])\n(2 3 4)\n```\n\n#### apply \n把给定的集合里面的所有元素一次性地给指定的函数作为参数调用，然后返回这个函数的返回值\n```clojure\nuser=> (apply + [1 2 3])\n6\n```\n\n#### first\n取集合中第一个元素\n```clojure\nuser=> (first [1 2 3])\n1\n```\n\n#### second\n```clojure\nuser=> (second [1 2 3])\n2\n```\n\n#### last\n```clojure\nuser=> (last [1 2 3])\n3\n\n```\n\n#### nth\n```clojure\nuser=> (nth [1 2 3] 2)\n3\n```\n\n#### next\n```clojure\nuser=> (next [1 2 3])\n(2 3)\n```\n\n#### butlast\n排除最后一个元素\n```clojure\n( print (butlast [1 2 3]))\n```\n\n#### drop-last\n```clojure\n( print (drop-last [1 2 3]))\n```\n\n#### filter\n\n```clojure\n( print (filter #(> % 1) [1 2 3]))\n```\n\n#### nthnext\n```clojure\n( print (nthnext  [1 2 3] 1))\n```\n\n#### some\n判断集合中是否包含某个元素\n```clojure\nuser=> (some #(= % 3) [1 2 3])\ntrue\n```\n\n#### contains\n```clojure\nuser=> (contains? [1 2 3] 3)\nfalse\nuser=> (contains? (set [1 2 3]) 3)\ntrue\n```\n\n#### conj\n通过一个已有的集合来创建一个新的包含更多元素的集合\n```clojure\nuser=> (conj [1 2 3] 4)\n[1 2 3 4]\nuser=> (conj [1 2 3] [4 5 6])\n[1 2 3 [4 5 6]]\n```\n\n#### cons\n通过一个已有的集合来创建一个新的包含更多元素的集合\n```clojure\nuser=> (cons [1 2 3] 4)\nIllegalArgumentException Don't know how to create ISeq from: java.lang.Long  clojure.lang.RT.seqFrom (RT.java:505)\n\nuser=> (cons 4 [1 2 3] )\n(4 1 2 3)\n```\n\n#### remove \n函数创建一个只包含所指定的谓词函数测试结果为false的元素的集合\n```clojure\nuser=> (remove #(= % 2) [1 2 3])\n(1 3)\n```\n\n#### into\n把两个list里面的元素合并成一个新的list\n```clojure\nuser=> (into [1 2] [3 4] )\n[1 2 3 4]\n```\n\n#### peek\n```clojure\nuser=> (peek [1 2 3])\n3\n\n```\n\n#### pop\n```clojure\nuser=> (pop [1 2 3])\n[1 2]\n```\n\n#### get\n```clojure\n\n```\n\n#### get\n```clojure\nuser=> (get [1 2 3] 1 110)\n2\nuser=> (get [1 2 3] 10 110)\n110\n```\n\n#### assoc\n替换指定位置元素\n```clojure\nuser=> (assoc [1 2 3] 2 4)\n[1 2 4]\n```\n\n#### subvec \n获取一个给定vector的子vector\n```clojure\nuser=> (subvec [1 2 3 ] 1 2)\n[2]\n```\n\n#### disj \n函数通过去掉给定的set里面的一些元素来创建一个新的set\n```clojure\n\n```\n\n\n## 语法糖\n\n### 注释\n`; text` 单行注释\n```clojure\n\n```\n\n### 字符\n`\\char` \n`\\tab`\n`\\newline`\n`\\space`\n`\\uunicode-hex-value`\n\n```clojure\n\n```\n\n### 字符串\n`\"text\"`\n```clojure\n\n```\n\n### 关键字\n关键字是一个内部字符串; 两个同样的关键字指向同一个对象; 通常被用来作为map的key\n\n`:name`\n```clojure\n\n```\n\n### 命名空间关键字\n`::name`\n```clojure\n\n```\n\n### 正则表达式\n`#\"pattern\"`\n```clojure\n\n```\n\n### 逗号\n逗号被当成空白（通常用在集合里面用来提高代码可读性）\n```clojure\n\n```\n\n### 链表\n`'(items)`(不会evaluate每个元素）\t\n\n函数 `(list items)`会evaluate每个元素\n```clojure\n\n```\n\n### vector\n`[items]`\n\n\n函数`(vector items)`\n```clojure\n\n```\n\n### set\n`#{items}`建立一个hash-set\t\n\n函数`(hash-set items)`\n`(sorted-set items)`\n```clojure\n\n```\n\n### map\t\n`{key-value-pairs}`建立一个hash-map\t\n\n函数`(hash-map key-value-pairs)`\n`(sorted-map key-value-pairs)`\n\n```clojure\n\n```\n\n### 绑定元数据\n给symbol或者集合绑定元数据\t`#^{key-value-pairs}` object在读入期处理\t\n\n函数`(with-meta object metadata-map)`在运行期处理\n```clojure\n\n```\n\n###获取symbol或者集合的元数据\n`^object`\t\n\n函数`(meta object)`\n```clojure\n\n```\n\n### 获取一个函数的参数列表（个数不定的）\n`& name`\n```clojure\n\n```\n\n### 创建一个java对象\n`(class-name. args)\t`\n\n函数`(new class-name args)`\n```clojure\n\n```\n\n### 调用java方法\n* (. class-or-instance method-name args) \n* (.method-name class-or-instance args)\n```clojure\n\n```\n\n### 创建匿名函数\n`#(single-expression)` 用% (等同于 %1), %1, %2来表示参数\t\n\n函数`(fn [arg-names] expressions)`\n```clojure\n\n```\n\n### 获取Ref, Atom 和Agent对应的valuea\n@ref\t\n\n函数(deref ref)\n```clojure\n\n```\n\n### syntax quote \n(使用在宏里面)  `\n```clojure\n\n```\n\n### unquote \n使用在宏里面`~value`\n```clojure\n\n```\n\n### unquote splicing \n(使用在宏里面)`~@value`\n```clojure\n\n```\n\n### auto-gensym \n(在宏里面用来产生唯一的symbol名字)\t\n`prefix#`\n\n函数`(gensym prefix )`\n```clojure\n\n```\n\n\n\n","source":"_posts/编程语言/Clojure.md","raw":"category: 编程语言\ndate: 2015-10-08\ntitle: Clojure\n---\n\n\n[Clojure入门教程](http://xumingming.sinaapp.com/302/clojure-functional-programming-for-the-jvm-clojure-tutorial)学习笔记.\n\n开发环境基于[IntelliJ IDEA 14 La Clojure](http://plugins.jetbrains.com/plugin/?id=4050)插件.\n\n## Clojure数据类型\n* 布尔值\n* 浮点数\n* 字符串\n* 分数\n\n\n\n## Clojure操作\nClojure里面的每个操作被实现成以下三种形式的一种: \n* 函数(function), \n* 宏(macro)\n* special form. \n\n### 函数\ndefn 宏用来定义一个函数。它的参数包括一个函数名字，一个可选的注释字符串，参数列表，然后一个方法体。而函数的返回值则是方法体里面最后一个表达式的值。所有的函数都会返回一个值， 只是有的返回的值是nil。\n\n通过宏defn- 定义的函数是私有的. 这意味着它们只在定义它们的名字空间里面可见. 其它一些类似定义私有函数/宏的还有：defmacro- 和defstruct- (在clojure.contrib.def里面)\n\n#### 定义函数\n```clojure\n(defn printHello ;定义函数名\n  \"println hello\" ;注释\n  [name]  ; 参数\n  (println \"hello\") ; 方法体\n\n  )\n\n(printHello \"\") ;调用函数\n```\n需要注意的是,调用函数时,如果参数声明了,则必须加上参数\n\n还有个有趣的特性是,我们可以在声明一个函数时, 添加多个参数列表以及与之对应的方法体.只要各个参数列表的参数数量不一致就可以了.\n```clojure\n(defn printHello\n  \"println hello\"\n\n  ([v] (println \"hello\" v))\n\n  ([] (println \"hello\"))\n\n  )\n\n(printHello)\n(printHello \"world\")\n```\n\n\n##### 匿名函数\n我们可以通过`fn`或者`#(...)`定义匿名函数\n\nfn 定义的匿名函数可以包含任意个数的表达式\n```clojure\nuser=> (map (fn [num] (+ num 1)) [1 2 3])\n(2 3 4)\n```\n\n`#(...)`定义的匿名函数则只能包含一个表达式，如果你想包含多个表达式，那么把它用do包起来\n```clojure\nuser=> (map #(+ % 1) [1 2 3])\n(2 3 4)\n```\n`%`代表参数,如果有多个参数可以使用`%1`, `%2`等.\n\n#### 函数重载\nClojure虽然只能根据参数个数进行重载,使用multimethods技术可以实现任意类型的重载。\n\nmultimethod使用宏`defmulti`和`defmethod`进行定义.\n* `defmulti` :参数包括一个方法名以及一个dispatch函数，这个dispatch函数的返回值会被用来选择到底调用哪个重载的函数\n* `defmethod`: 参数则包括方法名，dispatch的值， 参数列表以及方法体\n```clojure\n(defmulti printOne class)\n(defmethod printOne Number [arg] (println \"print \" arg))\n(defmethod printOne String [arg] (println \"print \" arg))\n(defmethod printOne :default [arg] (println \"print defult\"))\n(printOne 12)\n(printOne \"cde\")\n(printOne false)\n```\n\n\n#### 函数参数占位符\n`_`可以用来做函数的占位符 \n```clojure\n(defn call1 [n1] (println n1))\n(defn call2 [n1 n2] (println n1 n2))\n(defn call3 [n1 _] (println n1))\n(call1 1)\n(call2 2 3)\n(call3 3 4)\n```\n占位符的作用是表示这个位置有一个参数,但是我并不会使用它. 这种参数在回调函数里比较有用.\n```clojure\n(defn call2 [n1 n2] (println n1 n2))\n(defn call3 [n1 _] (println n1))\n(defn caller [call n](call n n))\n(caller call2 2)\n(caller call3 3)\n```\n\n#### 高阶函数\n##### complement\n接受一个函数作为参数，如果这个参数返回值是true， 那么它就返回false, 相当于一个取反的操作\n```clojure\n\n```\n\n##### comp\ncomp把任意多个函数组合成一个，前面一个函数的返回值作为后面一个函数的参数\n```clojure\n\n```\n\n##### partial\npartial 函数创建一个新的函数 — 通过给旧的函数制定一个初始值， 然后再调用原来的函数\n```clojure\n\n```\n\n##### memoize\n函数接受一个参数，它的作用就是给原来的函数加一个缓存，所以如果同样的参数被调用了两次， 那么它就直接从缓存里面返回缓存了的结果\n```clojure\n\n```\n\n##### time\n```clojure\n\n```\n\n#### 宏\n\n\n\n\n\n#### special form\nClojure支持以下几种special form\n\n##### def\n通过`def`来定义一个全局binding(还可以给他一个`root value`, 该值在所有线程里都是可见的).\n```clojure\n(def n 19)\n(print n)\n```\n\n##### var\n```clojure\n\n```\n\n##### do\n```clojure\n\n```\n\n\n##### dot (‘.’)\n```clojure\n\n```\n\n\n##### finally\n```clojure\n\n```\n\n\n##### fn\n```clojure\n\n```\n\n##### if\n```clojure\n\n```\n\n##### let\nlet 这个special form 创建局限于一个 当前form的bindings. 它的第一个参数是一个vector, 里面包含名字-表达式的对子。表达式的值会被解析然后赋给左边的名字。这些binding可以在这个vector后面的表达式里面使用。这些binding还可以被多次赋值以改变它们的值，let命令剩下的参数是一些利用这个binding来进行计算的一些表达式。注意：如果这些表达式里面有调用别的函数，那么这个函数是无法利用let创建的这个binding的。\n```clojure\n\n```\n\n##### loop\n```clojure\n\n```\n\n##### monitor-enter\n```clojure\n\n```\n\n##### monitor-exit\n```clojure\n\n```\n\n##### new\n```clojure\n\n```\n\n##### quote\n```clojure\n\n```\n\n##### recur\n```clojure\n\n```\n\n##### set!\n```clojure\n\n```\n\n##### try catch throw\n```clojure\n\n```\n\n\n\n## 安全共享数据\nClojure提供三种方法来安全地共享可修改的数据。所有三种方法的实现方式都是持有一个可以开遍的引用指向一个不可改变的数据。\n\n* 它们都可以指向任意类型的对象。\n* 都可以利用函数deref 以及宏@ 来读取它所指向的对象。\n* 它们都支持验证函数，这些函数在它们所指向的值发生变化的时候自动调用。如果新值是合法的值，那么验证函数简单的返回true, 如果新值是不合法的，那么要么返回false， 要么抛出一个异常。如果只是简单地返回了false, 那么一个IllegalStateException 异常会被抛出，并且带着提示信息： \"Invalid reference state\" 。\n* 如果是Agents的话，它们还支持watchers。如果被监听的引用的值发生了变化，那么Agent会得到通知， 详情见 \"Agents\" 一节。\n\n### binding\nClojure不支持变量但是支持`binding`。`binding`跟变量有点像，但是在被赋值之前是不允许改的，bingding类型有：\n* 全局binding: 通过`def`来定义一个全局binding\n* 线程本地(thread local)binding:\n* 函数内的本地binding:函数的参数是只在这个函数内可见的本地binding。\n* 表达式内部的binding:\n\n### vars\nVars数据被所有线程root binding, 并且每个线程线程对其有自己线程本地(thread-local)值的一种引用类型。这个类型是不是线程安全的,因为每个线程都有对其线程本地的拷贝,那么当A线程对值进行修改时,可能B线程会优先对其进行修改,但是这是B的修改对A是不可见的.\n\n创建\n```clojure\n(def name initial-value) ;如果不设置值的话,则默认是'unbound'\n```\n修改值\n```clojure\n(def name new-value) 可以赋新的值 \n(alter-var-root (var name) update-fn args) 自动设置新值\n(set! name new-value) 在一个binding form 里满设置一个新的、线程本地的值\n```\n创建线程本地binding\n```\n(binding [name expression] body)\n(set! name expression) ;\n```\n\n### Refs \nRefs是用来协调对于一个或者多个binding的并发修改的。这个协调机制是利用Software Transactional Memory (STM)来实现的。 \n\nRefs指定在一个事务里面修改。执行事务的代码要包在`dosync`体内,当在一个事务里面对值进行修改，被改的其实是一个私有的、线程内的、直到事务提交才会被别的线程看到的一快内存。当事务结束的时候如果没有抛出异常的话,事务会正常提交. 如果在提交时发现已经有其他的线程修改了该值,那么事务会从头再重新执行一边.\n\n要在事务里面执行的代码一定要是没有副作用的，这一点非常重要，因为前面提到的，事务可能会跟别的事务事务冲突，然后重试， 如果有副作用的话，那么出来的结果就不对了。不过要执行有副作用的代码也是可能的， 可以把这个方法调用包装给Agent, 然后这个方法会被hold住直到事务成功提交，然后执行一次。如果事务失败那么就不会执行。\n\n创建\n```clojure\n(def name (ref initial-value)) ;ref函数创建了一个 Ref 对象\n```\n\n如果你要赋的新值是基于旧的值的话，那么就需要三个步骤了：\n1. deference 这个 Ref 来获得它的旧值\n2. 计算新值\n3. 设置新值\n\n下面的alter函数和commite函数都完成了这三个操作,要赋的新的值是基于旧的值计算出来的时候, 那么我们鼓励使用alter 和commute 而不是ref-set.\n```clojure\n(ref-set ref new-value) 必须在dosync里面调用 \n(alter ref update-fn arguments) 必须在dosync里面调用\n(commute ref update-fn arguments) 必须在dosync 里面调用\n```\n* alter:用来操作那些必须以特定顺序进行的修改.如果alter 试图修改的 Ref 在当前事务开始之后被别的事务改变了，那么当前事务会进行重试\n* commite:操作那些修改顺序不是很重要,可以同时进行的修改.如果alter 试图修改的 Ref 在当前事务开始之后被别的事务改变了，commute 不会进行重试。它会以事务内的当前值进行计算。\n\ndosync宏\n```clojure\n(dosync\n  (ref-set name new-value)\n )\n```\n\n#### Validation函数\n他验证所有赋给Ref的值是数字。\n\n### Atoms \nAtoms 提供了一种比使用Refs&STM更简单的更新当个值的方法。它不受事务的影响\n\n\n创建\n```clojure\n(def my-atom (atom initial-value))\n```\n\n有三个函数可以修改一个Atom的值：\n#### reset! \n接受两个参数：要设值的Atom以及新值。它设置新的值，而不管你旧的值是什么。\n```clojure\n(reset! atom new-value) \n```\n\n#### compare-and-set! \n接受三个参数：要被修改的Atom, 上次读取时候的值，新的值。 这个函数在设置新值之前会去读Atom现在的值。如果与上次读的时候的值相等， 那么设置新值并返回true, 否则不设置新值， 返回false\n```clojure\n(compare-and-set! atom current-value new-value)\n```\n\n#### swap!: \n接受一个要修改的 Atom, 一个计算Atom新值的函数以及一些额外的参数(如果需要的话)。这个计算Atom新的值的函数会以这个Atom以及一些额外的参数做为输入。swap！函数实际上是对compare-and-set!函数的一个封装，但是有一个显著的不同。 它首先把Atom的当前值存入一个变量，然后调用计算新值的函数来计算新值， 然后再调用compare-and-set!函数来赋值。如果赋值成功的话，那就结束了。如果赋值不成功的话， 那么它会重复这个过程，一直到赋值成功为止\n```clojure\n(swap! atom update-fn arguments)\n```\n\n### Agents \nAgents 是用把一些事情放到另外一个线程来做 -- 一般来说不需要事务控制的。它们对于修改一个单个对象的值(也就是Agent的值)来说很方便。这个值是通过在另外的一个thread上面运行一个“action”来修改的。一个action是一个函数， 这个函数接受Agent的当前值以及一些其它参数。 Only one action at a time will be run on a given Agent在任意一个时间点一个Agent实例上面只能运行一个action.\n\n\n创建\n```clojure\n(def my-agent (agent initial-value))\n```\n\n有俩个个函数可以修改一个Agent的值：\n#### send\nend 函数把一个 action 分配给一个 Agent， 并且马上返回而不做任何等待。 这个action会在另外一个线程(一般是由一个线程池提供的)上面单独运行。 当这个action运行结束之后，返回值会被设置给这个Agent。\n\nsend 使用一个 \"固定大小的\" 线程吃 (java.util.concurrent.Executors里面的newFixedThreadPool ) ， 线程的个数是机器的处理器的个数加2。如果所有的线程都被占用，那么你如果要运行新的action， 那你就要等了\n```clojure\n(send agent update-fn arguments) \n```\n\n#### send-off\nsend-off 函数也类似只是线程来自另外一个线程吃。\n\nsend-off 使用的是 \"cached thread pool\" (java.util.concurrent.Executors里面的?newCachedThreadPool) ， 这个线程池里面的线程的个数是按照需要来分配的。\n```clojure \n(send-off agent update-fn arguments)\n```\n\n\n## 流程控制\n\n\n## 调用java\n\n\n## 谓词\nClojure 提供了很多函数来充当谓词的功能 — 测试条件是否成立\n\n### 测试对象类型谓词\n* `class?`\n* `coll?`\n* `decimal?`\n* `delay?`\n* `float?`\n* `fn?`\n* `instance?`\n* `integer?`\n* `isa?`\n* `keyword?`\n* `list?`\n* `macro?`\n* `map?`\n* `number?`\n* `seq?`\n* `set?`\n* `string?` \n* `vector?`\n\n### 测试两个值关系\n* `<`\n* `<=`\n* `=`\n* `not=`\n* `==`\n* `>`\n* `>=`\n* `compare`\n* `distinct?` \n* `identical?`\n\n### 测试逻辑关系\n* `and`\n* `or`\n* `not`\n* `true?`\n* `false?` \n* `nil?`\n\n\n### 测试集合\n* `empty?`\n* `not-empty`\n* `every?`\n* `not-every?`\n* `some?` \n* `not-any?`\n\n### 测试数字的谓词有\n* `even?`\n* `neg?`\n* `odd?`\n* `pos?` \n* `zero?`\n\n\n\n## Clojure集合\n所有的clojure集合有以下三个特性\n* 不可修改的:集合产生之后，不能从集合里面删除一个元素，也往集合里面添加一个元素\n* 异源的\n* 持久的\n\nClojure提供这些集合类型:\n* list\n* vector\n* set\n* map\n\n### list\nLists是一个有序的元素的集合\n\nlist有多种定义方式\n* `(def stooges (list \"Moe\" \"Larry\" \"Curly\"))`\n* `(def stooges (quote (\"Moe\" \"Larry\" \"Curly\")))`\n* `(def stooges '(\"Moe\" \"Larry\" \"Curly\"))`\n\n\n### Vectors\nVectors也是一种有序的集合。这种集合对于从最后面删除一个元素，或者获取最后面一个元素是非常高效的(O(1))。这意味着对于向vector里面添加元素使用conj被使用cons更高效。Vector对于以索引的方式访问某个元素（用nth命令）或者修改某个元素(用assoc)来说非常的高效。函数定义的时候指定参数列表用的就是vector。\n\n创建有多种定义方式\n* `(def stooges (vector \"Moe\" \"Larry\" \"Curly\"))`\n* `(def stooges [\"Moe\" \"Larry\" \"Curly\"])`\n\n### Sets\n一个包含不重复元素的集合。当我们要求集合里面的元素不可以重复，并且我们不要求集合里面的元素保持它们添加时候的顺序，那么sets是比较适合的。 Clojure 支持两种不同的set： 排序的和不排序的。如果添加到set里面的元素相互之间不能比较大小，那么一个ClassCastException 异常会被抛出来。\n\n创建有多种定义方式\n* (def stooges (hash-set \"Moe\" \"Larry\" \"Curly\"))\n* (def stooges #{\"Moe\" \"Larry\" \"Curly\"})  \n* (def stooges (sorted-set \"Moe\" \"Larry\" \"Curly\"))\n\n### Maps\nMaps 保存从key到value的a对应关系 \n\n创建有多种定义方式\n* (def popsicle-map (hash-map :red :cherry, :green :apple, :purple :grape))\n* (def popsicle-map {:red :cherry, :green :apple, :purple :grape}) ; same as previous\n* (def popsicle-map (sorted-map :red :cherry, :green :apple, :purple :grape))\n  \n\n### 集合函数:\n\n#### count\n统计集合里面的元素个数\n```clojure\nuser=> (count [19 \"yellow\" true])\n3\n```\n\n#### conj\n添加一个元素到集合里面去\n```clojure\n\n```\n\n#### reverse \n把集合里面的元素反转\n```clojure\nuser=> (reverse [1 2 3])\n(3 2 1)\n```\n\n#### map \n对一个给定的集合里面的每一个元素调用一个指定的方法，然后这些方法的所有返回值构成一个新的集合（LazySeq）返回\n```clojure\nuser=> (map #(+ % 1) [1 2 3])\n(2 3 4)\n```\n\n#### apply \n把给定的集合里面的所有元素一次性地给指定的函数作为参数调用，然后返回这个函数的返回值\n```clojure\nuser=> (apply + [1 2 3])\n6\n```\n\n#### first\n取集合中第一个元素\n```clojure\nuser=> (first [1 2 3])\n1\n```\n\n#### second\n```clojure\nuser=> (second [1 2 3])\n2\n```\n\n#### last\n```clojure\nuser=> (last [1 2 3])\n3\n\n```\n\n#### nth\n```clojure\nuser=> (nth [1 2 3] 2)\n3\n```\n\n#### next\n```clojure\nuser=> (next [1 2 3])\n(2 3)\n```\n\n#### butlast\n排除最后一个元素\n```clojure\n( print (butlast [1 2 3]))\n```\n\n#### drop-last\n```clojure\n( print (drop-last [1 2 3]))\n```\n\n#### filter\n\n```clojure\n( print (filter #(> % 1) [1 2 3]))\n```\n\n#### nthnext\n```clojure\n( print (nthnext  [1 2 3] 1))\n```\n\n#### some\n判断集合中是否包含某个元素\n```clojure\nuser=> (some #(= % 3) [1 2 3])\ntrue\n```\n\n#### contains\n```clojure\nuser=> (contains? [1 2 3] 3)\nfalse\nuser=> (contains? (set [1 2 3]) 3)\ntrue\n```\n\n#### conj\n通过一个已有的集合来创建一个新的包含更多元素的集合\n```clojure\nuser=> (conj [1 2 3] 4)\n[1 2 3 4]\nuser=> (conj [1 2 3] [4 5 6])\n[1 2 3 [4 5 6]]\n```\n\n#### cons\n通过一个已有的集合来创建一个新的包含更多元素的集合\n```clojure\nuser=> (cons [1 2 3] 4)\nIllegalArgumentException Don't know how to create ISeq from: java.lang.Long  clojure.lang.RT.seqFrom (RT.java:505)\n\nuser=> (cons 4 [1 2 3] )\n(4 1 2 3)\n```\n\n#### remove \n函数创建一个只包含所指定的谓词函数测试结果为false的元素的集合\n```clojure\nuser=> (remove #(= % 2) [1 2 3])\n(1 3)\n```\n\n#### into\n把两个list里面的元素合并成一个新的list\n```clojure\nuser=> (into [1 2] [3 4] )\n[1 2 3 4]\n```\n\n#### peek\n```clojure\nuser=> (peek [1 2 3])\n3\n\n```\n\n#### pop\n```clojure\nuser=> (pop [1 2 3])\n[1 2]\n```\n\n#### get\n```clojure\n\n```\n\n#### get\n```clojure\nuser=> (get [1 2 3] 1 110)\n2\nuser=> (get [1 2 3] 10 110)\n110\n```\n\n#### assoc\n替换指定位置元素\n```clojure\nuser=> (assoc [1 2 3] 2 4)\n[1 2 4]\n```\n\n#### subvec \n获取一个给定vector的子vector\n```clojure\nuser=> (subvec [1 2 3 ] 1 2)\n[2]\n```\n\n#### disj \n函数通过去掉给定的set里面的一些元素来创建一个新的set\n```clojure\n\n```\n\n\n## 语法糖\n\n### 注释\n`; text` 单行注释\n```clojure\n\n```\n\n### 字符\n`\\char` \n`\\tab`\n`\\newline`\n`\\space`\n`\\uunicode-hex-value`\n\n```clojure\n\n```\n\n### 字符串\n`\"text\"`\n```clojure\n\n```\n\n### 关键字\n关键字是一个内部字符串; 两个同样的关键字指向同一个对象; 通常被用来作为map的key\n\n`:name`\n```clojure\n\n```\n\n### 命名空间关键字\n`::name`\n```clojure\n\n```\n\n### 正则表达式\n`#\"pattern\"`\n```clojure\n\n```\n\n### 逗号\n逗号被当成空白（通常用在集合里面用来提高代码可读性）\n```clojure\n\n```\n\n### 链表\n`'(items)`(不会evaluate每个元素）\t\n\n函数 `(list items)`会evaluate每个元素\n```clojure\n\n```\n\n### vector\n`[items]`\n\n\n函数`(vector items)`\n```clojure\n\n```\n\n### set\n`#{items}`建立一个hash-set\t\n\n函数`(hash-set items)`\n`(sorted-set items)`\n```clojure\n\n```\n\n### map\t\n`{key-value-pairs}`建立一个hash-map\t\n\n函数`(hash-map key-value-pairs)`\n`(sorted-map key-value-pairs)`\n\n```clojure\n\n```\n\n### 绑定元数据\n给symbol或者集合绑定元数据\t`#^{key-value-pairs}` object在读入期处理\t\n\n函数`(with-meta object metadata-map)`在运行期处理\n```clojure\n\n```\n\n###获取symbol或者集合的元数据\n`^object`\t\n\n函数`(meta object)`\n```clojure\n\n```\n\n### 获取一个函数的参数列表（个数不定的）\n`& name`\n```clojure\n\n```\n\n### 创建一个java对象\n`(class-name. args)\t`\n\n函数`(new class-name args)`\n```clojure\n\n```\n\n### 调用java方法\n* (. class-or-instance method-name args) \n* (.method-name class-or-instance args)\n```clojure\n\n```\n\n### 创建匿名函数\n`#(single-expression)` 用% (等同于 %1), %1, %2来表示参数\t\n\n函数`(fn [arg-names] expressions)`\n```clojure\n\n```\n\n### 获取Ref, Atom 和Agent对应的valuea\n@ref\t\n\n函数(deref ref)\n```clojure\n\n```\n\n### syntax quote \n(使用在宏里面)  `\n```clojure\n\n```\n\n### unquote \n使用在宏里面`~value`\n```clojure\n\n```\n\n### unquote splicing \n(使用在宏里面)`~@value`\n```clojure\n\n```\n\n### auto-gensym \n(在宏里面用来产生唯一的symbol名字)\t\n`prefix#`\n\n函数`(gensym prefix )`\n```clojure\n\n```\n\n\n\n","slug":"编程语言/Clojure","published":1,"updated":"2015-10-26T10:32:28.980Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrv00120cufc3npp1lm"},{"date":"2015-10-07T16:00:00.000Z","title":"AWK","_content":"# AWK\nawk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。\n\n语法\n```\nawk [-F  field-separator]  'commands'  input-file(s)\n```\n* -F: 域分隔符,由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。(我们指定:为分隔符`-F ':'`)\n* commands: 'PATTERN{COMMAND}'. PATTERN为模式(正在表达式),COMMAND为要执行的命令.\n\n```\nawk  -F ':'  'BEGIN {print \"start\"}  {print $1\"} END {print \"end\"}' ./txt\n```\n上面的例子是读取`txt`文件,然后使用`:`分割每一行数据,在开始处理的时候输出start，在处理过程中第一列数据，最后输出end。\n\n## 变量\n\n### 内置变量\n我们可以在AWK命令中直接使用以下内置变量\n```\nARGC               命令行参数个数\nARGV               命令行参数排列\nENVIRON            支持队列中系统环境变量的使用\nFILENAME           awk浏览的文件名\nFNR                浏览文件的记录数\nFS                 设置输入域分隔符，等价于命令行 -F选项\nNF                 浏览记录的域的个数\nNR                 已读的记录数\nOFS                输出域分隔符\nORS                输出记录分隔符\nRS                 控制记录分隔符\n```\n例如\n```\njps -l | awk '{print ARGC}'\n```\n\n### 自定义变量\n我们通过赋值的方式直接定义一个变量\n```\njps -l | awk 'BEGIN{size=0;} {size=1+size} {print $1} END{print size}'\n```\n上面我们定义了一个数值型的size变量.\n\n### 数组\n\n# 运算符\n* `= += -= *= /= %= ^= **=`\t赋值\n* `?:`\tC条件表达式\n* `||`\t逻辑或\n* `&&`\t逻辑与\n* `~ ~!`\t匹配正则表达式和不匹配正则表达式\n* `< <= > >= != ==`\t关系运算符\n* `空格`\t连接\n* `+ -`\t加，减\n* `* / &`\t乘，除与求余\n* `+ - !`\t一元加，减和逻辑非\n* `^ ***`\t求幂\n* `++ --`\t增加或减少，作为前缀或后缀\n* `$`\t字段引用\n* `in`\t数组成员\n\n\n# 流程控制\n## 条件语句\n下面输出了大于10000的java进程号\n```\njps -l | awk 'BEGIN{size=0} {if($1>10000) {size++;print $1}} END{print size}'\n```\n\n## 循环语句\nawk中的循环语句借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。\n\n# 字符串处理\n## sub函数\n匹配从左侧开始找到的第一个符合规则的字符串，然后使用替换字符串替换这些字符串\n```\njps -l | awk '{sub(/moon/, \"sun\")} {print $2}'\n```\n上面这个例子就使用sun这个字符串替换了$2中的moon字符串。\n\n我们还可以指定在哪列执行查找替换\n```\njps -l | awk '{sub(/moon/, \"sun\", $1)} {print $2}'\n```\n上面的例子中我们只在第一列进行查找替换\n\n## gsub函数\n与sub函数不同的是，这个执行的是全局替换\n```\njps -l | awk '{gsub(/moon/, \"sun\")} {print $2}'\n```\n\n## index函数\n返回子字符串第一次被匹配的位置，偏移量从位置1开始\n```\njps -l | awk '{print$2; $2=index($2, \"moon\")} {print $2}'\n```\n\n## length函数\n返回记录的字符数\n```\njps -l | awk '{print$2; $2=length($2)} {print $2}'\n```\n\n## substr函数\n返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串\n```\njps -l | awk '{print substr($2, 2, 10)} '\n```\n上面的例子将$2字符串从第二个字符还是截取，截取10个长度的字符串出来\n\n## toupper和tolower函数\n可用于字符串大小间的转换\n```\nawk '{print toupper($2)} '\n```\n\n## split函数\n可按给定的分隔符把字符串分割为一个数组\n```\njps -l | awk '{ split($2, array, \"/\"); print array[3]} '\n```\n上面的例子我们将$2这一列按照`/`进行分割,然后将分割出的数据存储到array数组里. 注意这里首先不需要转义\n\n\n# 正则表达式\n\n## \\\n将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配换行符。序列“\\\\”匹配“\\”，“\\(”匹配“(”。\n```\nawk '/\\\\/{print $0}' ./txt \n```\n过滤出带有`\\`的行\n\n## ^\n匹配输入字符串与最左侧开始的位置的字符串。\n```\nawk '/^\\\\n/{print $0}' ./txt \n```\n找到所有以`\\n`字符串开始的数据\n\n## $\n匹配输入字符串结尾的位置。\n```\nawk '/)。$/{print $0}' ./txt \n```\n过滤以`)。`结尾的行\n\n## *\n零次或多次匹配前面的字符或子表达式。例如，zo* 匹配“z”和“zoo”。* 等效于 {0,}。\n```\nawk '/反向引用*/{print $0}' ./txt \n```\n\n## +\n一次或多次匹配前面的字符或子表达式。例如，“zo+”与“zo”和“zoo”匹配，但与“z”不匹配。+ 等效于 {1,}。\n```\nawk '/反向引用+/{print $0}' ./txt \n```\n\n## ?\n零次或一次匹配前面的字符或子表达式。例如，“do(es)?”匹配“do”或“does”中的“do”。? 等效于 {0,1}。\n```\nawk '/反向引用?/{print $0}' ./txt \n```\n\n## {n}\nn 是非负整数。正好匹配 n 次。例如，“o{2}”与“Bob”中的“o”不匹配，但与“food”中的两个“o”匹配。\n```\n\t\n```\n\n## {n,}\nn 是非负整数。至少匹配 n 次。例如，“o{2,}”不匹配“Bob”中的“o”，而匹配“foooood”中的所有 o。“o{1,}”等效于“o+”。“o{0,}”等效于“o*”。\n```\n\n```\n\n## {n,m}\nM 和 n 是非负整数，其中 n <= m。匹配至少 n 次，至多 m 次。例如，“o{1,3}”匹配“fooooood”中的头三个 o。'o{0,1}' 等效于 'o?'。注意：您不能将空格插入逗号和数字之间。\n```\n\n```\n\n## .\n匹配除“\\n”之外的任何单个字符。若要匹配包括“\\n”在内的任意字符，请使用诸如“[\\s\\S]”之类的模式。\n```\n\n```\n\n## (pattern)\n匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果“匹配”集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用“\\(”或者“\\)”。\n```\n\n```\n\n## (?:pattern)\n匹配 pattern 但不捕获该匹配的子表达式，即它是一个非捕获匹配，不存储供以后使用的匹配。这对于用“or”字符 (|) 组合模式部件的情况很有用。例如，'industr(?:y|ies) 是比 'industry|industries' 更经济的表达式。\n```\n\n```\n\n## (?=pattern)\n执行正向预测先行搜索的子表达式，该表达式匹配处于匹配 pattern 的字符串的起始点的字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?=95|98|NT|2000)' 匹配“Windows 2000”中的“Windows”，但不匹配“Windows 3.1”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```\n\n```\n\n## (?!pattern)\n执行反向预测先行搜索的子表达式，该表达式匹配不处于匹配 pattern 的字符串的起始点的搜索字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?!95|98|NT|2000)' 匹配“Windows 3.1”中的 “Windows”，但不匹配“Windows 2000”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```\n\n```\n\n## x|y\n匹配 x 或 y。\n```\n awk '/换页符等|十六进制转义码必须正好是两位数长/ {print $0}' ./txt \n```\n\n## [xyz]\n匹配是否包含xyz中任意一个字符\n```\nawk '/[前面至少有]/ {print $0}' ./txt \n```\n\n## [^xyz]\n匹配不能包含xyz任意一个字符\n```\nawk '/[^前面至少有]/ {print $0}' ./txt \n```\n\n## [a-z]\n与`[xyz]`规则相同,只不过这个模式提供了一个范围模式.例如[a-c]实际为匹配[abc]\n```\nawk '/[a-b]/ {print $0}' ./txt \n```\n\n## [^a-z]\n反向范围字符。匹配不在指定的范围内的任何字符。例如，“[^a-z]”匹配任何不在“a”到“z”范围内的任何字符。\n```\nawk '/[^a-z]/ {print $0}' ./txt \n```\n需要注意的是'\\t'会被匹配出来\n\n## \\d\n数字字符匹配。等效于 [0-9]。\n```\nawk '/\\d/ {print $0}' ./txt \n```\n\n## \\D\n非数字字符匹配。等效于 [^0-9]。\n```\nawk '/\\D/ {print $0}' ./txt\n```\n\n## \\n\n换行符匹配。等效于 \\x0a 和 \\cJ。\n```\nawk '/\\n/ {print $0}' ./txt \n```\n\n## \\r\n匹配一个回车符。等效于 \\x0d 和 \\cM。\n```\n awk '/\\t/ {print $0}' ./txt \n```\n\n## \\s\n匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。\n```\nawk '/\\s/ {print $0}' ./txt \n```\n\n## \\S\n匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。\n```\nawk '/\\S/ {print $0}' ./txt \n```\n\n## \\w\n匹配任何字类字符，包括下划线。与“[A-Za-z0-9_]”等效。\n```\nawk '/\\w/ {print $0}' ./txt \n```\n\n## \\W\n与任何非单词字符匹配。与“[^A-Za-z0-9_]”等效。\n```\nawk '/\\W/ {print $0}' ./txt \n```\n\n","source":"_posts/编程语言/2015-10-12-AWK.md","raw":"category: 编程语言\ndate: 2015-10-08\ntitle: AWK\n---\n# AWK\nawk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。\n\n语法\n```\nawk [-F  field-separator]  'commands'  input-file(s)\n```\n* -F: 域分隔符,由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。(我们指定:为分隔符`-F ':'`)\n* commands: 'PATTERN{COMMAND}'. PATTERN为模式(正在表达式),COMMAND为要执行的命令.\n\n```\nawk  -F ':'  'BEGIN {print \"start\"}  {print $1\"} END {print \"end\"}' ./txt\n```\n上面的例子是读取`txt`文件,然后使用`:`分割每一行数据,在开始处理的时候输出start，在处理过程中第一列数据，最后输出end。\n\n## 变量\n\n### 内置变量\n我们可以在AWK命令中直接使用以下内置变量\n```\nARGC               命令行参数个数\nARGV               命令行参数排列\nENVIRON            支持队列中系统环境变量的使用\nFILENAME           awk浏览的文件名\nFNR                浏览文件的记录数\nFS                 设置输入域分隔符，等价于命令行 -F选项\nNF                 浏览记录的域的个数\nNR                 已读的记录数\nOFS                输出域分隔符\nORS                输出记录分隔符\nRS                 控制记录分隔符\n```\n例如\n```\njps -l | awk '{print ARGC}'\n```\n\n### 自定义变量\n我们通过赋值的方式直接定义一个变量\n```\njps -l | awk 'BEGIN{size=0;} {size=1+size} {print $1} END{print size}'\n```\n上面我们定义了一个数值型的size变量.\n\n### 数组\n\n# 运算符\n* `= += -= *= /= %= ^= **=`\t赋值\n* `?:`\tC条件表达式\n* `||`\t逻辑或\n* `&&`\t逻辑与\n* `~ ~!`\t匹配正则表达式和不匹配正则表达式\n* `< <= > >= != ==`\t关系运算符\n* `空格`\t连接\n* `+ -`\t加，减\n* `* / &`\t乘，除与求余\n* `+ - !`\t一元加，减和逻辑非\n* `^ ***`\t求幂\n* `++ --`\t增加或减少，作为前缀或后缀\n* `$`\t字段引用\n* `in`\t数组成员\n\n\n# 流程控制\n## 条件语句\n下面输出了大于10000的java进程号\n```\njps -l | awk 'BEGIN{size=0} {if($1>10000) {size++;print $1}} END{print size}'\n```\n\n## 循环语句\nawk中的循环语句借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。\n\n# 字符串处理\n## sub函数\n匹配从左侧开始找到的第一个符合规则的字符串，然后使用替换字符串替换这些字符串\n```\njps -l | awk '{sub(/moon/, \"sun\")} {print $2}'\n```\n上面这个例子就使用sun这个字符串替换了$2中的moon字符串。\n\n我们还可以指定在哪列执行查找替换\n```\njps -l | awk '{sub(/moon/, \"sun\", $1)} {print $2}'\n```\n上面的例子中我们只在第一列进行查找替换\n\n## gsub函数\n与sub函数不同的是，这个执行的是全局替换\n```\njps -l | awk '{gsub(/moon/, \"sun\")} {print $2}'\n```\n\n## index函数\n返回子字符串第一次被匹配的位置，偏移量从位置1开始\n```\njps -l | awk '{print$2; $2=index($2, \"moon\")} {print $2}'\n```\n\n## length函数\n返回记录的字符数\n```\njps -l | awk '{print$2; $2=length($2)} {print $2}'\n```\n\n## substr函数\n返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串\n```\njps -l | awk '{print substr($2, 2, 10)} '\n```\n上面的例子将$2字符串从第二个字符还是截取，截取10个长度的字符串出来\n\n## toupper和tolower函数\n可用于字符串大小间的转换\n```\nawk '{print toupper($2)} '\n```\n\n## split函数\n可按给定的分隔符把字符串分割为一个数组\n```\njps -l | awk '{ split($2, array, \"/\"); print array[3]} '\n```\n上面的例子我们将$2这一列按照`/`进行分割,然后将分割出的数据存储到array数组里. 注意这里首先不需要转义\n\n\n# 正则表达式\n\n## \\\n将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配换行符。序列“\\\\”匹配“\\”，“\\(”匹配“(”。\n```\nawk '/\\\\/{print $0}' ./txt \n```\n过滤出带有`\\`的行\n\n## ^\n匹配输入字符串与最左侧开始的位置的字符串。\n```\nawk '/^\\\\n/{print $0}' ./txt \n```\n找到所有以`\\n`字符串开始的数据\n\n## $\n匹配输入字符串结尾的位置。\n```\nawk '/)。$/{print $0}' ./txt \n```\n过滤以`)。`结尾的行\n\n## *\n零次或多次匹配前面的字符或子表达式。例如，zo* 匹配“z”和“zoo”。* 等效于 {0,}。\n```\nawk '/反向引用*/{print $0}' ./txt \n```\n\n## +\n一次或多次匹配前面的字符或子表达式。例如，“zo+”与“zo”和“zoo”匹配，但与“z”不匹配。+ 等效于 {1,}。\n```\nawk '/反向引用+/{print $0}' ./txt \n```\n\n## ?\n零次或一次匹配前面的字符或子表达式。例如，“do(es)?”匹配“do”或“does”中的“do”。? 等效于 {0,1}。\n```\nawk '/反向引用?/{print $0}' ./txt \n```\n\n## {n}\nn 是非负整数。正好匹配 n 次。例如，“o{2}”与“Bob”中的“o”不匹配，但与“food”中的两个“o”匹配。\n```\n\t\n```\n\n## {n,}\nn 是非负整数。至少匹配 n 次。例如，“o{2,}”不匹配“Bob”中的“o”，而匹配“foooood”中的所有 o。“o{1,}”等效于“o+”。“o{0,}”等效于“o*”。\n```\n\n```\n\n## {n,m}\nM 和 n 是非负整数，其中 n <= m。匹配至少 n 次，至多 m 次。例如，“o{1,3}”匹配“fooooood”中的头三个 o。'o{0,1}' 等效于 'o?'。注意：您不能将空格插入逗号和数字之间。\n```\n\n```\n\n## .\n匹配除“\\n”之外的任何单个字符。若要匹配包括“\\n”在内的任意字符，请使用诸如“[\\s\\S]”之类的模式。\n```\n\n```\n\n## (pattern)\n匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果“匹配”集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用“\\(”或者“\\)”。\n```\n\n```\n\n## (?:pattern)\n匹配 pattern 但不捕获该匹配的子表达式，即它是一个非捕获匹配，不存储供以后使用的匹配。这对于用“or”字符 (|) 组合模式部件的情况很有用。例如，'industr(?:y|ies) 是比 'industry|industries' 更经济的表达式。\n```\n\n```\n\n## (?=pattern)\n执行正向预测先行搜索的子表达式，该表达式匹配处于匹配 pattern 的字符串的起始点的字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?=95|98|NT|2000)' 匹配“Windows 2000”中的“Windows”，但不匹配“Windows 3.1”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```\n\n```\n\n## (?!pattern)\n执行反向预测先行搜索的子表达式，该表达式匹配不处于匹配 pattern 的字符串的起始点的搜索字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，'Windows (?!95|98|NT|2000)' 匹配“Windows 3.1”中的 “Windows”，但不匹配“Windows 2000”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。\n```\n\n```\n\n## x|y\n匹配 x 或 y。\n```\n awk '/换页符等|十六进制转义码必须正好是两位数长/ {print $0}' ./txt \n```\n\n## [xyz]\n匹配是否包含xyz中任意一个字符\n```\nawk '/[前面至少有]/ {print $0}' ./txt \n```\n\n## [^xyz]\n匹配不能包含xyz任意一个字符\n```\nawk '/[^前面至少有]/ {print $0}' ./txt \n```\n\n## [a-z]\n与`[xyz]`规则相同,只不过这个模式提供了一个范围模式.例如[a-c]实际为匹配[abc]\n```\nawk '/[a-b]/ {print $0}' ./txt \n```\n\n## [^a-z]\n反向范围字符。匹配不在指定的范围内的任何字符。例如，“[^a-z]”匹配任何不在“a”到“z”范围内的任何字符。\n```\nawk '/[^a-z]/ {print $0}' ./txt \n```\n需要注意的是'\\t'会被匹配出来\n\n## \\d\n数字字符匹配。等效于 [0-9]。\n```\nawk '/\\d/ {print $0}' ./txt \n```\n\n## \\D\n非数字字符匹配。等效于 [^0-9]。\n```\nawk '/\\D/ {print $0}' ./txt\n```\n\n## \\n\n换行符匹配。等效于 \\x0a 和 \\cJ。\n```\nawk '/\\n/ {print $0}' ./txt \n```\n\n## \\r\n匹配一个回车符。等效于 \\x0d 和 \\cM。\n```\n awk '/\\t/ {print $0}' ./txt \n```\n\n## \\s\n匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。\n```\nawk '/\\s/ {print $0}' ./txt \n```\n\n## \\S\n匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。\n```\nawk '/\\S/ {print $0}' ./txt \n```\n\n## \\w\n匹配任何字类字符，包括下划线。与“[A-Za-z0-9_]”等效。\n```\nawk '/\\w/ {print $0}' ./txt \n```\n\n## \\W\n与任何非单词字符匹配。与“[^A-Za-z0-9_]”等效。\n```\nawk '/\\W/ {print $0}' ./txt \n```\n\n","slug":"编程语言/2015-10-12-AWK","published":1,"updated":"2015-10-20T01:10:44.562Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrx00140cuftcmr1039"},{"date":"2015-10-12T07:30:16.000Z","title":"双线程锁","_content":"所谓的双线程锁指的是这种锁适用于俩个线程运行的前提下. 下面我们依次给出了三种双线程锁解决方案：\n\n双线程算法遵循以下俩点约定:\n1. 线程标志为`0`或者`1`. 若当前线程调用者的标志为i,则另一方的调用者为1 - i\n2. 通过ThreadId.get()获取自己的标志\n\n* 互斥: 俩个线程的临界区是没有重叠的,那么我们撑这俩个临界区是互斥的.\n* 无死锁: 如果一个线程尝试获得一个锁,那么总会成功获得这个锁.\n* 无饥饿：每一个尝试获得锁的线程都能成功. 当线程调用一个锁方法的时候,这个方法立即返回,我们便称这个锁是无饥饿的.\n\n## LockOne\n```java\nclass LockOne {\n\tprivate volatile boolean[] flags = new boolean[2];\n\tpublic void lock() {\n\t\tint i = ThreadID.get();\n\t\tint j = 1- i;\n\t\tflag[i] = true;\n\t\twhile(flag[j]) {}\t\t\n\n\t}\n\n\tpublic void unlock() {\n\t\tint i = ThreadID.get();\n\t\tflag[i] = false;\n\t}\n}\n```\n\n假设线程A对应flag[0]标志,线程B对应flag[1]标志,那么我们得出下面这一个流程:\n1. `write_A(flag[0] = true) -> read_A(flag[1] == false) -> CS_A`这段话的意思是线程A将`flag[0]`的值置为true然后读取`flag[1]`的值,这个过程称为`CS_A`事件\n2. `write_B(flag[1] = true) -> read_B(flag[0] == false) -> CS_B`这段话的意思是线程B将`flag[1]`的值置为true然后读取`flag[0]`的值,这个过程称为`CS_B`事件\n\n> 我们验证一下LockOne算法是否满足互斥\n```\n假设这个算法不是互斥的，也就是无法得到`CS_A -> CS_B`且`CS_B -> CS_A`. \n假设CS_A事件先于CS_B事件,那么有：\nwrite_A(flag[0] = true) -> read_A(flag[1] == false) -> write_B(flag[1] = true)\n=> \nread_A(flag[1] == false) -> write_B(flag[1] = true)\n可以看到这俩个事件是互斥的(它们的临界区是没有重叠的).\n```\nLockOne算法满足了互斥,但是如果俩个线程并发执行的话，就会进入死锁,同样我们来证明一下\n```\n假设\nwrite_A(flag[0] = true) -> write_B(flag[1] = true) -> read_A(flag[1] == false) -> read_B(flag[0] == false)\n那么`flag[0]`和`flag[1]`就都成为true,也就是线程A和线程B进入了死锁.\n```\n\n至于说为什么要使用`volatile`关键字,这是为了保证`flags`变量的内存可见性,因为Java会将这段代码\n```java\nwhile(flag[j]) {}\t\n=>\nif(flag[j]) {\n\twhile(true) {\n\n\t}\n}\n```\n编译后的代码进行了提升优化,加上`volatile`关键字,就是告诉编译器,不要提升优化我的代码.\n\n## LockTwo\n```java\nclass LockTwo {\n\tprivate int lock;\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\t\twhile(lock == tid){}\n\t}\n\t\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\t\t\n\t}\n}\n```\n\n同样我们假设有俩个事件发生\n1. `write_A(lock = 1) -> read_A(lock == 1) -> CS_A`\n2. `write_B(lock = 2) -> read_B(lock == 2) -> CS_B`\n很明显任何线程调用加锁操作都会造成死循环. 但是,如果锁调用交叉调用的话\n```\nwrite_A(lock = 1) -> write_B(lock = 2) -> read_A(lock == 2) -> read_B(lock == 2) \n```\n直到A线程释放锁,B线程就一直在阻塞着. 因此只要这俩个事件并发执行就能完成互斥要求.\n\n## Peterson\n算法实现\n```\nclass Peterson {\n\tprivate voliate boolean[] flag = new boolean[2];\n\tprivate int lock;\n\t\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tint oid = 1 - tid;\n\t\tflag[oid] = true;\n\t\tlock = tid;\n\t\t\n\t\twhile(flag[tid] && lock == tid) {}\n\t}\n\t\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tflag[tid] = false;\n\t}\n}\n```\n同样的我们看看俩个线程依次调用锁过程(假设线程A对应flag[0]标志,线程B对应flag[1]标志)：\n```\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> read_A(flag[0] == false) -> read_A(lock == 0) -> CS_A\nwrite_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> CS_B\n```\n好，首先我们看一下\n* `CS_A`先于`CS_B`事件执行的话,那么B线程会进入锁等待. \n\n`CS_A`和`CS_B`事件并发执行我们分俩种情况分析：\n```\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_A(flag[1] == true) -> read_A(lock == 0) -> read_B(flag[1] == true) -> read_B(lock == 1)\n```\n同样的A线程事件先于B线程事件,我们看到A线程并没有进入锁等待,而是B线程进入了锁等待\n```\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> read_A(flag[1] == true) -> read_A(lock == 0)\n```\n我们发现这个锁算法仍然是有问题的.\n","source":"_posts/并发编程/1_1_双线程锁.md","raw":"category: 并发编程\ndate: 2015-10-12 15:30:16\ntitle: 双线程锁\n---\n所谓的双线程锁指的是这种锁适用于俩个线程运行的前提下. 下面我们依次给出了三种双线程锁解决方案：\n\n双线程算法遵循以下俩点约定:\n1. 线程标志为`0`或者`1`. 若当前线程调用者的标志为i,则另一方的调用者为1 - i\n2. 通过ThreadId.get()获取自己的标志\n\n* 互斥: 俩个线程的临界区是没有重叠的,那么我们撑这俩个临界区是互斥的.\n* 无死锁: 如果一个线程尝试获得一个锁,那么总会成功获得这个锁.\n* 无饥饿：每一个尝试获得锁的线程都能成功. 当线程调用一个锁方法的时候,这个方法立即返回,我们便称这个锁是无饥饿的.\n\n## LockOne\n```java\nclass LockOne {\n\tprivate volatile boolean[] flags = new boolean[2];\n\tpublic void lock() {\n\t\tint i = ThreadID.get();\n\t\tint j = 1- i;\n\t\tflag[i] = true;\n\t\twhile(flag[j]) {}\t\t\n\n\t}\n\n\tpublic void unlock() {\n\t\tint i = ThreadID.get();\n\t\tflag[i] = false;\n\t}\n}\n```\n\n假设线程A对应flag[0]标志,线程B对应flag[1]标志,那么我们得出下面这一个流程:\n1. `write_A(flag[0] = true) -> read_A(flag[1] == false) -> CS_A`这段话的意思是线程A将`flag[0]`的值置为true然后读取`flag[1]`的值,这个过程称为`CS_A`事件\n2. `write_B(flag[1] = true) -> read_B(flag[0] == false) -> CS_B`这段话的意思是线程B将`flag[1]`的值置为true然后读取`flag[0]`的值,这个过程称为`CS_B`事件\n\n> 我们验证一下LockOne算法是否满足互斥\n```\n假设这个算法不是互斥的，也就是无法得到`CS_A -> CS_B`且`CS_B -> CS_A`. \n假设CS_A事件先于CS_B事件,那么有：\nwrite_A(flag[0] = true) -> read_A(flag[1] == false) -> write_B(flag[1] = true)\n=> \nread_A(flag[1] == false) -> write_B(flag[1] = true)\n可以看到这俩个事件是互斥的(它们的临界区是没有重叠的).\n```\nLockOne算法满足了互斥,但是如果俩个线程并发执行的话，就会进入死锁,同样我们来证明一下\n```\n假设\nwrite_A(flag[0] = true) -> write_B(flag[1] = true) -> read_A(flag[1] == false) -> read_B(flag[0] == false)\n那么`flag[0]`和`flag[1]`就都成为true,也就是线程A和线程B进入了死锁.\n```\n\n至于说为什么要使用`volatile`关键字,这是为了保证`flags`变量的内存可见性,因为Java会将这段代码\n```java\nwhile(flag[j]) {}\t\n=>\nif(flag[j]) {\n\twhile(true) {\n\n\t}\n}\n```\n编译后的代码进行了提升优化,加上`volatile`关键字,就是告诉编译器,不要提升优化我的代码.\n\n## LockTwo\n```java\nclass LockTwo {\n\tprivate int lock;\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\t\twhile(lock == tid){}\n\t}\n\t\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tlock = tid;\n\t\t\n\t}\n}\n```\n\n同样我们假设有俩个事件发生\n1. `write_A(lock = 1) -> read_A(lock == 1) -> CS_A`\n2. `write_B(lock = 2) -> read_B(lock == 2) -> CS_B`\n很明显任何线程调用加锁操作都会造成死循环. 但是,如果锁调用交叉调用的话\n```\nwrite_A(lock = 1) -> write_B(lock = 2) -> read_A(lock == 2) -> read_B(lock == 2) \n```\n直到A线程释放锁,B线程就一直在阻塞着. 因此只要这俩个事件并发执行就能完成互斥要求.\n\n## Peterson\n算法实现\n```\nclass Peterson {\n\tprivate voliate boolean[] flag = new boolean[2];\n\tprivate int lock;\n\t\n\tpublic void lock() {\n\t\tint tid = ThreadID.get();\n\t\tint oid = 1 - tid;\n\t\tflag[oid] = true;\n\t\tlock = tid;\n\t\t\n\t\twhile(flag[tid] && lock == tid) {}\n\t}\n\t\n\tpublic void unlock() {\n\t\tint tid = ThreadID.get();\n\t\tflag[tid] = false;\n\t}\n}\n```\n同样的我们看看俩个线程依次调用锁过程(假设线程A对应flag[0]标志,线程B对应flag[1]标志)：\n```\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> read_A(flag[0] == false) -> read_A(lock == 0) -> CS_A\nwrite_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> CS_B\n```\n好，首先我们看一下\n* `CS_A`先于`CS_B`事件执行的话,那么B线程会进入锁等待. \n\n`CS_A`和`CS_B`事件并发执行我们分俩种情况分析：\n```\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_A(flag[1] == true) -> read_A(lock == 0) -> read_B(flag[1] == true) -> read_B(lock == 1)\n```\n同样的A线程事件先于B线程事件,我们看到A线程并没有进入锁等待,而是B线程进入了锁等待\n```\nwrite_A(flag[1] = true) -> write_A(lock = 0) -> write_B(flag[0] = true) -> write_B(lock = 1) -> read_B(flag[1] == true) -> read_B(lock == 1) -> read_A(flag[1] == true) -> read_A(lock == 0)\n```\n我们发现这个锁算法仍然是有问题的.\n","slug":"并发编程/1_1_双线程锁","published":1,"updated":"2015-10-16T02:41:32.897Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxrz00160cufrd2n6v4c"},{"date":"2015-10-07T16:00:00.000Z","title":"GVIM","_content":"\n# _vimrc配置文件\n## GVIM打开即全屏\n`au GUIEnter * simalt ~x `\n\n## 设置VeraMono字体\n[VeraMono](http://www.vimer.cn/wp-content/uploads/2009/11/VeraMono.ttf)需要下载安装(百度字体安装就好)\n`set guifont=Bitstream_Vera_Sans_Mono:h10:cANSI`\n\n## python编译\n```\nautocmd BufRead *.py set makeprg=python\\ -c\\ \\\"import\\ py_compile,sys;\\ sys.stderr=sys.stdout;\\ py_compile.compile(r'%')\\\"  \nautocmd BufRead *.py set efm=%C\\ %.%#,%A\\ \\ File\\ \\\"%f\\\"\\\\,\\ line\\ %l%.%#,%Z%[%^\\ ]%\\\\@=%m  \nautocmd BufRead *.py nmap <F5> :!python %<CR>  \nautocmd BufRead *.py nmap <F6> :make<CR>  \nautocmd BufRead *.py copen \"如果是py文件，则同时打开编译信息窗口  \n```\n\n# 快捷键\n* 搜索：`/`向下搜索. `?`向上搜索\n* 替换： `:%s/abc/123/g`, 将abc都替换为123\n* 删除行：`dd`删除整行. `5dd`从当前行开始向后删除5整行. `D`从光标删除到行尾\n* 删除字符：`x`向后删除一个字符. `X`向前删除一个字符\n* 撤销: `u`\n* 复制:`yy`复制一行. `5yy`从当前行开始向下复制5行\n* 粘贴: `p`光标向下移动. `P`光标不动\n* 块选择: `V`多行整行选择. `v`多行字符选择. `ctrl v`矩阵方式选择.\n* 光标移动：`$`移动到行尾. `0`移动到行首. `G`移动到最后一行. `gg`移动到最一行. \n* 窗口编辑: `：split`水平新建窗口. `：vsplit `垂直分割.\n* 在窗口间游走: `Ctrl W` 加 `h, j, k, l`一起使用\n* 分页编辑： `：tabnew`新建分页。 `：tabclose`关闭当前分页. `：tabonly `关闭其他所有的分页\n* 顶部底部跳转： 顶部``, 底部`shift + g`\n\n# 插件\n## [Pydiction ](http://www.vim.org/scripts/script.php?script_id=850)\npython自动补全插件\n\n配置,`_vimrc`文件追加\n```\nfiletype plugin on\nlet g:pydiction_location = 'D:/Program Files/Vim/pydiction/complete-dict'\n```\n然后将`pydiction/after/ftplugin/python_pydiction.vim`复制到`Vim\\vimfiles\\ftplugin\\python_pydiction.vim`\n\n## [The NERD tree](http://www.vim.org/scripts/script.php?script_id=1658)\n文件树. 将下载下来的压缩包解压到`Vim\\vimfiles`\n* `:NERDTree` 打开当前文件所在目录树. 该命令后可跟需要打开的目录路径\n* `:NERDTreeClose` 关闭目录树\n\n修改_vimrc配置文件,添加映射\n```\nnmap <F2> :NERDTreeToggle<CR>  \n```\n\n## [bsh.vim](http://www.vim.org/scripts/script.php?script_id=1202)\nShell语法高亮\n\n只需将`bsh.vim `文件拷贝到`Vim\\vimfiles\\syntax`就可以了","source":"_posts/工具/vim.md","raw":"category: 工具\ndate: 2015-10-08\ntitle: GVIM\n---\n\n# _vimrc配置文件\n## GVIM打开即全屏\n`au GUIEnter * simalt ~x `\n\n## 设置VeraMono字体\n[VeraMono](http://www.vimer.cn/wp-content/uploads/2009/11/VeraMono.ttf)需要下载安装(百度字体安装就好)\n`set guifont=Bitstream_Vera_Sans_Mono:h10:cANSI`\n\n## python编译\n```\nautocmd BufRead *.py set makeprg=python\\ -c\\ \\\"import\\ py_compile,sys;\\ sys.stderr=sys.stdout;\\ py_compile.compile(r'%')\\\"  \nautocmd BufRead *.py set efm=%C\\ %.%#,%A\\ \\ File\\ \\\"%f\\\"\\\\,\\ line\\ %l%.%#,%Z%[%^\\ ]%\\\\@=%m  \nautocmd BufRead *.py nmap <F5> :!python %<CR>  \nautocmd BufRead *.py nmap <F6> :make<CR>  \nautocmd BufRead *.py copen \"如果是py文件，则同时打开编译信息窗口  \n```\n\n# 快捷键\n* 搜索：`/`向下搜索. `?`向上搜索\n* 替换： `:%s/abc/123/g`, 将abc都替换为123\n* 删除行：`dd`删除整行. `5dd`从当前行开始向后删除5整行. `D`从光标删除到行尾\n* 删除字符：`x`向后删除一个字符. `X`向前删除一个字符\n* 撤销: `u`\n* 复制:`yy`复制一行. `5yy`从当前行开始向下复制5行\n* 粘贴: `p`光标向下移动. `P`光标不动\n* 块选择: `V`多行整行选择. `v`多行字符选择. `ctrl v`矩阵方式选择.\n* 光标移动：`$`移动到行尾. `0`移动到行首. `G`移动到最后一行. `gg`移动到最一行. \n* 窗口编辑: `：split`水平新建窗口. `：vsplit `垂直分割.\n* 在窗口间游走: `Ctrl W` 加 `h, j, k, l`一起使用\n* 分页编辑： `：tabnew`新建分页。 `：tabclose`关闭当前分页. `：tabonly `关闭其他所有的分页\n* 顶部底部跳转： 顶部``, 底部`shift + g`\n\n# 插件\n## [Pydiction ](http://www.vim.org/scripts/script.php?script_id=850)\npython自动补全插件\n\n配置,`_vimrc`文件追加\n```\nfiletype plugin on\nlet g:pydiction_location = 'D:/Program Files/Vim/pydiction/complete-dict'\n```\n然后将`pydiction/after/ftplugin/python_pydiction.vim`复制到`Vim\\vimfiles\\ftplugin\\python_pydiction.vim`\n\n## [The NERD tree](http://www.vim.org/scripts/script.php?script_id=1658)\n文件树. 将下载下来的压缩包解压到`Vim\\vimfiles`\n* `:NERDTree` 打开当前文件所在目录树. 该命令后可跟需要打开的目录路径\n* `:NERDTreeClose` 关闭目录树\n\n修改_vimrc配置文件,添加映射\n```\nnmap <F2> :NERDTreeToggle<CR>  \n```\n\n## [bsh.vim](http://www.vim.org/scripts/script.php?script_id=1202)\nShell语法高亮\n\n只需将`bsh.vim `文件拷贝到`Vim\\vimfiles\\syntax`就可以了","slug":"工具/vim","published":1,"updated":"2015-10-20T01:32:18.750Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxs100190cufvik6x0fm"},{"date":"2015-08-07T16:00:00.000Z","title":"unity命令行使用","_content":"# Command line arguments\n\n当从命令行启动`Unity`时,它可以在启动时接受一些参数和信息, 这种方式可以用于测试用例，自动构建和其他的任务。\n\n在`MacOS`系统下，你可以像下面这样启动\n```\n /Applications/Unity/Unity.app/Contents/MacOS/Unity\n```\n当在windows系统里，你就需要执行下面的命令了\n```\n \"C:\\Program Files (x86)\\Unity\\Editor\\Unity.exe\"\n```\n\n## Options\n\n正如上面提到的,`editor`也可以在启动时通过一些额外的命令来构建游戏, 下面就列举出了这些命令：\n\n* `-assetServerUpdate <IP[:port] projectName username password [r <revision>]>`\t从`IP:port`上的`Asset Server`强制更新项目. `port`是可选的,如果不指定的话,会默认选择`10733`这个端口. 这个命令可与`-projectPath`参数一起使用, 这样可确保你不会更新错项目.如果不指定项目名称的话,那么会默认的对`Unity`上次打开的项目进行更新. 如果`-projectPath`路径下不存在项目,那么会自动创建一个.\n* `-batchmode`  在`batch`模式下运行`Unity`.这个命令我们强烈建议你与其他命令一起使用, 它会确保不会弹出Edtior. 当由脚本代码抛出异常或者`Asset Server`更新失败或者其他操作引起的异常,`Unity`会直接返回错误码`1`并退出. 需要注意的是,在`batch`模式下,`Unity`会在控制台输出一些基础日志. 还有当在`batch`模式下打开一个项目,那么`Editor`就不能再开打这个相同的项目.\n* `-buildLinux32Player <pathname>`\t构建一个32位的linux版应用.(例如 `-buildLinux32Player path/to/your/build`).\n* `-buildLinux64Player <pathname>`\t构建一个64位的linux版应用.(例如 `-buildLinux64Player path/to/your/build`).\n* `-buildLinuxUniversalPlayer <pathname>`\t构建一个32位和64位的linux混合版应用.(例如 `-buildLinuxUniversalPlayer path/to/your/build`).\n* `-buildOSXPlayer <pathname>`\t构建一个32位的MacOS版应用.(例如 `-buildOSXPlayer path/to/your/build.app`).\n* `-buildOSX64Player <pathname>`\t构建一个64位的MacOS版应用.(例如 `-buildOSX64Player path/to/your/build.app`).\n* `-buildOSXUniversalPlayer <pathname>`\t构建一个32位和64位的MacOs混合版应用.(例如 `-buildOSXUniversalPlayer path/to/your/build.app`).\n* `-buildTarget <name>`\t当项目被加载之前允许用户选择的构建目标：`win32, win64, osx, linux, linux64, ios, android, web, webstreamed, webgl, xbox360, xboxone, ps3, ps4, psp2, wsa, wp8, bb10, tizen, samsungtv`.\n* `-buildWebPlayer <pathname>`\t构建一个在web上运行的应用.(例如`-buildWebPlayer path/to/your/build`).\n* `-buildWebPlayerStreamed <pathname>`\tBuild a streamed WebPlayer (`-buildWebPlayerStreamed path/to/your/build`).\n* `-buildWindowsPlayer <pathname>`\t构建一个32位的Windows版应用.(例如  `-buildWindowsPlayer path/to/your/build.exe`).\n* `-buildWindows64Player <pathname>`\t构建一个64位的Windows版应用.(例如  `-buildWindows64Player path/to/your/build.exe`).\n* `-createProject <pathname>`\t在指定路径下(`pathname`)创建一个空项目.\n* `-executeMethod <ClassName.MethodName>`\t只要Unity启动完成并且项目打开(可能还需要等待asset server更新完成)就执行该静态方法. 该功能可用于持续集成, 运行测试用例, 执行构建任务, 准备一些数据等等. 如果你想让程序在命令行中返回一个错误码,那么你可以直接在Unity中直接抛出一个异常,这时命令行返回的错误码是1，或者你可以调用`EditorApplication.Exit`,这时会返回一个非0的状态码. 如果你想要向该方法传递参数,那么你可以直接将这些参数添加到命令行上,然后在程序中使用`System.Environment.GetCommandLineArgs`获得这些参数.To use -executeMethod, you need to place the enclosing script in an Editor folder. The method to be executed must be defined as static.\n* `-exportPackage <exportAssetPath1 exportAssetPath2 ExportAssetPath3 exportFileName>`\t在指定的路径下导出`package`. `exportAssetPath`是一个从Unity项目导出到的文件夹(路径相对于Unity项目的根路径), `exportFileName`是package的名字. 一般这个选项可以一次性地导出整个文件夹.这个命令一般需要和`-projectPath`参数一起使用.\n* `-force-d3d9 (Windows only)`\t设置editor使用`Direct3D 9`进行渲染. 这个是默认选项,一般不需要你去设置这个值.\n* `-force-d3d11 (Windows only)`\t设置editor使用`Direct3D 11`进行渲染.\n* `-force-opengl (Windows only)`\t设置editor使用`OpenGL`进行渲染. 即使`Direct3D`可用我们也可以说使用`OpenGL`进行渲染. 一般我们是在` Direct3D 9.0c`不可用的情况下才选择使用`openGL`\n* `-force-free`\t让edtior在`Unity license`下运行, 即使我们安装了`Unity Pro license`\n* `-importPackage <pathname>`\t导入指定的`package`. 如果不进行导入的话,会出现一个对话框.\n* `-logFile <pathname>`\t指定Editor或者`Windows/Linux/OSX`版本应用的日志输出路径.\n* `-silent-crashes`\t不显示crashe对话框.\n* `-projectPath <pathname>`\t在指定的路径下打开项目.\n* `-quit`\t当其他命令都执行完之后退出Unity. 注意这个会将错误日志隐藏掉，但是可以在`Editor.log`中找到它.\n* `-serial <serial>`\tActivates Unity with the specified serial key. It is recommended to pass “-batchmode -quit” arguments as well, in order to quit Unity when done, if using this for automated activation of Unity. Please allow a few seconds before license file is created, as Unity needs to communicate with the license server. Make sure that License file folder exists, and has appropriate permissions before running Unity with this argument. In case activation fails, see the Editor.log for info. This option is new in Unity 5.0.\n\n#### Example usage\n```\n// C# example\nusing UnityEditor;\nclass MyEditorScript\n{\n     static void PerformBuild ()\n     {\n         string[] scenes = { \"Assets/MyScene.unity\" };\n         BuildPipeline.BuildPlayer(scenes, ...);\n     }\n}\n\n\n// JavaScript example\nstatic void PerformBuild ()\n{\n    string[] scenes = { \"Assets/MyScene.unity\" };\n    BuildPipeline.BuildPlayer(scenes, ...);\n}\n```\n下面的命令在`batch`模式下运行Unity, 同时执行`MyEditorScript.MyMethod`完成, 当该方法执行完之后退出.\n* `Windows`: `C:\\program files\\Unity\\Editor\\Unity.exe -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n* `Mac OS`: `/Applications/Unity/Unity.app/Contents/MacOS/Unity -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n\n下面的命令在`batch`执行Unity, 同时从`asset server`更新指定项目. 当全部的`asset`下载完之后, 指定的方法会被执行,当方法被完全执行之后,Unity会自动退出.\n```\n/Applications/Unity/Unity.app/Contents/MacOS/Unity -batchmode -projectPath ~/UnityProjects/AutobuildProject -assetServerUpdate 192.168.1.1 MyGame AutobuildUser l33tpa33 -executeMethod MyEditorScript.PerformBuild -quit\n```\n\n","source":"_posts/工具/unity命令行使用.md","raw":"category: 工具\ndate: 2015-08-08\ntitle: unity命令行使用\n---\n# Command line arguments\n\n当从命令行启动`Unity`时,它可以在启动时接受一些参数和信息, 这种方式可以用于测试用例，自动构建和其他的任务。\n\n在`MacOS`系统下，你可以像下面这样启动\n```\n /Applications/Unity/Unity.app/Contents/MacOS/Unity\n```\n当在windows系统里，你就需要执行下面的命令了\n```\n \"C:\\Program Files (x86)\\Unity\\Editor\\Unity.exe\"\n```\n\n## Options\n\n正如上面提到的,`editor`也可以在启动时通过一些额外的命令来构建游戏, 下面就列举出了这些命令：\n\n* `-assetServerUpdate <IP[:port] projectName username password [r <revision>]>`\t从`IP:port`上的`Asset Server`强制更新项目. `port`是可选的,如果不指定的话,会默认选择`10733`这个端口. 这个命令可与`-projectPath`参数一起使用, 这样可确保你不会更新错项目.如果不指定项目名称的话,那么会默认的对`Unity`上次打开的项目进行更新. 如果`-projectPath`路径下不存在项目,那么会自动创建一个.\n* `-batchmode`  在`batch`模式下运行`Unity`.这个命令我们强烈建议你与其他命令一起使用, 它会确保不会弹出Edtior. 当由脚本代码抛出异常或者`Asset Server`更新失败或者其他操作引起的异常,`Unity`会直接返回错误码`1`并退出. 需要注意的是,在`batch`模式下,`Unity`会在控制台输出一些基础日志. 还有当在`batch`模式下打开一个项目,那么`Editor`就不能再开打这个相同的项目.\n* `-buildLinux32Player <pathname>`\t构建一个32位的linux版应用.(例如 `-buildLinux32Player path/to/your/build`).\n* `-buildLinux64Player <pathname>`\t构建一个64位的linux版应用.(例如 `-buildLinux64Player path/to/your/build`).\n* `-buildLinuxUniversalPlayer <pathname>`\t构建一个32位和64位的linux混合版应用.(例如 `-buildLinuxUniversalPlayer path/to/your/build`).\n* `-buildOSXPlayer <pathname>`\t构建一个32位的MacOS版应用.(例如 `-buildOSXPlayer path/to/your/build.app`).\n* `-buildOSX64Player <pathname>`\t构建一个64位的MacOS版应用.(例如 `-buildOSX64Player path/to/your/build.app`).\n* `-buildOSXUniversalPlayer <pathname>`\t构建一个32位和64位的MacOs混合版应用.(例如 `-buildOSXUniversalPlayer path/to/your/build.app`).\n* `-buildTarget <name>`\t当项目被加载之前允许用户选择的构建目标：`win32, win64, osx, linux, linux64, ios, android, web, webstreamed, webgl, xbox360, xboxone, ps3, ps4, psp2, wsa, wp8, bb10, tizen, samsungtv`.\n* `-buildWebPlayer <pathname>`\t构建一个在web上运行的应用.(例如`-buildWebPlayer path/to/your/build`).\n* `-buildWebPlayerStreamed <pathname>`\tBuild a streamed WebPlayer (`-buildWebPlayerStreamed path/to/your/build`).\n* `-buildWindowsPlayer <pathname>`\t构建一个32位的Windows版应用.(例如  `-buildWindowsPlayer path/to/your/build.exe`).\n* `-buildWindows64Player <pathname>`\t构建一个64位的Windows版应用.(例如  `-buildWindows64Player path/to/your/build.exe`).\n* `-createProject <pathname>`\t在指定路径下(`pathname`)创建一个空项目.\n* `-executeMethod <ClassName.MethodName>`\t只要Unity启动完成并且项目打开(可能还需要等待asset server更新完成)就执行该静态方法. 该功能可用于持续集成, 运行测试用例, 执行构建任务, 准备一些数据等等. 如果你想让程序在命令行中返回一个错误码,那么你可以直接在Unity中直接抛出一个异常,这时命令行返回的错误码是1，或者你可以调用`EditorApplication.Exit`,这时会返回一个非0的状态码. 如果你想要向该方法传递参数,那么你可以直接将这些参数添加到命令行上,然后在程序中使用`System.Environment.GetCommandLineArgs`获得这些参数.To use -executeMethod, you need to place the enclosing script in an Editor folder. The method to be executed must be defined as static.\n* `-exportPackage <exportAssetPath1 exportAssetPath2 ExportAssetPath3 exportFileName>`\t在指定的路径下导出`package`. `exportAssetPath`是一个从Unity项目导出到的文件夹(路径相对于Unity项目的根路径), `exportFileName`是package的名字. 一般这个选项可以一次性地导出整个文件夹.这个命令一般需要和`-projectPath`参数一起使用.\n* `-force-d3d9 (Windows only)`\t设置editor使用`Direct3D 9`进行渲染. 这个是默认选项,一般不需要你去设置这个值.\n* `-force-d3d11 (Windows only)`\t设置editor使用`Direct3D 11`进行渲染.\n* `-force-opengl (Windows only)`\t设置editor使用`OpenGL`进行渲染. 即使`Direct3D`可用我们也可以说使用`OpenGL`进行渲染. 一般我们是在` Direct3D 9.0c`不可用的情况下才选择使用`openGL`\n* `-force-free`\t让edtior在`Unity license`下运行, 即使我们安装了`Unity Pro license`\n* `-importPackage <pathname>`\t导入指定的`package`. 如果不进行导入的话,会出现一个对话框.\n* `-logFile <pathname>`\t指定Editor或者`Windows/Linux/OSX`版本应用的日志输出路径.\n* `-silent-crashes`\t不显示crashe对话框.\n* `-projectPath <pathname>`\t在指定的路径下打开项目.\n* `-quit`\t当其他命令都执行完之后退出Unity. 注意这个会将错误日志隐藏掉，但是可以在`Editor.log`中找到它.\n* `-serial <serial>`\tActivates Unity with the specified serial key. It is recommended to pass “-batchmode -quit” arguments as well, in order to quit Unity when done, if using this for automated activation of Unity. Please allow a few seconds before license file is created, as Unity needs to communicate with the license server. Make sure that License file folder exists, and has appropriate permissions before running Unity with this argument. In case activation fails, see the Editor.log for info. This option is new in Unity 5.0.\n\n#### Example usage\n```\n// C# example\nusing UnityEditor;\nclass MyEditorScript\n{\n     static void PerformBuild ()\n     {\n         string[] scenes = { \"Assets/MyScene.unity\" };\n         BuildPipeline.BuildPlayer(scenes, ...);\n     }\n}\n\n\n// JavaScript example\nstatic void PerformBuild ()\n{\n    string[] scenes = { \"Assets/MyScene.unity\" };\n    BuildPipeline.BuildPlayer(scenes, ...);\n}\n```\n下面的命令在`batch`模式下运行Unity, 同时执行`MyEditorScript.MyMethod`完成, 当该方法执行完之后退出.\n* `Windows`: `C:\\program files\\Unity\\Editor\\Unity.exe -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n* `Mac OS`: `/Applications/Unity/Unity.app/Contents/MacOS/Unity -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n\n下面的命令在`batch`执行Unity, 同时从`asset server`更新指定项目. 当全部的`asset`下载完之后, 指定的方法会被执行,当方法被完全执行之后,Unity会自动退出.\n```\n/Applications/Unity/Unity.app/Contents/MacOS/Unity -batchmode -projectPath ~/UnityProjects/AutobuildProject -assetServerUpdate 192.168.1.1 MyGame AutobuildUser l33tpa33 -executeMethod MyEditorScript.PerformBuild -quit\n```\n\n","slug":"工具/unity命令行使用","published":1,"updated":"2015-10-14T01:53:12.247Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxs4001c0cufchbed4da"},{"date":"2012-08-19T16:00:00.000Z","title":"svn服务器搭建","_content":"下载svn服务器[subversion](http://sourceforge.net/projects/win32svn/)和svn客户端TortoiseSVN(下载页面有安装程序和汉化程序)，还有[apache]()(apache主要是为了解析成网络，要不然安装好的svn只能在局域网里使用)\n\n在e盘下创建svn仓库`svnresp` ![](https://raw.githubusercontent.com/ming15/blog-website/images/svn/0.jpg)\n\n创建好版本库后需要将版本库里的配置文件`E:\\svnresp\\conf\\svnserve.conf`文件进行修改\n```[general]\n# password-db = passwd \n将其修改成\npassword-db = passwd\n```\n如果不修改这个配置在提交文件是会产生：svn认证失败的错误。 修改如图,前面一定不能有空格：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/1.jpg)[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/2.jpg)\n然后修改同一目录下的`E:\\svnresp\\conf\\passwd.conf`文件\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/3.jpg)\n> 注意xiaoli是合法用户，而sally则是非法用户。=前面的为用户名，后面的为密码，同样的前面不能有空格\n\n都配置好成功之后，接下来我到一个测试项目下进行导入。\n\n首先是开启我们的svn服务器：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/4.jpg)\n\n回车后只要不显示其他内容那么就说明该svn服务器已经启动了。`svnserve -d -r`是固定写法，而其后面的内容是版本库地址。\n\n然后我们找到测试项目，在空白处右击\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/5.jpg)\n\n选择版本浏览器或者导入都可以，我选择的是导入。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/6.jpg)\n\n`localhost`是你要把文件提交到的svn版本库的ip，我在本机做的所以就填写的localhost。而newdemo是我为提交的文件所存放的文件夹。导入信息就是这个版本的信息，可以在版本浏览器中看到。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/7.jpg)\n填写好在passwd文件里配置好的用户名和密码就可以提交文件了。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/8.jpg)\n","source":"_posts/工具/svn服务器搭建.md","raw":"category: 工具\ndate: 2012-08-20\ntitle: svn服务器搭建\n---\n下载svn服务器[subversion](http://sourceforge.net/projects/win32svn/)和svn客户端TortoiseSVN(下载页面有安装程序和汉化程序)，还有[apache]()(apache主要是为了解析成网络，要不然安装好的svn只能在局域网里使用)\n\n在e盘下创建svn仓库`svnresp` ![](https://raw.githubusercontent.com/ming15/blog-website/images/svn/0.jpg)\n\n创建好版本库后需要将版本库里的配置文件`E:\\svnresp\\conf\\svnserve.conf`文件进行修改\n```[general]\n# password-db = passwd \n将其修改成\npassword-db = passwd\n```\n如果不修改这个配置在提交文件是会产生：svn认证失败的错误。 修改如图,前面一定不能有空格：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/1.jpg)[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/2.jpg)\n然后修改同一目录下的`E:\\svnresp\\conf\\passwd.conf`文件\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/3.jpg)\n> 注意xiaoli是合法用户，而sally则是非法用户。=前面的为用户名，后面的为密码，同样的前面不能有空格\n\n都配置好成功之后，接下来我到一个测试项目下进行导入。\n\n首先是开启我们的svn服务器：\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/4.jpg)\n\n回车后只要不显示其他内容那么就说明该svn服务器已经启动了。`svnserve -d -r`是固定写法，而其后面的内容是版本库地址。\n\n然后我们找到测试项目，在空白处右击\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/5.jpg)\n\n选择版本浏览器或者导入都可以，我选择的是导入。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/6.jpg)\n\n`localhost`是你要把文件提交到的svn版本库的ip，我在本机做的所以就填写的localhost。而newdemo是我为提交的文件所存放的文件夹。导入信息就是这个版本的信息，可以在版本浏览器中看到。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/7.jpg)\n填写好在passwd文件里配置好的用户名和密码就可以提交文件了。\n[](https://raw.githubusercontent.com/ming15/blog-website/images/svn/8.jpg)\n","slug":"工具/svn服务器搭建","published":1,"updated":"2015-10-20T03:44:30.994Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxs5001e0cufu5xi7938"},{"date":"2015-04-07T16:00:00.000Z","title":"springboot","_content":"# 添加依赖\n```xml\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-web</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-actuator</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-security</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-remote-shell</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!-- -->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-data-mongodb</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-jetty</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-redis</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-data-elasticsearch</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n```\n\n# 构建应用\n```java\n@Controller\n// 告诉Spring Boot根据添加的jar依赖猜测如何配置Spring\n@EnableAutoConfiguration\t\n@ComponentScan\npublic class App {\n\n    public static void main(String[] args) {\n    \tSpringApplication.run(App.class, new String[0]);\n    }\n}\n```\n\n```java\n@Component\n@RequestMapping(\"/\")\n// 该注解用来绑定HttpSession中的attribute对象的值,便于在方法中的参数里使用.\n@SessionAttributes(\"test\")\npublic class TestAction {\n\n\t// http://localhost:8080/h\n\t@RequestMapping(\"/h\")\n\t@ResponseBody\n\tString home() {\n\t\treturn \"home:Hello World!\";\n\t}\n\n\t@RequestMapping(value = \"post\", method = RequestMethod.POST)\n\t@ResponseBody\n\tString post() {\n\t\treturn \"post:Hello World!\";\n\t}\n\n\t// http://localhost:8080/pathVariable/a\n\t@RequestMapping(\"/pathVariable/{paramV}\")\n\t@ResponseBody\n\tString pathVariable(@PathVariable String paramV) {\n\t\treturn paramV;\n\t}\n\n\t// http://localhost:8080/requestHeader\n\t@RequestMapping(\"/requestHeader\")\n\t@ResponseBody\n\tString requestHeader(@RequestHeader(\"Accept-Encoding\") String encoding) {\n\t\treturn \"Accept-Encoding : \" + encoding;\n\t}\n\n\t//\n\t@RequestMapping(\"/cookieValue\")\n\t@ResponseBody\n\tString cookieValue(@CookieValue(\"SESSION_ID\") String v) {\n\t\treturn v;\n\t}\n\n\t/**\n\t * A） 常用来处理简单类型的绑定,可以处理get 方式中queryString的值,也可以处理post方式中 body data的值;\n\t * \n\t * B）用来处理Content-Type: 为application/x-www-form-urlencoded编码的内容,提交方式GET、POST;\n\t * \n\t * C) 该注解有两个属性： value、required; value用来指定要传入值的id名称,required用来指示参数是否必须绑定;\n\t * \n\t * @param v\n\t * @return\n\t */\n\t// http://localhost:8080/requestParam?v=v&n=n\n\t@RequestMapping(\"/requestParam\")\n\t@ResponseBody\n\tString requestParam(@RequestParam String v) {\n\t\treturn v;\n\t}\n\n\t/**\n\t * 该注解常用来处理Content-Type:\n\t * 不是application/x-www-form-urlencoded编码的内容,例如application/json,\n\t * application/xml等;\n\t * \n\t * 它是通过使用HandlerAdapter 配置的HttpMessageConverters来解析post data\n\t * body,然后绑定到相应的bean上的.\n\t * \n\t * 因为配置有FormHttpMessageConverter,所以也可以用来处理application/x-www-form-urlencoded的内容,\n\t * 处理完的结果放在一个MultiValueMap<String, String>里,这种情况在某些特殊需求下使用,详情查看FormHttpMessageConverter api;\n\t * \n\t * @param v\n\t * @return\n\t */\n\t//\n\t@RequestMapping(\"/requestBody\")\n\t@ResponseBody\n\tString requestBody(@RequestBody String v) {\n\t\treturn v;\n\t}\n\n\t//\n\t@RequestMapping(\"/modelAttribute\")\n\t@ResponseBody\n\tString modelAttribute(@ModelAttribute String v) {\n\t\treturn v;\n\t}\n}\n\n```","source":"_posts/工具/spring_boot.md","raw":"category: 工具\ndate: 2015-04-08\ntitle: springboot\n---\n# 添加依赖\n```xml\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-web</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<dependency>\n\t<groupId>org.springframework.boot</groupId>\n\t<artifactId>spring-boot-actuator</artifactId>\n\t<version>1.2.3.RELEASE</version>\n</dependency>\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-security</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-remote-shell</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!-- -->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-data-mongodb</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-jetty</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-redis</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n<!--<dependency>-->\n\t<!--<groupId>org.springframework.boot</groupId>-->\n\t<!--<artifactId>spring-boot-starter-data-elasticsearch</artifactId>-->\n\t<!--<version>1.2.3.RELEASE</version>-->\n<!--</dependency>-->\n```\n\n# 构建应用\n```java\n@Controller\n// 告诉Spring Boot根据添加的jar依赖猜测如何配置Spring\n@EnableAutoConfiguration\t\n@ComponentScan\npublic class App {\n\n    public static void main(String[] args) {\n    \tSpringApplication.run(App.class, new String[0]);\n    }\n}\n```\n\n```java\n@Component\n@RequestMapping(\"/\")\n// 该注解用来绑定HttpSession中的attribute对象的值,便于在方法中的参数里使用.\n@SessionAttributes(\"test\")\npublic class TestAction {\n\n\t// http://localhost:8080/h\n\t@RequestMapping(\"/h\")\n\t@ResponseBody\n\tString home() {\n\t\treturn \"home:Hello World!\";\n\t}\n\n\t@RequestMapping(value = \"post\", method = RequestMethod.POST)\n\t@ResponseBody\n\tString post() {\n\t\treturn \"post:Hello World!\";\n\t}\n\n\t// http://localhost:8080/pathVariable/a\n\t@RequestMapping(\"/pathVariable/{paramV}\")\n\t@ResponseBody\n\tString pathVariable(@PathVariable String paramV) {\n\t\treturn paramV;\n\t}\n\n\t// http://localhost:8080/requestHeader\n\t@RequestMapping(\"/requestHeader\")\n\t@ResponseBody\n\tString requestHeader(@RequestHeader(\"Accept-Encoding\") String encoding) {\n\t\treturn \"Accept-Encoding : \" + encoding;\n\t}\n\n\t//\n\t@RequestMapping(\"/cookieValue\")\n\t@ResponseBody\n\tString cookieValue(@CookieValue(\"SESSION_ID\") String v) {\n\t\treturn v;\n\t}\n\n\t/**\n\t * A） 常用来处理简单类型的绑定,可以处理get 方式中queryString的值,也可以处理post方式中 body data的值;\n\t * \n\t * B）用来处理Content-Type: 为application/x-www-form-urlencoded编码的内容,提交方式GET、POST;\n\t * \n\t * C) 该注解有两个属性： value、required; value用来指定要传入值的id名称,required用来指示参数是否必须绑定;\n\t * \n\t * @param v\n\t * @return\n\t */\n\t// http://localhost:8080/requestParam?v=v&n=n\n\t@RequestMapping(\"/requestParam\")\n\t@ResponseBody\n\tString requestParam(@RequestParam String v) {\n\t\treturn v;\n\t}\n\n\t/**\n\t * 该注解常用来处理Content-Type:\n\t * 不是application/x-www-form-urlencoded编码的内容,例如application/json,\n\t * application/xml等;\n\t * \n\t * 它是通过使用HandlerAdapter 配置的HttpMessageConverters来解析post data\n\t * body,然后绑定到相应的bean上的.\n\t * \n\t * 因为配置有FormHttpMessageConverter,所以也可以用来处理application/x-www-form-urlencoded的内容,\n\t * 处理完的结果放在一个MultiValueMap<String, String>里,这种情况在某些特殊需求下使用,详情查看FormHttpMessageConverter api;\n\t * \n\t * @param v\n\t * @return\n\t */\n\t//\n\t@RequestMapping(\"/requestBody\")\n\t@ResponseBody\n\tString requestBody(@RequestBody String v) {\n\t\treturn v;\n\t}\n\n\t//\n\t@RequestMapping(\"/modelAttribute\")\n\t@ResponseBody\n\tString modelAttribute(@ModelAttribute String v) {\n\t\treturn v;\n\t}\n}\n\n```","slug":"工具/spring_boot","published":1,"updated":"2015-10-14T01:53:23.392Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxs7001g0cufzdvl039b"},{"date":"2015-10-07T16:00:00.000Z","title":"Mycat","_content":"[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\n# Mycat配置文件\n\n## schema.xml\n\n### schema标签\n定义MyCat实例中的逻辑库,对于客户端来说,实际的数据库是不可见的,在sql中要使用逻辑库名称而不是实际的物理库的名称\n* `dataNode` : 对应实际的物理库(如果设置了这个属性,该逻辑库就不能实现分库功能了,但是该逻辑库就可以用作读写分离和主从切换). 它的值对应下面的dataNode标签.\n* `checkSQLschema` : 把schema字符去掉(在sql中将库名去掉)\n* `sqlMaxLimit` : 在分库中执行sql时,为sql添加`limit`字段\n* `name` : 逻辑库名称\n\n#### table标签\n定义MyCat中的逻辑表\n* `name` : 逻辑表表名\n* `dataNode` : 定义逻辑表所属的dataNode, 该属性值与schema标签dataNode属性值相对应\n* `rule` : 指定逻辑表要使用定义在rule.xml中的规则名字\n* `ruleRequired` : 指定表是否绑定分片规则(如果指定绑定但是在rule.xml中找不到则会报错)\n* `primaryKey` : 逻辑表对应真实表的主键\n* `type` : 逻辑表类型(可选值为global表示全局表,不设置的话为非全局表). 全局表就是每个分片内都保存一份全完相同的数据.\n* `autoIncrement` : 自增长主键,但是需要在Mysql中设置auto_increment属性\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n##### childTable标签\n用于定义E-R分片的子表\n* `name` : 子表名\n* `joinKey` : 插入子表的时候会使用这个列的值查找父表存储的数据节点\n* `parentKey` : \n* `primaryKey` : 逻辑表对应真实表的主键\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n### dataNode标签\n定义MyCat中的数据节点(也就是数据分片). \n* `name` : 数据节点名字\n* `dataHost` : 定义该分片属于哪个数据库实例\n* `database` : 分片属性哪个具体数据库实例上的具体库\n\n### dataHost标签\n定义了具体的数据库实例、读写分离配置和心跳语句。\n* `name` : dataHost标签名\n* `maxCon` : 每个读写实例连接池的最大连接\n* `minCon` : 每个读写实例连接池的最小连接，初始化连接池的大小。\n* `balance` : 负载均衡类型(`0`:所有读操作都发送到当前可用的writeHost上。'1`:所有读操作都随机的发送到readHost。`2`:所有读操作都随机的在writeHost、readhost上分发。)\n* `writeType` : 同balance属性\n* `dbType` : 后端连接的数据库类型(mysql,oracle等等)\n* `dbDriver` : 连接后端数据库使用的Driver，目前可选的值有native和JDBC\n\n#### heartbeat标签\n用于和后端数据库进行心跳检查的语句 \n\n#### writeHost, readHost\n用于实例化后端连接池.在一个dataHost内可以定义多个writeHost和readHost。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。另一方面，由于这个writeHost宕机系统会自动的检测到，并切换到备用的writeHost上去。\n* `host` : 标识不同实例\n* `url` : 后端实例连接地址\n* `password` : \n* `user` : 后端存储实例需要的用户名字\n* `password` :  后端存储实例需要的密码\n\n### schema.xml配置示例\n下面的例子实现一个分库,db1和db2各有一张idTable表\n```xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://org.opencloudb/\">\n\t<schema name=\"idDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\">\n\t\t<table name=\"idTable\" primaryKey=\"ID\" dataNode=\"dn1,dn2\" rule=\"mod-long\" />\n\t</schema>\n\t<dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"db1\" />\n\t<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"db2\" />\n\t<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t\t<heartbeat>select user()</heartbeat>\n\t\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"root\" />\n\t</dataHost>\n</mycat:schema>\n```\n\n如果我们要实现分表的功能需要在`rule.xml`中指定分表逻辑\n\n## server.xml\n保存mycat需要的系统配置信息.\n\n### user标签\n定义登录mycat的用户和权限,它可以定义`property`子标签.`property`子标签的name值可以是：\n* `password` : 该用户的密码\n* `schemas` : 该用户可访问的schema(在schema.xml中定义的schema)\n* `readOnly` : 该用户的读写权限\n\n### system标签\n与系统配置有关.它同样使用`property`子标签.`property`子标签的name值可以是：\n\n* `defaultSqlParser` : 指定默认的解析器\n* `processors` : 指定系统可用的线程数.(主要影响processorBufferPool、processorBufferLocalPercent、processorExecutor属性)\n* `processorBufferChunk` : 这个属性指定每次分配Socket Direct Buffer的大小，默认是4096个字节。这个属性也影响buffer pool的长度。\n* `processorBufferPool` : 这个属性指定bufferPool计算 比例值.\n* `processorBufferLocalPercent` : 控制分配ThreadLocalPool的大小用的，但其也并不是一个准确的值，也是一个比例值。这个属性默认值为100。\n* `processorExecutor` : 指定NIOProcessor上共享的businessExecutor固定线程池大小\n* `sequnceHandlerType` : 指定使用Mycat全局序列的类型。0为本地文件方式，1为数据库方式。\n###### TCP连接相关属性\n* `frontSocketSoRcvbuf` : \n* `frontSocketSoSndbuf` : \n* `frontSocketNoDelay` : \n###### Mysql连接相关属性\n* `packetHeaderSize` : 指定Mysql协议中的报文头长度\n* `maxPacketSize` : 指定Mysql协议可以携带的数据最大长度\n* `idleTimeout` :  指定连接的空闲超时时间。某连接在发起空闲检查下，发现距离上次使用超过了空闲时间，那么这个连接会被回收，就是被直接的关闭掉。默认30分钟。\n* `charset` : 连接的初始化字符集。默认为utf8。\n* `txIsolation` : 前端连接的初始化事务隔离级别，只在初始化的时候使用，后续会根据客户端传递过来的属性对后端数据库连接进行同步。默认为REPEATED_READ。\n* `sqlExecuteTimeout` : SQL执行超时的时间，Mycat会检查连接上最后一次执行SQL的时间，若超过这个时间则会直接关闭这连接。默认时间为300秒。\n###### 周期间隔相关属性\n* `processorCheckPeriod` : \n* `dataNodeIdleCheckPeriod` : \n* `dataNodeHeartbeatPeriod` : \n###### 服务相关属性\n* `bindIp` :  mycat服务监听的IP地址，默认值为0.0.0.0。\n* `serverPort` : mycat的使用端口，默认值为8066。\n* `managerPort` : mycat的管理端口，默认值为9066。\n\n### 示例\n```xml\n<mycat:server xmlns:mycat=\"http://org.opencloudb/\">\n\t<system>\n\t\t<property name=\"defaultSqlParser\">druidparser</property>\n\t</system>\n\t<user name=\"test\">\n\t\t<property name=\"password\">test</property>\n\t\t<property name=\"schemas\">idDB</property>\n\t</user>\n</mycat:server>\n```\n \n## rule.xml\n对表进行拆分所涉及到的规则定义\n\n### tableRule标签\n定义表规则\n* `name` : 表规则名称\n\n#### rule标签\n指定对物理表中的哪一列进行拆分和使用什么路由算法。\n\n##### columns标签\n指定要拆分的列名字。\n\n##### algorithm标签\n使用function标签中的name属性。\n\n### function标签\n* `name` : 算法的名字\n* `class` : 制定路由算法具体的类名字\n\n#### property标签\n具体算法需要用到的一些属性\n* `name` : \n\n\n### 示例\n```xml\n<tableRule name=\"rule2\">\n    <rule>\n      <columns>user_id</columns>\n      <algorithm>func1</algorithm>\n    </rule>\n</tableRule>\n```\n\n### 常用的分片规则\n由于分片规则主要定义在function里,因此下面的讲解中主要是针对function的讲解\n\n#### 分片枚举\n```xml\n<function name=\"hash-int\" class=\"org.opencloudb.route.function.PartitionByFileMap\">\n\t<property name=\"mapFile\">partition-hash-int.txt</property>\n\t<property name=\"type\">0</property>\n\t<property name=\"defaultNode\">0</property>\n</function>\n```\n* mapFile: 配置文件名称\n* type: 0表示Integer，非零表示String\n* defaultNode: 枚举分片时，如果碰到不识别的枚举值，就让它路由到默认节点\n\n#### 固定分片hash算法\n对columns取低10位进行求模运算\n```xml\n<function name=\"partitionByLong\" class=\"org.opencloudb.route.function.PartitionByLong\">\n\t<property name=\"partitionCount\">2,1</property>\n\t<property name=\"partitionLength\">256,512</property>\n</function>\n```","source":"_posts/工具/mycat.md","raw":"category: 工具\ndate: 2015-10-08\ntitle: Mycat\n---\n[Mycat权威指南V1](https://item.taobao.com/item.htm?spm=a230r.1.14.8.eRsdoe&id=44263828402&ns=1&abbucket=17#detail)学习总结\n\n# Mycat配置文件\n\n## schema.xml\n\n### schema标签\n定义MyCat实例中的逻辑库,对于客户端来说,实际的数据库是不可见的,在sql中要使用逻辑库名称而不是实际的物理库的名称\n* `dataNode` : 对应实际的物理库(如果设置了这个属性,该逻辑库就不能实现分库功能了,但是该逻辑库就可以用作读写分离和主从切换). 它的值对应下面的dataNode标签.\n* `checkSQLschema` : 把schema字符去掉(在sql中将库名去掉)\n* `sqlMaxLimit` : 在分库中执行sql时,为sql添加`limit`字段\n* `name` : 逻辑库名称\n\n#### table标签\n定义MyCat中的逻辑表\n* `name` : 逻辑表表名\n* `dataNode` : 定义逻辑表所属的dataNode, 该属性值与schema标签dataNode属性值相对应\n* `rule` : 指定逻辑表要使用定义在rule.xml中的规则名字\n* `ruleRequired` : 指定表是否绑定分片规则(如果指定绑定但是在rule.xml中找不到则会报错)\n* `primaryKey` : 逻辑表对应真实表的主键\n* `type` : 逻辑表类型(可选值为global表示全局表,不设置的话为非全局表). 全局表就是每个分片内都保存一份全完相同的数据.\n* `autoIncrement` : 自增长主键,但是需要在Mysql中设置auto_increment属性\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n##### childTable标签\n用于定义E-R分片的子表\n* `name` : 子表名\n* `joinKey` : 插入子表的时候会使用这个列的值查找父表存储的数据节点\n* `parentKey` : \n* `primaryKey` : 逻辑表对应真实表的主键\n* `needAddLimit` : 如果为false, 会屏蔽sqlMaxLimit功能\n\n### dataNode标签\n定义MyCat中的数据节点(也就是数据分片). \n* `name` : 数据节点名字\n* `dataHost` : 定义该分片属于哪个数据库实例\n* `database` : 分片属性哪个具体数据库实例上的具体库\n\n### dataHost标签\n定义了具体的数据库实例、读写分离配置和心跳语句。\n* `name` : dataHost标签名\n* `maxCon` : 每个读写实例连接池的最大连接\n* `minCon` : 每个读写实例连接池的最小连接，初始化连接池的大小。\n* `balance` : 负载均衡类型(`0`:所有读操作都发送到当前可用的writeHost上。'1`:所有读操作都随机的发送到readHost。`2`:所有读操作都随机的在writeHost、readhost上分发。)\n* `writeType` : 同balance属性\n* `dbType` : 后端连接的数据库类型(mysql,oracle等等)\n* `dbDriver` : 连接后端数据库使用的Driver，目前可选的值有native和JDBC\n\n#### heartbeat标签\n用于和后端数据库进行心跳检查的语句 \n\n#### writeHost, readHost\n用于实例化后端连接池.在一个dataHost内可以定义多个writeHost和readHost。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。另一方面，由于这个writeHost宕机系统会自动的检测到，并切换到备用的writeHost上去。\n* `host` : 标识不同实例\n* `url` : 后端实例连接地址\n* `password` : \n* `user` : 后端存储实例需要的用户名字\n* `password` :  后端存储实例需要的密码\n\n### schema.xml配置示例\n下面的例子实现一个分库,db1和db2各有一张idTable表\n```xml\n<?xml version=\"1.0\"?>\n<!DOCTYPE mycat:schema SYSTEM \"schema.dtd\">\n<mycat:schema xmlns:mycat=\"http://org.opencloudb/\">\n\t<schema name=\"idDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\">\n\t\t<table name=\"idTable\" primaryKey=\"ID\" dataNode=\"dn1,dn2\" rule=\"mod-long\" />\n\t</schema>\n\t<dataNode name=\"dn1\" dataHost=\"localhost1\" database=\"db1\" />\n\t<dataNode name=\"dn2\" dataHost=\"localhost1\" database=\"db2\" />\n\t<dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\">\n\t\t<heartbeat>select user()</heartbeat>\n\t\t<writeHost host=\"hostM1\" url=\"localhost:3306\" user=\"root\" password=\"root\" />\n\t</dataHost>\n</mycat:schema>\n```\n\n如果我们要实现分表的功能需要在`rule.xml`中指定分表逻辑\n\n## server.xml\n保存mycat需要的系统配置信息.\n\n### user标签\n定义登录mycat的用户和权限,它可以定义`property`子标签.`property`子标签的name值可以是：\n* `password` : 该用户的密码\n* `schemas` : 该用户可访问的schema(在schema.xml中定义的schema)\n* `readOnly` : 该用户的读写权限\n\n### system标签\n与系统配置有关.它同样使用`property`子标签.`property`子标签的name值可以是：\n\n* `defaultSqlParser` : 指定默认的解析器\n* `processors` : 指定系统可用的线程数.(主要影响processorBufferPool、processorBufferLocalPercent、processorExecutor属性)\n* `processorBufferChunk` : 这个属性指定每次分配Socket Direct Buffer的大小，默认是4096个字节。这个属性也影响buffer pool的长度。\n* `processorBufferPool` : 这个属性指定bufferPool计算 比例值.\n* `processorBufferLocalPercent` : 控制分配ThreadLocalPool的大小用的，但其也并不是一个准确的值，也是一个比例值。这个属性默认值为100。\n* `processorExecutor` : 指定NIOProcessor上共享的businessExecutor固定线程池大小\n* `sequnceHandlerType` : 指定使用Mycat全局序列的类型。0为本地文件方式，1为数据库方式。\n###### TCP连接相关属性\n* `frontSocketSoRcvbuf` : \n* `frontSocketSoSndbuf` : \n* `frontSocketNoDelay` : \n###### Mysql连接相关属性\n* `packetHeaderSize` : 指定Mysql协议中的报文头长度\n* `maxPacketSize` : 指定Mysql协议可以携带的数据最大长度\n* `idleTimeout` :  指定连接的空闲超时时间。某连接在发起空闲检查下，发现距离上次使用超过了空闲时间，那么这个连接会被回收，就是被直接的关闭掉。默认30分钟。\n* `charset` : 连接的初始化字符集。默认为utf8。\n* `txIsolation` : 前端连接的初始化事务隔离级别，只在初始化的时候使用，后续会根据客户端传递过来的属性对后端数据库连接进行同步。默认为REPEATED_READ。\n* `sqlExecuteTimeout` : SQL执行超时的时间，Mycat会检查连接上最后一次执行SQL的时间，若超过这个时间则会直接关闭这连接。默认时间为300秒。\n###### 周期间隔相关属性\n* `processorCheckPeriod` : \n* `dataNodeIdleCheckPeriod` : \n* `dataNodeHeartbeatPeriod` : \n###### 服务相关属性\n* `bindIp` :  mycat服务监听的IP地址，默认值为0.0.0.0。\n* `serverPort` : mycat的使用端口，默认值为8066。\n* `managerPort` : mycat的管理端口，默认值为9066。\n\n### 示例\n```xml\n<mycat:server xmlns:mycat=\"http://org.opencloudb/\">\n\t<system>\n\t\t<property name=\"defaultSqlParser\">druidparser</property>\n\t</system>\n\t<user name=\"test\">\n\t\t<property name=\"password\">test</property>\n\t\t<property name=\"schemas\">idDB</property>\n\t</user>\n</mycat:server>\n```\n \n## rule.xml\n对表进行拆分所涉及到的规则定义\n\n### tableRule标签\n定义表规则\n* `name` : 表规则名称\n\n#### rule标签\n指定对物理表中的哪一列进行拆分和使用什么路由算法。\n\n##### columns标签\n指定要拆分的列名字。\n\n##### algorithm标签\n使用function标签中的name属性。\n\n### function标签\n* `name` : 算法的名字\n* `class` : 制定路由算法具体的类名字\n\n#### property标签\n具体算法需要用到的一些属性\n* `name` : \n\n\n### 示例\n```xml\n<tableRule name=\"rule2\">\n    <rule>\n      <columns>user_id</columns>\n      <algorithm>func1</algorithm>\n    </rule>\n</tableRule>\n```\n\n### 常用的分片规则\n由于分片规则主要定义在function里,因此下面的讲解中主要是针对function的讲解\n\n#### 分片枚举\n```xml\n<function name=\"hash-int\" class=\"org.opencloudb.route.function.PartitionByFileMap\">\n\t<property name=\"mapFile\">partition-hash-int.txt</property>\n\t<property name=\"type\">0</property>\n\t<property name=\"defaultNode\">0</property>\n</function>\n```\n* mapFile: 配置文件名称\n* type: 0表示Integer，非零表示String\n* defaultNode: 枚举分片时，如果碰到不识别的枚举值，就让它路由到默认节点\n\n#### 固定分片hash算法\n对columns取低10位进行求模运算\n```xml\n<function name=\"partitionByLong\" class=\"org.opencloudb.route.function.PartitionByLong\">\n\t<property name=\"partitionCount\">2,1</property>\n\t<property name=\"partitionLength\">256,512</property>\n</function>\n```","slug":"工具/mycat","published":1,"updated":"2015-10-14T01:53:39.460Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxs9001i0cufubasqvja"},{"date":"2015-06-07T16:00:00.000Z","title":"maven","_content":"# maven生命周期\nMaven的生命周期就是对所有的构建过程进行抽象和统一.Maven的生命周期是抽象的,因此生命周期本身是并不做任何实际工作的,实际的任务交给插件来完成\n\nMaven拥有如下三套相互独立的生命周期,每个生命周期都包含一些阶段(phase),阶段是按照顺序执行的,而且当PhaseA在PhaseB之前,那么当执行PhaseB时会先执行PhaseA. 但是这三套生命周期是完全独立的.\n\n## clean\n清理项目,下列是该生命周期的阶段\n* `pre-clean`\n* `clean`\n* `post-clean`\n该生命周期包含的Maven命令：\n```\nmvn clean\n```\n\n## default\n构建项目,下列是该生命周期的阶段\n* `validate`\n* `initialize`\n* `generate-sources`\n* `process-sources`\n* `generate-resources`\n* `process-resources`\n* `compile`\n* `process-class`\n* `generate-test-sources`\n* `process-test-sourcs`\n* `generate-test-resources`\n* `process-test-resources`\n* `test-compile`\n* `process-test-classes`\n* `test`\n* `generate-package`\n* `package`\n* `pre-interation-test`\n* `interation-test`\n* `post-interatopm-test`\n* `verify`\n* `install`\n* `deploy`\n该生命周期包含的Maven命令：\n```\nmvn validate\nmvn compile\nmvn test\nmvn package\nmvn verify\nmvn install\nmvn deploy\n```\n\n## site\n建立项目站点,下列是该生命周期的阶段\n* `pre-site`\n* `site`\n* `post-site`\n* `site-deploy` \n该生命周期包含的Maven命令：\n```\nmvn clean\n```\n\n# 插件目标\n插件里会包含多个目标,每个目标都对应着特定的功能,也就是说插件里的功能是通过目标来实现了.\n\n例如`maven-compiler-plugin`的`compile`目标的写法为`compiler:compile`.\n\n## 插件绑定\n我们可以将插件的目标与生命周期的阶段相绑定. \n\n### default生命周期与内置插件绑定关系及具体任务\n生命周期阶段                  | 插件目标                              |执行任务\n-----------------------------|--------------------------------------|--------------\nprocess-resources            |maven-resources-plugin:resources      |复制主资源文件至主输出目录\ncompile                      |maven-compile-plugin:compile\t        |编译主代码至主输出目录\nprocess-test-resources       |maven-resources-plugin:testRresources |复制测试资源文件至测试输出目录\ntest-compile                 |maven-compiler-plugin:testCompile     |编译测试代码至测试输出目录\ntest\t                     |maven-surefire-plugin:test            |执行测试用例\npackage\t                     |maven-jar-plugin:jar                  |创建项目jar包\ninstall\t                     |maven-install-plugin:install          |将项目输出构件安装到本地仓库\ndeploy                       |maven-deploy-plugin:deploy            |将项目输出构件部署到远程仓库\n\n### 自定义绑定\n首先我们来给个定义：\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.codehaus.mojo</groupId>\n            <artifactId>exec-maven-plugin</artifactId>\n            <version>1.1.1</version>\n            <executions>\n                <execution>\n                    <phase>install</phase>\n                    <goals>\n                        <goal>java</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n</build>\n```\n我们在`install`阶段绑定了`exec-maven-plugin`插件的`java`目标.\n\n# maven版本管理\n## 自动化版本发布\n自动化版本发布基于正确的版本号. 一般我们的版本号构成为`主要版本号.次要版本号.增量版本号-里程碑版本号`\n\n### 插件\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-release-plugin</artifactId>\n    <version>2.5.2</version>\n    <configuration>\n\t\t<!-- 如果项目结构不是采用标准的SVN布局(平行的trunk/tags/branches),则需要配置下面俩项 -->\n\t\t<tagBase>https://svn.mycompany.com/repos/myapplication/tags</tagBase>\n\t\t<branchBase>https://svn.mycompany.com/repos/myapplication/branchs</branchBase>\n    </configuration>\n</plugin>\n```\n### 执行命令\n#### `mvn release:clean`\n\n#### `mvn release:prepare`\n准备版本发布,执行下列操作\n* 检查项目是否有未提交代码\n* 检查项目是否有快照版本依赖\n* 根据用户的输入将快照版本升级为发布版\n* 将POM中的SCM信息更新为TAG地址\n* 基于修改后的POM执行MAVEN构建\n* 提交POM变更\n* 基于用户的输入将代码打TAG\n* 将代码从发布版升级为新的快照版\n* 提交POM变更\n当前俩项检查ok之后,插件会提示用户输出想要发布的版本号,TAG名称和新的快照版本号\n\n#### `mvn release:rollback`\n回滚`release:prepare`所执行的操作. 但是需要注意的是在`release:prepare`步骤中打出的TAG并不会被删除,需要手动删除.\n\n#### `mvn release:perform`\n执行版本发布. 检出`release:prepare`生成的TAG源码,并在此基础上执行`mvn deploy`,打包并部署到仓库.\n\n#### `mvn release:stage`\n\n#### `mvn release:branch`\n通过maven打分支,执行下列操作\n* 检查项目是否有未提交代码\n* 为分支更改POM的版本,例如从`1.1.00SNAPSHOT`改变为`1.1.1-SNAPSHOT`\n* 将POM中的SCM信息更新为分支地址\n* 提交以上更改\n* 将主干代码更新为分支代码\n* 修改本地代码使之回退到之前的版本(用户可以指定新的版本)\n* 提交本地更改\n\n#### `mvn release:update-versions`\n\n\n# maven属性\n## 内置属性\n* `${basedir}`: 表示项目根目录,即包含`pom.xml`文件的目录\n* `${version}`:项目版本 \n\n## POM属性\n该类属性引用POM文件中对应的元素值,例如：\n* `${project.artifactId}`: 引用`<project><artifactId>`值\n* `${project.build.sourceDirectory}`: 项目的主源码目录\n* `${project.build.directory}`: 项目构建的输出目录\n\n## 自定义属性\n在`<Properties><property>`里定义的属性\n\n## setting属性\n与POM属性同理,但是以`settings`开头. 这个属性引用的是`setting.xml`文件中XML元素的值.\n\n## Java系统属性\n所有JAVA系统中的属性都可以使用Maven属性引用,使用`mvn help:system`查看所有Java系统属性\n\n## 环境变量属性\n所有环境变量属性属性都可以使用`env`开头的属性引用,例如`${env.JAVA_HOME}`\n\n\n\n\n\n\n\n\n","source":"_posts/工具/maven.md","raw":"category: 工具\ndate: 2015-06-08\ntitle: maven\n---\n# maven生命周期\nMaven的生命周期就是对所有的构建过程进行抽象和统一.Maven的生命周期是抽象的,因此生命周期本身是并不做任何实际工作的,实际的任务交给插件来完成\n\nMaven拥有如下三套相互独立的生命周期,每个生命周期都包含一些阶段(phase),阶段是按照顺序执行的,而且当PhaseA在PhaseB之前,那么当执行PhaseB时会先执行PhaseA. 但是这三套生命周期是完全独立的.\n\n## clean\n清理项目,下列是该生命周期的阶段\n* `pre-clean`\n* `clean`\n* `post-clean`\n该生命周期包含的Maven命令：\n```\nmvn clean\n```\n\n## default\n构建项目,下列是该生命周期的阶段\n* `validate`\n* `initialize`\n* `generate-sources`\n* `process-sources`\n* `generate-resources`\n* `process-resources`\n* `compile`\n* `process-class`\n* `generate-test-sources`\n* `process-test-sourcs`\n* `generate-test-resources`\n* `process-test-resources`\n* `test-compile`\n* `process-test-classes`\n* `test`\n* `generate-package`\n* `package`\n* `pre-interation-test`\n* `interation-test`\n* `post-interatopm-test`\n* `verify`\n* `install`\n* `deploy`\n该生命周期包含的Maven命令：\n```\nmvn validate\nmvn compile\nmvn test\nmvn package\nmvn verify\nmvn install\nmvn deploy\n```\n\n## site\n建立项目站点,下列是该生命周期的阶段\n* `pre-site`\n* `site`\n* `post-site`\n* `site-deploy` \n该生命周期包含的Maven命令：\n```\nmvn clean\n```\n\n# 插件目标\n插件里会包含多个目标,每个目标都对应着特定的功能,也就是说插件里的功能是通过目标来实现了.\n\n例如`maven-compiler-plugin`的`compile`目标的写法为`compiler:compile`.\n\n## 插件绑定\n我们可以将插件的目标与生命周期的阶段相绑定. \n\n### default生命周期与内置插件绑定关系及具体任务\n生命周期阶段                  | 插件目标                              |执行任务\n-----------------------------|--------------------------------------|--------------\nprocess-resources            |maven-resources-plugin:resources      |复制主资源文件至主输出目录\ncompile                      |maven-compile-plugin:compile\t        |编译主代码至主输出目录\nprocess-test-resources       |maven-resources-plugin:testRresources |复制测试资源文件至测试输出目录\ntest-compile                 |maven-compiler-plugin:testCompile     |编译测试代码至测试输出目录\ntest\t                     |maven-surefire-plugin:test            |执行测试用例\npackage\t                     |maven-jar-plugin:jar                  |创建项目jar包\ninstall\t                     |maven-install-plugin:install          |将项目输出构件安装到本地仓库\ndeploy                       |maven-deploy-plugin:deploy            |将项目输出构件部署到远程仓库\n\n### 自定义绑定\n首先我们来给个定义：\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.codehaus.mojo</groupId>\n            <artifactId>exec-maven-plugin</artifactId>\n            <version>1.1.1</version>\n            <executions>\n                <execution>\n                    <phase>install</phase>\n                    <goals>\n                        <goal>java</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n</build>\n```\n我们在`install`阶段绑定了`exec-maven-plugin`插件的`java`目标.\n\n# maven版本管理\n## 自动化版本发布\n自动化版本发布基于正确的版本号. 一般我们的版本号构成为`主要版本号.次要版本号.增量版本号-里程碑版本号`\n\n### 插件\n```xml\n<plugin>\n\t<groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-release-plugin</artifactId>\n    <version>2.5.2</version>\n    <configuration>\n\t\t<!-- 如果项目结构不是采用标准的SVN布局(平行的trunk/tags/branches),则需要配置下面俩项 -->\n\t\t<tagBase>https://svn.mycompany.com/repos/myapplication/tags</tagBase>\n\t\t<branchBase>https://svn.mycompany.com/repos/myapplication/branchs</branchBase>\n    </configuration>\n</plugin>\n```\n### 执行命令\n#### `mvn release:clean`\n\n#### `mvn release:prepare`\n准备版本发布,执行下列操作\n* 检查项目是否有未提交代码\n* 检查项目是否有快照版本依赖\n* 根据用户的输入将快照版本升级为发布版\n* 将POM中的SCM信息更新为TAG地址\n* 基于修改后的POM执行MAVEN构建\n* 提交POM变更\n* 基于用户的输入将代码打TAG\n* 将代码从发布版升级为新的快照版\n* 提交POM变更\n当前俩项检查ok之后,插件会提示用户输出想要发布的版本号,TAG名称和新的快照版本号\n\n#### `mvn release:rollback`\n回滚`release:prepare`所执行的操作. 但是需要注意的是在`release:prepare`步骤中打出的TAG并不会被删除,需要手动删除.\n\n#### `mvn release:perform`\n执行版本发布. 检出`release:prepare`生成的TAG源码,并在此基础上执行`mvn deploy`,打包并部署到仓库.\n\n#### `mvn release:stage`\n\n#### `mvn release:branch`\n通过maven打分支,执行下列操作\n* 检查项目是否有未提交代码\n* 为分支更改POM的版本,例如从`1.1.00SNAPSHOT`改变为`1.1.1-SNAPSHOT`\n* 将POM中的SCM信息更新为分支地址\n* 提交以上更改\n* 将主干代码更新为分支代码\n* 修改本地代码使之回退到之前的版本(用户可以指定新的版本)\n* 提交本地更改\n\n#### `mvn release:update-versions`\n\n\n# maven属性\n## 内置属性\n* `${basedir}`: 表示项目根目录,即包含`pom.xml`文件的目录\n* `${version}`:项目版本 \n\n## POM属性\n该类属性引用POM文件中对应的元素值,例如：\n* `${project.artifactId}`: 引用`<project><artifactId>`值\n* `${project.build.sourceDirectory}`: 项目的主源码目录\n* `${project.build.directory}`: 项目构建的输出目录\n\n## 自定义属性\n在`<Properties><property>`里定义的属性\n\n## setting属性\n与POM属性同理,但是以`settings`开头. 这个属性引用的是`setting.xml`文件中XML元素的值.\n\n## Java系统属性\n所有JAVA系统中的属性都可以使用Maven属性引用,使用`mvn help:system`查看所有Java系统属性\n\n## 环境变量属性\n所有环境变量属性属性都可以使用`env`开头的属性引用,例如`${env.JAVA_HOME}`\n\n\n\n\n\n\n\n\n","slug":"工具/maven","published":1,"updated":"2015-10-14T01:53:56.932Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsc001k0cufgsht9j6d"},{"date":"2015-08-07T16:00:00.000Z","title":"logstash配置文件","_content":"### input插件\n```json\ninput {\n    # 用来收集系统性能和提供各种存储方式来存储不同值的机制\n\tcollectd {\t\n\t\tport => 25826 ## 端口号与发送端对应\n\t\ttype => collectd\n\t}\n\t# collectd的替换配置\n\tudp {\n\t\tport \t\t=> 25826\n\t\tbuffer_size => 1452\n\t\tworkers \t=> 3       # Default is 2\n\t\tqueue_size \t=> 30000   # Default is 2000\n\t\tcodec \t\t=> collectd { }\n\t\ttype \t\t=> \"collectd\"\n\t}\n\t# 只支持文件的绝对路径，而且会不自动递归目录. /path/to/**/*.log，用 ** 来缩写表示递归全部子目录。\n\tfile {\n        path \t\t\t\t=> [\"D:/logs/*.log\"]\n        type \t\t\t\t=> \"system\"\n        start_position \t\t=> \"beginning\"\n\t\tdiscover_interval \t=> # logstash 每隔多久去检查一次被监听的 path 下是否有新文件。默认值是 15 秒。\n\t\texclude \t\t\t=> # 不想被监听的文件可以排除出去，这里跟 path 一样支持 glob 展开。\n\t\tstat_interval  \t\t=> # logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒。\n\t\tstart_position   \t=> # logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行\n\t\t\n\t\t# codec配置\n\t\tcodec \t\t\t\t=> \"json\"\n    }\n\tstdin {\n        add_field => {\"key\" => \"value\"}\n        codec => \"plain\"\n        tags => [\"add\"]\n        type => \"std\"\n\t\t\n\t\tcodec => multiline {\n            pattern => \"^\\[\"\n            negate => true\n            what => \"previous\"\n        }\n    }\n\tsyslog {\n\t\tport => \"514\"\n\t}\n\tinput {\n\t\ttcp {\n\t\t\tport => 8888\n\t\t\tmode => \"server\"\n\t\t\tssl_enable => false\n\t\t}\n\t}\n}\n```\n\n### filter插件\n```json\nfilter {\n\t#命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它\t\n    grok {\n        match => [\"message\",  \"%{COMBINEDAPACHELOG}\"]\n    }\n\tdate {\n        match => [\"logdate\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\n    }\n\tjson {\n        source => \"message\"\n        target => \"jsoncontent\"\n    }\n\tmutate {\n\t\t#类型转换\n        convert => [\"request_time\", \"float\"]\n\t\t#字符串处理\n\t\tgsub \t=> [\"urlparams\", \"[\\\\?#]\", \"_\"]\n\t\tsplit \t=> [\"message\", \"|\"]\n\t\tjoin \t=> [\"message\", \",\"]\n\t\tmerge \t=> [\"message\", \"message\"]\n\t\t#字段处理\n\t\trename => [\"syslog_host\", \"host\"]\n\t\tupdate => [\"syslog_host\", \"host\"]\n\t\treplace => [\"syslog_host\", \"host\"]\n    }\n\truby {\n        \n    }\n\tsplit {\n        field => \"message\"\n        terminator => \"#\"\n    }\n\t\n}\n```\n\n### output插件\n```json\noutput {\n    file {\n        path => \"D:\\logs\\a.log\"\n        message_format => \"%{message}\"\n        gzip => false\n    }\n\telasticsearch {\n        host => \"192.168.0.2\"\n        protocol => \"http\"\n        index => \"logstash-%{type}-%{+YYYY.MM.dd}\"\n        index_type => \"%{type}\"\n        workers => 5\n        template_overwrite => true\n    }\n}\n```","source":"_posts/工具/logstash_config.md","raw":"category: 工具\ndate: 2015-08-08\ntitle: logstash配置文件\n---\n### input插件\n```json\ninput {\n    # 用来收集系统性能和提供各种存储方式来存储不同值的机制\n\tcollectd {\t\n\t\tport => 25826 ## 端口号与发送端对应\n\t\ttype => collectd\n\t}\n\t# collectd的替换配置\n\tudp {\n\t\tport \t\t=> 25826\n\t\tbuffer_size => 1452\n\t\tworkers \t=> 3       # Default is 2\n\t\tqueue_size \t=> 30000   # Default is 2000\n\t\tcodec \t\t=> collectd { }\n\t\ttype \t\t=> \"collectd\"\n\t}\n\t# 只支持文件的绝对路径，而且会不自动递归目录. /path/to/**/*.log，用 ** 来缩写表示递归全部子目录。\n\tfile {\n        path \t\t\t\t=> [\"D:/logs/*.log\"]\n        type \t\t\t\t=> \"system\"\n        start_position \t\t=> \"beginning\"\n\t\tdiscover_interval \t=> # logstash 每隔多久去检查一次被监听的 path 下是否有新文件。默认值是 15 秒。\n\t\texclude \t\t\t=> # 不想被监听的文件可以排除出去，这里跟 path 一样支持 glob 展开。\n\t\tstat_interval  \t\t=> # logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒。\n\t\tstart_position   \t=> # logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行\n\t\t\n\t\t# codec配置\n\t\tcodec \t\t\t\t=> \"json\"\n    }\n\tstdin {\n        add_field => {\"key\" => \"value\"}\n        codec => \"plain\"\n        tags => [\"add\"]\n        type => \"std\"\n\t\t\n\t\tcodec => multiline {\n            pattern => \"^\\[\"\n            negate => true\n            what => \"previous\"\n        }\n    }\n\tsyslog {\n\t\tport => \"514\"\n\t}\n\tinput {\n\t\ttcp {\n\t\t\tport => 8888\n\t\t\tmode => \"server\"\n\t\t\tssl_enable => false\n\t\t}\n\t}\n}\n```\n\n### filter插件\n```json\nfilter {\n\t#命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它\t\n    grok {\n        match => [\"message\",  \"%{COMBINEDAPACHELOG}\"]\n    }\n\tdate {\n        match => [\"logdate\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\n    }\n\tjson {\n        source => \"message\"\n        target => \"jsoncontent\"\n    }\n\tmutate {\n\t\t#类型转换\n        convert => [\"request_time\", \"float\"]\n\t\t#字符串处理\n\t\tgsub \t=> [\"urlparams\", \"[\\\\?#]\", \"_\"]\n\t\tsplit \t=> [\"message\", \"|\"]\n\t\tjoin \t=> [\"message\", \",\"]\n\t\tmerge \t=> [\"message\", \"message\"]\n\t\t#字段处理\n\t\trename => [\"syslog_host\", \"host\"]\n\t\tupdate => [\"syslog_host\", \"host\"]\n\t\treplace => [\"syslog_host\", \"host\"]\n    }\n\truby {\n        \n    }\n\tsplit {\n        field => \"message\"\n        terminator => \"#\"\n    }\n\t\n}\n```\n\n### output插件\n```json\noutput {\n    file {\n        path => \"D:\\logs\\a.log\"\n        message_format => \"%{message}\"\n        gzip => false\n    }\n\telasticsearch {\n        host => \"192.168.0.2\"\n        protocol => \"http\"\n        index => \"logstash-%{type}-%{+YYYY.MM.dd}\"\n        index_type => \"%{type}\"\n        workers => 5\n        template_overwrite => true\n    }\n}\n```","slug":"工具/logstash_config","published":1,"updated":"2015-10-14T01:54:03.041Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsd001m0cufwulc425a"},{"date":"2015-10-14T16:00:00.000Z","title":"Linux命令使用","_content":"\n## 常用命令\n### gzip\n将文件或者文件夹压缩成后缀为`.gz`的文件\n\n* `-a` 　使用ASCII文字模式。 \n* `-c` 　把压缩后的文件输出到标准输出设备，不去更动原始文件。 \n* `-d` 　解开压缩文件。 \n* `-f` 　强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 \n* `-l` 　列出压缩文件的相关信息。 \n* `-L` 　显示版本与版权信息。 \n* `-n` 　压缩文件时，不保存原来的文件名称及时间戳记。 \n* `-N` 　压缩文件时，保存原来的文件名称及时间戳记。 \n* `-q` 　不显示警告信息。 \n* `-r` 　递归处理，将指定目录下的所有文件及子目录一并处理。 \n* `-S` 　更改压缩字尾字符串。 \n* `-t` 　测试压缩文件是否正确无误。 \n* `-v` 　显示指令执行过程。 \n* `-num` 用指定的数字num调整压缩的速度，-1或--fast表示最快压缩方法（低压缩比），-9或--best表示最慢压缩方法（高压缩比）。系统缺省值为6。 \n\n常用命令\n* `gzip *`  把test6目录下的每个文件压缩成.gz文件 \n* `gzip -dv *` 把例1中每个压缩的文件解压，并列出详细的信息\n* `gzip -l *` 详细显示例1中每个压缩的文件的信息，并不解压\n* `gzip -r log.tar` 压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz\n* `gzip -rv test6` 递归的压缩目录\n* `gzip -dr test6` 递归地解压目录\n\n### grep\n一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来\n\n主要参数：\n* `－c`：只输出匹配行的计数。\n* `－I`：不区分大小写(只适用于单字符)。\n* `－h`：查询多文件时不显示文件名。\n* `－l`：查询多文件时只输出包含匹配字符的文件名。\n* `－n`：显示匹配行及行号。\n* `－s`：不显示不存在或无匹配文本的错误信息。\n* `－v`：显示不包含匹配文本的所有行。\n\npattern正则表达式主要参数：\n* `\\`： 忽略正则表达式中特殊字符的原有含义。\n* `^`：匹配正则表达式的开始行。\n* `$`: 匹配正则表达式的结束行。\n* `\\<`：从匹配正则表达 式的行开始。\n* `\\>`：到匹配正则表达式的行结束。\n* `[ ]`：单个字符，如[A]即A符合要求 。\n* `[ - ]`：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。\n* `。`：所有的单个字符。\n* `*` ：有字符，长度可以为0。\n\n### tar\ntar可用于建立、还原、查看、管理文件，也可方 便的追加新文件到备份文件中，或仅更新部分的备份文件，以及解压、删除指定的文件\n\n\n## 系统性能监控命令\n\n### Vmstat\nvmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写, 是实时系统监控工具。\n\n一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:\n```\n[root@cvs /]# vmstat 2 1\n=>\nprocs  -----------memory----------     ---swap--  -----io----  --system--   -----cpu-----\n r  b    swpd   free   buff  cache      si   so     bi    bo    in   cs     us sy id wa st\n 1  0  1339624 525012 464316 6796908    0    0      5    32     0    0      2  0 98  0  0\n```\n参数\n* -a：显示活跃和非活跃内存\n* -f：显示从系统启动至今的fork数量 。\n* -m：显示slabinfo\n* -n：只在开始时显示一次各字段名称。\n* -s：显示内存相关统计信息及多种系统活动数量。\n* delay：刷新时间间隔。如果不指定，只显示一条结果。\n* count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。\n* -d：显示磁盘相关统计信息。\n* -p：显示指定磁盘分区统计信息\n* -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）\n* -V：显示vmstat版本信息。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.gif)\n我们从上面那个图来解释各个参数\n> porcs\n* r：表示运行队列(分配到CPU进程数)\n* b：阻塞状态的进程数\n\n> memory\n* swpd：虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了\n* free：空闲的物理内存的大小\n* buff：作为buffer使用的内存数量（Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存）\n* cache：作为缓存使用的内存数量（ cache直接用来记忆我们打开的文件,给文件做缓冲）\n* inact：非活跃内存数\n* active： 活跃内存数\n\n> swap\n* si：从磁盘交换的内存量（每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了）\n* so：向磁盘交换的内存量（每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上）\n\n> io\n* bi：从阻塞设备接受到的块数据数量。\n* bo：向阻塞设备发送的块数据数量。\n\n> system\n* in：每秒CPU的中断次数，包括时间中断\n* cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目\n\n> cpu\n* us：用户CPU时间\n* sy：系统CPU时间\n* id：空闲 CPU时间\n* wa：等待IO CPU时间\n* st\n\n\n### pidstat\n监控锁竞争\n```\n[root@cvs /]# pidstat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月15日  _x86_64_        (8 CPU)\n\nPID    %usr %system  %guest    %CPU   CPU  Command\n```\n显式参数\n* PID : 被监控的任务的进程号\n* %usr :  当在用户层执行(应用程序)时这个任务的cpu使用率，和 nice 优先级无关。注意这个字段计算的cpu时间不包括在虚拟处理器中花去的时间。\n* %system :  这个任务在系统层使用时的cpu使用率。\n* %guest ：  任务花费在虚拟机上的cpu使用率（运行在虚拟处理器）。\n* %CPU ：  任务总的cpu使用率。在SMP环境(多处理器)中，如果在命令行中输入-I参数的话，cpu使用率会除以你的cpu数量。\n* CPU ： 正在运行这个任务的处理器编号。\n* Command ： 这个任务的命令名称。\n\n参数\n* -u: pidstat将显示各活动进程的cpu使用统计\n* -p: 我们可以查看特定进程的系统资源使用情况：\n* -r: pidstat将显示各活动进程的内存使用统计：\n* -d: 我们可以查看进程IO的统计信息\n\n-d:\n* kB_rd/s: 每秒进程从磁盘读取的数据量(以kB为单位)\n* kB_wr/s: 每秒进程向磁盘写的数据量(以kB为单位)\n* Command: 拉起进程对应的命令\n\n-r:\n* minflt/s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数\n* majflt/s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生\n* VSZ:      该进程使用的虚拟内存(以kB为单位)\n* RSS:      该进程使用的物理内存(以kB为单位)\n* %MEM:     该进程使用内存的百分比\n* Command:  拉起进程对应的命令\n\n \n### iostat\niostat用于输出CPU和磁盘I/O相关的统计信息. \n\n* `-c` 仅显示CPU统计信息.与-d选项互斥.\n* `-d` 仅显示磁盘统计信息.与-c选项互斥.\n* `-k` 以K为单位显示每秒的磁盘请求数,默认单位块.\n* `-p device | ALL`  与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:`iostat -p hda` 或显示所有设备`iostat -p ALL`\n* `-t`    在输出数据时,打印搜集数据的时间.\n* `-V`    打印版本号和帮助信息.\n* `-x`    输出扩展信息.\n* \n```\n[root@cvs /]# iostat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月16日  _x86_64_        (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.67    0.00    0.21    0.38    0.00   97.74\n\nDevice:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\nsda              18.64        72.79       512.65  951732770 6702726216\n```\navg-cpu:  \n* `%user`: 在用户级别运行所使用的CPU的百分比.\n* `%nice`: nice操作所使用的CPU的百分比.\n* `%system`: 在系统级别(kernel)运行所使用CPU的百分比.\n* `%iowait`: CPU等待硬件I/O时,所占用CPU百分比.\n* `%steal`: \n* `%idle`: CPU空闲时间的百分比.\n           \n\nDevice:            \n* `tps`: 每秒钟发送到的I/O请求数.\n* `Blk_read/s`: 每秒读取的block数.\n* `Blk_wrtn/s`: 每秒写入的block数.\n* `Blk_read`: 读入的block总数.\n* `Blk_wrtn`: 写入的block总数.\n\n\n* `Blk_read` 读入块的当总数.\n* `Blk_wrtn` 写入块的总数.\n* `kB_read/s` 每秒从驱动器读入的数据量,单位为K.\n* `kB_wrtn/s` 每秒向驱动器写入的数据量,单位为K.\n* `kB_read` 读入的数据总量,单位为K.\n* `kB_wrtn` 写入的数据总量,单位为K.\n* `rrqm/s`  将读入请求合并后,每秒发送到设备的读入请求数.\n* `wrqm/s`  将写入请求合并后,每秒发送到设备的写入请求数.\n* `r/s`     每秒发送到设备的读入请求数.\n* `w/s`     每秒发送到设备的写入请求数.\n* `rsec/s`  每秒从设备读入的扇区数.\n* `wsec/s`  每秒向设备写入的扇区数.\n* `rkB/s`  每秒从设备读入的数据量,单位为K.\n* `wkB/s`  每秒向设备写入的数据量,单位为K.\n* `avgrq-sz`  发送到设备的请求的平均大小,单位是扇区.\n* `avgqu-sz` 发送到设备的请求的平均队列长度.\n* `await`  I/O请求平均执行时间.包括发送请求和执行的时间.单位是毫秒.\n* `svctm` 发送到设备的I/O请求的平均执行时间.单位是毫秒.\n* `%util`  在I/O请求发送到设备期间,占用CPU时间的百分比.用于显示设备的带宽利用率.当这个值接近100%时,表示设备带宽已经占满.\n\n### uname \n* `-a` 　显示全部的信息。 \n* `-m`　显示电脑类型。 \n* `-n`　显示在网络上的主机名称。 \n* `-r`　显示操作系统的发行编号。 \n* `-s`　显示操作系统名称。 \n* `-v` 　显示操作系统的版本。 \n\n\n### sar \n系统报告命令\n* sar -q 1 5    察看cpu的load状况，每1s钟统计1次，共统计5次\n* sar -u 2 3   察看cpu使用率，每2s统计1次，共统计3次\n* sar -r   察看当日内存占用情况(默认每10分钟统计一次)\n* sar -b 察看当日IO使用情况\n* sar -n SOCK   察看网络sock连接\n* sar -n DEV 察看网络流量\n\n\n### top  \n\n### ps \n\n### df \n检查文件系统的磁盘空间占用情况\n* -a 显示所有文件系统的磁盘使用情况，包括0块（block）的文件系统，如/proc文件系统。\n* -k 以k字节为单位显示。\n* -i 显示i节点信息，而不是磁盘块。\n* -t 显示各指定类型的文件系统的磁盘空间使用情况。\n* -x 列出不是某一指定类型文件系统的磁盘空间使用情况（与t选项相反）。\n* -T 显示文件系统类型。\n```\n文件系统                 1K-块      已用      可用 已用% 挂载点\n/dev/sda2             10079084   6660892   2906192  70% /\ntmpfs                  8141376         0   8141376   0% /dev/shm\n/dev/sda1             10079084    173308   9393776   2% /boot\n/dev/sda5            257592732 241557292   2950464  99% /opt\n```\n\n### du \n显示每个文件和目录的磁盘使用空间。\n* -a或-all  显示目录中个别文件的大小。   \n* -b或-bytes  显示目录或文件大小时，以byte为单位。   \n* -c或--total  除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 \n* -k或--kilobytes  以KB(1024bytes)为单位输出。\n* -m或--megabytes  以MB为单位输出。   \n* -s或--summarize  仅显示总计，只列出最后加总的值。\n* -h或--human-readable  以K，M，G为单位，提高信息的可读性。\n* -x或--one-file-xystem  以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 \n* -L<符号链接>或--dereference<符号链接> 显示选项中所指定符号链接的源文件大小。   \n* -S或--separate-dirs   显示个别目录的大小时，并不含其子目录的大小。 \n* -X<文件>或--exclude-from=<文件>  在<文件>指定目录或文件。   \n* --exclude=<目录或文件>         略过指定的目录或文件。    \n* -D或--dereference-args   显示指定符号链接的源文件大小。   \n* -H或--si  与-h参数相同，但是K，M，G是以1000为换算单位。   \n* -l或--count-links   重复计算硬件链接的文件。  \n```\n# 对当前目前下所有文件按文件大小倒排序，大小相同按文件名字母倒排序\ndu -ak | sort -t$'\\t' -l1 -nr -k2 -r \n```\n\n## 配置文件\n\n### /proc/cpuinfo\n```\n[root@cvs /]# cat /proc/cpuinfo\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 45\nmodel name      : Intel(R) Xeon(R) CPU E5-2603 0 @ 1.80GHz\nstepping        : 7\ncpu MHz         : 1800.009\ncache size      : 10240 KB\nphysical id     : 0\nsiblings        : 4\ncore id         : 0\ncpu cores       : 4\napicid          : 0\ninitial apicid  : 0\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nflags           : fpu vme de pse tsc msr pae mce ...\nbogomips        : 3600.01\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 46 bits physical, 48 bits virtual\npower management:\n```\n* `processor`       : CPU号\n* `vendor_id`       : CPU制造商   \n* `cpu family`      : CPU产品系列代号\n* `model`           : CPU属于其系列中的哪一代的代号\n* `model name`      : CPU属于的名字及其编号、标称主频\n* `stepping`        : CPU属于制作更新版本\n* `cpu MHz`         : CPU的实际使用主频\n* `cache size`      : CPU二级缓存大小\n* `physical id`     : 单个CPU的标号\n* `siblings`        : 单个CPU逻辑物理核数\n* `core id`         : 当前物理核在其所处CPU中的编号，这个编号不一定连续\n* `cpu cores`       : 该逻辑核所处CPU的物理核数\n* `apicid`          : 用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续\n* `initial apicid`  :\n* `fpu`             : 是否具有浮点运算单元（Floating Point Unit）\n* `fpu_exception`   : 是否支持浮点计算异常\n* `cpuid level`     : 执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容\n* `wp`              : 表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）\n* `flags`           : 当前CPU支持的功能\n* `bogomips`        : 在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）\n* `clflush size`    : 每次刷新缓存的大小单位\n* `cache_alignment` : 缓存地址对齐单位\n* `address sizes`   : 可访问地址空间位数\n* `power management`: 对能源管理的支持，有以下几个可选支持功能\n\n### /proc/meminfo \n```\n[root@cvs /]# cat /proc/meminfo \nMemTotal:       16282756 kB\nMemFree:         2012664 kB\nBuffers:          491980 kB\nCached:          5477644 kB\nSwapCached:       110344 kB\nActive:          9224100 kB\nInactive:        4478716 kB\nActive(anon):    6410680 kB\nInactive(anon):  1322576 kB\nActive(file):    2813420 kB\nInactive(file):  3156140 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nSwapTotal:      10239992 kB\nSwapFree:        8921364 kB\nDirty:              1176 kB\nWriteback:             0 kB\nAnonPages:       7679964 kB\nMapped:            25344 kB\nShmem:                36 kB\nSlab:             328340 kB\nSReclaimable:     284284 kB\nSUnreclaim:        44056 kB\nKernelStack:        8504 kB\nPageTables:        27520 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:    18381368 kB\nCommitted_AS:   11103356 kB\nVmallocTotal:   34359738367 kB\nVmallocUsed:      307784 kB\nVmallocChunk:   34350792204 kB\nHardwareCorrupted:     0 kB\nAnonHugePages:   6842368 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nDirectMap4k:        5056 kB\nDirectMap2M:     2045952 kB\nDirectMap1G:    14680064 kB\n```\n* `MemTotal`: \n* `MemFree`:空闲内存\n* `Buffers`:给文件的缓冲大小\n* `Cached`: 高速缓冲存储器(http://baike.baidu.com/view/496990.htm)使用的大小\n* `SwapCached`: 被高速缓冲存储用的交换空间大小\n* `Active`: 活跃使用中的高速缓冲存储器页面文件大小\n* `Inactive`: 不经常使用的高速缓冲存储器页面文件大小\n* `Active(anon)`: \n* `Inactive(anon)`: \n* `Active(file)`: \n* `Inactive(file)`: \n* `Unevictable`:\n* `Mlocked`:\n* `SwapTotal`:交换空间总大小\n* `SwapFree`: 空闲交换空间\n* `Dirty`:等待被写回到磁盘的大小\n* `Writeback`:正在被写回的大小\n* `AnonPages`:未映射的页的大小\n* `Mapped`: 设备和文件映射的大小\n* `Shmem`:\n* `Slab`: 内核数据结构缓存的大小，可减少申请和释放内存带来的消耗\n* `SReclaimable`: 可收回slab的大小\n* `SUnreclaim`: 不可收回的slab的大小23204+14164=37368\n* `KernelStack`:\n* `PageTables`: 管理内存分页的索引表的大小\n* `NFS_Unstable`: 不稳定页表的大小\n* `Bounce`: bounce:退回\n* `WritebackTmp`: \n* `CommitLimit`:\n* `Committed_AS`: \n* `VmallocTotal`: 虚拟内存大小\n* `VmallocUsed`:已经被使用的虚拟内存大小\n* `VmallocChunk`: \n* `HardwareCorrupted`:\n* `AnonHugePages`:\n* `HugePages_Total`:大页面的分配\n* `HugePages_Free`: \n* `HugePages_Rsvd`: \n* `HugePages_Surp`: \n* `Hugepagesize`: \n* `DirectMap4k`:\n* `DirectMap2M`:\n* `DirectMap1G`:\n\n### /proc/net/dev\n```\n[root@cvs /]# cat /proc/net/dev\nInter-|   Receive                                                |  Transmit\n face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed\n    lo:365528559149 865504543    0    0    0     0          0         0 365528559149 865504543    0    0    0     0       0          0\n   em1:542483270223 575346473    0    0    0    62          0   8267561 580200919340 586706511    0    0    0     0       0          0\n   em2:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em3:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em4:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n```\n\nInter                                                     \n* `face`:接口的名字\n \nReceive\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`: \n* `frame`: \n* `compressed`: \n* `multicast`:\n\nTransmit\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`: \n* `colls`: \n* `carrier`: \n* `compressed`:\n\n\n![性能测评工具](https://raw.githubusercontent.com/ming15/blog-website/images/other/Linux%20%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%84%E5%B7%A5%E5%85%B7.jpg)\n![性能观测工具](https://raw.githubusercontent.com/ming15/blog-website/images/other/Linux%20%E6%80%A7%E8%83%BD%E8%A7%82%E6%B5%8B%E5%B7%A5%E5%85%B7.jpg)\n![性能调优工具](https://raw.githubusercontent.com/ming15/blog-website/images/other/Linux%20%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7.jpg)\n![](https://github.com/ming15/blog-website/blob/images/other/Linux%20observability%20sar.jpg)\n\n## 其他小工具\n\n### nload\n可以分开来监控入站流量和出站流量\n\n### iftop\n可测量通过每一个套接字连接传输的数据\n\n### nethogs\n显示每个进程所使用的带宽\n\n### bmon\n一款类似nload的工具，它可以显示系统上所有网络接口的流量负载\n\n### speedometer\n绘制外观漂亮的图形，显示通过某个接口传输的入站流量和出站流量。\n\n### pktstat\n实时显示所有活动连接，并显示哪些数据通过这些活动连接传输的速度。它还可以显示连接类型，比如TCP连接或UDP连接；如果涉及HTTP连接，还会显示关于HTTP请求的详细信息。\n\n### dstat\n监控系统的不同统计信息，并使用批处理模式来报告，或者将相关数据记入到CSV或类似的文件\n","source":"_posts/工具/linux命令.md","raw":"category: 工具\ndate: 2015-10-15\ntitle: Linux命令使用\n---\n\n## 常用命令\n### gzip\n将文件或者文件夹压缩成后缀为`.gz`的文件\n\n* `-a` 　使用ASCII文字模式。 \n* `-c` 　把压缩后的文件输出到标准输出设备，不去更动原始文件。 \n* `-d` 　解开压缩文件。 \n* `-f` 　强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 \n* `-l` 　列出压缩文件的相关信息。 \n* `-L` 　显示版本与版权信息。 \n* `-n` 　压缩文件时，不保存原来的文件名称及时间戳记。 \n* `-N` 　压缩文件时，保存原来的文件名称及时间戳记。 \n* `-q` 　不显示警告信息。 \n* `-r` 　递归处理，将指定目录下的所有文件及子目录一并处理。 \n* `-S` 　更改压缩字尾字符串。 \n* `-t` 　测试压缩文件是否正确无误。 \n* `-v` 　显示指令执行过程。 \n* `-num` 用指定的数字num调整压缩的速度，-1或--fast表示最快压缩方法（低压缩比），-9或--best表示最慢压缩方法（高压缩比）。系统缺省值为6。 \n\n常用命令\n* `gzip *`  把test6目录下的每个文件压缩成.gz文件 \n* `gzip -dv *` 把例1中每个压缩的文件解压，并列出详细的信息\n* `gzip -l *` 详细显示例1中每个压缩的文件的信息，并不解压\n* `gzip -r log.tar` 压缩一个tar备份文件，此时压缩文件的扩展名为.tar.gz\n* `gzip -rv test6` 递归的压缩目录\n* `gzip -dr test6` 递归地解压目录\n\n### grep\n一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来\n\n主要参数：\n* `－c`：只输出匹配行的计数。\n* `－I`：不区分大小写(只适用于单字符)。\n* `－h`：查询多文件时不显示文件名。\n* `－l`：查询多文件时只输出包含匹配字符的文件名。\n* `－n`：显示匹配行及行号。\n* `－s`：不显示不存在或无匹配文本的错误信息。\n* `－v`：显示不包含匹配文本的所有行。\n\npattern正则表达式主要参数：\n* `\\`： 忽略正则表达式中特殊字符的原有含义。\n* `^`：匹配正则表达式的开始行。\n* `$`: 匹配正则表达式的结束行。\n* `\\<`：从匹配正则表达 式的行开始。\n* `\\>`：到匹配正则表达式的行结束。\n* `[ ]`：单个字符，如[A]即A符合要求 。\n* `[ - ]`：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。\n* `。`：所有的单个字符。\n* `*` ：有字符，长度可以为0。\n\n### tar\ntar可用于建立、还原、查看、管理文件，也可方 便的追加新文件到备份文件中，或仅更新部分的备份文件，以及解压、删除指定的文件\n\n\n## 系统性能监控命令\n\n### Vmstat\nvmstat是Virtual Meomory Statistics（虚拟内存统计）的缩写, 是实时系统监控工具。\n\n一般vmstat工具的使用是通过两个数字参数来完成的，第一个参数是采样的时间间隔数，单位是秒，第二个参数是采样的次数，如:\n```\n[root@cvs /]# vmstat 2 1\n=>\nprocs  -----------memory----------     ---swap--  -----io----  --system--   -----cpu-----\n r  b    swpd   free   buff  cache      si   so     bi    bo    in   cs     us sy id wa st\n 1  0  1339624 525012 464316 6796908    0    0      5    32     0    0      2  0 98  0  0\n```\n参数\n* -a：显示活跃和非活跃内存\n* -f：显示从系统启动至今的fork数量 。\n* -m：显示slabinfo\n* -n：只在开始时显示一次各字段名称。\n* -s：显示内存相关统计信息及多种系统活动数量。\n* delay：刷新时间间隔。如果不指定，只显示一条结果。\n* count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。\n* -d：显示磁盘相关统计信息。\n* -p：显示指定磁盘分区统计信息\n* -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）\n* -V：显示vmstat版本信息。\n\n![](https://raw.githubusercontent.com/ming15/blog-website/images/other/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.gif)\n我们从上面那个图来解释各个参数\n> porcs\n* r：表示运行队列(分配到CPU进程数)\n* b：阻塞状态的进程数\n\n> memory\n* swpd：虚拟内存已使用的大小，如果大于0，表示你的机器物理内存不足了\n* free：空闲的物理内存的大小\n* buff：作为buffer使用的内存数量（Linux/Unix系统是用来存储，目录里面有什么内容，权限等的缓存）\n* cache：作为缓存使用的内存数量（ cache直接用来记忆我们打开的文件,给文件做缓冲）\n* inact：非活跃内存数\n* active： 活跃内存数\n\n> swap\n* si：从磁盘交换的内存量（每秒从磁盘读入虚拟内存的大小，如果这个值大于0，表示物理内存不够用或者内存泄露了）\n* so：向磁盘交换的内存量（每秒虚拟内存写入磁盘的大小，如果这个值大于0，同上）\n\n> io\n* bi：从阻塞设备接受到的块数据数量。\n* bo：向阻塞设备发送的块数据数量。\n\n> system\n* in：每秒CPU的中断次数，包括时间中断\n* cs：每秒上下文切换次数，例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目\n\n> cpu\n* us：用户CPU时间\n* sy：系统CPU时间\n* id：空闲 CPU时间\n* wa：等待IO CPU时间\n* st\n\n\n### pidstat\n监控锁竞争\n```\n[root@cvs /]# pidstat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月15日  _x86_64_        (8 CPU)\n\nPID    %usr %system  %guest    %CPU   CPU  Command\n```\n显式参数\n* PID : 被监控的任务的进程号\n* %usr :  当在用户层执行(应用程序)时这个任务的cpu使用率，和 nice 优先级无关。注意这个字段计算的cpu时间不包括在虚拟处理器中花去的时间。\n* %system :  这个任务在系统层使用时的cpu使用率。\n* %guest ：  任务花费在虚拟机上的cpu使用率（运行在虚拟处理器）。\n* %CPU ：  任务总的cpu使用率。在SMP环境(多处理器)中，如果在命令行中输入-I参数的话，cpu使用率会除以你的cpu数量。\n* CPU ： 正在运行这个任务的处理器编号。\n* Command ： 这个任务的命令名称。\n\n参数\n* -u: pidstat将显示各活动进程的cpu使用统计\n* -p: 我们可以查看特定进程的系统资源使用情况：\n* -r: pidstat将显示各活动进程的内存使用统计：\n* -d: 我们可以查看进程IO的统计信息\n\n-d:\n* kB_rd/s: 每秒进程从磁盘读取的数据量(以kB为单位)\n* kB_wr/s: 每秒进程向磁盘写的数据量(以kB为单位)\n* Command: 拉起进程对应的命令\n\n-r:\n* minflt/s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数\n* majflt/s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生\n* VSZ:      该进程使用的虚拟内存(以kB为单位)\n* RSS:      该进程使用的物理内存(以kB为单位)\n* %MEM:     该进程使用内存的百分比\n* Command:  拉起进程对应的命令\n\n \n### iostat\niostat用于输出CPU和磁盘I/O相关的统计信息. \n\n* `-c` 仅显示CPU统计信息.与-d选项互斥.\n* `-d` 仅显示磁盘统计信息.与-c选项互斥.\n* `-k` 以K为单位显示每秒的磁盘请求数,默认单位块.\n* `-p device | ALL`  与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:`iostat -p hda` 或显示所有设备`iostat -p ALL`\n* `-t`    在输出数据时,打印搜集数据的时间.\n* `-V`    打印版本号和帮助信息.\n* `-x`    输出扩展信息.\n* \n```\n[root@cvs /]# iostat\nLinux 2.6.32-279.el6.x86_64 (cvs)       2015年10月16日  _x86_64_        (8 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           1.67    0.00    0.21    0.38    0.00   97.74\n\nDevice:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn\nsda              18.64        72.79       512.65  951732770 6702726216\n```\navg-cpu:  \n* `%user`: 在用户级别运行所使用的CPU的百分比.\n* `%nice`: nice操作所使用的CPU的百分比.\n* `%system`: 在系统级别(kernel)运行所使用CPU的百分比.\n* `%iowait`: CPU等待硬件I/O时,所占用CPU百分比.\n* `%steal`: \n* `%idle`: CPU空闲时间的百分比.\n           \n\nDevice:            \n* `tps`: 每秒钟发送到的I/O请求数.\n* `Blk_read/s`: 每秒读取的block数.\n* `Blk_wrtn/s`: 每秒写入的block数.\n* `Blk_read`: 读入的block总数.\n* `Blk_wrtn`: 写入的block总数.\n\n\n* `Blk_read` 读入块的当总数.\n* `Blk_wrtn` 写入块的总数.\n* `kB_read/s` 每秒从驱动器读入的数据量,单位为K.\n* `kB_wrtn/s` 每秒向驱动器写入的数据量,单位为K.\n* `kB_read` 读入的数据总量,单位为K.\n* `kB_wrtn` 写入的数据总量,单位为K.\n* `rrqm/s`  将读入请求合并后,每秒发送到设备的读入请求数.\n* `wrqm/s`  将写入请求合并后,每秒发送到设备的写入请求数.\n* `r/s`     每秒发送到设备的读入请求数.\n* `w/s`     每秒发送到设备的写入请求数.\n* `rsec/s`  每秒从设备读入的扇区数.\n* `wsec/s`  每秒向设备写入的扇区数.\n* `rkB/s`  每秒从设备读入的数据量,单位为K.\n* `wkB/s`  每秒向设备写入的数据量,单位为K.\n* `avgrq-sz`  发送到设备的请求的平均大小,单位是扇区.\n* `avgqu-sz` 发送到设备的请求的平均队列长度.\n* `await`  I/O请求平均执行时间.包括发送请求和执行的时间.单位是毫秒.\n* `svctm` 发送到设备的I/O请求的平均执行时间.单位是毫秒.\n* `%util`  在I/O请求发送到设备期间,占用CPU时间的百分比.用于显示设备的带宽利用率.当这个值接近100%时,表示设备带宽已经占满.\n\n### uname \n* `-a` 　显示全部的信息。 \n* `-m`　显示电脑类型。 \n* `-n`　显示在网络上的主机名称。 \n* `-r`　显示操作系统的发行编号。 \n* `-s`　显示操作系统名称。 \n* `-v` 　显示操作系统的版本。 \n\n\n### sar \n系统报告命令\n* sar -q 1 5    察看cpu的load状况，每1s钟统计1次，共统计5次\n* sar -u 2 3   察看cpu使用率，每2s统计1次，共统计3次\n* sar -r   察看当日内存占用情况(默认每10分钟统计一次)\n* sar -b 察看当日IO使用情况\n* sar -n SOCK   察看网络sock连接\n* sar -n DEV 察看网络流量\n\n\n### top  \n\n### ps \n\n### df \n检查文件系统的磁盘空间占用情况\n* -a 显示所有文件系统的磁盘使用情况，包括0块（block）的文件系统，如/proc文件系统。\n* -k 以k字节为单位显示。\n* -i 显示i节点信息，而不是磁盘块。\n* -t 显示各指定类型的文件系统的磁盘空间使用情况。\n* -x 列出不是某一指定类型文件系统的磁盘空间使用情况（与t选项相反）。\n* -T 显示文件系统类型。\n```\n文件系统                 1K-块      已用      可用 已用% 挂载点\n/dev/sda2             10079084   6660892   2906192  70% /\ntmpfs                  8141376         0   8141376   0% /dev/shm\n/dev/sda1             10079084    173308   9393776   2% /boot\n/dev/sda5            257592732 241557292   2950464  99% /opt\n```\n\n### du \n显示每个文件和目录的磁盘使用空间。\n* -a或-all  显示目录中个别文件的大小。   \n* -b或-bytes  显示目录或文件大小时，以byte为单位。   \n* -c或--total  除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 \n* -k或--kilobytes  以KB(1024bytes)为单位输出。\n* -m或--megabytes  以MB为单位输出。   \n* -s或--summarize  仅显示总计，只列出最后加总的值。\n* -h或--human-readable  以K，M，G为单位，提高信息的可读性。\n* -x或--one-file-xystem  以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 \n* -L<符号链接>或--dereference<符号链接> 显示选项中所指定符号链接的源文件大小。   \n* -S或--separate-dirs   显示个别目录的大小时，并不含其子目录的大小。 \n* -X<文件>或--exclude-from=<文件>  在<文件>指定目录或文件。   \n* --exclude=<目录或文件>         略过指定的目录或文件。    \n* -D或--dereference-args   显示指定符号链接的源文件大小。   \n* -H或--si  与-h参数相同，但是K，M，G是以1000为换算单位。   \n* -l或--count-links   重复计算硬件链接的文件。  \n```\n# 对当前目前下所有文件按文件大小倒排序，大小相同按文件名字母倒排序\ndu -ak | sort -t$'\\t' -l1 -nr -k2 -r \n```\n\n## 配置文件\n\n### /proc/cpuinfo\n```\n[root@cvs /]# cat /proc/cpuinfo\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 45\nmodel name      : Intel(R) Xeon(R) CPU E5-2603 0 @ 1.80GHz\nstepping        : 7\ncpu MHz         : 1800.009\ncache size      : 10240 KB\nphysical id     : 0\nsiblings        : 4\ncore id         : 0\ncpu cores       : 4\napicid          : 0\ninitial apicid  : 0\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nflags           : fpu vme de pse tsc msr pae mce ...\nbogomips        : 3600.01\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 46 bits physical, 48 bits virtual\npower management:\n```\n* `processor`       : CPU号\n* `vendor_id`       : CPU制造商   \n* `cpu family`      : CPU产品系列代号\n* `model`           : CPU属于其系列中的哪一代的代号\n* `model name`      : CPU属于的名字及其编号、标称主频\n* `stepping`        : CPU属于制作更新版本\n* `cpu MHz`         : CPU的实际使用主频\n* `cache size`      : CPU二级缓存大小\n* `physical id`     : 单个CPU的标号\n* `siblings`        : 单个CPU逻辑物理核数\n* `core id`         : 当前物理核在其所处CPU中的编号，这个编号不一定连续\n* `cpu cores`       : 该逻辑核所处CPU的物理核数\n* `apicid`          : 用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续\n* `initial apicid`  :\n* `fpu`             : 是否具有浮点运算单元（Floating Point Unit）\n* `fpu_exception`   : 是否支持浮点计算异常\n* `cpuid level`     : 执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容\n* `wp`              : 表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）\n* `flags`           : 当前CPU支持的功能\n* `bogomips`        : 在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）\n* `clflush size`    : 每次刷新缓存的大小单位\n* `cache_alignment` : 缓存地址对齐单位\n* `address sizes`   : 可访问地址空间位数\n* `power management`: 对能源管理的支持，有以下几个可选支持功能\n\n### /proc/meminfo \n```\n[root@cvs /]# cat /proc/meminfo \nMemTotal:       16282756 kB\nMemFree:         2012664 kB\nBuffers:          491980 kB\nCached:          5477644 kB\nSwapCached:       110344 kB\nActive:          9224100 kB\nInactive:        4478716 kB\nActive(anon):    6410680 kB\nInactive(anon):  1322576 kB\nActive(file):    2813420 kB\nInactive(file):  3156140 kB\nUnevictable:           0 kB\nMlocked:               0 kB\nSwapTotal:      10239992 kB\nSwapFree:        8921364 kB\nDirty:              1176 kB\nWriteback:             0 kB\nAnonPages:       7679964 kB\nMapped:            25344 kB\nShmem:                36 kB\nSlab:             328340 kB\nSReclaimable:     284284 kB\nSUnreclaim:        44056 kB\nKernelStack:        8504 kB\nPageTables:        27520 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:    18381368 kB\nCommitted_AS:   11103356 kB\nVmallocTotal:   34359738367 kB\nVmallocUsed:      307784 kB\nVmallocChunk:   34350792204 kB\nHardwareCorrupted:     0 kB\nAnonHugePages:   6842368 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nDirectMap4k:        5056 kB\nDirectMap2M:     2045952 kB\nDirectMap1G:    14680064 kB\n```\n* `MemTotal`: \n* `MemFree`:空闲内存\n* `Buffers`:给文件的缓冲大小\n* `Cached`: 高速缓冲存储器(http://baike.baidu.com/view/496990.htm)使用的大小\n* `SwapCached`: 被高速缓冲存储用的交换空间大小\n* `Active`: 活跃使用中的高速缓冲存储器页面文件大小\n* `Inactive`: 不经常使用的高速缓冲存储器页面文件大小\n* `Active(anon)`: \n* `Inactive(anon)`: \n* `Active(file)`: \n* `Inactive(file)`: \n* `Unevictable`:\n* `Mlocked`:\n* `SwapTotal`:交换空间总大小\n* `SwapFree`: 空闲交换空间\n* `Dirty`:等待被写回到磁盘的大小\n* `Writeback`:正在被写回的大小\n* `AnonPages`:未映射的页的大小\n* `Mapped`: 设备和文件映射的大小\n* `Shmem`:\n* `Slab`: 内核数据结构缓存的大小，可减少申请和释放内存带来的消耗\n* `SReclaimable`: 可收回slab的大小\n* `SUnreclaim`: 不可收回的slab的大小23204+14164=37368\n* `KernelStack`:\n* `PageTables`: 管理内存分页的索引表的大小\n* `NFS_Unstable`: 不稳定页表的大小\n* `Bounce`: bounce:退回\n* `WritebackTmp`: \n* `CommitLimit`:\n* `Committed_AS`: \n* `VmallocTotal`: 虚拟内存大小\n* `VmallocUsed`:已经被使用的虚拟内存大小\n* `VmallocChunk`: \n* `HardwareCorrupted`:\n* `AnonHugePages`:\n* `HugePages_Total`:大页面的分配\n* `HugePages_Free`: \n* `HugePages_Rsvd`: \n* `HugePages_Surp`: \n* `Hugepagesize`: \n* `DirectMap4k`:\n* `DirectMap2M`:\n* `DirectMap1G`:\n\n### /proc/net/dev\n```\n[root@cvs /]# cat /proc/net/dev\nInter-|   Receive                                                |  Transmit\n face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed\n    lo:365528559149 865504543    0    0    0     0          0         0 365528559149 865504543    0    0    0     0       0          0\n   em1:542483270223 575346473    0    0    0    62          0   8267561 580200919340 586706511    0    0    0     0       0          0\n   em2:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em3:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n   em4:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0\n```\n\nInter                                                     \n* `face`:接口的名字\n \nReceive\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`: \n* `frame`: \n* `compressed`: \n* `multicast`:\n\nTransmit\n* `bytes`: 收发的字节数   \n* `packets`: 收发正确的包量\n* `errs`: 收发错误的包量\n* `drop`: 收发丢弃的包量\n* `fifo`: \n* `colls`: \n* `carrier`: \n* `compressed`:\n\n\n![性能测评工具](https://raw.githubusercontent.com/ming15/blog-website/images/other/Linux%20%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%84%E5%B7%A5%E5%85%B7.jpg)\n![性能观测工具](https://raw.githubusercontent.com/ming15/blog-website/images/other/Linux%20%E6%80%A7%E8%83%BD%E8%A7%82%E6%B5%8B%E5%B7%A5%E5%85%B7.jpg)\n![性能调优工具](https://raw.githubusercontent.com/ming15/blog-website/images/other/Linux%20%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%B7%A5%E5%85%B7.jpg)\n![](https://github.com/ming15/blog-website/blob/images/other/Linux%20observability%20sar.jpg)\n\n## 其他小工具\n\n### nload\n可以分开来监控入站流量和出站流量\n\n### iftop\n可测量通过每一个套接字连接传输的数据\n\n### nethogs\n显示每个进程所使用的带宽\n\n### bmon\n一款类似nload的工具，它可以显示系统上所有网络接口的流量负载\n\n### speedometer\n绘制外观漂亮的图形，显示通过某个接口传输的入站流量和出站流量。\n\n### pktstat\n实时显示所有活动连接，并显示哪些数据通过这些活动连接传输的速度。它还可以显示连接类型，比如TCP连接或UDP连接；如果涉及HTTP连接，还会显示关于HTTP请求的详细信息。\n\n### dstat\n监控系统的不同统计信息，并使用批处理模式来报告，或者将相关数据记入到CSV或类似的文件\n","slug":"工具/linux命令","published":1,"updated":"2015-10-20T01:58:06.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsf001o0cufafthzbn1"},{"date":"2015-08-07T16:00:00.000Z","title":"IDEA缩进设置","_content":"\n![](https://github.com/wanggnim/blog-website/blob/images/other/idea_indent.jpg)\n* `Use tab character` : 如果勾选则使用tab缩进,否则使用空格缩进\n* `Tab size` : 每个tab占用几个空格. \n* `Indent` : 每个缩进占用几个空格. ","source":"_posts/工具/idea_indent.md","raw":"category: 工具\ndate: 2015-08-08\ntitle: IDEA缩进设置\n---\n\n![](https://github.com/wanggnim/blog-website/blob/images/other/idea_indent.jpg)\n* `Use tab character` : 如果勾选则使用tab缩进,否则使用空格缩进\n* `Tab size` : 每个tab占用几个空格. \n* `Indent` : 每个缩进占用几个空格. ","slug":"工具/idea_indent","published":1,"updated":"2015-10-14T01:54:12.273Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsh001q0cuftbe4c2hp"},{"date":"2014-09-07T16:00:00.000Z","title":"gitbook使用","_content":"# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n\n","source":"_posts/工具/gitbook.md","raw":"category: 工具\ndate: 2014-09-08\ntitle: gitbook使用\n---\n# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n\n","slug":"工具/gitbook","published":1,"updated":"2015-10-14T01:54:19.890Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsi001s0cuffjcdapmr"},{"date":"2015-04-07T16:00:00.000Z","title":"Dropwizard","_content":"\n# Setting Up Maven\n\n在MAVEN的dependency里添加`metrics-core`库\n```xml\n<dependencies>\n    <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics.version}</version>\n    </dependency>\n</dependencies>\n```\n注意，使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n# Meters\n\n`meter`表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, `meter`仍然会追踪`1-,5-,15-`分钟的移动平均数.\n```java\nprivate final Meter requests = metrics.meter(\"requests\");\n\npublic void handleRequest(Request request, Response response) {\n    requests.mark();\n    // etc\n}\n```\n上面的`meter`表示每秒请求数的比例。\n\n# Console Reporter\n\n`Console Reporter`正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次.\n```java\nConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n       .convertRatesTo(TimeUnit.SECONDS)\n       .convertDurationsTo(TimeUnit.MILLISECONDS)\n       .build();\n   reporter.start(1, TimeUnit.SECONDS);\n```\n\n# Complete getting started\n\n下面是一个完整的示例：\n```java\n  package sample;\n  import com.codahale.metrics.*;\n  import java.util.concurrent.TimeUnit;\n\n  public class GetStarted {\n    static final MetricRegistry metrics = new MetricRegistry();\n    public static void main(String args[]) {\n      startReport();\n      Meter requests = metrics.meter(\"requests\");\n      requests.mark();\n      wait5Seconds();\n    }\n\n  static void startReport() {\n      ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n          .convertRatesTo(TimeUnit.SECONDS)\n          .convertDurationsTo(TimeUnit.MILLISECONDS)\n          .build();\n      reporter.start(1, TimeUnit.SECONDS);\n  }\n\n  static void wait5Seconds() {\n      try {\n          Thread.sleep(5*1000);\n      }\n      catch(InterruptedException e) {}\n  }\n}\n```\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>somegroup</groupId>\n  <artifactId>sample</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <name>Example project for Metrics</name>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.dropwizard.metrics</groupId>\n      <artifactId>metrics-core</artifactId>\n      <version>${metrics.version}</version>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n注意：使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n```\nmvn package exec:java -Dexec.mainClass=sample.First\n```\n\n# The Registry\n\nMetrics的核心部分是`MetricRegistry`类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的`MetricRegistry`:\n```java\nfinal MetricRegistry metrics = new MetricRegistry();\n```\n如果你在应用程序中嵌入一个自己创建的`MetricRegistry`实例，你应该将这个属性置为静态的.\n\n# Gauges\n\n`gauge`表示的是一个瞬时值. 例如我们获取队列里待执行的任务数\n```xml\npublic class QueueManager {\n    private final Queue queue;\n\n    public QueueManager(MetricRegistry metrics, String name) {\n        this.queue = new Queue();\n        metrics.register(MetricRegistry.name(QueueManager.class, name, \"size\"),\n                         new Gauge<Integer>() {\n                             @Override\n                             public Integer getValue() {\n                                 return queue.size();\n                             }\n                         });\n    }\n}\n```\n当完成计算之后,它将会返回队列里的任务数。\n\n在`registry`里的每个`metric`都有一个唯一的名字,其命名规范为用`.`分割的字符串,例如`things.count`或者`com.example.Thing.latency`. `MetricRegistry`类提供了一个静态方法来构建这些名字.\n```xml\nMetricRegistry.name(QueueManager.class, \"jobs\", \"size\")\n```\n上面的调用会返回`com.example.QueueManager.jobs.size`。\n\n对于大多数队列或者类队列结构,你也许仅想要获得`queue.size()`这个值. 大多数`java.util`和`java.util.concurrent`包都实现了`size()`方法,它的复杂度是`O(n)`,这意味着你的`gauge`也许会很慢(也许还会持有锁)\n\n# Counters\n\n`counter`是一个内部采用`AtomicLong`计数器的`gauge`实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式:\n```xml\nprivate final Counter pendingJobs = metrics.counter(name(QueueManager.class, \"pending-jobs\"));\n\npublic void addJob(Job job) {\n    pendingJobs.inc();\n    queue.offer(job);\n}\n\npublic Job takeJob() {\n    pendingJobs.dec();\n    return queue.take();\n}\n```\n每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数.\n\n正如你看到的,counter的API是非常不同的是,`counter(String)`取代了`register(String, Metric)`，然而你可以仍然可以使用`register`方法创建你自己的`Counter`实例,实际上`counter(String)`在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用\n\n还需要说明一点,在上例中,我们静态引入了`MetricRegistry`的`name`方法.\n\n# Histograms\n\n`histogram`表示的是流中数据值的静态分布. 除了计算`minimum, maximum, mean, etc`等值,它还计算中间值或者`75th, 90th, 95th, 98th, 99th, 99.9th`等百分比.\n```xml\nprivate final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, \"response-sizes\"));\n\npublic void handleRequest(Request request, Response response) {\n    // etc\n    responseSizes.update(response.getContent().length);\n}\n```\n上面的`histogram`统计了响应中的字节数.\n\n# Timers\n`timer`可以计算某个代码段的调用比例,和调用期间的分布状况.\n```xml\nprivate final Timer responses = metrics.timer(name(RequestHandler.class, \"responses\"));\n\npublic String handleRequest(Request request, Response response) {\n    final Timer.Context context = responses.time();\n    try {\n        // etc;\n        return \"OK\";\n    } finally {\n        context.stop();\n    }\n}\n```\nThis timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second.\n\n\n# Health Checks\n\nMetrics还可以通过`metrics-healthchecks`模块集中检查你的服务的健康.\n\n首先创建一个新的`HealthCheckRegistry`实例\n```xml\nfinal HealthCheckRegistry healthChecks = new HealthCheckRegistry();\nSecond, implement a HealthCheck subclass:\n\npublic class DatabaseHealthCheck extends HealthCheck {\n    private final Database database;\n\n    public DatabaseHealthCheck(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public HealthCheck.Result check() throws Exception {\n        if (database.isConnected()) {\n            return HealthCheck.Result.healthy();\n        } else {\n            return HealthCheck.Result.unhealthy(\"Cannot connect to \" + database.getUrl());\n        }\n    }\n}\n```\n然后将Metrics注册到它身上：\n```xml\nhealthChecks.register(\"postgres\", new DatabaseHealthCheck(database));\n```\n接下来运行所有的health checks:\n```xml\nfinal Map<String, HealthCheck.Resultresults = healthChecks.runHealthChecks();\nfor (Entry<String, HealthCheck.Resultentry : results.entrySet()) {\n    if (entry.getValue().isHealthy()) {\n        System.out.println(entry.getKey() + \" is healthy\");\n    } else {\n        System.err.println(entry.getKey() + \" is UNHEALTHY: \" + entry.getValue().getMessage());\n        final Throwable e = entry.getValue().getError();\n        if (e != null) {\n            e.printStackTrace();\n        }\n    }\n}\n```\nMetrics内置了一种health check：`ThreadDeadlockHealthCheck`,它使用了java内置的线程死锁检测来查找死锁线程.\n\n# Reporting Via JMX\n\n通过`JMX`报告metrics：\n```xml\nfinal JmxReporter reporter = JmxReporter.forRegistry(registry).build();\nreporter.start();\n```\n一旦reporter启动了,registry中的所有的metrics都可以通过`JConsole`或者`VisualVM`看到.\n\nMetrics被包装成`JMX MBeans`,可以在`VisualVM's MBeans browser`查看`Metrics`.\n\n注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你.\n\n# Reporting Via HTTP\n\nMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告`health checks`,打印`thread dump`,或者提供一个负载均衡的简单响应. (它还提供了其他的`servlets–MetricsServlet`,例如`HealthCheckServlet, ThreadDumpServlet`或者`PingServlet`.)\n\n如果想要使用servlet你必须在pom文件中依赖`metrics-servlets`.\n```xml\n<dependency>\n    <groupId>io.dropwizard.metrics</groupId>\n    <artifactId>metrics-servlets</artifactId>\n    <version>${metrics.version}</version>\n</dependency>\n```\n\n# Other Reporting\n\n除了`JMX`和`HTTP`以外,Metrics还提供了下面的报告方式\n\n* `STDOUT`: 使用`metrics-core`的`ConsoleReporter`报告\n* `CSV files`, 使用`metrics-core`的`CsvReporter`报告\n* `SLF4J loggers`, 使用`metrics-core`的`Slf4jReporter`报告\n* `Ganglia`, 使用`metrics-ganglia`的`GangliaReporter`报告\n* `Graphite`, 使用`metrics-graphite`的`GraphiteReporter`报告 ","source":"_posts/工具/dropwizard.md","raw":"category: 工具\ndate: 2015-04-08\ntitle: Dropwizard\n---\n\n# Setting Up Maven\n\n在MAVEN的dependency里添加`metrics-core`库\n```xml\n<dependencies>\n    <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics.version}</version>\n    </dependency>\n</dependencies>\n```\n注意，使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n# Meters\n\n`meter`表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, `meter`仍然会追踪`1-,5-,15-`分钟的移动平均数.\n```java\nprivate final Meter requests = metrics.meter(\"requests\");\n\npublic void handleRequest(Request request, Response response) {\n    requests.mark();\n    // etc\n}\n```\n上面的`meter`表示每秒请求数的比例。\n\n# Console Reporter\n\n`Console Reporter`正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次.\n```java\nConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n       .convertRatesTo(TimeUnit.SECONDS)\n       .convertDurationsTo(TimeUnit.MILLISECONDS)\n       .build();\n   reporter.start(1, TimeUnit.SECONDS);\n```\n\n# Complete getting started\n\n下面是一个完整的示例：\n```java\n  package sample;\n  import com.codahale.metrics.*;\n  import java.util.concurrent.TimeUnit;\n\n  public class GetStarted {\n    static final MetricRegistry metrics = new MetricRegistry();\n    public static void main(String args[]) {\n      startReport();\n      Meter requests = metrics.meter(\"requests\");\n      requests.mark();\n      wait5Seconds();\n    }\n\n  static void startReport() {\n      ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n          .convertRatesTo(TimeUnit.SECONDS)\n          .convertDurationsTo(TimeUnit.MILLISECONDS)\n          .build();\n      reporter.start(1, TimeUnit.SECONDS);\n  }\n\n  static void wait5Seconds() {\n      try {\n          Thread.sleep(5*1000);\n      }\n      catch(InterruptedException e) {}\n  }\n}\n```\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>somegroup</groupId>\n  <artifactId>sample</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <name>Example project for Metrics</name>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.dropwizard.metrics</groupId>\n      <artifactId>metrics-core</artifactId>\n      <version>${metrics.version}</version>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n注意：使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n```\nmvn package exec:java -Dexec.mainClass=sample.First\n```\n\n# The Registry\n\nMetrics的核心部分是`MetricRegistry`类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的`MetricRegistry`:\n```java\nfinal MetricRegistry metrics = new MetricRegistry();\n```\n如果你在应用程序中嵌入一个自己创建的`MetricRegistry`实例，你应该将这个属性置为静态的.\n\n# Gauges\n\n`gauge`表示的是一个瞬时值. 例如我们获取队列里待执行的任务数\n```xml\npublic class QueueManager {\n    private final Queue queue;\n\n    public QueueManager(MetricRegistry metrics, String name) {\n        this.queue = new Queue();\n        metrics.register(MetricRegistry.name(QueueManager.class, name, \"size\"),\n                         new Gauge<Integer>() {\n                             @Override\n                             public Integer getValue() {\n                                 return queue.size();\n                             }\n                         });\n    }\n}\n```\n当完成计算之后,它将会返回队列里的任务数。\n\n在`registry`里的每个`metric`都有一个唯一的名字,其命名规范为用`.`分割的字符串,例如`things.count`或者`com.example.Thing.latency`. `MetricRegistry`类提供了一个静态方法来构建这些名字.\n```xml\nMetricRegistry.name(QueueManager.class, \"jobs\", \"size\")\n```\n上面的调用会返回`com.example.QueueManager.jobs.size`。\n\n对于大多数队列或者类队列结构,你也许仅想要获得`queue.size()`这个值. 大多数`java.util`和`java.util.concurrent`包都实现了`size()`方法,它的复杂度是`O(n)`,这意味着你的`gauge`也许会很慢(也许还会持有锁)\n\n# Counters\n\n`counter`是一个内部采用`AtomicLong`计数器的`gauge`实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式:\n```xml\nprivate final Counter pendingJobs = metrics.counter(name(QueueManager.class, \"pending-jobs\"));\n\npublic void addJob(Job job) {\n    pendingJobs.inc();\n    queue.offer(job);\n}\n\npublic Job takeJob() {\n    pendingJobs.dec();\n    return queue.take();\n}\n```\n每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数.\n\n正如你看到的,counter的API是非常不同的是,`counter(String)`取代了`register(String, Metric)`，然而你可以仍然可以使用`register`方法创建你自己的`Counter`实例,实际上`counter(String)`在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用\n\n还需要说明一点,在上例中,我们静态引入了`MetricRegistry`的`name`方法.\n\n# Histograms\n\n`histogram`表示的是流中数据值的静态分布. 除了计算`minimum, maximum, mean, etc`等值,它还计算中间值或者`75th, 90th, 95th, 98th, 99th, 99.9th`等百分比.\n```xml\nprivate final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, \"response-sizes\"));\n\npublic void handleRequest(Request request, Response response) {\n    // etc\n    responseSizes.update(response.getContent().length);\n}\n```\n上面的`histogram`统计了响应中的字节数.\n\n# Timers\n`timer`可以计算某个代码段的调用比例,和调用期间的分布状况.\n```xml\nprivate final Timer responses = metrics.timer(name(RequestHandler.class, \"responses\"));\n\npublic String handleRequest(Request request, Response response) {\n    final Timer.Context context = responses.time();\n    try {\n        // etc;\n        return \"OK\";\n    } finally {\n        context.stop();\n    }\n}\n```\nThis timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second.\n\n\n# Health Checks\n\nMetrics还可以通过`metrics-healthchecks`模块集中检查你的服务的健康.\n\n首先创建一个新的`HealthCheckRegistry`实例\n```xml\nfinal HealthCheckRegistry healthChecks = new HealthCheckRegistry();\nSecond, implement a HealthCheck subclass:\n\npublic class DatabaseHealthCheck extends HealthCheck {\n    private final Database database;\n\n    public DatabaseHealthCheck(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public HealthCheck.Result check() throws Exception {\n        if (database.isConnected()) {\n            return HealthCheck.Result.healthy();\n        } else {\n            return HealthCheck.Result.unhealthy(\"Cannot connect to \" + database.getUrl());\n        }\n    }\n}\n```\n然后将Metrics注册到它身上：\n```xml\nhealthChecks.register(\"postgres\", new DatabaseHealthCheck(database));\n```\n接下来运行所有的health checks:\n```xml\nfinal Map<String, HealthCheck.Resultresults = healthChecks.runHealthChecks();\nfor (Entry<String, HealthCheck.Resultentry : results.entrySet()) {\n    if (entry.getValue().isHealthy()) {\n        System.out.println(entry.getKey() + \" is healthy\");\n    } else {\n        System.err.println(entry.getKey() + \" is UNHEALTHY: \" + entry.getValue().getMessage());\n        final Throwable e = entry.getValue().getError();\n        if (e != null) {\n            e.printStackTrace();\n        }\n    }\n}\n```\nMetrics内置了一种health check：`ThreadDeadlockHealthCheck`,它使用了java内置的线程死锁检测来查找死锁线程.\n\n# Reporting Via JMX\n\n通过`JMX`报告metrics：\n```xml\nfinal JmxReporter reporter = JmxReporter.forRegistry(registry).build();\nreporter.start();\n```\n一旦reporter启动了,registry中的所有的metrics都可以通过`JConsole`或者`VisualVM`看到.\n\nMetrics被包装成`JMX MBeans`,可以在`VisualVM's MBeans browser`查看`Metrics`.\n\n注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你.\n\n# Reporting Via HTTP\n\nMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告`health checks`,打印`thread dump`,或者提供一个负载均衡的简单响应. (它还提供了其他的`servlets–MetricsServlet`,例如`HealthCheckServlet, ThreadDumpServlet`或者`PingServlet`.)\n\n如果想要使用servlet你必须在pom文件中依赖`metrics-servlets`.\n```xml\n<dependency>\n    <groupId>io.dropwizard.metrics</groupId>\n    <artifactId>metrics-servlets</artifactId>\n    <version>${metrics.version}</version>\n</dependency>\n```\n\n# Other Reporting\n\n除了`JMX`和`HTTP`以外,Metrics还提供了下面的报告方式\n\n* `STDOUT`: 使用`metrics-core`的`ConsoleReporter`报告\n* `CSV files`, 使用`metrics-core`的`CsvReporter`报告\n* `SLF4J loggers`, 使用`metrics-core`的`Slf4jReporter`报告\n* `Ganglia`, 使用`metrics-ganglia`的`GangliaReporter`报告\n* `Graphite`, 使用`metrics-graphite`的`GraphiteReporter`报告 ","slug":"工具/dropwizard","published":1,"updated":"2015-10-16T02:38:40.084Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsk001u0cuf4yu3nnup"},{"date":"2015-06-07T16:00:00.000Z","title":"docker命令","_content":"## Docker命令\n#### `service docker start`  \n安装之后启动 Docker 服务.\n\n#### `docker pull` \n命令来从仓库获取所需要的镜像\n```\ndocker pull ubuntu12.04\n```\n\n#### `docker push` \n把自己创建的镜像上传到仓库中来共享\n```\ndocker push ouruser/sinatra\n```\n\n#### `docker images` \n显示本地已有的镜像.\n\n#### `docker commit` \n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n#### `docker build` \n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n#### `docker tag` \n命令来修改镜像的标签.\n```\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n#### `docker import` \n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n#### `docker save` \n导出镜像到本地文件\n```\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n#### `docker load` \n从导出的本地文件中再导入到本地镜像库 \n```\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n#### `docker rmi` \n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```\nsudo docker rmi training/sinatra\n```\n\n#### `docker run`  \n基于镜像新建一个容器并启动\n```\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n###### 映射所有接口地址\n使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n###### 此时默认会绑定本地所有接口上的所有地址。\n映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n##### 映射到指定地址的任意端口\n使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n#### `docker start` \n直接将一个已经终止的容器启动运行\n\n#### `docker stop` \n终止一个运行中的容器.\n\n#### `docker restart` \n将一个运行态的容器终止,然后再重新启动它.\n\n#### `docker attach` \n进入容器\n\n#### `docker export ` \n导出本地某个容器\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n#### `docker import` \n从容器快照文件中再导入为镜像\n```\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n#### `docker rm` \n移除容器.删除一个处于终止状态的容器\n```\ndocker rm  trusting_newton\n```\n\n#### `docker search` \n查找官方仓库中的镜像\n\n#### `docker ps` \n\n#### `docker logs` \n获取容器的输出信息\n```\ndocker logs insane_babbage\n```\n\n#### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile \n\nDockerfile中每一条指令都创建镜像的一层,例如\n```\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n##### 当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n##### `docker load` vs `docker import`\n用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n\n","source":"_posts/工具/docker命令.md","raw":"category: 工具\ndate: 2015-06-08\ntitle: docker命令\n---\n## Docker命令\n#### `service docker start`  \n安装之后启动 Docker 服务.\n\n#### `docker pull` \n命令来从仓库获取所需要的镜像\n```\ndocker pull ubuntu12.04\n```\n\n#### `docker push` \n把自己创建的镜像上传到仓库中来共享\n```\ndocker push ouruser/sinatra\n```\n\n#### `docker images` \n显示本地已有的镜像.\n\n#### `docker commit` \n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n#### `docker build` \n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n#### `docker tag` \n命令来修改镜像的标签.\n```\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n#### `docker import` \n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n#### `docker save` \n导出镜像到本地文件\n```\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n#### `docker load` \n从导出的本地文件中再导入到本地镜像库 \n```\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n#### `docker rmi` \n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```\nsudo docker rmi training/sinatra\n```\n\n#### `docker run`  \n基于镜像新建一个容器并启动\n```\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n###### 映射所有接口地址\n使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n###### 此时默认会绑定本地所有接口上的所有地址。\n映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n##### 映射到指定地址的任意端口\n使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n#### `docker start` \n直接将一个已经终止的容器启动运行\n\n#### `docker stop` \n终止一个运行中的容器.\n\n#### `docker restart` \n将一个运行态的容器终止,然后再重新启动它.\n\n#### `docker attach` \n进入容器\n\n#### `docker export ` \n导出本地某个容器\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n#### `docker import` \n从容器快照文件中再导入为镜像\n```\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n#### `docker rm` \n移除容器.删除一个处于终止状态的容器\n```\ndocker rm  trusting_newton\n```\n\n#### `docker search` \n查找官方仓库中的镜像\n\n#### `docker ps` \n\n#### `docker logs` \n获取容器的输出信息\n```\ndocker logs insane_babbage\n```\n\n#### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile \n\nDockerfile中每一条指令都创建镜像的一层,例如\n```\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n##### 当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n##### `docker load` vs `docker import`\n用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n\n","slug":"工具/docker命令","published":1,"updated":"2015-10-14T01:54:36.338Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsm001w0cufmvzxthqr"},{"date":"2015-03-07T16:00:00.000Z","title":"MongoDB","_content":"# Run MongoDB\n\n## Run MongoDB On Windows\n如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见.\n\n### 设置MOngoDB环境\n\n#### 设置环境变量\n在环境变量里添加环境变量 `D:\\Program Files\\MongoDB\\Server\\3.0\\` 然后在Path里添加： `%MONGODB_HOME%\\bin`\n\n#### data directory\n```\nMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是\\data\\db, \n所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: D:\\mongodb\\data\\db.\n\n你可以通过--dbpath选项给mongod.exe设置另一个data directory.\nmongod.exe --dbpath D:\\mongodb\\data\\db\n\n如果你的data directory包含空格的话,那么就需要使用\"\"将他们包含起来：\nmongod.exe --dbpath \"d:\\test\\mongo db data\"\n```\n\n## 启动MongoDB\n\n### 使用mongod.exe命令启动mongoDB\n```\n\tmongod.exe\n```\n\n### 启动日志\n最后我们在启动日志里看到\n```\nwaiting for connections on port 27017\n```\n\n### 命令行方式启动\n\nMongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017.\n```\nmongod --dbpath=/data/db\n```\n\n### 配置文件方式启动\nMongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下:\n```\ncat /etc/mongodb.cnf\n```\n启动时加上”-f”参数,并指向配置文件即可:\n```\nmongod -f /etc/mongodb.cnf\n```\n\n#### Daemon 方式启动\nMongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” --fork”参数即可,,但如果用到了 ” --fork”参数就必须也启用 ”--logpath”参数,这是强制的\n```\nmongod --dbpath=/data/db --logpath=/data/log/r3.log --fork\n```\n\n#### mongod 参数说明\nmongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数\n\nmongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,\nmmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经\n有了一定程度的改善.\n\n##### mongod 的主要参数有：\n* dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中.\n* logpath —— 错误日志文件\n* logappend —— 错误日志采用追加模式（默认是覆写模式）\n* bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定\n* port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000\n* fork —— 以后台 Daemon 形式运行服务\n* journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数.\n* syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒.\n* directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似\n* maxConns —— 最大连接数\n* repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作.\n\n## 停止数据库\n\n* Control-C\n* shutdownServer()指令\n```\nmongo --port 28013\nuse admin\ndb.shutdownServer()\n```\n\n## 常用工具集\nMongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上的方便。\n* bsondump: 将 bson 格式的文件转储为 json 格式的数据\n* mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法\n* mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行\n* mongodump/ mongorestore: 数据库备份和恢复工具\n* mongoexport/ mongoimport: 数据导出和导入工具\n* mongofiles: GridFS 管理工具,可实现二制文件的存取\n* mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod\n* mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出\n* mongostat: 实时性能监控工具\n\n## 部署 Replica Sets\n* 创建数据文件存储路径\n```\nmkdir E:/mongoData/data/r0\nmkdir E:/mongoData/data/r1\nmkdir E:/mongoData/data/r2\n```\n* 创建日志文件路径\n```\nmkdir E:/mongoData/log\n```\n* 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。\n```\nmkdir E:/mongoData/key\necho \"this is rs1 super secret key\" > E:/mongoData/key/r0\necho \"this is rs1 super secret key\" > E:/mongoData/key/r1\necho \"this is rs1 super secret key\" > E:/mongoData/key/r2\n```\n* 启动 3 个实例\n```\nmongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend\n```\n* 配置及初始化 Replica Sets\n```\nmongo -port 28010\n```\n\n\n# Introduction\n\n## A Quick Tour\n\n使用java 驱动开发是非常简单的,首先你要确保你的`classpath`中包含`mongo.jar`\n\n### Making a Connection\n\n为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库\n\n另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地`mydb`数据库的方式\n```java\nimport com.mongodb.BasicDBObject;\nimport com.mongodb.BulkWriteOperation;\nimport com.mongodb.BulkWriteResult;\nimport com.mongodb.Cursor;\nimport com.mongodb.DB;\nimport com.mongodb.DBCollection;\nimport com.mongodb.DBCursor;\nimport com.mongodb.DBObject;\nimport com.mongodb.MongoClient;\nimport com.mongodb.ParallelScanOptions;\nimport com.mongodb.ServerAddress;\n\nimport java.util.List;\nimport java.util.Set;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\n// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even\n// if it's a member of a replica set:\nMongoClient mongoClient = new MongoClient();\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" );\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" , 27017 );\n// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of members\nMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(\"localhost\", 27017),\n                                      new ServerAddress(\"localhost\", 27018),\n                                      new ServerAddress(\"localhost\", 27019)));\n\nDB db = mongoClient.getDB( \"mydb\" );\n```\n\n在这个例子中`db`对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作\n\n> Note:\n>\n> `MongoClient`实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个`MongoClient`实例, 参考[concurrency doc page]()\n\n\n`MongoClient`被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个`MongoClient`实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个`MongoClient`实例,那么你需要注意下面俩点：\n\n* all resource usage limits (max connections, etc) apply per MongoClient instance\n* 当关闭一个实例时,你必须确保你调用了`MongoClient.close()`清理掉了全部的资源\n\nNew in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead.\n\n### Authentication (Optional)\n\nMongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建`MongoClient`实例时提供一下证书.\n```java\nMongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);\nMongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential));\n```\n\nMongoDB支持不同的认证机制,具体参考[the access control tutorials]()\n\n### Getting a Collection\n\n如果想要使用一个collection,那么你仅仅需要调用`getCollection(String collectionName)`方法,然后指定该collection名称就好\n\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\n```\n\n一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了\n\n### Setting Write Concern\n\n在2.10.0这个版本里,默认的write concern是`WriteConcern.ACKNOWLEDGED`不过你可以通过下面的方法轻松改变它\n```java\nmongoClient.setWriteConcern(WriteConcern.JOURNALED);\n```\n\n对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载.\n\n\n### Inserting a Document\n\n一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档\n```json\n{\n   \"name\" : \"MongoDB\",\n   \"type\" : \"database\",\n   \"count\" : 1,\n   \"info\" : {\n               x : 203,\n               y : 102\n             }\n}\n```\n\n注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用`BasicDBObject`类来实现：\n```java\nBasicDBObject doc = new BasicDBObject(\"name\", \"MongoDB\")\n        .append(\"type\", \"database\")\n        .append(\"count\", 1)\n        .append(\"info\", new BasicDBObject(\"x\", 203).append(\"y\", 102));\ncoll.insert(doc);\n```\n\n\n### findOne()\n\n如果想要查看刚才插入的文档,我们可以简单地调用`findOne()`,这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而`find()`会返回一个`DBCursor`对象),当collection中只有一个文档的时候,这是非常有用的.\n```java\nDBObject myDoc = coll.findOne();\nSystem.out.println(myDoc);\n```\n结果如下：\n```json\n{ \"_id\" : \"49902cde5162504500b45c2c\" ,\n  \"name\" : \"MongoDB\" ,\n  \"type\" : \"database\" ,\n  \"count\" : 1 ,\n  \"info\" : { \"x\" : 203 , \"y\" : 102}}\n\n```\n\n>Note:\n>\n> `_id`元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称\n\n### Adding Multiple Documents\n\n当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中.\n```json\n{\n   \"i\" : value\n}\n```\n\n我们可以在一个循环中不断地插入数据\n```java\nfor (int i=0; i < 100; i++) {\n    coll.insert(new BasicDBObject(\"i\", i));\n}\n```\n\n注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为`schema-free`\n\n### Counting Documents in A Collection\n\n通过以上的操作我们已经插入了101个文档,我们通过`getCount()`方法来检查一下.\n```java\nSystem.out.println(coll.getCount());\n```\n\n### Using a Cursor to Get All the Documents\n\n如果想要获得collection中的全部文档,我们可以使用`find()`方法. `find()`返回一个`DBCursor`对象,我们可以通过遍历该对象获取所有匹配我们需求的文档.\n```java\nDBCursor cursor = coll.find();\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n### Getting A Single Document with A Query\n\n我们可以向`find()`方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档.\n```java\nBasicDBObject query = new BasicDBObject(\"i\", 71);\n\ncursor = coll.find(query);\n\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n该代码只会输出一个文档\n```json\n{ \"_id\" : \"49903677516250c1008d624e\" , \"i\" : 71 }\n```\n\n你也可以从其他的实例和文档中查看`$`操作符的用法：\n```java\ndb.things.find({j: {$ne: 3}, k: {$gt: 10} });\n```\n\n使用内嵌的`DBObject`,`$`可以看作是正则表达式字串\n``` java\nquery = new BasicDBObject(\"j\", new BasicDBObject(\"$ne\", 3))\n        .append(\"k\", new BasicDBObject(\"$gt\", 10));\n\ncursor = coll.find(query);\n\ntry {\n    while(cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### Getting A Set of Documents With a Query\n\n我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i > 50的文档\n```java\n// find all where i > 50\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 50));\n\ncursor = coll.find(query);\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n我们还可以获得一个区间(20 < i <= 30)文档集合\n```java\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 20).append(\"$lte\", 30));\ncursor = coll.find(query);\n\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### MaxTime\n\nMongoDB2.6 添加查询超时的能力\n\n```java\ncoll.find().maxTime(1, SECONDS).count();\n```\n\n在上面的例子中将`maxTime`设置为1s,当时间到后查询将被打断\n\n### Bulk operations\n\nUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations:\n\n1. Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出\n2. Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行\n\n下面展示了上面所说的俩个示例\n```java\n// 1. Ordered bulk operation\nBulkWriteOperation builder = coll.initializeOrderedBulkOperation();\nbuilder.insert(new BasicDBObject(\"_id\", 1));\nbuilder.insert(new BasicDBObject(\"_id\", 2));\nbuilder.insert(new BasicDBObject(\"_id\", 3));\n\nbuilder.find(new BasicDBObject(\"_id\", 1)).updateOne(new BasicDBObject(\"$set\", new BasicDBObject(\"x\", 2)));\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 3)).replaceOne(new BasicDBObject(\"_id\", 3).append(\"x\", 4));\n\nBulkWriteResult result = builder.execute();\n\n// 2. Unordered bulk operation - no guarantee of order of operation\nbuilder = coll.initializeUnorderedBulkOperation();\nbuilder.find(new BasicDBObject(\"_id\", 1)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\n\nresult = builder.execute();\n```\n\n\n> Note:\n> \nFor servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers.\n\n\n### parallelScan\n\nMongoDB 2.6 增加了`parallelCollectionScan`命令, 该命令通过使用多个游标读取整个collection.\n```java\nParallelScanOptions parallelScanOptions = ParallelScanOptions\n        .builder()\n        .numCursors(3)\n        .batchSize(300)\n        .build();\n\nList<Cursor> cursors = coll.parallelScan(parallelScanOptions);\nfor (Cursor pCursor: cursors) {\n    while (pCursor.hasNext()) {\n        System.out.println((pCursor.next()));\n    }\n}\n```\n\n其对collection进行IO吞吐量的优化.\n\n> Note:\n>\n> `ParallelScan`不能通过`mongos`运行\n\n## Quick Tour of the Administrative Functions\n\n### Getting A List of Databases\n\n通过下面的代码你可以获取一个可用数据库列表\n```java\nMongoClient mongoClient = new MongoClient();\n\nfor (String s : mongoClient.getDatabaseNames()) {\n   System.out.println(s);\n}\n```\n\n调用`mongoClient.getDB()`并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档.\n\n### Dropping A Database\n\n通过`MongoClient`实例你也可以`drop`掉一个数据库\n```java\nMongoClient mongoClient = new MongoClient();\nmongoClient.dropDatabase(\"databaseToBeDropped\");\n```\n\n### Creating A Collection\n\n有俩种方式创建collection：\n1. 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来\n2. 或者直接调用`createCollection`命令\n\n下面的例子展示了创建1M大小的collection\n```java\ndb = mongoClient.getDB(\"mydb\");\ndb.createCollection(\"testCollection\", new BasicDBObject(\"capped\", true)\n        .append(\"size\", 1048576));\n```\n\n### Getting A List of Collections\n\n你可以通过下面的方式获得一个数据库当中可用collection列表\n```java\nfor (String s : db.getCollectionNames()) {\n   System.out.println(s);\n}\n```\n\n上面的例子会输出：\n```\nsystem.indexes\ntestCollection\n```\n\n>Note:\n>\n> `system.indexes` collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它\n\n### Dropping A Collection\n\n你可以通过`drop()`方法直接drop掉一个collection\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\ncoll.drop();\nSystem.out.println(db.getCollectionNames());\n```\n\n### Getting a List of Indexes on a Collection\n\n下例展示了如何获得一个collection中索引的列表\n```java\nList<DBObject> list = coll.getIndexInfo();\n\nfor (DBObject o : list) {\n   System.out.println(o.get(\"key\"));\n}\n```\n\n上面的实例会进行下面的输出：\n```json\n{ \"v\" : 1 , \"key\" : { \"_id\" : 1} , \"name\" : \"_id_\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"i\" : 1} , \"name\" : \"i_1\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"loc\" : \"2dsphere\"} , \"name\" : \"loc_2dsphere\" , ... }\n{ \"v\" : 1 , \"key\" : { \"_fts\" : \"text\" , \"_ftsx\" : 1} , \"name\" : \"content_text\" , ... }\n```\n\n\n### Creating An Index\n\nMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1).\n```java\ncoll.createIndex(new BasicDBObject(\"i\", 1));  // create index on \"i\", ascending\n```\n\n\n### Geo indexes\n\nMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个`2dsphere`索引, 我们可以通过标准`GeoJson`标记进行查询. 想要创建一个`2dsphere`索引,我们需要在索引文档中指定`2dsphere`这个字面量.\n```java\ncoll.createIndex(new BasicDBObject(\"loc\", \"2dsphere\"));\n```\n\n有不同的方式去查询`2dsphere`索引,下面的例子中找到了500m以内的位置.\n```java\nBasicDBList coordinates = new BasicDBList();\ncoordinates.put(0, -73.97);\ncoordinates.put(1, 40.77);\ncoll.insert(new BasicDBObject(\"name\", \"Central Park\")\n                .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n                .append(\"category\", \"Parks\"));\n\ncoordinates.put(0, -73.88);\ncoordinates.put(1, 40.78);\ncoll.insert(new BasicDBObject(\"name\", \"La Guardia Airport\")\n        .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n        .append(\"category\", \"Airport\"));\n\n\n// Find whats within 500m of my location\nBasicDBList myLocation = new BasicDBList();\nmyLocation.put(0, -73.965);\nmyLocation.put(1, 40.769);\nmyDoc = coll.findOne(\n            new BasicDBObject(\"loc\",\n                new BasicDBObject(\"$near\",\n                        new BasicDBObject(\"$geometry\",\n                                new BasicDBObject(\"type\", \"Point\")\n                                    .append(\"coordinates\", myLocation))\n                             .append(\"$maxDistance\",  500)\n                        )\n                )\n            );\nSystem.out.println(myDoc.get(\"name\"));\n```\n\n更多参考[geospatial]()文档\n\n### Text indexes\n\nMongoDB还支持`text`索引,该索引用来支持从String中搜索文本. `text`索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个`text`索引,只需要在索引文档中指定`text`字面量.\n```java\n// create a text index on the \"content\" field\ncoll.createIndex(new BasicDBObject(\"content\", \"text\"));\n```\n\nMongoDB2.6 以后`text`索引融进了主要的查询语言中,并且成为了一种默认的方式.\n```java\n// Insert some documents\ncoll.insert(new BasicDBObject(\"_id\", 0).append(\"content\", \"textual content\"));\ncoll.insert(new BasicDBObject(\"_id\", 1).append(\"content\", \"additional content\"));\ncoll.insert(new BasicDBObject(\"_id\", 2).append(\"content\", \"irrelevant content\"));\n\n// Find using the text index\nBasicDBObject search = new BasicDBObject(\"$search\", \"textual content -irrelevant\");\nBasicDBObject textSearch = new BasicDBObject(\"$text\", search);\nint matchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches: \"+ matchCount);\n\n// Find using the $language operator\ntextSearch = new BasicDBObject(\"$text\", search.append(\"$language\", \"english\"));\nmatchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches (english): \"+ matchCount);\n\n// Find the highest scoring match\nBasicDBObject projection = new BasicDBObject(\"score\", new BasicDBObject(\"$meta\", \"textScore\"));\nmyDoc = coll.findOne(textSearch, projection);\nSystem.out.println(\"Highest scoring document: \"+ myDoc);\n```\n\n上面的代码应该输出：\n```java\nText search matches: 2\nText search matches (english): 2\nHighest scoring document: { \"_id\" : 1 , \"content\" : \"additional content\" , \"score\" : 0.75}\n```\n\n更多关于text search,参考[text index and $text query operator]()\n\n# Replica\n# Deploy a Replica Set\n\n这篇教程讲述的是如何基于正在运行的不进行控制访问的`mongod`创建三个`replica set`.\n\n如果想要创建带有控制访问功能的`replica set`,参考[Deploy Replica Set and Configure Authentication and Authorization](http://docs.mongodb.org/manual/tutorial/deploy-replica-set-with-auth/). 如果你想要在一个单独的MongoDB上部署`replica set`, 可以参考[Convert a Standalone to a Replica Set](http://docs.mongodb.org/manual/tutorial/convert-standalone-to-replica-set/). 关于更多的`replica set`部署信息,参考[Replication](http://docs.mongodb.org/manual/replication/)和[Replica Set Deployment Architectures](http://docs.mongodb.org/manual/core/replica-set-architectures/)\n\n## Overview\n\n带有三个成员的`replica sets`就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. `Replica sets`应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的[elections](http://docs.mongodb.org/manual/core/replica-set-elections/). 更多关于对`replica sets`的设计,参考[Replication overview](http://docs.mongodb.org/manual/core/replication-introduction/)\n\n基本的步骤是: 首先启动要成为`replica set`成员的`mongod`, 然后配置`replica set`, 最后将`mongod`添加到`replica set`上.\n\n## Requirements\n\n在生产部署阶段, 你应该尽量在不同的主机上部署代理`mongod`的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个'mongod'.\n\n在你创建`replica set`之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的`replica set`部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考[Test Connections Between all Members](http://docs.mongodb.org/manual/tutorial/troubleshoot-replica-sets/#replica-set-troubleshooting-check-connection)\n\n## Considerations When Deploying a Replica Set\n\n### Architecture\n\n在生产阶段, 将`replica set`和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用`bind_ip`选项确保MongoDB会根据配置好的地址监听来自应用程序的连接.\n\n如果`replica set`在不同的机房内部署, 那么应该确保大多数的`mongod`实例部署在第一站点上.参考[Replica Set Deployment Architectures]()\n\n### Connectivity\n\n确保网络中所有的`replica set`成员和客户端的流量能够安全和高效地传输:\n\n* 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量.\n* 配置访问控制能够阻止未知的客户端连接到 `replica set`上\n* 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上.\n\n最终确保`replica set`中每个成员都可以通过可解析的`DNS`或者`hostname`访问到. 你应该恰当地设置上`DNS`名称或者通过`/etc/hosts`文件来映射这个配置\n\n### Configuration\nSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB.\n\nFor more information about the run time options used above and other configuration options, see Configuration File Options.\n\n## Procedure\n\n下面的步骤概括了在`access control`失效的情况下如何部署replica set\n\n### Start each member of the replica set with the appropriate options.\n\n启动`mongod`然后通过`replSet`选项设定`replica set`名字, 向`replica set`中添加一个成员. 如果想要配置其他特有参数,参考[Replication Options]()\n\n如果你的应用程序连接了多个`replica set`, 每一个`replica set`都应该有一个独立的名字. 某些驱动会根据`replica set`名称将`replica set`连接进行分组.\n\n下面是一个示例：\n```\nmongod --replSet \"rs0\"\n```\n\n你也通过配置文件设置`replica set`名字. 如果想要通过配置文件启动`mongod`, 那么你需要`--config`选项指定配置文件\n```\nmongod --config $HOME/.mongodb/config\n```\n在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围.\n\n> 注意:\n>\n> 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样. \n>\n> 那么你就需要在命令上加上 --dbpath 选项了\n\n### Connect a mongo shell to a replica set member.\n\n下例展示了如何连接到在`localhost:27017`上运行的`mongod`:\n```\nmongo\n```\n\n### Initiate the replica set.\n\n接着这`mongo`shell里使用`rs.initiate()`设置成员.\n```\nrs.initiate()\n```\nMongoDB使用`replica set`默认配置启动了一个包含当前成员的`replica set`\n\n> 注意:\n>\n> 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下.\n\n### Verify the initial replica set configuration.\n\n在`mongo`shell中使用`rs.conf()`输出`replica set`配置:\n```\nrs.conf()\n```\n\n输出的`replica set`配置类似于下面的结构\n```json\n{\n   \"_id\" : \"rs0\",\n   \"version\" : 1,\n   \"members\" : [\n      {\n         \"_id\" : 1,\n         \"host\" : \"mongodb0.example.net:27017\"\n      }\n   ]\n}\n```\n\n### Add the remaining members to the replica set.\n\n在`mongo`shell中使用`rs.add()`方法添加俩个成员:\n```\nrs.add(\"mongodb1.example.net\")\nrs.add(\"mongodb2.example.net\")\n```\n\n完成这一步之后,你就获得了一个拥有完整功能的`replica set`. 新的`replica set`会选出一个主要的来.\n\n### Check the status of the replica set.\n\n在`mongo`shell中使用`rs.status()`方法查看`replica set`状态.\n```\nrs.status()\n```\n\n## Replication Introduction\n\n`Replication` 是用于多台服务器间数据同步的一个进程.\n","source":"_posts/工具/MongoDB.md","raw":"category: 工具\ndate: 2015-03-08\ntitle: MongoDB\n---\n# Run MongoDB\n\n## Run MongoDB On Windows\n如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见.\n\n### 设置MOngoDB环境\n\n#### 设置环境变量\n在环境变量里添加环境变量 `D:\\Program Files\\MongoDB\\Server\\3.0\\` 然后在Path里添加： `%MONGODB_HOME%\\bin`\n\n#### data directory\n```\nMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是\\data\\db, \n所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: D:\\mongodb\\data\\db.\n\n你可以通过--dbpath选项给mongod.exe设置另一个data directory.\nmongod.exe --dbpath D:\\mongodb\\data\\db\n\n如果你的data directory包含空格的话,那么就需要使用\"\"将他们包含起来：\nmongod.exe --dbpath \"d:\\test\\mongo db data\"\n```\n\n## 启动MongoDB\n\n### 使用mongod.exe命令启动mongoDB\n```\n\tmongod.exe\n```\n\n### 启动日志\n最后我们在启动日志里看到\n```\nwaiting for connections on port 27017\n```\n\n### 命令行方式启动\n\nMongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017.\n```\nmongod --dbpath=/data/db\n```\n\n### 配置文件方式启动\nMongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下:\n```\ncat /etc/mongodb.cnf\n```\n启动时加上”-f”参数,并指向配置文件即可:\n```\nmongod -f /etc/mongodb.cnf\n```\n\n#### Daemon 方式启动\nMongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” --fork”参数即可,,但如果用到了 ” --fork”参数就必须也启用 ”--logpath”参数,这是强制的\n```\nmongod --dbpath=/data/db --logpath=/data/log/r3.log --fork\n```\n\n#### mongod 参数说明\nmongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数\n\nmongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,\nmmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经\n有了一定程度的改善.\n\n##### mongod 的主要参数有：\n* dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中.\n* logpath —— 错误日志文件\n* logappend —— 错误日志采用追加模式（默认是覆写模式）\n* bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定\n* port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000\n* fork —— 以后台 Daemon 形式运行服务\n* journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数.\n* syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒.\n* directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似\n* maxConns —— 最大连接数\n* repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作.\n\n## 停止数据库\n\n* Control-C\n* shutdownServer()指令\n```\nmongo --port 28013\nuse admin\ndb.shutdownServer()\n```\n\n## 常用工具集\nMongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上的方便。\n* bsondump: 将 bson 格式的文件转储为 json 格式的数据\n* mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法\n* mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行\n* mongodump/ mongorestore: 数据库备份和恢复工具\n* mongoexport/ mongoimport: 数据导出和导入工具\n* mongofiles: GridFS 管理工具,可实现二制文件的存取\n* mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod\n* mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出\n* mongostat: 实时性能监控工具\n\n## 部署 Replica Sets\n* 创建数据文件存储路径\n```\nmkdir E:/mongoData/data/r0\nmkdir E:/mongoData/data/r1\nmkdir E:/mongoData/data/r2\n```\n* 创建日志文件路径\n```\nmkdir E:/mongoData/log\n```\n* 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。\n```\nmkdir E:/mongoData/key\necho \"this is rs1 super secret key\" > E:/mongoData/key/r0\necho \"this is rs1 super secret key\" > E:/mongoData/key/r1\necho \"this is rs1 super secret key\" > E:/mongoData/key/r2\n```\n* 启动 3 个实例\n```\nmongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappend\nmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend\n```\n* 配置及初始化 Replica Sets\n```\nmongo -port 28010\n```\n\n\n# Introduction\n\n## A Quick Tour\n\n使用java 驱动开发是非常简单的,首先你要确保你的`classpath`中包含`mongo.jar`\n\n### Making a Connection\n\n为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库\n\n另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地`mydb`数据库的方式\n```java\nimport com.mongodb.BasicDBObject;\nimport com.mongodb.BulkWriteOperation;\nimport com.mongodb.BulkWriteResult;\nimport com.mongodb.Cursor;\nimport com.mongodb.DB;\nimport com.mongodb.DBCollection;\nimport com.mongodb.DBCursor;\nimport com.mongodb.DBObject;\nimport com.mongodb.MongoClient;\nimport com.mongodb.ParallelScanOptions;\nimport com.mongodb.ServerAddress;\n\nimport java.util.List;\nimport java.util.Set;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\n// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even\n// if it's a member of a replica set:\nMongoClient mongoClient = new MongoClient();\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" );\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" , 27017 );\n// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of members\nMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(\"localhost\", 27017),\n                                      new ServerAddress(\"localhost\", 27018),\n                                      new ServerAddress(\"localhost\", 27019)));\n\nDB db = mongoClient.getDB( \"mydb\" );\n```\n\n在这个例子中`db`对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作\n\n> Note:\n>\n> `MongoClient`实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个`MongoClient`实例, 参考[concurrency doc page]()\n\n\n`MongoClient`被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个`MongoClient`实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个`MongoClient`实例,那么你需要注意下面俩点：\n\n* all resource usage limits (max connections, etc) apply per MongoClient instance\n* 当关闭一个实例时,你必须确保你调用了`MongoClient.close()`清理掉了全部的资源\n\nNew in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead.\n\n### Authentication (Optional)\n\nMongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建`MongoClient`实例时提供一下证书.\n```java\nMongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);\nMongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential));\n```\n\nMongoDB支持不同的认证机制,具体参考[the access control tutorials]()\n\n### Getting a Collection\n\n如果想要使用一个collection,那么你仅仅需要调用`getCollection(String collectionName)`方法,然后指定该collection名称就好\n\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\n```\n\n一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了\n\n### Setting Write Concern\n\n在2.10.0这个版本里,默认的write concern是`WriteConcern.ACKNOWLEDGED`不过你可以通过下面的方法轻松改变它\n```java\nmongoClient.setWriteConcern(WriteConcern.JOURNALED);\n```\n\n对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载.\n\n\n### Inserting a Document\n\n一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档\n```json\n{\n   \"name\" : \"MongoDB\",\n   \"type\" : \"database\",\n   \"count\" : 1,\n   \"info\" : {\n               x : 203,\n               y : 102\n             }\n}\n```\n\n注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用`BasicDBObject`类来实现：\n```java\nBasicDBObject doc = new BasicDBObject(\"name\", \"MongoDB\")\n        .append(\"type\", \"database\")\n        .append(\"count\", 1)\n        .append(\"info\", new BasicDBObject(\"x\", 203).append(\"y\", 102));\ncoll.insert(doc);\n```\n\n\n### findOne()\n\n如果想要查看刚才插入的文档,我们可以简单地调用`findOne()`,这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而`find()`会返回一个`DBCursor`对象),当collection中只有一个文档的时候,这是非常有用的.\n```java\nDBObject myDoc = coll.findOne();\nSystem.out.println(myDoc);\n```\n结果如下：\n```json\n{ \"_id\" : \"49902cde5162504500b45c2c\" ,\n  \"name\" : \"MongoDB\" ,\n  \"type\" : \"database\" ,\n  \"count\" : 1 ,\n  \"info\" : { \"x\" : 203 , \"y\" : 102}}\n\n```\n\n>Note:\n>\n> `_id`元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称\n\n### Adding Multiple Documents\n\n当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中.\n```json\n{\n   \"i\" : value\n}\n```\n\n我们可以在一个循环中不断地插入数据\n```java\nfor (int i=0; i < 100; i++) {\n    coll.insert(new BasicDBObject(\"i\", i));\n}\n```\n\n注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为`schema-free`\n\n### Counting Documents in A Collection\n\n通过以上的操作我们已经插入了101个文档,我们通过`getCount()`方法来检查一下.\n```java\nSystem.out.println(coll.getCount());\n```\n\n### Using a Cursor to Get All the Documents\n\n如果想要获得collection中的全部文档,我们可以使用`find()`方法. `find()`返回一个`DBCursor`对象,我们可以通过遍历该对象获取所有匹配我们需求的文档.\n```java\nDBCursor cursor = coll.find();\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n### Getting A Single Document with A Query\n\n我们可以向`find()`方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档.\n```java\nBasicDBObject query = new BasicDBObject(\"i\", 71);\n\ncursor = coll.find(query);\n\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n该代码只会输出一个文档\n```json\n{ \"_id\" : \"49903677516250c1008d624e\" , \"i\" : 71 }\n```\n\n你也可以从其他的实例和文档中查看`$`操作符的用法：\n```java\ndb.things.find({j: {$ne: 3}, k: {$gt: 10} });\n```\n\n使用内嵌的`DBObject`,`$`可以看作是正则表达式字串\n``` java\nquery = new BasicDBObject(\"j\", new BasicDBObject(\"$ne\", 3))\n        .append(\"k\", new BasicDBObject(\"$gt\", 10));\n\ncursor = coll.find(query);\n\ntry {\n    while(cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### Getting A Set of Documents With a Query\n\n我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i > 50的文档\n```java\n// find all where i > 50\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 50));\n\ncursor = coll.find(query);\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n我们还可以获得一个区间(20 < i <= 30)文档集合\n```java\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 20).append(\"$lte\", 30));\ncursor = coll.find(query);\n\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### MaxTime\n\nMongoDB2.6 添加查询超时的能力\n\n```java\ncoll.find().maxTime(1, SECONDS).count();\n```\n\n在上面的例子中将`maxTime`设置为1s,当时间到后查询将被打断\n\n### Bulk operations\n\nUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations:\n\n1. Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出\n2. Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行\n\n下面展示了上面所说的俩个示例\n```java\n// 1. Ordered bulk operation\nBulkWriteOperation builder = coll.initializeOrderedBulkOperation();\nbuilder.insert(new BasicDBObject(\"_id\", 1));\nbuilder.insert(new BasicDBObject(\"_id\", 2));\nbuilder.insert(new BasicDBObject(\"_id\", 3));\n\nbuilder.find(new BasicDBObject(\"_id\", 1)).updateOne(new BasicDBObject(\"$set\", new BasicDBObject(\"x\", 2)));\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 3)).replaceOne(new BasicDBObject(\"_id\", 3).append(\"x\", 4));\n\nBulkWriteResult result = builder.execute();\n\n// 2. Unordered bulk operation - no guarantee of order of operation\nbuilder = coll.initializeUnorderedBulkOperation();\nbuilder.find(new BasicDBObject(\"_id\", 1)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\n\nresult = builder.execute();\n```\n\n\n> Note:\n> \nFor servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers.\n\n\n### parallelScan\n\nMongoDB 2.6 增加了`parallelCollectionScan`命令, 该命令通过使用多个游标读取整个collection.\n```java\nParallelScanOptions parallelScanOptions = ParallelScanOptions\n        .builder()\n        .numCursors(3)\n        .batchSize(300)\n        .build();\n\nList<Cursor> cursors = coll.parallelScan(parallelScanOptions);\nfor (Cursor pCursor: cursors) {\n    while (pCursor.hasNext()) {\n        System.out.println((pCursor.next()));\n    }\n}\n```\n\n其对collection进行IO吞吐量的优化.\n\n> Note:\n>\n> `ParallelScan`不能通过`mongos`运行\n\n## Quick Tour of the Administrative Functions\n\n### Getting A List of Databases\n\n通过下面的代码你可以获取一个可用数据库列表\n```java\nMongoClient mongoClient = new MongoClient();\n\nfor (String s : mongoClient.getDatabaseNames()) {\n   System.out.println(s);\n}\n```\n\n调用`mongoClient.getDB()`并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档.\n\n### Dropping A Database\n\n通过`MongoClient`实例你也可以`drop`掉一个数据库\n```java\nMongoClient mongoClient = new MongoClient();\nmongoClient.dropDatabase(\"databaseToBeDropped\");\n```\n\n### Creating A Collection\n\n有俩种方式创建collection：\n1. 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来\n2. 或者直接调用`createCollection`命令\n\n下面的例子展示了创建1M大小的collection\n```java\ndb = mongoClient.getDB(\"mydb\");\ndb.createCollection(\"testCollection\", new BasicDBObject(\"capped\", true)\n        .append(\"size\", 1048576));\n```\n\n### Getting A List of Collections\n\n你可以通过下面的方式获得一个数据库当中可用collection列表\n```java\nfor (String s : db.getCollectionNames()) {\n   System.out.println(s);\n}\n```\n\n上面的例子会输出：\n```\nsystem.indexes\ntestCollection\n```\n\n>Note:\n>\n> `system.indexes` collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它\n\n### Dropping A Collection\n\n你可以通过`drop()`方法直接drop掉一个collection\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\ncoll.drop();\nSystem.out.println(db.getCollectionNames());\n```\n\n### Getting a List of Indexes on a Collection\n\n下例展示了如何获得一个collection中索引的列表\n```java\nList<DBObject> list = coll.getIndexInfo();\n\nfor (DBObject o : list) {\n   System.out.println(o.get(\"key\"));\n}\n```\n\n上面的实例会进行下面的输出：\n```json\n{ \"v\" : 1 , \"key\" : { \"_id\" : 1} , \"name\" : \"_id_\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"i\" : 1} , \"name\" : \"i_1\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"loc\" : \"2dsphere\"} , \"name\" : \"loc_2dsphere\" , ... }\n{ \"v\" : 1 , \"key\" : { \"_fts\" : \"text\" , \"_ftsx\" : 1} , \"name\" : \"content_text\" , ... }\n```\n\n\n### Creating An Index\n\nMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1).\n```java\ncoll.createIndex(new BasicDBObject(\"i\", 1));  // create index on \"i\", ascending\n```\n\n\n### Geo indexes\n\nMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个`2dsphere`索引, 我们可以通过标准`GeoJson`标记进行查询. 想要创建一个`2dsphere`索引,我们需要在索引文档中指定`2dsphere`这个字面量.\n```java\ncoll.createIndex(new BasicDBObject(\"loc\", \"2dsphere\"));\n```\n\n有不同的方式去查询`2dsphere`索引,下面的例子中找到了500m以内的位置.\n```java\nBasicDBList coordinates = new BasicDBList();\ncoordinates.put(0, -73.97);\ncoordinates.put(1, 40.77);\ncoll.insert(new BasicDBObject(\"name\", \"Central Park\")\n                .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n                .append(\"category\", \"Parks\"));\n\ncoordinates.put(0, -73.88);\ncoordinates.put(1, 40.78);\ncoll.insert(new BasicDBObject(\"name\", \"La Guardia Airport\")\n        .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n        .append(\"category\", \"Airport\"));\n\n\n// Find whats within 500m of my location\nBasicDBList myLocation = new BasicDBList();\nmyLocation.put(0, -73.965);\nmyLocation.put(1, 40.769);\nmyDoc = coll.findOne(\n            new BasicDBObject(\"loc\",\n                new BasicDBObject(\"$near\",\n                        new BasicDBObject(\"$geometry\",\n                                new BasicDBObject(\"type\", \"Point\")\n                                    .append(\"coordinates\", myLocation))\n                             .append(\"$maxDistance\",  500)\n                        )\n                )\n            );\nSystem.out.println(myDoc.get(\"name\"));\n```\n\n更多参考[geospatial]()文档\n\n### Text indexes\n\nMongoDB还支持`text`索引,该索引用来支持从String中搜索文本. `text`索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个`text`索引,只需要在索引文档中指定`text`字面量.\n```java\n// create a text index on the \"content\" field\ncoll.createIndex(new BasicDBObject(\"content\", \"text\"));\n```\n\nMongoDB2.6 以后`text`索引融进了主要的查询语言中,并且成为了一种默认的方式.\n```java\n// Insert some documents\ncoll.insert(new BasicDBObject(\"_id\", 0).append(\"content\", \"textual content\"));\ncoll.insert(new BasicDBObject(\"_id\", 1).append(\"content\", \"additional content\"));\ncoll.insert(new BasicDBObject(\"_id\", 2).append(\"content\", \"irrelevant content\"));\n\n// Find using the text index\nBasicDBObject search = new BasicDBObject(\"$search\", \"textual content -irrelevant\");\nBasicDBObject textSearch = new BasicDBObject(\"$text\", search);\nint matchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches: \"+ matchCount);\n\n// Find using the $language operator\ntextSearch = new BasicDBObject(\"$text\", search.append(\"$language\", \"english\"));\nmatchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches (english): \"+ matchCount);\n\n// Find the highest scoring match\nBasicDBObject projection = new BasicDBObject(\"score\", new BasicDBObject(\"$meta\", \"textScore\"));\nmyDoc = coll.findOne(textSearch, projection);\nSystem.out.println(\"Highest scoring document: \"+ myDoc);\n```\n\n上面的代码应该输出：\n```java\nText search matches: 2\nText search matches (english): 2\nHighest scoring document: { \"_id\" : 1 , \"content\" : \"additional content\" , \"score\" : 0.75}\n```\n\n更多关于text search,参考[text index and $text query operator]()\n\n# Replica\n# Deploy a Replica Set\n\n这篇教程讲述的是如何基于正在运行的不进行控制访问的`mongod`创建三个`replica set`.\n\n如果想要创建带有控制访问功能的`replica set`,参考[Deploy Replica Set and Configure Authentication and Authorization](http://docs.mongodb.org/manual/tutorial/deploy-replica-set-with-auth/). 如果你想要在一个单独的MongoDB上部署`replica set`, 可以参考[Convert a Standalone to a Replica Set](http://docs.mongodb.org/manual/tutorial/convert-standalone-to-replica-set/). 关于更多的`replica set`部署信息,参考[Replication](http://docs.mongodb.org/manual/replication/)和[Replica Set Deployment Architectures](http://docs.mongodb.org/manual/core/replica-set-architectures/)\n\n## Overview\n\n带有三个成员的`replica sets`就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. `Replica sets`应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的[elections](http://docs.mongodb.org/manual/core/replica-set-elections/). 更多关于对`replica sets`的设计,参考[Replication overview](http://docs.mongodb.org/manual/core/replication-introduction/)\n\n基本的步骤是: 首先启动要成为`replica set`成员的`mongod`, 然后配置`replica set`, 最后将`mongod`添加到`replica set`上.\n\n## Requirements\n\n在生产部署阶段, 你应该尽量在不同的主机上部署代理`mongod`的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个'mongod'.\n\n在你创建`replica set`之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的`replica set`部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考[Test Connections Between all Members](http://docs.mongodb.org/manual/tutorial/troubleshoot-replica-sets/#replica-set-troubleshooting-check-connection)\n\n## Considerations When Deploying a Replica Set\n\n### Architecture\n\n在生产阶段, 将`replica set`和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用`bind_ip`选项确保MongoDB会根据配置好的地址监听来自应用程序的连接.\n\n如果`replica set`在不同的机房内部署, 那么应该确保大多数的`mongod`实例部署在第一站点上.参考[Replica Set Deployment Architectures]()\n\n### Connectivity\n\n确保网络中所有的`replica set`成员和客户端的流量能够安全和高效地传输:\n\n* 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量.\n* 配置访问控制能够阻止未知的客户端连接到 `replica set`上\n* 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上.\n\n最终确保`replica set`中每个成员都可以通过可解析的`DNS`或者`hostname`访问到. 你应该恰当地设置上`DNS`名称或者通过`/etc/hosts`文件来映射这个配置\n\n### Configuration\nSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB.\n\nFor more information about the run time options used above and other configuration options, see Configuration File Options.\n\n## Procedure\n\n下面的步骤概括了在`access control`失效的情况下如何部署replica set\n\n### Start each member of the replica set with the appropriate options.\n\n启动`mongod`然后通过`replSet`选项设定`replica set`名字, 向`replica set`中添加一个成员. 如果想要配置其他特有参数,参考[Replication Options]()\n\n如果你的应用程序连接了多个`replica set`, 每一个`replica set`都应该有一个独立的名字. 某些驱动会根据`replica set`名称将`replica set`连接进行分组.\n\n下面是一个示例：\n```\nmongod --replSet \"rs0\"\n```\n\n你也通过配置文件设置`replica set`名字. 如果想要通过配置文件启动`mongod`, 那么你需要`--config`选项指定配置文件\n```\nmongod --config $HOME/.mongodb/config\n```\n在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围.\n\n> 注意:\n>\n> 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样. \n>\n> 那么你就需要在命令上加上 --dbpath 选项了\n\n### Connect a mongo shell to a replica set member.\n\n下例展示了如何连接到在`localhost:27017`上运行的`mongod`:\n```\nmongo\n```\n\n### Initiate the replica set.\n\n接着这`mongo`shell里使用`rs.initiate()`设置成员.\n```\nrs.initiate()\n```\nMongoDB使用`replica set`默认配置启动了一个包含当前成员的`replica set`\n\n> 注意:\n>\n> 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下.\n\n### Verify the initial replica set configuration.\n\n在`mongo`shell中使用`rs.conf()`输出`replica set`配置:\n```\nrs.conf()\n```\n\n输出的`replica set`配置类似于下面的结构\n```json\n{\n   \"_id\" : \"rs0\",\n   \"version\" : 1,\n   \"members\" : [\n      {\n         \"_id\" : 1,\n         \"host\" : \"mongodb0.example.net:27017\"\n      }\n   ]\n}\n```\n\n### Add the remaining members to the replica set.\n\n在`mongo`shell中使用`rs.add()`方法添加俩个成员:\n```\nrs.add(\"mongodb1.example.net\")\nrs.add(\"mongodb2.example.net\")\n```\n\n完成这一步之后,你就获得了一个拥有完整功能的`replica set`. 新的`replica set`会选出一个主要的来.\n\n### Check the status of the replica set.\n\n在`mongo`shell中使用`rs.status()`方法查看`replica set`状态.\n```\nrs.status()\n```\n\n## Replication Introduction\n\n`Replication` 是用于多台服务器间数据同步的一个进程.\n","slug":"工具/MongoDB","published":1,"updated":"2015-10-14T01:53:47.865Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxso001y0cufg9y7miea"},{"date":"2015-05-07T16:00:00.000Z","title":"Flick Ticket Server","_content":"## 为什么采用Ticket Server\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外Flicker Mysql是基于`主-主`复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n## 考虑GUID \n\nGUID是非常大的,但是他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会建立索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n## 一致性哈希 \n像Amazon Dynamo等项目提出了在数据存储顶部采用`一致性哈希环`,来解决`GUID/sharding`问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然而MYSQL针对快速随机读进行了优化\n\n\n## 集中自动增量\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n## 替换(重新插入) \n\n大概十多年前,mysql对`ANSI SQL`实现了一个非标准化的拓展-`REPLACE INTO`. 随后`INSERT ON DUPLICATE KEY UPDATE`做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是`REPLACE INTO` 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的`PRIMARY KEY`或者 `UNIQUE index`重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n## 组装 \n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n\n#### 下面展示了一下Ticket64 schema\n\n```\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n#### 当我需要一个新的64位ID时,我执行面貌这个sql\n\n```\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n#### SPOF(单点故障) \n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n\n#### 我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n###### 在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n\n","source":"_posts/工具/Flick Ticket Server.md","raw":"category: 工具\ndate: 2015-05-08\ntitle: Flick Ticket Server\n---\n## 为什么采用Ticket Server\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外Flicker Mysql是基于`主-主`复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n## 考虑GUID \n\nGUID是非常大的,但是他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会建立索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n## 一致性哈希 \n像Amazon Dynamo等项目提出了在数据存储顶部采用`一致性哈希环`,来解决`GUID/sharding`问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然而MYSQL针对快速随机读进行了优化\n\n\n## 集中自动增量\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n## 替换(重新插入) \n\n大概十多年前,mysql对`ANSI SQL`实现了一个非标准化的拓展-`REPLACE INTO`. 随后`INSERT ON DUPLICATE KEY UPDATE`做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是`REPLACE INTO` 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的`PRIMARY KEY`或者 `UNIQUE index`重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n## 组装 \n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n\n#### 下面展示了一下Ticket64 schema\n\n```\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n#### 当我需要一个新的64位ID时,我执行面貌这个sql\n\n```\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n#### SPOF(单点故障) \n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n\n#### 我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n###### 在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n\n","slug":"工具/Flick Ticket Server","published":1,"updated":"2015-10-14T01:54:27.858Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsq00200cufa19el8jz"},{"date":"2015-10-07T16:00:00.000Z","title":"DevOps","_content":"## Mac\n\n### Screenhero\n协作编程工具：双方都能控制鼠标/键盘\n\n### [asciinema](https://asciinema.org)\n终端录制与屏幕分享工具\n\n### [keen.io](https://keen.io)\n用来追踪时间段发生的一系列事件\n\n### [iTerm2](http://www.iterm2.com/)\n命令行工具 \n\n### [Oh My Zsh](http://ohmyz.sh/)\nmac下的shell,你懂得\n\n### CakeBrew\n图形化管理homebrew的工具\n\n### [CMAKE](https://cmake.org/)\nCMake 是一个跨平台的自动化建构系统,它使用一个名为 CMakeLists.txt 的文件来描述构建过程,可以产生标准的构建文件\n\n### Patterns\n用来复查正则表达式\n\n### CheatSheet\nCheatSheet在后台运行\n\n### [SonarQube](http://www.sonarqube.org/)\n代码质量管理的开源平台\n\n### [Keka](http://www.kekaosx.com/zh-cn/)\n免费的 Mac OS X 文件解压缩程序。\n\nKeka 所支持的文件压缩格式：7z, Zip, Tar, Gzip, Bzip2, DMG, ISO\n\nKeka 所支持的文件解压格式：RAR, 7z, Lzma, xz, Zip, Tar, Gzip, Bzip2, ISO, EXE, CAB, PAX, ACE (PPC)\n\n### [Tuxera NTFS](http://www.tuxera.com/products/tuxera-ntfs-for-mac/)\n为 Mac用户提供的专业 NTFS 驱动软件\n\n### [PopClip](http://sspai.com/25483)\nMac上的小工具，简单高效，具有强大的拓展功能\n\n### [Transmit]()\nFTP 客户端软件\n\n### [MacVim](http://www.macupdate.com/app/mac/25988/macvim)\nvim的mac移植版本\n\n## windows\n\n### [babun](http://babun.github.io/)\nWindows 上的开箱即用的壳程序，基于 Cygwin，胜于 Cygwin\n\n### [msys2](http://msys2.github.io/)\n用于 shell 命令行开发环境\n\n### [gitbook]()\nmarkdown写书工具\n\n### [PowerCMD](http://www.powercmd.com/)\n增强版本的CMD工具\n\n### [Cyberduck](https://cyberduck.io/)\nFTP客户端软件,同样适用于Mac\n\n\n\n\n","source":"_posts/工具/DevOps.md","raw":"category: 工具\ndate: 2015-10-08\ntitle: DevOps\n---\n## Mac\n\n### Screenhero\n协作编程工具：双方都能控制鼠标/键盘\n\n### [asciinema](https://asciinema.org)\n终端录制与屏幕分享工具\n\n### [keen.io](https://keen.io)\n用来追踪时间段发生的一系列事件\n\n### [iTerm2](http://www.iterm2.com/)\n命令行工具 \n\n### [Oh My Zsh](http://ohmyz.sh/)\nmac下的shell,你懂得\n\n### CakeBrew\n图形化管理homebrew的工具\n\n### [CMAKE](https://cmake.org/)\nCMake 是一个跨平台的自动化建构系统,它使用一个名为 CMakeLists.txt 的文件来描述构建过程,可以产生标准的构建文件\n\n### Patterns\n用来复查正则表达式\n\n### CheatSheet\nCheatSheet在后台运行\n\n### [SonarQube](http://www.sonarqube.org/)\n代码质量管理的开源平台\n\n### [Keka](http://www.kekaosx.com/zh-cn/)\n免费的 Mac OS X 文件解压缩程序。\n\nKeka 所支持的文件压缩格式：7z, Zip, Tar, Gzip, Bzip2, DMG, ISO\n\nKeka 所支持的文件解压格式：RAR, 7z, Lzma, xz, Zip, Tar, Gzip, Bzip2, ISO, EXE, CAB, PAX, ACE (PPC)\n\n### [Tuxera NTFS](http://www.tuxera.com/products/tuxera-ntfs-for-mac/)\n为 Mac用户提供的专业 NTFS 驱动软件\n\n### [PopClip](http://sspai.com/25483)\nMac上的小工具，简单高效，具有强大的拓展功能\n\n### [Transmit]()\nFTP 客户端软件\n\n### [MacVim](http://www.macupdate.com/app/mac/25988/macvim)\nvim的mac移植版本\n\n## windows\n\n### [babun](http://babun.github.io/)\nWindows 上的开箱即用的壳程序，基于 Cygwin，胜于 Cygwin\n\n### [msys2](http://msys2.github.io/)\n用于 shell 命令行开发环境\n\n### [gitbook]()\nmarkdown写书工具\n\n### [PowerCMD](http://www.powercmd.com/)\n增强版本的CMD工具\n\n### [Cyberduck](https://cyberduck.io/)\nFTP客户端软件,同样适用于Mac\n\n\n\n\n","slug":"工具/DevOps","published":1,"updated":"2015-10-20T08:54:57.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxss00220cuf45ij4ona"},{"date":"2013-09-12T16:00:00.000Z","title":"CachesExplained","_content":"\n## Example\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .expireAfterWrite(10, TimeUnit.MINUTES)  \n       .removalListener(MY_LISTENER)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n## 适用范围\n缓存的使用范围是十分广泛的。每当计算或者通过一些方式生成一个值的时候，会造成资源严重浪费的时候我们可以考虑用缓存技术来存储该值。\n\n缓存和`CurrentMap`十分相似(键值对形式),但是他们之间还是仍有诸多不同.他们之间最大的不同之处是`ConcurrentMap`里的元素在被明确地删除之前会一直被存储在`Map`里，但是对于cache来说，为了维护cache的内存占用，cache被设计成会自动删除其中的数据。在一些应用场合中，使用`LoadingCache也`是非常有用的，即使它不被允许自动删除其entries(由于它的自动内存加载机制，他不允许这么做)。\n    \n一般来说，Guava的缓存技术一般适用于以下场合\n1. 想要消耗掉一些内存来换取速度的提升\n2. key(map中也有key)会在一段时间内被频繁的访问。\n3. 在cache存储的数据容量不会大于其RAM中存储的。\n\n你可以按照上文中的例子(CacheBuilder的builder pattern)来创建一个Cache，但是定制属于自己应用程序的Cache才是最激动人心的事。\n\n>注：如果你的应用程序中不会用到上文提到的Cache的特性，那么你可以考虑ConcurrentHashMap，它在内存方面也许更有优势。但是ConcurrentHashMap是非常困难，甚至不可能的来模拟出Cache那样的强大功能。\n至于如何选择，就要看你的应用程序需求了,仔细看看下面提到的特性----例如元素的存活期，元素的大小等等，这些特点都是在ConcurrentMap里所不存在的。\n\n## 总体\n你应该先问自己第一个问题：你是否有特定的明确的通过某些keys的作参数生成Value的方法？如果你的回答是肯定的话，那么`CacheLoader`是适合你的。如果你不需要通过某些key来生成value或者你想要重载默认的方法或者想要使用`get-if-absent-compute`方式,你可以参考[From A Callable]()。一般我们可以通过`Cache.put`直接将元素插入cache中，但是我们应该首先考虑它的自动缓存加载，因为它会考虑到所有缓存内容的一致性。\n\n> From A CacheLoader : LoadingCache通过一个附着的CacheLoader来创建。创建一个CacheLoader也是非常简单的，只要实现一个V load(K key) throws exception的方法就可以了.下面的例子展示出如何创建一个LoadingCache\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n  \n...  \ntry {  \n  return graphs.get(key);  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\n上面的例子也展示除了我们可以通过`get(K)`的方式对`LoadingCache`进行查询获取值。我们如果可以从cache中查找到该key，那么将会直接返回该key对应的value，否则会通过cache的`CacheLoader`自动加载一个新的键值对，然后返回该值。因为`CacheLoader`可能会抛出异常，所以get(K)可能会抛出`Execution`。如果在`CacheLoader`中定义了一个非异常检查的`load`方法，那么在查询取值时可以使用`getUnchecked(Key)`;但是如果你声明了throws，则一定不要调用`getUnchecked(Key)`. 下面是一个例子：\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .expireAfterAccess(10, TimeUnit.MINUTES)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n  \n...  \nreturn graphs.getUnchecked(key);  \n```\n\n当我们想要获取N多值的时候，在查询时可以使用方法`getAll(Iterable<? extends K>)`.在getAll中，对每一个不存在于cache里的key都会执行一个单独的对`CacheLoader.load`的方法调用来加载该值。看，guava提供了如此优秀的方法当进行一次getAll比多次get更有优势时，我们就应该重载`CacheLoader.loadAll`来实现这个功能。\n\n可以通过实现`CacheLoader.loadAll`这个方法来加载那些不被包含的显示请求的值。\n\n如果想要设定cache有一定的大小可以通过`CacheBuilder.maximumSize(long)`来设定。如此设定会使得cache在达到限定值时删除那些没有被使用过或者不经常使用的entries.\n\n> From a Callable: 所有的Guava caches，不管是否是loading模式的，都支持get(K, Callable<V>)方法。这个方法会从cache中返回与该key相关联的value，或者从Callable中计算该值并把它放进cache中。这个方法使用了一个非常简单的模式\"if cached, return; otherwise create, cache and return\"\n\n```java\nCache<Key, Value> cache = CacheBuilder.newBuilder()  \n    .maximumSize(1000)  \n    .build(); // look Ma, no CacheLoader  \n...  \ntry {  \n  // If the key wasn't in the \"easy to compute\" group, we need to  \n  // do things the hard way.  \n  cache.get(key, new Callable<Value>() {  \n    @Override  \n    public Value call() throws AnyException {  \n      return doThingsTheHardWay(key);  \n    }  \n  });  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\nInserted Directly : Values也可以通过cache.put(key,value)直接将值插入cache中。该方法将重写先前与key匹配的entry。\n\n## Eviction\n一个不能避免的问题：由于内存原因，我们不能将所有的东西都加载进cache中。那么你必须下决定：一个cache entry应该何时被抛弃。Guava提供了三种entry释放策略：size-basd evicton，time-based eviction 和reference-based eviction\n\n### Size-based Eviction\n如果你的cache不允许扩容,即不允许超过设定的最大值，那么使用CacheBuilder.maxmuSize(long)即可。在这种条件下，cache会自己释放掉那些最近没有或者不经常使用的entries内存。注意：cache并不是在超过限定时才会删除掉那些entries，而是在即将达到这个限定值时，那么你就要小心考虑这种情况了，因为很明显即使没有达到这个限定值，cache仍然会进行删除操作。\n\n还有一种情况：cache里不同的entries可能会有不同的weight。例如：如果你的cache values有着截然不同的内存占用----你可以使用CacheBuilder.weigher(Weigher)设定weigh和使用CacheBuilder.maximumWeight(long)设定一个最大值。\n下面代码展示了对weight的使用\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumWeight(100000)  \n       .weigher(new Weigher<Key, Graph>() {  \n          public int weigh(Key k, Graph g) {  \n            return g.vertices().size();  \n          }  \n        })  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n### Timed Eviction\nCacheBuilder 提供了俩种方式来实现这一模式\nexpireAfterAccess(long, TimeUnit) \n从最后一次访问(读或者写)开始计时，过了这段指定的时间就会释放掉该entries。注意：那些被删掉的entries的顺序时和size-based eviction是十分相似的。\nexpireAfterWrite(long,TimeUnit)\n它是从entries被创建或者最后一次被修改值的点来计时的，如果从这个点开始超过了那段指定的时间，entries就会被删除掉。这点设计的很精明，因为数据会随着时间变得越来越陈旧。\n如果想要测试Timed Eviction，使用Ticker interface和CacheBuilder.ticker(Ticker)方法对你的cache设定一个时间即可，那么你就不需要去等待系统时间了。\n\n### Reference-based Eviction\nGuava为你准备了entries的垃圾回收器，对于keys或者values可以使用`weak reference` ，对于values可以使用 `soft reference`.\n\n`CacheBuilder.weakKeys()`通过weak reference存储keys。在这种情况下，如果keys没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个key的，而不是equals();\n\n`CacheBuilder.weakValues()`  通过weak referene 存储values.在这种情况下，如果valves没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个values的，而不是equals();\nCacheBuilder.softValues() \n\n### Explicit Removals\n也许在某年某月某天你不想再等cache释放entries，而是自己能手动的去释放掉这些entries，下面三个方法会帮助你\n* 单个释放：Cache.invalidate(key)\n* 多个释放：Cache.invalidateAll(keys)\n* 全部释放：Cache.invalidateAll()\n\n### Removal Listeners\ncache允许你指定一个removal listener监听entry的移除操作(例如`CacheBuilder.removalListener(RemovalListener)`).通过R`emovaNotification`获得的`RemovalListener`制定了RemovalCause,key和value`。\n\n>注意RemovalListener抛出的任何异常都会被Logger记录然后被丢弃\n\n```java\nCacheLoader<Key, DatabaseConnection> loader = new CacheLoader<Key, DatabaseConnection> () {  \n  public DatabaseConnection load(Key key) throws Exception {  \n    return openConnection(key);  \n  }  \n};  \nRemovalListener<Key, DatabaseConnection> removalListener = new RemovalListener<Key, DatabaseConnection>() {  \n  public void onRemoval(RemovalNotification<Key, DatabaseConnection> removal) {  \n    DatabaseConnection conn = removal.getValue();  \n    conn.close(); // tear down properly  \n  }  \n};  \n  \nreturn CacheBuilder.newBuilder()  \n  .expireAfterWrite(2, TimeUnit.MINUTES)  \n  .removalListener(removalListener)  \n  .build(loader);  \n```\n警告：removal listeners是被默认同步执行的，而且cache的维护是在其普通操作中维护的，那么“昂贵的”removal listener会降低cache操作(某些方法)的效率。如果你在使用一个\"昂贵的\"removal listener，你可以使用RemovalListener.asynchronous(RemovalListener,Executor),将其布置成异步操作.\n","source":"_posts/工具/CachesExplained.md","raw":"category: 工具\ndate: 2013-09-13\ntitle: CachesExplained\n---\n\n## Example\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .expireAfterWrite(10, TimeUnit.MINUTES)  \n       .removalListener(MY_LISTENER)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n## 适用范围\n缓存的使用范围是十分广泛的。每当计算或者通过一些方式生成一个值的时候，会造成资源严重浪费的时候我们可以考虑用缓存技术来存储该值。\n\n缓存和`CurrentMap`十分相似(键值对形式),但是他们之间还是仍有诸多不同.他们之间最大的不同之处是`ConcurrentMap`里的元素在被明确地删除之前会一直被存储在`Map`里，但是对于cache来说，为了维护cache的内存占用，cache被设计成会自动删除其中的数据。在一些应用场合中，使用`LoadingCache也`是非常有用的，即使它不被允许自动删除其entries(由于它的自动内存加载机制，他不允许这么做)。\n    \n一般来说，Guava的缓存技术一般适用于以下场合\n1. 想要消耗掉一些内存来换取速度的提升\n2. key(map中也有key)会在一段时间内被频繁的访问。\n3. 在cache存储的数据容量不会大于其RAM中存储的。\n\n你可以按照上文中的例子(CacheBuilder的builder pattern)来创建一个Cache，但是定制属于自己应用程序的Cache才是最激动人心的事。\n\n>注：如果你的应用程序中不会用到上文提到的Cache的特性，那么你可以考虑ConcurrentHashMap，它在内存方面也许更有优势。但是ConcurrentHashMap是非常困难，甚至不可能的来模拟出Cache那样的强大功能。\n至于如何选择，就要看你的应用程序需求了,仔细看看下面提到的特性----例如元素的存活期，元素的大小等等，这些特点都是在ConcurrentMap里所不存在的。\n\n## 总体\n你应该先问自己第一个问题：你是否有特定的明确的通过某些keys的作参数生成Value的方法？如果你的回答是肯定的话，那么`CacheLoader`是适合你的。如果你不需要通过某些key来生成value或者你想要重载默认的方法或者想要使用`get-if-absent-compute`方式,你可以参考[From A Callable]()。一般我们可以通过`Cache.put`直接将元素插入cache中，但是我们应该首先考虑它的自动缓存加载，因为它会考虑到所有缓存内容的一致性。\n\n> From A CacheLoader : LoadingCache通过一个附着的CacheLoader来创建。创建一个CacheLoader也是非常简单的，只要实现一个V load(K key) throws exception的方法就可以了.下面的例子展示出如何创建一个LoadingCache\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumSize(1000)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) throws AnyException {  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n  \n...  \ntry {  \n  return graphs.get(key);  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\n上面的例子也展示除了我们可以通过`get(K)`的方式对`LoadingCache`进行查询获取值。我们如果可以从cache中查找到该key，那么将会直接返回该key对应的value，否则会通过cache的`CacheLoader`自动加载一个新的键值对，然后返回该值。因为`CacheLoader`可能会抛出异常，所以get(K)可能会抛出`Execution`。如果在`CacheLoader`中定义了一个非异常检查的`load`方法，那么在查询取值时可以使用`getUnchecked(Key)`;但是如果你声明了throws，则一定不要调用`getUnchecked(Key)`. 下面是一个例子：\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .expireAfterAccess(10, TimeUnit.MINUTES)  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n  \n...  \nreturn graphs.getUnchecked(key);  \n```\n\n当我们想要获取N多值的时候，在查询时可以使用方法`getAll(Iterable<? extends K>)`.在getAll中，对每一个不存在于cache里的key都会执行一个单独的对`CacheLoader.load`的方法调用来加载该值。看，guava提供了如此优秀的方法当进行一次getAll比多次get更有优势时，我们就应该重载`CacheLoader.loadAll`来实现这个功能。\n\n可以通过实现`CacheLoader.loadAll`这个方法来加载那些不被包含的显示请求的值。\n\n如果想要设定cache有一定的大小可以通过`CacheBuilder.maximumSize(long)`来设定。如此设定会使得cache在达到限定值时删除那些没有被使用过或者不经常使用的entries.\n\n> From a Callable: 所有的Guava caches，不管是否是loading模式的，都支持get(K, Callable<V>)方法。这个方法会从cache中返回与该key相关联的value，或者从Callable中计算该值并把它放进cache中。这个方法使用了一个非常简单的模式\"if cached, return; otherwise create, cache and return\"\n\n```java\nCache<Key, Value> cache = CacheBuilder.newBuilder()  \n    .maximumSize(1000)  \n    .build(); // look Ma, no CacheLoader  \n...  \ntry {  \n  // If the key wasn't in the \"easy to compute\" group, we need to  \n  // do things the hard way.  \n  cache.get(key, new Callable<Value>() {  \n    @Override  \n    public Value call() throws AnyException {  \n      return doThingsTheHardWay(key);  \n    }  \n  });  \n} catch (ExecutionException e) {  \n  throw new OtherException(e.getCause());  \n}  \n```\nInserted Directly : Values也可以通过cache.put(key,value)直接将值插入cache中。该方法将重写先前与key匹配的entry。\n\n## Eviction\n一个不能避免的问题：由于内存原因，我们不能将所有的东西都加载进cache中。那么你必须下决定：一个cache entry应该何时被抛弃。Guava提供了三种entry释放策略：size-basd evicton，time-based eviction 和reference-based eviction\n\n### Size-based Eviction\n如果你的cache不允许扩容,即不允许超过设定的最大值，那么使用CacheBuilder.maxmuSize(long)即可。在这种条件下，cache会自己释放掉那些最近没有或者不经常使用的entries内存。注意：cache并不是在超过限定时才会删除掉那些entries，而是在即将达到这个限定值时，那么你就要小心考虑这种情况了，因为很明显即使没有达到这个限定值，cache仍然会进行删除操作。\n\n还有一种情况：cache里不同的entries可能会有不同的weight。例如：如果你的cache values有着截然不同的内存占用----你可以使用CacheBuilder.weigher(Weigher)设定weigh和使用CacheBuilder.maximumWeight(long)设定一个最大值。\n下面代码展示了对weight的使用\n```java\nLoadingCache<Key, Graph> graphs = CacheBuilder.newBuilder()  \n       .maximumWeight(100000)  \n       .weigher(new Weigher<Key, Graph>() {  \n          public int weigh(Key k, Graph g) {  \n            return g.vertices().size();  \n          }  \n        })  \n       .build(  \n           new CacheLoader<Key, Graph>() {  \n             public Graph load(Key key) { // no checked exception  \n               return createExpensiveGraph(key);  \n             }  \n           });  \n```\n\n### Timed Eviction\nCacheBuilder 提供了俩种方式来实现这一模式\nexpireAfterAccess(long, TimeUnit) \n从最后一次访问(读或者写)开始计时，过了这段指定的时间就会释放掉该entries。注意：那些被删掉的entries的顺序时和size-based eviction是十分相似的。\nexpireAfterWrite(long,TimeUnit)\n它是从entries被创建或者最后一次被修改值的点来计时的，如果从这个点开始超过了那段指定的时间，entries就会被删除掉。这点设计的很精明，因为数据会随着时间变得越来越陈旧。\n如果想要测试Timed Eviction，使用Ticker interface和CacheBuilder.ticker(Ticker)方法对你的cache设定一个时间即可，那么你就不需要去等待系统时间了。\n\n### Reference-based Eviction\nGuava为你准备了entries的垃圾回收器，对于keys或者values可以使用`weak reference` ，对于values可以使用 `soft reference`.\n\n`CacheBuilder.weakKeys()`通过weak reference存储keys。在这种情况下，如果keys没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个key的，而不是equals();\n\n`CacheBuilder.weakValues()`  通过weak referene 存储values.在这种情况下，如果valves没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个values的，而不是equals();\nCacheBuilder.softValues() \n\n### Explicit Removals\n也许在某年某月某天你不想再等cache释放entries，而是自己能手动的去释放掉这些entries，下面三个方法会帮助你\n* 单个释放：Cache.invalidate(key)\n* 多个释放：Cache.invalidateAll(keys)\n* 全部释放：Cache.invalidateAll()\n\n### Removal Listeners\ncache允许你指定一个removal listener监听entry的移除操作(例如`CacheBuilder.removalListener(RemovalListener)`).通过R`emovaNotification`获得的`RemovalListener`制定了RemovalCause,key和value`。\n\n>注意RemovalListener抛出的任何异常都会被Logger记录然后被丢弃\n\n```java\nCacheLoader<Key, DatabaseConnection> loader = new CacheLoader<Key, DatabaseConnection> () {  \n  public DatabaseConnection load(Key key) throws Exception {  \n    return openConnection(key);  \n  }  \n};  \nRemovalListener<Key, DatabaseConnection> removalListener = new RemovalListener<Key, DatabaseConnection>() {  \n  public void onRemoval(RemovalNotification<Key, DatabaseConnection> removal) {  \n    DatabaseConnection conn = removal.getValue();  \n    conn.close(); // tear down properly  \n  }  \n};  \n  \nreturn CacheBuilder.newBuilder()  \n  .expireAfterWrite(2, TimeUnit.MINUTES)  \n  .removalListener(removalListener)  \n  .build(loader);  \n```\n警告：removal listeners是被默认同步执行的，而且cache的维护是在其普通操作中维护的，那么“昂贵的”removal listener会降低cache操作(某些方法)的效率。如果你在使用一个\"昂贵的\"removal listener，你可以使用RemovalListener.asynchronous(RemovalListener,Executor),将其布置成异步操作.\n","slug":"工具/CachesExplained","published":1,"updated":"2015-10-20T08:53:24.794Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxst00240cufuf22qp37"},{"date":"2015-09-07T16:00:00.000Z","title":"Archiva","_content":"\n## 安装步骤\n1. 从[Archiva官网]()下载Archiva后解压到`D:\\archiva`里\n2. 运行`bin\\archiva.bat install`, archiva就启动成功了\n3. 在浏览器运行`http://localhost:8080/`就可以进入archiva本地主页了\n4. 当进入之后我们需要创建一个账号：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/0.jpg)\n5. 接着我们创建一个私有的仓库![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/1.jpg)\n6. 我们创建一个最简单的私有仓库：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/2.jpg)\n7. 创建一个连接器![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/3.jpg)\n8. 同样我们只选用必须的![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/4.jpg)\n9. 接着如图操作![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/5.jpg)\n10. 然后我们修改项目中的`pom.xml`文件!\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>testMaven</groupId>\n    <artifactId>testDeply</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <distributionManagement>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </distributionManagement>\n</project>\n```\n11. 修改本地仓库中的`setting.xml`文件(我的目录`C:\\Users\\Administrator\\.m2`),我们添加私有仓库的用户名和密码!\n```xml\n<settings xmlns=\"http://maven.apache.org/settings/1.0.0\" \n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n   \n\t<servers>\n        <server>\n            <id>ID2015_09_17</id>\n            <username>admin</username>\n            <password>admin1</password>\n        </server>\n    </servers>\n  \n </settings>\n ```\n\n\n","source":"_posts/工具/Archiva.md","raw":"category: 工具\ndate: 2015-09-08\ntitle: Archiva\n---\n\n## 安装步骤\n1. 从[Archiva官网]()下载Archiva后解压到`D:\\archiva`里\n2. 运行`bin\\archiva.bat install`, archiva就启动成功了\n3. 在浏览器运行`http://localhost:8080/`就可以进入archiva本地主页了\n4. 当进入之后我们需要创建一个账号：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/0.jpg)\n5. 接着我们创建一个私有的仓库![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/1.jpg)\n6. 我们创建一个最简单的私有仓库：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/2.jpg)\n7. 创建一个连接器![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/3.jpg)\n8. 同样我们只选用必须的![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/4.jpg)\n9. 接着如图操作![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/5.jpg)\n10. 然后我们修改项目中的`pom.xml`文件!\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>testMaven</groupId>\n    <artifactId>testDeply</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <distributionManagement>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </distributionManagement>\n</project>\n```\n11. 修改本地仓库中的`setting.xml`文件(我的目录`C:\\Users\\Administrator\\.m2`),我们添加私有仓库的用户名和密码!\n```xml\n<settings xmlns=\"http://maven.apache.org/settings/1.0.0\" \n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n   \n\t<servers>\n        <server>\n            <id>ID2015_09_17</id>\n            <username>admin</username>\n            <password>admin1</password>\n        </server>\n    </servers>\n  \n </settings>\n ```\n\n\n","slug":"工具/Archiva","published":1,"updated":"2015-10-14T01:54:42.168Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsv00260cufo382c9ap"},{"date":"2014-10-07T16:00:00.000Z","title":"类加载机制","_content":"## 类加载机制\n\n### 生命周期\n类从被加载进虚拟机内存开始到卸载出内存的生命周期:\n```java\n  1. 加载\n  2. 验证\n  3. 准备\n  4. 解析\n  5. 初始化\n  6. 使用\n  7. 卸载\n```\n\n> 特殊说明\n> 2.验证, 3.准备, 4.解析 又称为连接阶段\n> 1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载\n\n\n### 加载:\n加载的过程其实就是将class文件字节码加载进虚拟机的方法区中(方法区中数据格式由虚拟机定义),然后在堆中实例化对其实例化一个`java.lang.Class`对象,然后程序使用该对象访问存储在方法区里的类型数据.\n\n虚拟机通过下面三个阶段完成一个类的加载过程\n1. 通过一个类的全限定名来获取此类的二进制流.\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构\n3. 在java堆中生成一个代表这个类的`java.class.Class`对象.\n\n类的加载过程必须完成以上三个过程但是这三个阶段并没有具体说明从哪里获取以及如何获取类的字节码,我们可以使用系统提供的类加载器或者自定义类加载器完成读取二进制流的动作.\n\n加载阶段与连接阶段开始时间顺序是一定的,但是加载阶段可能还没完成,连接阶段就已经开始了,但这些夹在加载阶段的动作,仍然属于连接阶段的内容.\n\n### 验证:\n验证阶段是为了确保Class文件的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全.java语言本身是相对安全的语言,使用纯粹的java代码无法做到诸如访问数组边界以外的数据,将一个对象转型为它并未实现的类型,跳转到不存在的代码之类的事情,如果这样做了,编译器将拒绝编译. 在字节码层面上, 上述java代码无法做到的事情是可以实现的,至少语义上是可以表达的. 虚拟机如果不检查输入的字节流,对其完全信任的话,很可能会输入有害的字节流而导致系统崩溃.\n\n#### 校验过程\n##### class文件格式验证\n保证输入的字节流能正确地解析并存储于方法区之内.确保符合Class文件规范,且能被当前版本的虚拟机处理.\n\n1. 是否以魔术0xCAFEBABY 开头\n2. 主次版本号是否在当前虚拟机处理范围内.\n3. 常量池中是否有不被支持的常量类型(检查常量tag标志)\n4. ... 还有很多其他校验\n\n##### 元数据验证  \n基于方法区的数据结构进行语义分析验证,以便符合java语言规范. 基本上就是在检验数据类型\n\n1. 这个类是否是父类.\n2. 这个类是否继承了不允许继承的类(被final修饰的类)\n3. 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法\n4. ... 还有很多其他校验\n\n##### 字节码验证\n基于方法区的数据结构,基本上是在对方法体进行验证.这个校验是整个验证过程中最复杂的一个阶段,主要是针对数据流和控制流进行分析. 在对元数据信息的数据类型做完校验后,这阶段对类的方法体进行校验.\n\n1. 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表.\n2. 保证跳转指令不会跳转到方法体以外的字节码指令上\n3. ...  还有很多其他校验\n\n在JDK1.6之后javac编译器进行了一项优化, 给方法体的Code属性的属性表中增加了一项\"StackMapTable\"属性,这项属性描述了方法体中所有的基本块(Basic Block,按照控制流拆分的代码块) 开始时本地变量表和操作数栈应有的状态, 这可以将字节码验证的类型推导转变为类型检查从而节省一些时间.\n\n##### 符号引用验证\n符号引用的校验是确保解析动作能正常执行.最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验\n\n1. 符号引用通过字符串描述的全限定名是否能找到对应的类\n2. 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段\n3. ... 还有很多其他的校验\n\n### 3. 准备\n\n准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些内存都将在方法区中进行分配. 这个阶段中有俩个容易产生混淆的概念需要强调一下,首先是这时候进行内存分配的仅包括类变量,而不包括实例变量,实例变量将会在对象实例化时随着对象\n一起分配在java堆中. 其中是这里所说的初始值\"通常情况\"下是数据类型为0.例如:\n```java\npublic static int value = 123;\n```\n\n变量value在准备阶段初始值为0而不是123,因为这时候尚未开始执行任何java方法,而把value赋值为123的putstatic指令是程序编译后,存放于类构造器<clinit>()方法之中,所以value赋值123的动作将在初始化阶段才会被执行.但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值.\n\n\n### 4. 解析\n\n解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量)\n\n1. 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中.\n2. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在.\n\n#### 解析时间\n\n虚拟机并没有规定解析阶段发生的具体时间,只要求在`anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic`这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析.所以虚拟机会根据需要来判断,到底是在类被加载器加载时对常量池的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它.\n\n#### 多次解析\n\n对同一个符号引用进行多次解析请求是很常见的,虚拟机实现可能会对第一次解析的结果进行缓存(在运行时常量池中记录直接引用,并发常量标志为已解析状态)从而避免重复解析动作.无论是否真正执行了多次解析动作,虚拟机需要保证的都是在同一个实体中,如果一个符号引用之前已经被成功解析过,那么后续的引用解析请求就应当一直成功,同样,如果第一次解析失败,其他指令对这个符号的解析请求也应当收到相同的异常.下面将讲解四种引用的解析过程\n\n#### 解析过程\n##### 类或接口解析(CONSTANT_Class_info)\n\n假设当前代码所处的类为D,如果把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,虚拟机完成整个解析需要以下步骤\n\n1. 如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C.在加载过程中,由于元数据验证,字节码验证的需要,又将可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将宣告失败.\n\n2. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似\"[Ljava.lang.Integer\"的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是\"java.lang.Integer\",接着由虚拟机生成一个代表此数组维度和元素的数组对象\n\n3. 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出\"java.lang.IllegalAccessError\"异常\n\n##### 字段解析(CONSTANT_Fieldref_info)\n\n要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用. 如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示.\n\n1. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束\n\n2. 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n3. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n4. 否则,查找失败,抛出java.lang.NoSuchFieldError异常\n\n如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出\"java.lang.IllegalAccessError\"异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译~.\n\n##### 类方法解析(CONSTANT_Methodref_info)\n\n类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类.\n\n1. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError.\n\n2. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束.\n\n3. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束\n\n4. 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常\n\n5. 否则,宣告查找失败,抛出java.lang.NoSuchMethodError.\n\n最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError\n\n##### 接口方法解析(CONSTANT_InterfaceMethodref_info)\n\n接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口:\n\n1. 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常.\n\n2. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n3. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n4. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常\n\n由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出\"java.lang.IllegalAccessError\"异常\n\n### 5. 类的初始化\n\n类初始化阶段是类加载过程中最后一步,前面的类加载过程中,除了加载阶段用户应用程序可以通过自定义类加载参与之外,其余动作全部由虚拟机主导和控制.到了初始化阶段才真正开始执行类中定义的java字节码.\n\n在准备阶段,变量已经赋值过一次系统要求的初始值,而在初始阶段,则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源,或者可以从另一个角度来表达: 初始化阶段执行类构造器<clinit>方法的过程.\n\n#### <clinit>方法执行过程可能会影响程序运行行为的一些特点和细节\n\n1. <clinit>方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问.\n\n2. <clinit>()方法和实例的构造函数(<init>)不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的<clinit>()方法执行之前,父类的<clinit>方法已经执行完毕,因此虚拟机中第一个被执行的<clinit>()方法的类肯定是java.lang.Object\n\n3. 由于父类的<clinit>()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作\n\n4. <clinit>()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<clinit>()方法.\n\n5. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成<clinit>()方法.但接口与类不同的是,执行接口<clinit>方法不需要先执行父接口<clinit>()方法.只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的<clinit>()方法.\n\n6. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的<clinit>()方法,其他线程都需要阻塞等待,直到活动线程执行<clinit>()方法完毕. 如果,在一个类的<clinit>()方法中有耗时很长的操作,那就很可能造成多个进程阻塞.\n\n###### <clinit>方法执行顺序\n```java\n    public class NewClass {\n\n    static class Parent {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent {\n        public static int B = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n\n```\n###### 字段解析\n```java\n    public class DeadLoopClass {\n\n    static {\n        if(true) {\n            System.out.println(Thread.currentThread() + \" init DeadLoopClass \");\n            while(true){}\n        }\n    }\n\n    public static void main(String[] args) {\n        Runnable script = new Runnable() {\n\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread() + \" start\");\n                DeadLoopClass dlc = new DeadLoopClass();\n                System.out.println(Thread.currentThread() + \" run over\");\n            }\n\n        };\n\n        Thread t1 = new Thread(script);\n        Thread t2 = new Thread(script);\n        t1.start();\n        t2.start();\n    }\n}\n\n```\n#### 对类进行初始化的四种情况\n\n1. 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化\n\n2. 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化\n\n3. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化.\n\n4. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类.\n\n#### 被动引用的例子1\n```java\n/**\n *\n * 通过子类引用父类的静态字段,不会导致子类的类初始化\n */\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n\n\n}\n\nclass SubClass extends SuperClass {\n    static {\n        System.out.println(\"SubClass init\");\n    }\n}\n\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(SubClass.value);\n    }\n}\n```\n###### 被动引用的例子2\n```java\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n}\n\n/**\n *\n * 通过数组定义来引用类,不会触发此类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        SuperClass[] sca = new SuperClass[10];\n    }\n}\n```\n###### 被动引用的例子3\n```java\nclass ConstClass {\n    static {\n        System.out.println(\"ConstClass init\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n}\n/**\n *\n * 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,\n * 因此不会触发定义常量的类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n```\n\n# 类加载器\n\n## 类和类加载器\n\n### 类加载器的意义\n\n类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等.\n\n### 类加载器相等判断\n\n判断俩个类相等可以通过下面方法: Class对象的equals()方法, isAssignbleFrom()方法, isInstance()方法的返回结果, 也包括使用instanceof关键字做对象所属关系判断等.\n\n不同的类加载器对instanceof关键字运算结果的影响\n```java\npublic class ClassLoaderTest {\n\n\tpublic static void main(String args) throws Exception {\n\n\t\tClassLoader myLoader = new ClassLoader() {\n\n\t\t\t@Override\n\t\t\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\t\t\ttry{\n\t\t\t\t\tint index = name.lastIndexOf(\".\") + 1;\n\t\t\t\t\tString fileName = name.substring(index) + \".class\";\n\t\t\t\t\tInputStream in = getClass().getResourceAsStream(fileName);\n\t\t\t\t\tif(in == null) {\n\t\t\t\t\t\treturn super.loadClass(name);\n\t\t\t\t\t}\n\n\t\t\t\t\tbyte[] b = new byte[in.available()];\n\t\t\t\t\tin.read(b);\n\t\t\t\t\treturn defineClass(name, b, 0, b.length);\n\t\t\t\t} catch(IOException e) {\n\t\t\t\t\tthrow new ClassNotFoundException(name);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tObject obj = myLoader.loadClass(ClassLoaderTest.class.getCanonicalName()).newInstance();\n\t\tSystem.out.println(obj.getClass());\n\t\tSystem.out.println(obj instanceof ClassLoaderTest);\n\t}\n}\n```\n\n### URLClassLoader\n该类加载器根据`URL`指定的路径从`JAR`文件或者目录里加载`class`文件或者其他资源文件. 如果`URL`以`/`结束,就表示到某个目录里进行加载. 否则就表示到某个`JAR`文件里进行加载. 线程里用于创建`URLClassLoader`实例的`AccessControlContext`会在加载类文件以及资源文件时使用到. `URLClassLoader`实例创建好之后会根据默认的授权权限依据指定的`URL`来进行加载类.\n\n\n## 双亲委派模型\n\n![ClassLoader的体系架构](/images/ClassLoader的体系架构.png)\n从JVM来角度讲, 只存在俩种不同的类加载器:\n* 启动类加载器: 使用C++语言实践,是虚拟机自身的一部分. \n* 其他类加载器: 这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:`java.lang.ClassLoader`\n\n如果一个类加载器收到了类加载的请求,它首先不会自己去尝试加载这个类,而是把这个请求委派给父类加载器去完成,每一个层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载.\n\n使用双亲委派模型来组织类加载之间的关系,有一个显而易见的好处就是java类随着它的类加载一起具备了一种带有优先级的层次关系.例如类 `java.lang.Object`,它存放在`rt.jar`之中,无论哪一个类加载要加载这个类,最终都是委派给启动类加载器进行加载,因此Object类在程序的各种类加载器环境中都是同一个类.\n\n相反,如果没有使用双亲委派模型,由各个类加载器自行去加载的话,如果用户自己写了一个名为`java.lang.Object`的类,并放在程序ClassPath中,那系统中将会出现多个不同的Object类,java类型体系中最基础的行为也就无从保证,应用程序也将会变得一片混乱. (可以自己试试写一个与rt.jar类库中已有类重名的java类,将会发现可以正常编译,但永远无法被加载运行).\n\n### 系统提供的类加载器\n* 启动类加载器 : 这个类加载器负责将`<JAVA_HOME>\\lib`目录中的,或者`-Xbootclasspath`参数所指定的路径中的,并且是虚拟机识别的(仅按照文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法被java程序直接使用.\n* 扩展类加载器 : 这个类加载器由`sun.misc.Launcher$ExtClassLoader`实现,负责加载`<JAVA_HOME>\\lib\\ext`目录中的,或者被`java.ext.dirs`系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器.\n* 应用程序加载器 : 这个类加载器由`sun.misc.Launcher$AppClassLoader`来实现. 由于类加载器是`ClassLoader`中`getSystemClassLoader()`方法的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器.\n\n### 破坏双亲委派模型\n为了向前兼容,JDK1.2之后的`java.lang.ClassLoader`添加了一个新的protected方法`findClass()`,应当把自己的类加载逻辑写到`findClass()`方法中,JDK1.2之后已不提倡用户再去覆盖`loadClass()`方法,而在`loadClass()`方法的逻辑里如果父类加载失败,则会调用自己的`findClass()`方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的.\n> 在JDK1.2之前,用户去继承`java.lang.ClassLoader`的唯一目的就是为了重写`loadClass()`方法,因此虚拟机在进行类加载的时候会调用加载器的私有方法`loadClassInternal()`,而这个类的唯一逻辑就是去调用自己的`loadClass()`.\n\n为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过`java.lang.Thread`类的`setContextClassLoaser()`方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则.\n\n\n\n\n\n\n\n\n\n","source":"_posts/jvm7/类加载.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: 类加载机制\n---\n## 类加载机制\n\n### 生命周期\n类从被加载进虚拟机内存开始到卸载出内存的生命周期:\n```java\n  1. 加载\n  2. 验证\n  3. 准备\n  4. 解析\n  5. 初始化\n  6. 使用\n  7. 卸载\n```\n\n> 特殊说明\n> 2.验证, 3.准备, 4.解析 又称为连接阶段\n> 1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载\n\n\n### 加载:\n加载的过程其实就是将class文件字节码加载进虚拟机的方法区中(方法区中数据格式由虚拟机定义),然后在堆中实例化对其实例化一个`java.lang.Class`对象,然后程序使用该对象访问存储在方法区里的类型数据.\n\n虚拟机通过下面三个阶段完成一个类的加载过程\n1. 通过一个类的全限定名来获取此类的二进制流.\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构\n3. 在java堆中生成一个代表这个类的`java.class.Class`对象.\n\n类的加载过程必须完成以上三个过程但是这三个阶段并没有具体说明从哪里获取以及如何获取类的字节码,我们可以使用系统提供的类加载器或者自定义类加载器完成读取二进制流的动作.\n\n加载阶段与连接阶段开始时间顺序是一定的,但是加载阶段可能还没完成,连接阶段就已经开始了,但这些夹在加载阶段的动作,仍然属于连接阶段的内容.\n\n### 验证:\n验证阶段是为了确保Class文件的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全.java语言本身是相对安全的语言,使用纯粹的java代码无法做到诸如访问数组边界以外的数据,将一个对象转型为它并未实现的类型,跳转到不存在的代码之类的事情,如果这样做了,编译器将拒绝编译. 在字节码层面上, 上述java代码无法做到的事情是可以实现的,至少语义上是可以表达的. 虚拟机如果不检查输入的字节流,对其完全信任的话,很可能会输入有害的字节流而导致系统崩溃.\n\n#### 校验过程\n##### class文件格式验证\n保证输入的字节流能正确地解析并存储于方法区之内.确保符合Class文件规范,且能被当前版本的虚拟机处理.\n\n1. 是否以魔术0xCAFEBABY 开头\n2. 主次版本号是否在当前虚拟机处理范围内.\n3. 常量池中是否有不被支持的常量类型(检查常量tag标志)\n4. ... 还有很多其他校验\n\n##### 元数据验证  \n基于方法区的数据结构进行语义分析验证,以便符合java语言规范. 基本上就是在检验数据类型\n\n1. 这个类是否是父类.\n2. 这个类是否继承了不允许继承的类(被final修饰的类)\n3. 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法\n4. ... 还有很多其他校验\n\n##### 字节码验证\n基于方法区的数据结构,基本上是在对方法体进行验证.这个校验是整个验证过程中最复杂的一个阶段,主要是针对数据流和控制流进行分析. 在对元数据信息的数据类型做完校验后,这阶段对类的方法体进行校验.\n\n1. 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表.\n2. 保证跳转指令不会跳转到方法体以外的字节码指令上\n3. ...  还有很多其他校验\n\n在JDK1.6之后javac编译器进行了一项优化, 给方法体的Code属性的属性表中增加了一项\"StackMapTable\"属性,这项属性描述了方法体中所有的基本块(Basic Block,按照控制流拆分的代码块) 开始时本地变量表和操作数栈应有的状态, 这可以将字节码验证的类型推导转变为类型检查从而节省一些时间.\n\n##### 符号引用验证\n符号引用的校验是确保解析动作能正常执行.最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验\n\n1. 符号引用通过字符串描述的全限定名是否能找到对应的类\n2. 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段\n3. ... 还有很多其他的校验\n\n### 3. 准备\n\n准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些内存都将在方法区中进行分配. 这个阶段中有俩个容易产生混淆的概念需要强调一下,首先是这时候进行内存分配的仅包括类变量,而不包括实例变量,实例变量将会在对象实例化时随着对象\n一起分配在java堆中. 其中是这里所说的初始值\"通常情况\"下是数据类型为0.例如:\n```java\npublic static int value = 123;\n```\n\n变量value在准备阶段初始值为0而不是123,因为这时候尚未开始执行任何java方法,而把value赋值为123的putstatic指令是程序编译后,存放于类构造器<clinit>()方法之中,所以value赋值123的动作将在初始化阶段才会被执行.但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值.\n\n\n### 4. 解析\n\n解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量)\n\n1. 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中.\n2. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在.\n\n#### 解析时间\n\n虚拟机并没有规定解析阶段发生的具体时间,只要求在`anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic`这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析.所以虚拟机会根据需要来判断,到底是在类被加载器加载时对常量池的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它.\n\n#### 多次解析\n\n对同一个符号引用进行多次解析请求是很常见的,虚拟机实现可能会对第一次解析的结果进行缓存(在运行时常量池中记录直接引用,并发常量标志为已解析状态)从而避免重复解析动作.无论是否真正执行了多次解析动作,虚拟机需要保证的都是在同一个实体中,如果一个符号引用之前已经被成功解析过,那么后续的引用解析请求就应当一直成功,同样,如果第一次解析失败,其他指令对这个符号的解析请求也应当收到相同的异常.下面将讲解四种引用的解析过程\n\n#### 解析过程\n##### 类或接口解析(CONSTANT_Class_info)\n\n假设当前代码所处的类为D,如果把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,虚拟机完成整个解析需要以下步骤\n\n1. 如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C.在加载过程中,由于元数据验证,字节码验证的需要,又将可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将宣告失败.\n\n2. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似\"[Ljava.lang.Integer\"的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是\"java.lang.Integer\",接着由虚拟机生成一个代表此数组维度和元素的数组对象\n\n3. 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出\"java.lang.IllegalAccessError\"异常\n\n##### 字段解析(CONSTANT_Fieldref_info)\n\n要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用. 如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示.\n\n1. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束\n\n2. 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n3. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n4. 否则,查找失败,抛出java.lang.NoSuchFieldError异常\n\n如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出\"java.lang.IllegalAccessError\"异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译~.\n\n##### 类方法解析(CONSTANT_Methodref_info)\n\n类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类.\n\n1. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError.\n\n2. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束.\n\n3. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束\n\n4. 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常\n\n5. 否则,宣告查找失败,抛出java.lang.NoSuchMethodError.\n\n最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError\n\n##### 接口方法解析(CONSTANT_InterfaceMethodref_info)\n\n接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口:\n\n1. 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常.\n\n2. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n3. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n4. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常\n\n由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出\"java.lang.IllegalAccessError\"异常\n\n### 5. 类的初始化\n\n类初始化阶段是类加载过程中最后一步,前面的类加载过程中,除了加载阶段用户应用程序可以通过自定义类加载参与之外,其余动作全部由虚拟机主导和控制.到了初始化阶段才真正开始执行类中定义的java字节码.\n\n在准备阶段,变量已经赋值过一次系统要求的初始值,而在初始阶段,则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源,或者可以从另一个角度来表达: 初始化阶段执行类构造器<clinit>方法的过程.\n\n#### <clinit>方法执行过程可能会影响程序运行行为的一些特点和细节\n\n1. <clinit>方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问.\n\n2. <clinit>()方法和实例的构造函数(<init>)不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的<clinit>()方法执行之前,父类的<clinit>方法已经执行完毕,因此虚拟机中第一个被执行的<clinit>()方法的类肯定是java.lang.Object\n\n3. 由于父类的<clinit>()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作\n\n4. <clinit>()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<clinit>()方法.\n\n5. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成<clinit>()方法.但接口与类不同的是,执行接口<clinit>方法不需要先执行父接口<clinit>()方法.只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的<clinit>()方法.\n\n6. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的<clinit>()方法,其他线程都需要阻塞等待,直到活动线程执行<clinit>()方法完毕. 如果,在一个类的<clinit>()方法中有耗时很长的操作,那就很可能造成多个进程阻塞.\n\n###### <clinit>方法执行顺序\n```java\n    public class NewClass {\n\n    static class Parent {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent {\n        public static int B = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n\n```\n###### 字段解析\n```java\n    public class DeadLoopClass {\n\n    static {\n        if(true) {\n            System.out.println(Thread.currentThread() + \" init DeadLoopClass \");\n            while(true){}\n        }\n    }\n\n    public static void main(String[] args) {\n        Runnable script = new Runnable() {\n\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread() + \" start\");\n                DeadLoopClass dlc = new DeadLoopClass();\n                System.out.println(Thread.currentThread() + \" run over\");\n            }\n\n        };\n\n        Thread t1 = new Thread(script);\n        Thread t2 = new Thread(script);\n        t1.start();\n        t2.start();\n    }\n}\n\n```\n#### 对类进行初始化的四种情况\n\n1. 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化\n\n2. 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化\n\n3. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化.\n\n4. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类.\n\n#### 被动引用的例子1\n```java\n/**\n *\n * 通过子类引用父类的静态字段,不会导致子类的类初始化\n */\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n\n\n}\n\nclass SubClass extends SuperClass {\n    static {\n        System.out.println(\"SubClass init\");\n    }\n}\n\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(SubClass.value);\n    }\n}\n```\n###### 被动引用的例子2\n```java\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n}\n\n/**\n *\n * 通过数组定义来引用类,不会触发此类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        SuperClass[] sca = new SuperClass[10];\n    }\n}\n```\n###### 被动引用的例子3\n```java\nclass ConstClass {\n    static {\n        System.out.println(\"ConstClass init\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n}\n/**\n *\n * 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,\n * 因此不会触发定义常量的类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n```\n\n# 类加载器\n\n## 类和类加载器\n\n### 类加载器的意义\n\n类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等.\n\n### 类加载器相等判断\n\n判断俩个类相等可以通过下面方法: Class对象的equals()方法, isAssignbleFrom()方法, isInstance()方法的返回结果, 也包括使用instanceof关键字做对象所属关系判断等.\n\n不同的类加载器对instanceof关键字运算结果的影响\n```java\npublic class ClassLoaderTest {\n\n\tpublic static void main(String args) throws Exception {\n\n\t\tClassLoader myLoader = new ClassLoader() {\n\n\t\t\t@Override\n\t\t\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\t\t\ttry{\n\t\t\t\t\tint index = name.lastIndexOf(\".\") + 1;\n\t\t\t\t\tString fileName = name.substring(index) + \".class\";\n\t\t\t\t\tInputStream in = getClass().getResourceAsStream(fileName);\n\t\t\t\t\tif(in == null) {\n\t\t\t\t\t\treturn super.loadClass(name);\n\t\t\t\t\t}\n\n\t\t\t\t\tbyte[] b = new byte[in.available()];\n\t\t\t\t\tin.read(b);\n\t\t\t\t\treturn defineClass(name, b, 0, b.length);\n\t\t\t\t} catch(IOException e) {\n\t\t\t\t\tthrow new ClassNotFoundException(name);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tObject obj = myLoader.loadClass(ClassLoaderTest.class.getCanonicalName()).newInstance();\n\t\tSystem.out.println(obj.getClass());\n\t\tSystem.out.println(obj instanceof ClassLoaderTest);\n\t}\n}\n```\n\n### URLClassLoader\n该类加载器根据`URL`指定的路径从`JAR`文件或者目录里加载`class`文件或者其他资源文件. 如果`URL`以`/`结束,就表示到某个目录里进行加载. 否则就表示到某个`JAR`文件里进行加载. 线程里用于创建`URLClassLoader`实例的`AccessControlContext`会在加载类文件以及资源文件时使用到. `URLClassLoader`实例创建好之后会根据默认的授权权限依据指定的`URL`来进行加载类.\n\n\n## 双亲委派模型\n\n![ClassLoader的体系架构](/images/ClassLoader的体系架构.png)\n从JVM来角度讲, 只存在俩种不同的类加载器:\n* 启动类加载器: 使用C++语言实践,是虚拟机自身的一部分. \n* 其他类加载器: 这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:`java.lang.ClassLoader`\n\n如果一个类加载器收到了类加载的请求,它首先不会自己去尝试加载这个类,而是把这个请求委派给父类加载器去完成,每一个层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载.\n\n使用双亲委派模型来组织类加载之间的关系,有一个显而易见的好处就是java类随着它的类加载一起具备了一种带有优先级的层次关系.例如类 `java.lang.Object`,它存放在`rt.jar`之中,无论哪一个类加载要加载这个类,最终都是委派给启动类加载器进行加载,因此Object类在程序的各种类加载器环境中都是同一个类.\n\n相反,如果没有使用双亲委派模型,由各个类加载器自行去加载的话,如果用户自己写了一个名为`java.lang.Object`的类,并放在程序ClassPath中,那系统中将会出现多个不同的Object类,java类型体系中最基础的行为也就无从保证,应用程序也将会变得一片混乱. (可以自己试试写一个与rt.jar类库中已有类重名的java类,将会发现可以正常编译,但永远无法被加载运行).\n\n### 系统提供的类加载器\n* 启动类加载器 : 这个类加载器负责将`<JAVA_HOME>\\lib`目录中的,或者`-Xbootclasspath`参数所指定的路径中的,并且是虚拟机识别的(仅按照文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法被java程序直接使用.\n* 扩展类加载器 : 这个类加载器由`sun.misc.Launcher$ExtClassLoader`实现,负责加载`<JAVA_HOME>\\lib\\ext`目录中的,或者被`java.ext.dirs`系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器.\n* 应用程序加载器 : 这个类加载器由`sun.misc.Launcher$AppClassLoader`来实现. 由于类加载器是`ClassLoader`中`getSystemClassLoader()`方法的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器.\n\n### 破坏双亲委派模型\n为了向前兼容,JDK1.2之后的`java.lang.ClassLoader`添加了一个新的protected方法`findClass()`,应当把自己的类加载逻辑写到`findClass()`方法中,JDK1.2之后已不提倡用户再去覆盖`loadClass()`方法,而在`loadClass()`方法的逻辑里如果父类加载失败,则会调用自己的`findClass()`方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的.\n> 在JDK1.2之前,用户去继承`java.lang.ClassLoader`的唯一目的就是为了重写`loadClass()`方法,因此虚拟机在进行类加载的时候会调用加载器的私有方法`loadClassInternal()`,而这个类的唯一逻辑就是去调用自己的`loadClass()`.\n\n为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过`java.lang.Thread`类的`setContextClassLoaser()`方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则.\n\n\n\n\n\n\n\n\n\n","slug":"jvm7/类加载","published":1,"updated":"2015-10-30T10:32:04.355Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsx00280cufapklena7"},{"date":"2014-10-07T16:00:00.000Z","title":"字节码指令","_content":"## 字节码指令\n### 虚拟机指令集所支持的数据类型\n\n|操作码    |byte   |short  |int     |long   |float  |double |char   |refernce |\n|---------|------:|------:|-------:|------:|------:|------:|------:|--------:|\n|Tipush   |bipush |sipush |        |       |       |       |       |         |\n|Tconst   |       |       |iconst  |lconst |fconst |dconst |       |aconst   |\n|Tload    |       |       |iload   |lload  |fload  |dload  |       |aload    |\n|Tstore   |       |       |store   |lstore |fstore |dstore |cstore |astore   |\n|Tinc     |       |       |iinc    |       |       |       |       |         |\n|Taload   |baload |saload |iaload  |laload |faload |daload |caload |aaload   |\n|Tastore  |bastore|sastore|iastore |lastore|fastore|dastore|castore|aastore  |\n|Tadd     |       |       |iadd    |ladd   |fadd   |dadd   |       |         |\n|Tsub     |       |       |isub    |lsub   |fsub   |dsub   |       |         |\n|Tmul     |       |       |imul    |lmul   |fmul   |dmul   |       |         |\n|Tdiv     |       |       |idiv    |ldiv   |fdiv   |ddiv   |       |         |\n|Trem     |       |       |irem    |lrem   |frem   |drem   |       |         |\n|Tneg     |       |       |ineg    |lneg   |fneg   |dneg   |       |         |\n|Tshl     |       |       |ishl    |lshl   |       |       |       |         |\n|Tshr     |       |       |ishr    |lshr   |       |       |       |         |\n|Tushr    |       |       |iushr   |lushr  |       |       |       |         |\n|Tand     |       |       |iand    |land   |       |       |       |         |\n|Tor      |       |       |ior     |lor    |       |       |       |         |\n|Txor     |       |       |ixor    |lxor   |       |       |       |         |\n|i2T      |i2b    |i2s    |        |i2l    |i2f    |i2d    |       |         |\n|l2T      |       |       |l2i     |       |l2f    |l2d    |       |         |\n|f2T      |       |       |f2i     |f2l    |       |f2d    |       |         |\n|d2T      |       |       |d2i     |d2l    |d2f    |       |       |         |\n|Tcmp     |       |       |        |lcmp   |       |       |       |         |\n|Tcmpl    |       |       |        |       |fcmpl  |dcmpl  |       |         |\n|if_TcmpOP|       |       |if_icmOP|       |       |       |       |if_acmpOP|\n|Treturn  |       |       |ireturn |lreturn|freturn|dreturn|       |areturn  |\n\n\n### 加载和存储指令\n* 加载和存储指令用于将数据从栈帧的本地变量表和操作数栈之间来回传递\n* 将一个本地变量加载到操作数栈的指令有:\n```\n  1. iload,\n  2. iload_<n>,\n  3. lload,\n  4. lload_<n>,\n  5. fload,\n  6. fload_<n>,\n  7. dload,\n  8. dload_<n>,\n  9. aload       从局部变量表加载一个reference类型值到操作数栈\n  10. aload_<n>  从局部变量表加载一个reference类型值到操作数栈\n  11. caload     从数组中加载一个char类型数据到操作数栈\n```\n* 将一个数值从操作数栈存储到局部变量表的指令有:\n```\n  1. istore\n  2. istore_<n>\n  3. lstore\n  4. lstore_<n>\n  5. fstore\n  6. fstore_<n>\n  7. dstore\n  8. dstore_<n>\n  9. astore       将一个reference类型数据保存到本地变量表\n  10. astore_<n>  将一个reference类型数据保存到本地变量表\n```\n* 将一个常量加载到操作数栈的指令有:\n```\n  1. bipush       将一个byte类型数据入栈\n  2. sipush\n  3. ldc\n  4. ldc_w\n  5. ldc2_w\n  6. aconst_null   将一个null值入栈到操作数栈中.\n  7. iconst_m1\n  8. iconst_<i>\n  9. locnst_<l>\n  10. fconst_<f>\n  11. dconst_<d>\n```\n* 以上指令中有部分是以尖括号为结尾的,这种代表了一组指令, 例如iload_1, iload_2, 等等. 他们表面上没有操作数, 不需要进行取操作数的动作,但操作数都包含在指令中\n\n### 算数指令\n* 算数指令是对俩个操作数栈上的值进行某种特定运算,然后把结构重新压入操作数栈.\n* 加法指令\n```\n  1.  iadd\n  2.  ladd\n  3.  fadd\n  4.  dadd\n```\n* 减法指令\n```\n  1.  isub\n  2.  lsub\n  3.  fsub\n  4.  dsub\n```\n* 乘法指令\n```\n  1.  imul\n  2.  lmul\n  3.  fmul\n  4.  dmul\n```\n* 除法指令\n```\n  1.  idiv\n  2.  ldiv\n  3.  fdiv\n  4.  ddiv\n```\n* 求余指令\n```\n  1.  irem\n  2.  lrem\n  3.  frem\n  4.  drem\n```\n* 取反指令\n```\n  1.  ineg\n  2.  lneg\n  3.  dneg\n  4.  dneg\n```\n* 位移指令\n```\n  1.  ishl\n  2.  ishr\n  3.  iushr\n  4.  lshl\n  5.  lshr\n  6.  lushr\n```\n* 按位或指令\n```\n  1.  ior\n  2.  lor\n```\n* 按位与指令\n```\n  1.  iand\n  2.  land\n```\n* 按位异或指令\n```\n  1.  ixor\n  2.  lxor\n```\n* 局部变量自增指令\n```\n  1.  iinc\n```\n* 比较之类\n```\n  1.  dcmpg\n  2.  dcmpl\n  3.  fcmpg\n  4.  fcmpl\n  5.  lcmp\n```\n\n### 类型转换指令\n* 可以将俩种java虚拟机数值类型进行相互转换\n* 这些转换指令一般用于实现用户代码的显示类型转换或用来处理虚拟机字节码指令集中指令的非完全独立的问题\n* 宽化类型转换:\n```\n  1. 从int类型到long, float, double类型. i2l和i2d 指令都不会丢失精确度,但是i2f可能会发生精度丢失\n  2. 从long类型到float, double类型. l2f,l2d都可能会发生精度丢失\n  3. 从float到double类型. 在FP-strict模式下可以确保,精度不会丢失\n```\n* 窄化类型转换\n```\n  1. 从int到byte, short, char 类型\n  2. 从long到int类型\n  3. 从float到int 或者 long类型\n  4. 从double 到int, long, float.\n```\n### 对象创建与操作\n* 创建类实例的指令\n```\n  1.  new\n```\n* 创建数组的指令\n```\n  1.  newarray\n  2.  anewarray       创建一个类型为reference类型的数组\n  3.  multianewarray\n```\n* 访问类字段和类实例字段\n```\n  1.  getstatic\n  2.  putstatic\n  3.  getfield\n  4.  putfield\n```\n* 把一个数组元素加载到操作数栈的指令\n```\n  1.  baload  从数组中读取byte或者boolean类型的数据\n  2.  aload   从局部变量表加载一个reference类型值到操作数栈\n  3.  saload\n  4.  iaload\n  5.  laload\n  6.  faload\n  7.  daload\n  8.  aaload  从数组中加一个reference类型数据到操作数栈.\n```\n* 将一个操作数栈元素存储到数组元素中\n```\n  1.  bastore  从操作数栈读取一个byte或者boolean类型数据并存储数组中\n  2.  castore  从操作数栈读取一个char类型并存储数组\n  3.  sastore\n  4.  iastore\n  5.  fastore\n  6.  dastore\n  7.  aastore  从操作数栈读取一个reference类型数据存入到数组中.\n```\n* 取数组长度的指令\n```\n  1.  arraylength  取数组长度\n```\n* 检查类实例类型的指令\n```\n  1.  instanceof\n  2.  instancecast\n```\n\n### 操作数栈管理指令\n* 直接用于操作操作数栈的指令:\n```\n  1. pop\n  2. pop2\n  3. dup\n  4. dup2\n  5. dip_x1\n  6. dup2_x1\n  7. dup_x2\n  8. dup2_x2\n  9. swap\n```\n### 控制转移指令\n*   控制转移指令可以让虚拟机有条件或者无条件地从指定指令而不是控制转移指令的下一条指令继续执行程序\n*   条件分支指令\n```\n  1. ifeq\n  2. iflt\n  3. ifle\n  4. ifgt\n  5. ifnull\n  6. ifnonnull\n  7. if_icmpeq\n  8. if_icmpne\n  9. if_icmplt\n  10. if_icmmpgt\n  11. if_cfimmple\n  12. if_acmpeq\n  13. if_acmpne\n```\n* 复合条件分支\n```\n  1. tableswitch\n  2. lookupswitch\n```\n* 无条件分支\n```\n  1. goto\n  2. goto_w\n  3. jsr\n  4. jsr_w\n  5. ret\n```\n* boolean, byte, char, short 类型作为条件分支比较操作, 都使用int 类型的比较指令完成\n* long, float, double 类型的条件分支, 则先会执行相应类型的比较运算指令, 运算指令会返回一个整型值到操作数栈中,然后再执行int类型的条件分支比较操作来完成整个分支的跳转.\n* 所有int类型的条件分支转移指令进行的都是有符号的比较操作\n\n### 方法调用和返回指令\n* 方法调用\n```\n 1. invokevirtual: 用于调用对象的实例方法, 根据对象的实际类型进行分派(虚方法分派).\n 2. invokeinterface: 用于调用接口方法. 它会在运行时搜索一个实现了这个接口方法的对象, 并找出合适的方法进行调用\n 3. invokespecial: 指令用于一些需要特殊处理的实例方法, 包括实例初始化方法, 私有方法和父类方法\n 4. invokestatic:  指令用于调用命名类中的类方法\n 5. invokedynamic: 指令用于绑定了invokedynamic指令的调用点对象作为目标的方法. 调用点对象是一个特殊的语法结构,\n                   当一条invokedynamic首次被java虚拟机执行前, java虚拟机会执行一个引导方法并以这个方法的运行结果\n                   作为调用点对象.因此每条invokedynamic指令都有一个独一无二的链接期状态.\n```\n* 返回指令\n```\n  1. ireturn  用以返回boolean, byte, char, short, int 类型使用\n  2. lreturn\n  3. freturn\n  4. dreturn\n  5. areturn  从方法中返回一个reference类型数据\n  6. 有一条特殊的return指令供声明为void的方法, 实例初始化方法, 类和接口的类初始化方法使用\n```\n\n### 抛出异常\n* 程序中显式的异常由athrow指令抛出, 其他的异常会在其他指令检测到异常时由虚拟机自动抛出\n```\n   1. athrow  抛出一个异常\n```\n\n### 同步\njava虚拟机支持方法级的同步以及方法内部一段指令序列的同步.这俩种同步机制都使用同步锁来支持的.方法级的同步是隐式的,无需通过字节码指令来控制,它实现在方法调用和返回操作之中.\n\n虚拟机从方法常量池中的方法表结构中的`ACC_SYNCHRONIZED`访问标志来区分一个方法是否是同步方法.当调用同步方法时,调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否设置了,如果设置了,执行线程会先持有同步锁,然后执行方法.最后在方法结束时,释放掉同步锁. 在方法执行期间,执行线程有了同步锁,其他线程都无法再获得同一个同步锁.\n\n同步一段指令集序列, 通常是由java中`synchronized`块表示的. java虚拟机中有`monitorenter`和`monitorexit`俩个指令来支持`synchronized`语义.\n\n结构化锁定指的是在方法调用期间每一个同步锁退出斗鱼前面的同步锁进入相匹配的情形. 因为无法保证所有提交给java虚拟机执行的代码都满足结构化锁定,所以java虚拟机允许通过以下俩条规则来保证结构化锁定成立. (T代表一个线程, M代表一个同步锁)\n\n1. T在方法执行时持有的同步锁M的次数必须与T在此方法完成时释放同步锁M的次数想等\n2. 在方法调用过程中,任何时刻都不会出现线程T释放同步锁M的次数比T持有同步锁M次数多的情况\n","source":"_posts/jvm7/字节码指令.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: 字节码指令\n---\n## 字节码指令\n### 虚拟机指令集所支持的数据类型\n\n|操作码    |byte   |short  |int     |long   |float  |double |char   |refernce |\n|---------|------:|------:|-------:|------:|------:|------:|------:|--------:|\n|Tipush   |bipush |sipush |        |       |       |       |       |         |\n|Tconst   |       |       |iconst  |lconst |fconst |dconst |       |aconst   |\n|Tload    |       |       |iload   |lload  |fload  |dload  |       |aload    |\n|Tstore   |       |       |store   |lstore |fstore |dstore |cstore |astore   |\n|Tinc     |       |       |iinc    |       |       |       |       |         |\n|Taload   |baload |saload |iaload  |laload |faload |daload |caload |aaload   |\n|Tastore  |bastore|sastore|iastore |lastore|fastore|dastore|castore|aastore  |\n|Tadd     |       |       |iadd    |ladd   |fadd   |dadd   |       |         |\n|Tsub     |       |       |isub    |lsub   |fsub   |dsub   |       |         |\n|Tmul     |       |       |imul    |lmul   |fmul   |dmul   |       |         |\n|Tdiv     |       |       |idiv    |ldiv   |fdiv   |ddiv   |       |         |\n|Trem     |       |       |irem    |lrem   |frem   |drem   |       |         |\n|Tneg     |       |       |ineg    |lneg   |fneg   |dneg   |       |         |\n|Tshl     |       |       |ishl    |lshl   |       |       |       |         |\n|Tshr     |       |       |ishr    |lshr   |       |       |       |         |\n|Tushr    |       |       |iushr   |lushr  |       |       |       |         |\n|Tand     |       |       |iand    |land   |       |       |       |         |\n|Tor      |       |       |ior     |lor    |       |       |       |         |\n|Txor     |       |       |ixor    |lxor   |       |       |       |         |\n|i2T      |i2b    |i2s    |        |i2l    |i2f    |i2d    |       |         |\n|l2T      |       |       |l2i     |       |l2f    |l2d    |       |         |\n|f2T      |       |       |f2i     |f2l    |       |f2d    |       |         |\n|d2T      |       |       |d2i     |d2l    |d2f    |       |       |         |\n|Tcmp     |       |       |        |lcmp   |       |       |       |         |\n|Tcmpl    |       |       |        |       |fcmpl  |dcmpl  |       |         |\n|if_TcmpOP|       |       |if_icmOP|       |       |       |       |if_acmpOP|\n|Treturn  |       |       |ireturn |lreturn|freturn|dreturn|       |areturn  |\n\n\n### 加载和存储指令\n* 加载和存储指令用于将数据从栈帧的本地变量表和操作数栈之间来回传递\n* 将一个本地变量加载到操作数栈的指令有:\n```\n  1. iload,\n  2. iload_<n>,\n  3. lload,\n  4. lload_<n>,\n  5. fload,\n  6. fload_<n>,\n  7. dload,\n  8. dload_<n>,\n  9. aload       从局部变量表加载一个reference类型值到操作数栈\n  10. aload_<n>  从局部变量表加载一个reference类型值到操作数栈\n  11. caload     从数组中加载一个char类型数据到操作数栈\n```\n* 将一个数值从操作数栈存储到局部变量表的指令有:\n```\n  1. istore\n  2. istore_<n>\n  3. lstore\n  4. lstore_<n>\n  5. fstore\n  6. fstore_<n>\n  7. dstore\n  8. dstore_<n>\n  9. astore       将一个reference类型数据保存到本地变量表\n  10. astore_<n>  将一个reference类型数据保存到本地变量表\n```\n* 将一个常量加载到操作数栈的指令有:\n```\n  1. bipush       将一个byte类型数据入栈\n  2. sipush\n  3. ldc\n  4. ldc_w\n  5. ldc2_w\n  6. aconst_null   将一个null值入栈到操作数栈中.\n  7. iconst_m1\n  8. iconst_<i>\n  9. locnst_<l>\n  10. fconst_<f>\n  11. dconst_<d>\n```\n* 以上指令中有部分是以尖括号为结尾的,这种代表了一组指令, 例如iload_1, iload_2, 等等. 他们表面上没有操作数, 不需要进行取操作数的动作,但操作数都包含在指令中\n\n### 算数指令\n* 算数指令是对俩个操作数栈上的值进行某种特定运算,然后把结构重新压入操作数栈.\n* 加法指令\n```\n  1.  iadd\n  2.  ladd\n  3.  fadd\n  4.  dadd\n```\n* 减法指令\n```\n  1.  isub\n  2.  lsub\n  3.  fsub\n  4.  dsub\n```\n* 乘法指令\n```\n  1.  imul\n  2.  lmul\n  3.  fmul\n  4.  dmul\n```\n* 除法指令\n```\n  1.  idiv\n  2.  ldiv\n  3.  fdiv\n  4.  ddiv\n```\n* 求余指令\n```\n  1.  irem\n  2.  lrem\n  3.  frem\n  4.  drem\n```\n* 取反指令\n```\n  1.  ineg\n  2.  lneg\n  3.  dneg\n  4.  dneg\n```\n* 位移指令\n```\n  1.  ishl\n  2.  ishr\n  3.  iushr\n  4.  lshl\n  5.  lshr\n  6.  lushr\n```\n* 按位或指令\n```\n  1.  ior\n  2.  lor\n```\n* 按位与指令\n```\n  1.  iand\n  2.  land\n```\n* 按位异或指令\n```\n  1.  ixor\n  2.  lxor\n```\n* 局部变量自增指令\n```\n  1.  iinc\n```\n* 比较之类\n```\n  1.  dcmpg\n  2.  dcmpl\n  3.  fcmpg\n  4.  fcmpl\n  5.  lcmp\n```\n\n### 类型转换指令\n* 可以将俩种java虚拟机数值类型进行相互转换\n* 这些转换指令一般用于实现用户代码的显示类型转换或用来处理虚拟机字节码指令集中指令的非完全独立的问题\n* 宽化类型转换:\n```\n  1. 从int类型到long, float, double类型. i2l和i2d 指令都不会丢失精确度,但是i2f可能会发生精度丢失\n  2. 从long类型到float, double类型. l2f,l2d都可能会发生精度丢失\n  3. 从float到double类型. 在FP-strict模式下可以确保,精度不会丢失\n```\n* 窄化类型转换\n```\n  1. 从int到byte, short, char 类型\n  2. 从long到int类型\n  3. 从float到int 或者 long类型\n  4. 从double 到int, long, float.\n```\n### 对象创建与操作\n* 创建类实例的指令\n```\n  1.  new\n```\n* 创建数组的指令\n```\n  1.  newarray\n  2.  anewarray       创建一个类型为reference类型的数组\n  3.  multianewarray\n```\n* 访问类字段和类实例字段\n```\n  1.  getstatic\n  2.  putstatic\n  3.  getfield\n  4.  putfield\n```\n* 把一个数组元素加载到操作数栈的指令\n```\n  1.  baload  从数组中读取byte或者boolean类型的数据\n  2.  aload   从局部变量表加载一个reference类型值到操作数栈\n  3.  saload\n  4.  iaload\n  5.  laload\n  6.  faload\n  7.  daload\n  8.  aaload  从数组中加一个reference类型数据到操作数栈.\n```\n* 将一个操作数栈元素存储到数组元素中\n```\n  1.  bastore  从操作数栈读取一个byte或者boolean类型数据并存储数组中\n  2.  castore  从操作数栈读取一个char类型并存储数组\n  3.  sastore\n  4.  iastore\n  5.  fastore\n  6.  dastore\n  7.  aastore  从操作数栈读取一个reference类型数据存入到数组中.\n```\n* 取数组长度的指令\n```\n  1.  arraylength  取数组长度\n```\n* 检查类实例类型的指令\n```\n  1.  instanceof\n  2.  instancecast\n```\n\n### 操作数栈管理指令\n* 直接用于操作操作数栈的指令:\n```\n  1. pop\n  2. pop2\n  3. dup\n  4. dup2\n  5. dip_x1\n  6. dup2_x1\n  7. dup_x2\n  8. dup2_x2\n  9. swap\n```\n### 控制转移指令\n*   控制转移指令可以让虚拟机有条件或者无条件地从指定指令而不是控制转移指令的下一条指令继续执行程序\n*   条件分支指令\n```\n  1. ifeq\n  2. iflt\n  3. ifle\n  4. ifgt\n  5. ifnull\n  6. ifnonnull\n  7. if_icmpeq\n  8. if_icmpne\n  9. if_icmplt\n  10. if_icmmpgt\n  11. if_cfimmple\n  12. if_acmpeq\n  13. if_acmpne\n```\n* 复合条件分支\n```\n  1. tableswitch\n  2. lookupswitch\n```\n* 无条件分支\n```\n  1. goto\n  2. goto_w\n  3. jsr\n  4. jsr_w\n  5. ret\n```\n* boolean, byte, char, short 类型作为条件分支比较操作, 都使用int 类型的比较指令完成\n* long, float, double 类型的条件分支, 则先会执行相应类型的比较运算指令, 运算指令会返回一个整型值到操作数栈中,然后再执行int类型的条件分支比较操作来完成整个分支的跳转.\n* 所有int类型的条件分支转移指令进行的都是有符号的比较操作\n\n### 方法调用和返回指令\n* 方法调用\n```\n 1. invokevirtual: 用于调用对象的实例方法, 根据对象的实际类型进行分派(虚方法分派).\n 2. invokeinterface: 用于调用接口方法. 它会在运行时搜索一个实现了这个接口方法的对象, 并找出合适的方法进行调用\n 3. invokespecial: 指令用于一些需要特殊处理的实例方法, 包括实例初始化方法, 私有方法和父类方法\n 4. invokestatic:  指令用于调用命名类中的类方法\n 5. invokedynamic: 指令用于绑定了invokedynamic指令的调用点对象作为目标的方法. 调用点对象是一个特殊的语法结构,\n                   当一条invokedynamic首次被java虚拟机执行前, java虚拟机会执行一个引导方法并以这个方法的运行结果\n                   作为调用点对象.因此每条invokedynamic指令都有一个独一无二的链接期状态.\n```\n* 返回指令\n```\n  1. ireturn  用以返回boolean, byte, char, short, int 类型使用\n  2. lreturn\n  3. freturn\n  4. dreturn\n  5. areturn  从方法中返回一个reference类型数据\n  6. 有一条特殊的return指令供声明为void的方法, 实例初始化方法, 类和接口的类初始化方法使用\n```\n\n### 抛出异常\n* 程序中显式的异常由athrow指令抛出, 其他的异常会在其他指令检测到异常时由虚拟机自动抛出\n```\n   1. athrow  抛出一个异常\n```\n\n### 同步\njava虚拟机支持方法级的同步以及方法内部一段指令序列的同步.这俩种同步机制都使用同步锁来支持的.方法级的同步是隐式的,无需通过字节码指令来控制,它实现在方法调用和返回操作之中.\n\n虚拟机从方法常量池中的方法表结构中的`ACC_SYNCHRONIZED`访问标志来区分一个方法是否是同步方法.当调用同步方法时,调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否设置了,如果设置了,执行线程会先持有同步锁,然后执行方法.最后在方法结束时,释放掉同步锁. 在方法执行期间,执行线程有了同步锁,其他线程都无法再获得同一个同步锁.\n\n同步一段指令集序列, 通常是由java中`synchronized`块表示的. java虚拟机中有`monitorenter`和`monitorexit`俩个指令来支持`synchronized`语义.\n\n结构化锁定指的是在方法调用期间每一个同步锁退出斗鱼前面的同步锁进入相匹配的情形. 因为无法保证所有提交给java虚拟机执行的代码都满足结构化锁定,所以java虚拟机允许通过以下俩条规则来保证结构化锁定成立. (T代表一个线程, M代表一个同步锁)\n\n1. T在方法执行时持有的同步锁M的次数必须与T在此方法完成时释放同步锁M的次数想等\n2. 在方法调用过程中,任何时刻都不会出现线程T释放同步锁M的次数比T持有同步锁M次数多的情况\n","slug":"jvm7/字节码指令","published":1,"updated":"2015-10-16T02:39:33.119Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxsz002b0cufdellf96j"},{"date":"2014-10-07T16:00:00.000Z","title":"垃圾收集器","_content":"# 垃圾收集器\n## 对象引用\n\n引用计数算法, 引用计数算法的问题是,它很难解决对象之间相互循环引用的问题\n```java\npublic class ReferenceCountingGC {\n\n    public Object instance = null;\n\n    private static final int _1MB = 1024 * 1024;\n\n    private byte[] bigSize = new byte[_1MB];\n\n    public static void main(String[] args) {\n        ReferenceCountingGC obj1 = new ReferenceCountingGC();\n        ReferenceCountingGC obj2 = new ReferenceCountingGC();\n\n        obj1.instance = obj2;\n        obj2.instance = obj1;\n\n        System.gc();\n    }\n}\n```\n### 根搜索算法\n这个算法的基本思想是:通过一系列的名为\"GC Roots\"的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的.\n\n#### 在java语言里, 可作为GC Roots的对象包括以下几种:\n1. 虚拟机栈(栈帧中的本地变量表)中的引用对象.\n2. 方法区中的类静态属性引用的对象.\n3. 方法区中的常量引用对象\n4. 本地方法栈中JNI的引用的对象\n\n### 再谈引用\n\nJDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用\n1. 强引用: 指的是在代码之中普遍存在的,类似`Object obj = new Object()` 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象\n2. 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常.\n3. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象\n4. 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知.\n\n\n## 垃圾回收算法\n### 标记-清除算法\n\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95a.jpg)\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95b.jpg)\n#### 算法简介\n算法分为标记和清除俩个部分. 首先标记出要所有要回收的对象, 然后统一回收掉所有被标记的对象.\n\n#### 这种算法的缺点主要是:\n1. 效率问题. 标记和清除的效率都不高.\n2. 空间问题. 标记和清除之后会存在大量不连续空间碎片. 空间碎片太多可能导致,在程序以后运行过程中需要分配较大对象时,无法找到足够的内存连续内存,而不得不提前触发另一次的垃圾收集动作.\n\n#### 算法伪代码\n##### NEW操作\n```java\nNew():\n    ref <- allocate()  //分配新的内存到ref指针\n    if ref == null\n       collect()  //内存不足,则触发垃圾收集\n       ref <- allocate()\n       if ref == null\n          throw \"Out of Memory\"   //垃圾收集后仍然内存不足,则抛出Out of Memory错误\n          return ref\n\natomic collect():\n    markFromRoots()\n    sweep(HeapStart,HeapEnd)\n\n```\n###### mark算法\n```\nmarkFromRoots():\n    worklist <- empty\n    for each fld in Roots  //遍历所有mutator根对象\n        ref <- *fld\n        if ref != null && isNotMarked(ref)  //如果它是可达的而且没有被标记的,直接标记该对象并将其加到worklist中\n           setMarked(ref)\n           add(worklist,ref)\n           mark()\nmark():\n    while not isEmpty(worklist)\n          ref <- remove(worklist)  //将worklist的最后一个元素弹出,赋值给ref\n          for each fld in Pointers(ref)\n          //遍历ref对象的所有指针域,如果其指针域(child)是可达的,直接标记其为可达对象并且将其加入worklist中\n          //通过这样的方式来实现深度遍历,直到将该对象下面所有可以访问到的对象都标记为可达对象.\n                child <- *fld\n                if child != null && isNotMarked(child)\n                   setMarked(child)\n                   add(worklist,child)\n\n```\n###### sweep算法\n```\nsweep(start,end):\n    scan <- start\n   while scan < end\n       if isMarked(scan)\n          setUnMarked(scan)\n      else\n          free(scan)\n      scan <- nextObject(scan)\n```\n* 复制算法\n\n![复制算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95a.jpg)\n![复制算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95b.jpg)\n##### 算法原理\n为了解决效率问题, 复制算法将可用内存按照容量划分为大小相等的俩块,每次只使用其中的一块. 当这一块内存用完了,就将还活着的对象复制到另一块上面,然后再把已经使用过的内存一次清理掉.\n\n##### 缺陷解决\n这种算法实现简单,运行高效,只不过将原来内存缩小为原来一半,这实在是有点高. 不过现在的商业虚拟机都采用这种算法来收集新生代. 根据IBM研究, 新生代的对象98%都是朝生夕死, 所以并不需要按照1:1 的比例分配内存. 而是分为一块\n较大的Eden区和俩块较小的Survivor区. 每次都使用Eden和一块Survivor区,当回收时, 将Eden还活着的对象一次性拷贝到另一块Survivor区,最后清理掉Eden区和刚才使用过的Survivor区.\nHotSpot默认Eden和Survivor的大小比例是8:1, 也就是每次新生代可用内存空间为90%(8 + 1), 如果发现剩余的存活对象多余10%,另一块Survivor不够的话,需要依赖其他内存(老年代)进行分配担保.\n\n* 标记-整理算法\n[标记整理算法](http://www.jianshu.com/p/698eb5e1ccb9)\n![标记  - 整理算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95a.jpg)\n![标记  - 整理算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95b.jpg)\n\n复制算法在对象存活率较高的情况下需要执行多次复制操作,效率会变低,所以老年代一般不选用这个算法. 根据老年代的特点,就提出了标记-整理算法,标记过程和\"标记-清除算法\"一样,但后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉端边界以外的内存.\n\n* 分代收集算法\n这种算法的思想是:把java堆分为新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法.\n\n在新生代,每次垃圾收集时发现有大批对象死去,只有少量对象存活,那就采用复制算法,只要付出少量存活对象的复制成本就可以完成收集. 而老年代对象存活效率高,没有额外的空间对它进行分配担保,就必须采用\"标记清除\"或者\"标记整理\"来进行回收\n\n## 垃圾收集器\n![https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg](https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg)\n### Serial收集器\nSerial收集器是最基本、历史最悠久的收集器,曾经（在JDK 1.3.1之前）是虚拟机`新生代`收集的唯一选择.\n\n#### Serial收集器运行原理\n看名字就知道,这个收集器是一个`单线程`的收集器,但它的“单线程”的意义并不仅仅是说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作,更重要的是在它进行垃圾收集时,必须暂停其他所有的工作线程（Sun将这件事情称之为“Stop The World”）,直到它收集结束.“Stop The World”这个名字也许听起来很酷,但这项工作实际上是由虚拟机在后台自动发起和自动完成的,在用户不可见的情况下把用户的正常工作的线程全部停掉,这对很多应用来说都是难以接受的.\n\n#### Serial收集器存在必要\n从JDK 1.3开始,一直到现在还没正式发布的JDK 1.7,HotSpot虚拟机开发团队为消除或减少工作线程因内存回收而导致停顿的努力一直在进行着,从`Serial`收集器到`Parallel`收集器,再到`ConcurrentMarkSweep（CMS）`现在正式发布的`Garbage First（G1）`收集器,我们看到了一个个越来越优秀（也越来越复杂）的收集器的出现,用户线程的停顿时间在不断缩短,但是仍然没有办法完全消除（这里暂不包括RTSJ中的收集器）.\n\n到这里,Serial收集器似乎成了一个老而无用,食之无味弃之可惜的鸡肋了,但实际上到现在为止,它依然是虚拟机运行在Client模式下的默认新生代收集器.它也有着优于其他收集器的地方：简单而高效(与其他收集器的单线程比）,对于限定单个CPU的环境来说,`Serial`收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率.在用户的桌面应用场景中,分配给虚拟机管理的内存一般来说不会很大,收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存,桌面应用基本上不会再大了）,停顿时间完全可以控制在几十毫秒最多一百多毫秒以内,只要不是频繁发生,这点停顿是可以接受的.所以,`Serial`收集器对于运行在Client模式下的虚拟机来说是一个很好的选择.\n\n### ParNew收集器\n\n#### 对比`Serial`收集器\n`ParNew`收集器其实就是`Serial`收集器的多线程版本,除了使用多线程进行垃圾收集之外,其余行为包括Serial收集器可用的所有控制参数（例如：`-XX:SurvivorRatio`、 `-XX:PretenureSizeThreshold`、`-XX:HandlePromotionFailure`等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样,实现上这两种收集器也共用了相当多的代码.\n\n#### 为什么选择ParNew收集器\nParNew收集器除了多线程收集之外,其他与Serial收集器相比并没有太多创新之处,但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器,其中有一个与性能无关但很重要的原因是,除了Serial收集器外,目前只有它能与CMS收集器配合工作.\n\n> 在JDK 1.5时期,HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器Concurrent Mark Sweep）,这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器,它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作.\n\n不幸的是,CMS收集器作为老年代的收集器,却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择ParNew或Serial收集器中的一个.ParNew收集器也是使用`-XX: +UseConcMarkSweepGC`选项后的默认新生代收集器,也可以使用 `-XX:+UseParNewGC`选项来强制指定它.\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果,甚至由于存在线程交互的开销,该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器.当然,随着可以使用的CPU的数量的增加,它对于GC时系统资源的利用还是很有好处的.它默认开启的收集线程数与CPU的数量相同,在CPU非常多（譬如32个,现在CPU动辄就4核加超线程,服务器超过32个逻辑CPU的情况越来越多了）的环境下,可以使用`-XX:ParallelGCThreads`参数来限制垃圾收集的线程数.\n\n##### 注意  \n从ParNew收集器开始,后面还将会接触到几款并发和并行的收集器.在大家可能产生疑惑之前,有必要先解释两个名词：并发和并行.这两个名词都是并发编程中的概念,在谈论垃圾收集器的上下文语境中,他们可以解释为：\n* 并行（Parallel）：指多条垃圾收集线程并行工作,但此时用户线程仍然处于等待状态.\n* 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的,可能会交替执行）,用户程序继续运行,而垃圾收集程序运行于另一个CPU上.\n\n### Parallel Scavege收集器\n\nParallel Scavenge收集器也是一个新生代收集器,它也是使用复制算法的收集器,又是并行的多线程收集器……看上去和ParNew都一样,那它有什么特别之处呢？\n\n#### Parallel Scavenge收集器的特点\n它的关注点与其他收集器不同,CMS等收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）.\n\n> 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）,虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%.\n\n停顿时间越短就越适合需要与用户交互的程序,良好的响应速度能提升用户的体验;而高吞吐量则可以最高效率地利用CPU时间,尽快地完成程序的运算任务,主要适合在后台运算而不需要太多交互的任务.\n\n#### Parallel Scavenge收集器设定\nParallel Scavenge收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集停顿时间的`-XX:MaxGCPauseMillis`参数及直接设置吞吐量大小的 `-XX:GCTimeRatio`参数.\n\n* `MaxGCPauseMillis` : 参数允许的值是一个大于0的毫秒数,收集器将尽力保证内存回收花费的时间不超过设定值.不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快,GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些,收集300MB新生代肯定比收集500MB快吧,这也直接导致垃圾收集发生得更频繁一些,原来10秒收集一次、每次停顿100毫秒,现在变成5秒收集一次、每次停顿70毫秒.停顿时间的确在下降,但吞吐量也降下来了.\n\n* `GCTimeRatio` : 参数的值应当是一个大于0小于100的整数,也就是垃圾收集时间占总时间的比率,相当于是吞吐量的倒数.如果把此参数设置为19,那允许的最大GC时间就占总时间的5%（即1 /（1+19））,默认值为99,就是允许最大1%（即1 /（1+99））的垃圾收集时间.\n\n由于与吞吐量关系密切,Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器.除上述两个参数之外,Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得关注.\n* `-XX:+UseAdaptiveSizePolicy` :这是一个开关参数,当这个参数打开之后,就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（`-XX:SurvivorRatio`）、晋升老年代对象年龄（`-XX:PretenureSizeThreshold`）等细节参数了,虚拟机会根据当前系统的运行情况收集性能监控信息,动态调整这些参数以提供最合适的停顿时间或最大的吞吐量,这种调节方式称为GC自适应的调节策略（GC Ergonomics）.\n> 如果读者对于收集器运作原理不太了解,手工优化存在困难的时候,使用Parallel Scavenge收集器配合自适应调节策略,把内存管理的调优任务交给虚拟机去完成将是一个很不错的选择.只需要把基本的内存数据设置好（如-Xmx设置最大堆）,然后使用`MaxGCPauseMillis`参数（更关注最大停顿时间）或`GCTimeRatio`参数（更关注吞吐量）给虚拟机设立一个优化目标,那具体细节参数的调节工作就由虚拟机完成了.自适应调节策略也是`Parallel Scavenge`收集器与`ParNew`收集器的一个重要区别.\n\n### Serial Old收集器\n\nSerial Old是Serial收集器的老年代版本,它同样是一个单线程收集器,使用“标记-整理”算法.这个收集器的主要意义也是被Client模式下的虚拟机使用.如果在Server模式下,它主要还有两大用途：一个是在JDK 1.5及之前的版本中与Parallel Scavenge收集器搭配使用,另外一个就是作为CMS收集器的后备预案,在并发收集发生Concurrent Mode Failure的时候使用.\n\n### Parallel old收集器\n\nParallel Old是Parallel Scavenge收集器的老年代版本,使用多线程和“标记－整理”算法.这个收集器是在JDK 1.6中才开始提供的,在此之前,新生代的Parallel Scavenge收集器一直处于比较尴尬的状态.原因是,如果新生代选择了Parallel Scavenge收集器,老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）.由于单线程的老年代Serial Old收集器在服务端应用性能上的“拖累”,即便使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果,又因为老年代收集中无法充分利用服务器多CPU的处理能力,在老年代很大而且硬件比较高级的环境中,这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”.\n\n直到Parallel Old收集器出现后,“吞吐量优先”收集器终于有了比较名副其实的应用组合,在注重吞吐量及CPU资源敏感的场合,都可以优先考虑Parallel Scavenge加Parallel Old收集器.\n\n### CMS收集器\n\n#### 用途\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器.目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验.CMS收集器就非常符合这类应用的需求.\n\n##### 采用算法\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的,它的运作过程相对于前面几种收集器来说要更复杂一些,整个过程分为4个步骤,包括：\n1. 初始标记（CMS initial mark）\n2. 并发标记（CMS concurrent mark）\n3. 重新标记（CMS remark）\n4. 并发清除（CMS concurrent sweep）\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象,速度很快,并发标记阶段就是进行GC Roots Tracing的过程,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段稍长一些,但远比并发标记的时间短.\n\n由于整个过程中耗时最长的并发标记和并发清除过程中,收集器线程都可以与用户线程一起工作,所以总体上来说,CMS收集器的内存回收过程是与用户线程一起并发地执行的.通过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间.\n\nCMS是一款优秀的收集器,它的最主要优点在名字上已经体现出来了：并发收集、低停顿,Sun的一些官方文档里面也称之为并发低停顿收集器（Concurrent Low Pause Collector）.但是CMS还远达不到完美的程度,它有以下三个显著的缺点：\n\nCMS收集器对CPU资源非常敏感.其实,面向并发设计的程序都对CPU资源比较敏感.在并发阶段,它虽然不会导致用户线程停顿,但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢,总吞吐量会降低.CMS默认启动的回收线程数是（CPU数量+3）/ 4,也就是当CPU在4个以上时,并发回收时垃圾收集线程最多占用不超过25%的CPU资源.但是当CPU不足4个时（譬如2个）,那么CMS对用户程序的影响就可能变得很大,如果CPU负载本来就比较大的时候,还分出一半的运算能力去执行收集器线程,就可能导致用户程序的执行速度忽然降低了50%,这也很让人受不了.为了解决这种情况,虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep / i-CMS）的CMS收集器变种,所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样,就是在并发标记和并发清理的时候让GC线程、用户线程交替运行,尽量减少GC线程的独占资源的时间,这样整个垃圾收集的过程会更长,但对用户程序的影响就会显得少一些,速度下降也就没有那么明显,但是目前版本中,i-CMS已经被声明为“deprecated”,即不再提倡用户使用.\n\nCMS收集器无法处理浮动垃圾（Floating Garbage）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生.由于CMS并发清理阶段用户线程还在运行着,伴随程序的运行自然还会有新的垃圾不断产生,这一部分垃圾出现在标记过程之后,CMS无法在本次收集中处理掉它们,只好留待下一次GC时再将其清理掉.这一部分垃圾就称为“浮动垃圾”.也是由于在垃圾收集阶段用户线程还需要运行,即还需要预留足够的内存空间给用户线程使用,因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,需要预留一部分空间提供并发收集时的程序运作使用.在默认设置下,CMS收集器在老年代使用了68%的空间后就会被激活,这是一个偏保守的设置,如果在应用中老年代增长不是太快,可以适当调高参数`-XX:CMSInitiatingOccupancyFraction`的值来提高触发百分比,以便降低内存回收次数以获取更好的性能.要是CMS运行期间预留的内存无法满足程序需要,就会出现一次“Concurrent Mode Failure”失败,这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了.所以说参数`-XX:CMSInitiatingOccupancyFraction`设置得太高将会很容易导致大量“Concurrent Mode Failure”失败,性能反而降低.\n\n还有最后一个缺点,在本节在开头说过,CMS是一款基于“标记-清除”算法实现的收集器,如果读者对前面这种算法介绍还有印象的话,就可能想到这意味着收集结束时会产生大量空间碎片.空间碎片过多时,将会给大对象分配带来很大的麻烦,往往会出现老年代还有很大的空间剩余,但是无法找到足够大的连续空间来分配当前对象,不得不提前触发一次Full GC.为了解决这个问题,CMS收集器提供了一个`-XX:+UseCMSCompactAtFullCollection`开关参数,用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程,内存整理的过程是无法并发的.空间碎片问题没有了,但停顿时间不得不变长了.虚拟机设计者们还提供了另外一个参数`-XX: CMSFullGCsBeforeCompaction`,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的.\n\n### G1收集器\n\nG1（Garbage First）收集器是当前收集器技术发展的最前沿成果,在JDK 1.6_Update14中提供了EarlyAccess版本的G1收集器以供试用.在将来JDK 1.7正式发布的时候,G1收集器很可能会有一个成熟的商用版本随之发布.这里只对G1收集器进行简单介绍.\n\nG1收集器是垃圾收集器理论进一步发展的产物,它与前面的CMS收集器相比有两个显著的改进：一是G1收集器是基于“标记-整理”算法实现的收集器,也就是说它不会产生空间碎片,这对于长时间运行的应用系统来说非常重要.二是它可以非常精确地控制停顿,\n既能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒,这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了.\n\nG1收集器可以实现在基本不牺牲吞吐量的前提下完成低停顿的内存回收,这是由于它能够极力地避免全区域的垃圾收集,之前的收集器进行收集的范围都是整个新生代或老年代,而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域（Region）,并且跟踪这些区域里面的垃圾堆积程度,在后台维护一个优先列表,每次根据允许的收集时间,优先回收垃圾最多的区域（这就是Garbage First名称的来由）.区域划分及有优先级的区域回收,保证了G1收集器在有限的时间内可以获得最高的收集效率.\n\n\n","source":"_posts/jvm7/垃圾收集.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: 垃圾收集器\n---\n# 垃圾收集器\n## 对象引用\n\n引用计数算法, 引用计数算法的问题是,它很难解决对象之间相互循环引用的问题\n```java\npublic class ReferenceCountingGC {\n\n    public Object instance = null;\n\n    private static final int _1MB = 1024 * 1024;\n\n    private byte[] bigSize = new byte[_1MB];\n\n    public static void main(String[] args) {\n        ReferenceCountingGC obj1 = new ReferenceCountingGC();\n        ReferenceCountingGC obj2 = new ReferenceCountingGC();\n\n        obj1.instance = obj2;\n        obj2.instance = obj1;\n\n        System.gc();\n    }\n}\n```\n### 根搜索算法\n这个算法的基本思想是:通过一系列的名为\"GC Roots\"的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的.\n\n#### 在java语言里, 可作为GC Roots的对象包括以下几种:\n1. 虚拟机栈(栈帧中的本地变量表)中的引用对象.\n2. 方法区中的类静态属性引用的对象.\n3. 方法区中的常量引用对象\n4. 本地方法栈中JNI的引用的对象\n\n### 再谈引用\n\nJDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用\n1. 强引用: 指的是在代码之中普遍存在的,类似`Object obj = new Object()` 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象\n2. 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常.\n3. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象\n4. 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知.\n\n\n## 垃圾回收算法\n### 标记-清除算法\n\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95a.jpg)\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95b.jpg)\n#### 算法简介\n算法分为标记和清除俩个部分. 首先标记出要所有要回收的对象, 然后统一回收掉所有被标记的对象.\n\n#### 这种算法的缺点主要是:\n1. 效率问题. 标记和清除的效率都不高.\n2. 空间问题. 标记和清除之后会存在大量不连续空间碎片. 空间碎片太多可能导致,在程序以后运行过程中需要分配较大对象时,无法找到足够的内存连续内存,而不得不提前触发另一次的垃圾收集动作.\n\n#### 算法伪代码\n##### NEW操作\n```java\nNew():\n    ref <- allocate()  //分配新的内存到ref指针\n    if ref == null\n       collect()  //内存不足,则触发垃圾收集\n       ref <- allocate()\n       if ref == null\n          throw \"Out of Memory\"   //垃圾收集后仍然内存不足,则抛出Out of Memory错误\n          return ref\n\natomic collect():\n    markFromRoots()\n    sweep(HeapStart,HeapEnd)\n\n```\n###### mark算法\n```\nmarkFromRoots():\n    worklist <- empty\n    for each fld in Roots  //遍历所有mutator根对象\n        ref <- *fld\n        if ref != null && isNotMarked(ref)  //如果它是可达的而且没有被标记的,直接标记该对象并将其加到worklist中\n           setMarked(ref)\n           add(worklist,ref)\n           mark()\nmark():\n    while not isEmpty(worklist)\n          ref <- remove(worklist)  //将worklist的最后一个元素弹出,赋值给ref\n          for each fld in Pointers(ref)\n          //遍历ref对象的所有指针域,如果其指针域(child)是可达的,直接标记其为可达对象并且将其加入worklist中\n          //通过这样的方式来实现深度遍历,直到将该对象下面所有可以访问到的对象都标记为可达对象.\n                child <- *fld\n                if child != null && isNotMarked(child)\n                   setMarked(child)\n                   add(worklist,child)\n\n```\n###### sweep算法\n```\nsweep(start,end):\n    scan <- start\n   while scan < end\n       if isMarked(scan)\n          setUnMarked(scan)\n      else\n          free(scan)\n      scan <- nextObject(scan)\n```\n* 复制算法\n\n![复制算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95a.jpg)\n![复制算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95b.jpg)\n##### 算法原理\n为了解决效率问题, 复制算法将可用内存按照容量划分为大小相等的俩块,每次只使用其中的一块. 当这一块内存用完了,就将还活着的对象复制到另一块上面,然后再把已经使用过的内存一次清理掉.\n\n##### 缺陷解决\n这种算法实现简单,运行高效,只不过将原来内存缩小为原来一半,这实在是有点高. 不过现在的商业虚拟机都采用这种算法来收集新生代. 根据IBM研究, 新生代的对象98%都是朝生夕死, 所以并不需要按照1:1 的比例分配内存. 而是分为一块\n较大的Eden区和俩块较小的Survivor区. 每次都使用Eden和一块Survivor区,当回收时, 将Eden还活着的对象一次性拷贝到另一块Survivor区,最后清理掉Eden区和刚才使用过的Survivor区.\nHotSpot默认Eden和Survivor的大小比例是8:1, 也就是每次新生代可用内存空间为90%(8 + 1), 如果发现剩余的存活对象多余10%,另一块Survivor不够的话,需要依赖其他内存(老年代)进行分配担保.\n\n* 标记-整理算法\n[标记整理算法](http://www.jianshu.com/p/698eb5e1ccb9)\n![标记  - 整理算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95a.jpg)\n![标记  - 整理算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95b.jpg)\n\n复制算法在对象存活率较高的情况下需要执行多次复制操作,效率会变低,所以老年代一般不选用这个算法. 根据老年代的特点,就提出了标记-整理算法,标记过程和\"标记-清除算法\"一样,但后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉端边界以外的内存.\n\n* 分代收集算法\n这种算法的思想是:把java堆分为新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法.\n\n在新生代,每次垃圾收集时发现有大批对象死去,只有少量对象存活,那就采用复制算法,只要付出少量存活对象的复制成本就可以完成收集. 而老年代对象存活效率高,没有额外的空间对它进行分配担保,就必须采用\"标记清除\"或者\"标记整理\"来进行回收\n\n## 垃圾收集器\n![https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg](https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg)\n### Serial收集器\nSerial收集器是最基本、历史最悠久的收集器,曾经（在JDK 1.3.1之前）是虚拟机`新生代`收集的唯一选择.\n\n#### Serial收集器运行原理\n看名字就知道,这个收集器是一个`单线程`的收集器,但它的“单线程”的意义并不仅仅是说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作,更重要的是在它进行垃圾收集时,必须暂停其他所有的工作线程（Sun将这件事情称之为“Stop The World”）,直到它收集结束.“Stop The World”这个名字也许听起来很酷,但这项工作实际上是由虚拟机在后台自动发起和自动完成的,在用户不可见的情况下把用户的正常工作的线程全部停掉,这对很多应用来说都是难以接受的.\n\n#### Serial收集器存在必要\n从JDK 1.3开始,一直到现在还没正式发布的JDK 1.7,HotSpot虚拟机开发团队为消除或减少工作线程因内存回收而导致停顿的努力一直在进行着,从`Serial`收集器到`Parallel`收集器,再到`ConcurrentMarkSweep（CMS）`现在正式发布的`Garbage First（G1）`收集器,我们看到了一个个越来越优秀（也越来越复杂）的收集器的出现,用户线程的停顿时间在不断缩短,但是仍然没有办法完全消除（这里暂不包括RTSJ中的收集器）.\n\n到这里,Serial收集器似乎成了一个老而无用,食之无味弃之可惜的鸡肋了,但实际上到现在为止,它依然是虚拟机运行在Client模式下的默认新生代收集器.它也有着优于其他收集器的地方：简单而高效(与其他收集器的单线程比）,对于限定单个CPU的环境来说,`Serial`收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率.在用户的桌面应用场景中,分配给虚拟机管理的内存一般来说不会很大,收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存,桌面应用基本上不会再大了）,停顿时间完全可以控制在几十毫秒最多一百多毫秒以内,只要不是频繁发生,这点停顿是可以接受的.所以,`Serial`收集器对于运行在Client模式下的虚拟机来说是一个很好的选择.\n\n### ParNew收集器\n\n#### 对比`Serial`收集器\n`ParNew`收集器其实就是`Serial`收集器的多线程版本,除了使用多线程进行垃圾收集之外,其余行为包括Serial收集器可用的所有控制参数（例如：`-XX:SurvivorRatio`、 `-XX:PretenureSizeThreshold`、`-XX:HandlePromotionFailure`等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样,实现上这两种收集器也共用了相当多的代码.\n\n#### 为什么选择ParNew收集器\nParNew收集器除了多线程收集之外,其他与Serial收集器相比并没有太多创新之处,但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器,其中有一个与性能无关但很重要的原因是,除了Serial收集器外,目前只有它能与CMS收集器配合工作.\n\n> 在JDK 1.5时期,HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器Concurrent Mark Sweep）,这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器,它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作.\n\n不幸的是,CMS收集器作为老年代的收集器,却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择ParNew或Serial收集器中的一个.ParNew收集器也是使用`-XX: +UseConcMarkSweepGC`选项后的默认新生代收集器,也可以使用 `-XX:+UseParNewGC`选项来强制指定它.\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果,甚至由于存在线程交互的开销,该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器.当然,随着可以使用的CPU的数量的增加,它对于GC时系统资源的利用还是很有好处的.它默认开启的收集线程数与CPU的数量相同,在CPU非常多（譬如32个,现在CPU动辄就4核加超线程,服务器超过32个逻辑CPU的情况越来越多了）的环境下,可以使用`-XX:ParallelGCThreads`参数来限制垃圾收集的线程数.\n\n##### 注意  \n从ParNew收集器开始,后面还将会接触到几款并发和并行的收集器.在大家可能产生疑惑之前,有必要先解释两个名词：并发和并行.这两个名词都是并发编程中的概念,在谈论垃圾收集器的上下文语境中,他们可以解释为：\n* 并行（Parallel）：指多条垃圾收集线程并行工作,但此时用户线程仍然处于等待状态.\n* 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的,可能会交替执行）,用户程序继续运行,而垃圾收集程序运行于另一个CPU上.\n\n### Parallel Scavege收集器\n\nParallel Scavenge收集器也是一个新生代收集器,它也是使用复制算法的收集器,又是并行的多线程收集器……看上去和ParNew都一样,那它有什么特别之处呢？\n\n#### Parallel Scavenge收集器的特点\n它的关注点与其他收集器不同,CMS等收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）.\n\n> 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）,虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%.\n\n停顿时间越短就越适合需要与用户交互的程序,良好的响应速度能提升用户的体验;而高吞吐量则可以最高效率地利用CPU时间,尽快地完成程序的运算任务,主要适合在后台运算而不需要太多交互的任务.\n\n#### Parallel Scavenge收集器设定\nParallel Scavenge收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集停顿时间的`-XX:MaxGCPauseMillis`参数及直接设置吞吐量大小的 `-XX:GCTimeRatio`参数.\n\n* `MaxGCPauseMillis` : 参数允许的值是一个大于0的毫秒数,收集器将尽力保证内存回收花费的时间不超过设定值.不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快,GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些,收集300MB新生代肯定比收集500MB快吧,这也直接导致垃圾收集发生得更频繁一些,原来10秒收集一次、每次停顿100毫秒,现在变成5秒收集一次、每次停顿70毫秒.停顿时间的确在下降,但吞吐量也降下来了.\n\n* `GCTimeRatio` : 参数的值应当是一个大于0小于100的整数,也就是垃圾收集时间占总时间的比率,相当于是吞吐量的倒数.如果把此参数设置为19,那允许的最大GC时间就占总时间的5%（即1 /（1+19））,默认值为99,就是允许最大1%（即1 /（1+99））的垃圾收集时间.\n\n由于与吞吐量关系密切,Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器.除上述两个参数之外,Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得关注.\n* `-XX:+UseAdaptiveSizePolicy` :这是一个开关参数,当这个参数打开之后,就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（`-XX:SurvivorRatio`）、晋升老年代对象年龄（`-XX:PretenureSizeThreshold`）等细节参数了,虚拟机会根据当前系统的运行情况收集性能监控信息,动态调整这些参数以提供最合适的停顿时间或最大的吞吐量,这种调节方式称为GC自适应的调节策略（GC Ergonomics）.\n> 如果读者对于收集器运作原理不太了解,手工优化存在困难的时候,使用Parallel Scavenge收集器配合自适应调节策略,把内存管理的调优任务交给虚拟机去完成将是一个很不错的选择.只需要把基本的内存数据设置好（如-Xmx设置最大堆）,然后使用`MaxGCPauseMillis`参数（更关注最大停顿时间）或`GCTimeRatio`参数（更关注吞吐量）给虚拟机设立一个优化目标,那具体细节参数的调节工作就由虚拟机完成了.自适应调节策略也是`Parallel Scavenge`收集器与`ParNew`收集器的一个重要区别.\n\n### Serial Old收集器\n\nSerial Old是Serial收集器的老年代版本,它同样是一个单线程收集器,使用“标记-整理”算法.这个收集器的主要意义也是被Client模式下的虚拟机使用.如果在Server模式下,它主要还有两大用途：一个是在JDK 1.5及之前的版本中与Parallel Scavenge收集器搭配使用,另外一个就是作为CMS收集器的后备预案,在并发收集发生Concurrent Mode Failure的时候使用.\n\n### Parallel old收集器\n\nParallel Old是Parallel Scavenge收集器的老年代版本,使用多线程和“标记－整理”算法.这个收集器是在JDK 1.6中才开始提供的,在此之前,新生代的Parallel Scavenge收集器一直处于比较尴尬的状态.原因是,如果新生代选择了Parallel Scavenge收集器,老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）.由于单线程的老年代Serial Old收集器在服务端应用性能上的“拖累”,即便使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果,又因为老年代收集中无法充分利用服务器多CPU的处理能力,在老年代很大而且硬件比较高级的环境中,这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”.\n\n直到Parallel Old收集器出现后,“吞吐量优先”收集器终于有了比较名副其实的应用组合,在注重吞吐量及CPU资源敏感的场合,都可以优先考虑Parallel Scavenge加Parallel Old收集器.\n\n### CMS收集器\n\n#### 用途\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器.目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验.CMS收集器就非常符合这类应用的需求.\n\n##### 采用算法\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的,它的运作过程相对于前面几种收集器来说要更复杂一些,整个过程分为4个步骤,包括：\n1. 初始标记（CMS initial mark）\n2. 并发标记（CMS concurrent mark）\n3. 重新标记（CMS remark）\n4. 并发清除（CMS concurrent sweep）\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象,速度很快,并发标记阶段就是进行GC Roots Tracing的过程,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段稍长一些,但远比并发标记的时间短.\n\n由于整个过程中耗时最长的并发标记和并发清除过程中,收集器线程都可以与用户线程一起工作,所以总体上来说,CMS收集器的内存回收过程是与用户线程一起并发地执行的.通过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间.\n\nCMS是一款优秀的收集器,它的最主要优点在名字上已经体现出来了：并发收集、低停顿,Sun的一些官方文档里面也称之为并发低停顿收集器（Concurrent Low Pause Collector）.但是CMS还远达不到完美的程度,它有以下三个显著的缺点：\n\nCMS收集器对CPU资源非常敏感.其实,面向并发设计的程序都对CPU资源比较敏感.在并发阶段,它虽然不会导致用户线程停顿,但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢,总吞吐量会降低.CMS默认启动的回收线程数是（CPU数量+3）/ 4,也就是当CPU在4个以上时,并发回收时垃圾收集线程最多占用不超过25%的CPU资源.但是当CPU不足4个时（譬如2个）,那么CMS对用户程序的影响就可能变得很大,如果CPU负载本来就比较大的时候,还分出一半的运算能力去执行收集器线程,就可能导致用户程序的执行速度忽然降低了50%,这也很让人受不了.为了解决这种情况,虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep / i-CMS）的CMS收集器变种,所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样,就是在并发标记和并发清理的时候让GC线程、用户线程交替运行,尽量减少GC线程的独占资源的时间,这样整个垃圾收集的过程会更长,但对用户程序的影响就会显得少一些,速度下降也就没有那么明显,但是目前版本中,i-CMS已经被声明为“deprecated”,即不再提倡用户使用.\n\nCMS收集器无法处理浮动垃圾（Floating Garbage）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生.由于CMS并发清理阶段用户线程还在运行着,伴随程序的运行自然还会有新的垃圾不断产生,这一部分垃圾出现在标记过程之后,CMS无法在本次收集中处理掉它们,只好留待下一次GC时再将其清理掉.这一部分垃圾就称为“浮动垃圾”.也是由于在垃圾收集阶段用户线程还需要运行,即还需要预留足够的内存空间给用户线程使用,因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,需要预留一部分空间提供并发收集时的程序运作使用.在默认设置下,CMS收集器在老年代使用了68%的空间后就会被激活,这是一个偏保守的设置,如果在应用中老年代增长不是太快,可以适当调高参数`-XX:CMSInitiatingOccupancyFraction`的值来提高触发百分比,以便降低内存回收次数以获取更好的性能.要是CMS运行期间预留的内存无法满足程序需要,就会出现一次“Concurrent Mode Failure”失败,这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了.所以说参数`-XX:CMSInitiatingOccupancyFraction`设置得太高将会很容易导致大量“Concurrent Mode Failure”失败,性能反而降低.\n\n还有最后一个缺点,在本节在开头说过,CMS是一款基于“标记-清除”算法实现的收集器,如果读者对前面这种算法介绍还有印象的话,就可能想到这意味着收集结束时会产生大量空间碎片.空间碎片过多时,将会给大对象分配带来很大的麻烦,往往会出现老年代还有很大的空间剩余,但是无法找到足够大的连续空间来分配当前对象,不得不提前触发一次Full GC.为了解决这个问题,CMS收集器提供了一个`-XX:+UseCMSCompactAtFullCollection`开关参数,用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程,内存整理的过程是无法并发的.空间碎片问题没有了,但停顿时间不得不变长了.虚拟机设计者们还提供了另外一个参数`-XX: CMSFullGCsBeforeCompaction`,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的.\n\n### G1收集器\n\nG1（Garbage First）收集器是当前收集器技术发展的最前沿成果,在JDK 1.6_Update14中提供了EarlyAccess版本的G1收集器以供试用.在将来JDK 1.7正式发布的时候,G1收集器很可能会有一个成熟的商用版本随之发布.这里只对G1收集器进行简单介绍.\n\nG1收集器是垃圾收集器理论进一步发展的产物,它与前面的CMS收集器相比有两个显著的改进：一是G1收集器是基于“标记-整理”算法实现的收集器,也就是说它不会产生空间碎片,这对于长时间运行的应用系统来说非常重要.二是它可以非常精确地控制停顿,\n既能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒,这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了.\n\nG1收集器可以实现在基本不牺牲吞吐量的前提下完成低停顿的内存回收,这是由于它能够极力地避免全区域的垃圾收集,之前的收集器进行收集的范围都是整个新生代或老年代,而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域（Region）,并且跟踪这些区域里面的垃圾堆积程度,在后台维护一个优先列表,每次根据允许的收集时间,优先回收垃圾最多的区域（这就是Garbage First名称的来由）.区域划分及有优先级的区域回收,保证了G1收集器在有限的时间内可以获得最高的收集效率.\n\n\n","slug":"jvm7/垃圾收集","published":1,"updated":"2015-10-16T02:39:48.846Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxt0002d0cuftp51ffwf"},{"date":"2014-10-07T16:00:00.000Z","title":"内存分配以及内存溢出","_content":"## 内存分配\n### 对象优先在Eden分配\n\n大多数情况下,对象在新生代`Eden`区中分配.当`Eden`区没有足够的空间进行分配时,虚拟机将发起一次`Minor GC`.\n\n虚拟机提供了`-XX:+PrintGCDetails`这个收集器日志参数,告诉虚拟机在发生垃圾收集行为时打印内存回收日志,并且在进程退出的时候输出当前内存各区域的分配情况.在实际应用中,内存回收日志一般是打印到文件后通过日志工具进行分析.\n\n1. 新生代GC(`Minor GC`)：指发生在新生代的垃圾收集动作,因为Java对象大多都具备朝生夕灭的特性,所以`Minor GC`非常频繁,一般回收速度也比较快.\n2. 老年代GC(`Major GC/Full GC`)：指发生在老年代的GC,出现了Major GC,经常会伴随至少一次的Minor GC(但非绝对的,在ParallelScavenge收集器的收集策略里就有直接进行Major GC的策略选择过程).MajorGC的速度一般会比Minor GC慢10倍以上.\n\n#### 示例代码\n```java\nprivate static final int _1MB = 1024 #### 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  */\npublic static void testAllocation() {\n\t    byte[] allocation1, allocation2, allocation3, allocation4;\n\t    allocation1 = new byte[2 #### _1MB];\n\t    allocation2 = new byte[2 #### _1MB];\n\t    allocation3 = new byte[2 #### _1MB];\n\t    allocation4 = new byte[4 #### _1MB];  // 出现一次Minor GC\n}\n```\n#### 代码分析\n\n`testAllocation()`方法中,尝试分配3个2MB大小和1个4MB大小的对象, 在运行时通过`-Xms20M、 -Xmx20M`和`-Xmn10M`这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代.\n\n`-XX:SurvivorRatio=8`决定了新生代中Eden区与一个`Survivor`区的空间比例是8比1,从输出的结果也能清晰地看到`“eden space 8192K、from space 1024K、to space 1024K”`的信息,新生代总可用空间为`9216KB`(`Eden`区+1个`Survivor`区的总容量).\n\n执行`testAllocation()`中分配`allocation4`对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象).\n\n这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去.\n\n这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用).通过GC日志可以证实这一点.\n\n### 大对象直接进入老年代\n\n所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组(笔者例子中的byte[]数组就是典型的大对象).大对象对虚拟机的内存分配来说就是一个坏消息(替Java虚拟机抱怨一句,比遇到一个大对象更加坏的消息 就是遇到一群“朝生夕灭”的“短命大对象”,写程序的时候应当避免),经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们.\n\n虚拟机提供了一个`-XX:PretenureSizeThreshold`参数,令大于这个设置值的对象直接在老年代中分配.这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(复习一下：新生代采用复制算法收集内存).\n\n执行代码清单3-4中的`testPretenureSizeThreshold()`方法后,我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为`PretenureSizeThreshold`被设置为3MB(就是3145728B,这个参数不能与`-Xmx`之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配.\n\n> 注意　`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效,`Parallel Scavenge`收集器不认识这个参数,\n>\n> `Parallel Scavenge`收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n\t  * -XX:PretenureSizeThreshold=3145728\n\t  */\n\tpublic static void testPretenureSizeThreshold() {\n\t\t　byte[] allocation;\n\t\t　allocation = new byte[4 #### _1MB];  //直接分配在老年代中\n\t}\n```\n#### 长期存活的对象将进入老年代\n\n虚拟机既然采用了分代收集的思想来管理内存,那内存回收时就必须能识别哪些对象应当放在新生代,哪些对象应放在老年代中.为了做到这点,虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活,\t并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数`-XX:MaxTenuringThreshold`来设置.\n\n读者可以试试分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行代码清单3-5中的`testTenuringThreshold()`方法,此方法中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用.\n\n###### 实例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold() {\n\t\t byte[] allocation1, allocation2, allocation3;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置\n\t\t allocation2 = new byte[4 #### _1MB];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation3 = null;\n\t\t allocation3 = new byte[4 #### _1MB];\n\t}\n```\n#### 动态年龄判断\n\n为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升老年代,如果在`Survivor`空间中相同年龄所有对象大小的总和大于`Survivor`空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到`MaxTenuringThreshold`中要求的年龄.\n\n执行代码清单3-6中的testTenuringThreshold2()方法,并设置参数`-XX: MaxTenuringThreshold=15`,会发现运行结果中`Survivor`的空间占用仍然为0%,而老年代比预期增加了`6%`,也就是说`allocation1、allocation2`对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold2() {\n\t\t byte[] allocation1, allocation2, allocation3, allocation4;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // allocation1+allocation2大于survivor空间的一半\n\t\t allocation2 = new byte[_1MB / 4];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation4 = new byte[4 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation4 = new byte[4 #### _1MB];\n\t}\n```\n#### 空间分配担保\n\n在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC.\n\n前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor\t无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的\t剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间.\n\n取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败,\t那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将\tHandlePromotionFailure开关打开,避免Full GC过于频繁,\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testHandlePromotion() {\n\t\t byte[] allocation1, allocation2, allocation3,\n\t\t allocation4, allocation5, allocation6, allocation7;\n\t\t allocation1 = new byte[2 #### _1MB];\n\t\t allocation2 = new byte[2 #### _1MB];\n\t\t allocation3 = new byte[2 #### _1MB];\n\t\t allocation1 = null;\n\t\t allocation4 = new byte[2 #### _1MB];\n\t\t allocation5 = new byte[2 #### _1MB];\n\t\t allocation6 = new byte[2 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation5 = null;\n\t\t allocation6 = null;\n\t\t allocation7 = new byte[2 #### _1MB];\n\t}\n```\n\n\n## 各种内存异常\n### java堆溢出\n溢出代码\n\n```java\n  public class HeapOOM {\n\n\tstatic class OOMObject {\n\t}\n\n\t/**\n\t * -verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t * -XX:PrintGCDetails\n\t * -XX:SurvivorRatio=8\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tList<OOMObject> list = new ArrayList<>();\n\t\twhile(true) {\n\t\t\tlist.add(new OOMObject());\n\t\t}\n\t}\n\n}\n```\n执行代码\n```\n\tjavac HeapOOM.java\n\tjava -verbose:gc -Xms20M -Xmx20M -Xmn10M   -XX:+PrintGCDetails  -XX:SurvivorRatio=8  HeapOOM\n\tpause\n```\n解决java堆内存溢出,一般的手段是通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出的堆转储快照进行分析.重点是确认内存中的对象是否是必要的,也就是先分清楚是内存泄漏还是内存溢出.\n1. 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位出泄漏代码的位置.\n2. 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗.\n\n### 虚拟机栈和本地方法栈溢出\n溢出代码\n```java\n\t/**\n\t  * -Xoss 设置本地放发栈 但是此参数无效\n\t  * -Xss 虚拟机栈 设置此参数\n\t  * @param args\n\t  */\n\n\tpublic class JavaVMStackSOF {\n\n\t\tprivate int stackLength = 1;\n\n\t\tpublic void stackLeak() {\n\t\t\tstackLength ++;\n\t\t\tstackLeak();\n\t\t}\n\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackSOF oom = new JavaVMStackSOF();\n\t\t\ttry {\n\t\t\t\toom.stackLeak();\n\t\t\t} catch(Throwable e) {\n\t\t\t\tSystem.out.println(\"stack length:\" + oom.stackLength);\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic class JavaVMStackOOM {\n\t\tprivate void dontStop() {\n\t\t\twhile(true) {\n\n\t\t\t}\n\t\t}\n\n\t\tpublic void stackLeakByThread() {\n\t\t\twhile(true) {\n\t\t\t\tThread t = new Thread(new Runnable(){\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tdontStop();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackOM om = new JavaVMStackOM();\n\t\t\tom.stackLeakByThread();\n\t\t}\n\t}\n```\n以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常.\n\n当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆和减少栈容量来换取更多的线程.\n\n### 运行时常量池溢出\n\n#### 溢出代码\n\n```java\n\t/**\n\t * 运行时常量溢出\n\t * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class RuntimeConstantPoolOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\tList<String> list = new ArrayList<>();\n\t\t\tint i = 0;\n\t\t\twhile(true) {\n\t\t\t\tlist.add(String.valueOf(i++).intern());\n\t\t\t}\n\t\t}\n\t}\n```\n如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String对象包含的字符串添加到常量池中,并返回次String对象音乐.\n\n### 方法区溢出\n溢出代码\n```java\n\t/**\n\t * 借助CGLib使得方法区内存溢出异常\n\t * -XX:PermSize10M -XX:MaxPermSize10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class JavaMethodAreaOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\twhile(true) {\n\t\t\t\tEnhancer enhancer = new Enhancer();\n\t\t\t\tenhancer.setSuperclass(OOMObject.class);\n\t\t\t\tenhancer.setUseCache(false);\n\t\t\t\tenhancer.setCallBack(new MethodInterceptor(){\n\t\t\t\t\tpublic Object intercept(Object obj, Method method, Object[] objs,\n\t\t\t\t\tMethodProxy proxy) throws Throwable {\n\t\t\t\t\t\treturn proxy.invokeSuper(obj, args);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tstatic class OOMObject {\n\n\t\t}\n\t}\n```\n执行代码\n```\n\tjavac JavaMethodAreaOOMRun.java\n\tjava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun\npause\n```\n方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.本例中使用的是CGLib, 还可以使用ASM等框架进行测试.方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类)\n\n\n### 本地内存直接溢出\n溢出代码\n```java\n\t/**\n\t * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M\n\t */\n\tpublic class DirectMemoryOOM {\n\t    private static final int _1MB = 1024 * 1024;\n\n\t    public static void main(String[] args) throws Exception {\n\t        Field unsafeField = Unsafe.class.getDeclaredFields()[0];\n\t        unsafeField.setAccessible(true);\n\t        Unsafe unsafe = (Unsafe)unsafeField.get(null);\n\t        while(true)\n\t            unsafe.allocateMemory(_1MB);\n\t    }\n}\n```\n直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:unsafe.allocateMemory(_1MB);\n","source":"_posts/jvm7/内存分配以及内存溢出.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: 内存分配以及内存溢出\n---\n## 内存分配\n### 对象优先在Eden分配\n\n大多数情况下,对象在新生代`Eden`区中分配.当`Eden`区没有足够的空间进行分配时,虚拟机将发起一次`Minor GC`.\n\n虚拟机提供了`-XX:+PrintGCDetails`这个收集器日志参数,告诉虚拟机在发生垃圾收集行为时打印内存回收日志,并且在进程退出的时候输出当前内存各区域的分配情况.在实际应用中,内存回收日志一般是打印到文件后通过日志工具进行分析.\n\n1. 新生代GC(`Minor GC`)：指发生在新生代的垃圾收集动作,因为Java对象大多都具备朝生夕灭的特性,所以`Minor GC`非常频繁,一般回收速度也比较快.\n2. 老年代GC(`Major GC/Full GC`)：指发生在老年代的GC,出现了Major GC,经常会伴随至少一次的Minor GC(但非绝对的,在ParallelScavenge收集器的收集策略里就有直接进行Major GC的策略选择过程).MajorGC的速度一般会比Minor GC慢10倍以上.\n\n#### 示例代码\n```java\nprivate static final int _1MB = 1024 #### 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  */\npublic static void testAllocation() {\n\t    byte[] allocation1, allocation2, allocation3, allocation4;\n\t    allocation1 = new byte[2 #### _1MB];\n\t    allocation2 = new byte[2 #### _1MB];\n\t    allocation3 = new byte[2 #### _1MB];\n\t    allocation4 = new byte[4 #### _1MB];  // 出现一次Minor GC\n}\n```\n#### 代码分析\n\n`testAllocation()`方法中,尝试分配3个2MB大小和1个4MB大小的对象, 在运行时通过`-Xms20M、 -Xmx20M`和`-Xmn10M`这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代.\n\n`-XX:SurvivorRatio=8`决定了新生代中Eden区与一个`Survivor`区的空间比例是8比1,从输出的结果也能清晰地看到`“eden space 8192K、from space 1024K、to space 1024K”`的信息,新生代总可用空间为`9216KB`(`Eden`区+1个`Survivor`区的总容量).\n\n执行`testAllocation()`中分配`allocation4`对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象).\n\n这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去.\n\n这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用).通过GC日志可以证实这一点.\n\n### 大对象直接进入老年代\n\n所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组(笔者例子中的byte[]数组就是典型的大对象).大对象对虚拟机的内存分配来说就是一个坏消息(替Java虚拟机抱怨一句,比遇到一个大对象更加坏的消息 就是遇到一群“朝生夕灭”的“短命大对象”,写程序的时候应当避免),经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们.\n\n虚拟机提供了一个`-XX:PretenureSizeThreshold`参数,令大于这个设置值的对象直接在老年代中分配.这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(复习一下：新生代采用复制算法收集内存).\n\n执行代码清单3-4中的`testPretenureSizeThreshold()`方法后,我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为`PretenureSizeThreshold`被设置为3MB(就是3145728B,这个参数不能与`-Xmx`之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配.\n\n> 注意　`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效,`Parallel Scavenge`收集器不认识这个参数,\n>\n> `Parallel Scavenge`收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n\t  * -XX:PretenureSizeThreshold=3145728\n\t  */\n\tpublic static void testPretenureSizeThreshold() {\n\t\t　byte[] allocation;\n\t\t　allocation = new byte[4 #### _1MB];  //直接分配在老年代中\n\t}\n```\n#### 长期存活的对象将进入老年代\n\n虚拟机既然采用了分代收集的思想来管理内存,那内存回收时就必须能识别哪些对象应当放在新生代,哪些对象应放在老年代中.为了做到这点,虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活,\t并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数`-XX:MaxTenuringThreshold`来设置.\n\n读者可以试试分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行代码清单3-5中的`testTenuringThreshold()`方法,此方法中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用.\n\n###### 实例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold() {\n\t\t byte[] allocation1, allocation2, allocation3;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置\n\t\t allocation2 = new byte[4 #### _1MB];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation3 = null;\n\t\t allocation3 = new byte[4 #### _1MB];\n\t}\n```\n#### 动态年龄判断\n\n为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升老年代,如果在`Survivor`空间中相同年龄所有对象大小的总和大于`Survivor`空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到`MaxTenuringThreshold`中要求的年龄.\n\n执行代码清单3-6中的testTenuringThreshold2()方法,并设置参数`-XX: MaxTenuringThreshold=15`,会发现运行结果中`Survivor`的空间占用仍然为0%,而老年代比预期增加了`6%`,也就是说`allocation1、allocation2`对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold2() {\n\t\t byte[] allocation1, allocation2, allocation3, allocation4;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // allocation1+allocation2大于survivor空间的一半\n\t\t allocation2 = new byte[_1MB / 4];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation4 = new byte[4 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation4 = new byte[4 #### _1MB];\n\t}\n```\n#### 空间分配担保\n\n在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC.\n\n前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor\t无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的\t剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间.\n\n取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败,\t那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将\tHandlePromotionFailure开关打开,避免Full GC过于频繁,\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testHandlePromotion() {\n\t\t byte[] allocation1, allocation2, allocation3,\n\t\t allocation4, allocation5, allocation6, allocation7;\n\t\t allocation1 = new byte[2 #### _1MB];\n\t\t allocation2 = new byte[2 #### _1MB];\n\t\t allocation3 = new byte[2 #### _1MB];\n\t\t allocation1 = null;\n\t\t allocation4 = new byte[2 #### _1MB];\n\t\t allocation5 = new byte[2 #### _1MB];\n\t\t allocation6 = new byte[2 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation5 = null;\n\t\t allocation6 = null;\n\t\t allocation7 = new byte[2 #### _1MB];\n\t}\n```\n\n\n## 各种内存异常\n### java堆溢出\n溢出代码\n\n```java\n  public class HeapOOM {\n\n\tstatic class OOMObject {\n\t}\n\n\t/**\n\t * -verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t * -XX:PrintGCDetails\n\t * -XX:SurvivorRatio=8\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tList<OOMObject> list = new ArrayList<>();\n\t\twhile(true) {\n\t\t\tlist.add(new OOMObject());\n\t\t}\n\t}\n\n}\n```\n执行代码\n```\n\tjavac HeapOOM.java\n\tjava -verbose:gc -Xms20M -Xmx20M -Xmn10M   -XX:+PrintGCDetails  -XX:SurvivorRatio=8  HeapOOM\n\tpause\n```\n解决java堆内存溢出,一般的手段是通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出的堆转储快照进行分析.重点是确认内存中的对象是否是必要的,也就是先分清楚是内存泄漏还是内存溢出.\n1. 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位出泄漏代码的位置.\n2. 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗.\n\n### 虚拟机栈和本地方法栈溢出\n溢出代码\n```java\n\t/**\n\t  * -Xoss 设置本地放发栈 但是此参数无效\n\t  * -Xss 虚拟机栈 设置此参数\n\t  * @param args\n\t  */\n\n\tpublic class JavaVMStackSOF {\n\n\t\tprivate int stackLength = 1;\n\n\t\tpublic void stackLeak() {\n\t\t\tstackLength ++;\n\t\t\tstackLeak();\n\t\t}\n\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackSOF oom = new JavaVMStackSOF();\n\t\t\ttry {\n\t\t\t\toom.stackLeak();\n\t\t\t} catch(Throwable e) {\n\t\t\t\tSystem.out.println(\"stack length:\" + oom.stackLength);\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic class JavaVMStackOOM {\n\t\tprivate void dontStop() {\n\t\t\twhile(true) {\n\n\t\t\t}\n\t\t}\n\n\t\tpublic void stackLeakByThread() {\n\t\t\twhile(true) {\n\t\t\t\tThread t = new Thread(new Runnable(){\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tdontStop();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackOM om = new JavaVMStackOM();\n\t\t\tom.stackLeakByThread();\n\t\t}\n\t}\n```\n以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常.\n\n当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆和减少栈容量来换取更多的线程.\n\n### 运行时常量池溢出\n\n#### 溢出代码\n\n```java\n\t/**\n\t * 运行时常量溢出\n\t * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class RuntimeConstantPoolOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\tList<String> list = new ArrayList<>();\n\t\t\tint i = 0;\n\t\t\twhile(true) {\n\t\t\t\tlist.add(String.valueOf(i++).intern());\n\t\t\t}\n\t\t}\n\t}\n```\n如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String对象包含的字符串添加到常量池中,并返回次String对象音乐.\n\n### 方法区溢出\n溢出代码\n```java\n\t/**\n\t * 借助CGLib使得方法区内存溢出异常\n\t * -XX:PermSize10M -XX:MaxPermSize10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class JavaMethodAreaOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\twhile(true) {\n\t\t\t\tEnhancer enhancer = new Enhancer();\n\t\t\t\tenhancer.setSuperclass(OOMObject.class);\n\t\t\t\tenhancer.setUseCache(false);\n\t\t\t\tenhancer.setCallBack(new MethodInterceptor(){\n\t\t\t\t\tpublic Object intercept(Object obj, Method method, Object[] objs,\n\t\t\t\t\tMethodProxy proxy) throws Throwable {\n\t\t\t\t\t\treturn proxy.invokeSuper(obj, args);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tstatic class OOMObject {\n\n\t\t}\n\t}\n```\n执行代码\n```\n\tjavac JavaMethodAreaOOMRun.java\n\tjava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun\npause\n```\n方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.本例中使用的是CGLib, 还可以使用ASM等框架进行测试.方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类)\n\n\n### 本地内存直接溢出\n溢出代码\n```java\n\t/**\n\t * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M\n\t */\n\tpublic class DirectMemoryOOM {\n\t    private static final int _1MB = 1024 * 1024;\n\n\t    public static void main(String[] args) throws Exception {\n\t        Field unsafeField = Unsafe.class.getDeclaredFields()[0];\n\t        unsafeField.setAccessible(true);\n\t        Unsafe unsafe = (Unsafe)unsafeField.get(null);\n\t        while(true)\n\t            unsafe.allocateMemory(_1MB);\n\t    }\n}\n```\n直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:unsafe.allocateMemory(_1MB);\n","slug":"jvm7/内存分配以及内存溢出","published":1,"updated":"2015-10-16T07:03:51.882Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxt2002f0cuf7j4rulgf"},{"date":"2014-10-07T16:00:00.000Z","title":"OQL","_content":"# OQL\n\n## SELECT\n`select`用于确定查询语句从堆转储快照中选择什么内容,如果需要显示堆转储快照中的对象,并且浏览这些对象的引用关系,可以使用`*`:\n\n```sql\nSELECT * FEOM java.lang.String\n```\n\n####选择特定的显示列\n查询也可以选择特定需要显示的字段:\n```sql\nSELECT toString(s), s.count, s.value From java.lang.String s\n```\n查询可以十一`@`符号来适应java对象的内存属性访问器\n```sql\nSELECT toString(s), s.@useHeapSize, s.retainedHeapSize From java.lang.String s\n```\n\n####使用列别名\n\n```sql\n\n```\n\n\n\n####拼合成为一个对象列表选择项目\n\n```sql\n\n```\n\n\n\n####排除重复对象\n\n```sql\n\n```\n\n\n\n##FROM\n\n####FROM子句指定需要查询的类\n\n```sql\n\n```\n\n\n\n####包含子类\n\n```sql\n\n```\n\n\n\n####禁止查询类实例\n\n\n```sql\n\n```\n\n\n## WHERE\n\n\n\n```sql\n\n```\n\n####>=,<=,>,<[NOT]LIKE,[NOT]IN\n\n\n```sql\n\n```\n\n\n####=,!=\n\n\n```sql\n\n```\n\n\n####AND\n\n\n```sql\n\n```\n\n\n####OR\n\n\n```sql\n\n```\n\n\n####文字表达式\n\n\n```sql\n\n```\n\n\n##属性访问器\n####访问堆存储快照中对象的字段\n\n\n```sql\n\n```\n\n\n####访问java bean属性\n\n\n```sql\n\n```\n\n\n####钓鱼OQL java语法\n\n\n```sql\n\n```\n\n\n####OQL内建函数\n\n\n\n```sql\n\n```\n\n##OQL语言的BNF范式\n\n\n```sql\n\n```\n\n","source":"_posts/jvm7/oql.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: OQL\n---\n# OQL\n\n## SELECT\n`select`用于确定查询语句从堆转储快照中选择什么内容,如果需要显示堆转储快照中的对象,并且浏览这些对象的引用关系,可以使用`*`:\n\n```sql\nSELECT * FEOM java.lang.String\n```\n\n####选择特定的显示列\n查询也可以选择特定需要显示的字段:\n```sql\nSELECT toString(s), s.count, s.value From java.lang.String s\n```\n查询可以十一`@`符号来适应java对象的内存属性访问器\n```sql\nSELECT toString(s), s.@useHeapSize, s.retainedHeapSize From java.lang.String s\n```\n\n####使用列别名\n\n```sql\n\n```\n\n\n\n####拼合成为一个对象列表选择项目\n\n```sql\n\n```\n\n\n\n####排除重复对象\n\n```sql\n\n```\n\n\n\n##FROM\n\n####FROM子句指定需要查询的类\n\n```sql\n\n```\n\n\n\n####包含子类\n\n```sql\n\n```\n\n\n\n####禁止查询类实例\n\n\n```sql\n\n```\n\n\n## WHERE\n\n\n\n```sql\n\n```\n\n####>=,<=,>,<[NOT]LIKE,[NOT]IN\n\n\n```sql\n\n```\n\n\n####=,!=\n\n\n```sql\n\n```\n\n\n####AND\n\n\n```sql\n\n```\n\n\n####OR\n\n\n```sql\n\n```\n\n\n####文字表达式\n\n\n```sql\n\n```\n\n\n##属性访问器\n####访问堆存储快照中对象的字段\n\n\n```sql\n\n```\n\n\n####访问java bean属性\n\n\n```sql\n\n```\n\n\n####钓鱼OQL java语法\n\n\n```sql\n\n```\n\n\n####OQL内建函数\n\n\n\n```sql\n\n```\n\n##OQL语言的BNF范式\n\n\n```sql\n\n```\n\n","slug":"jvm7/oql","published":1,"updated":"2015-10-16T02:39:51.254Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxt4002h0cufk3etx2sq"},{"date":"2014-10-07T16:00:00.000Z","title":"运行时数据区","_content":"## 运行时数据区\n### PC寄存器 (线程独有)\n* 每一个虚拟机线程都有自己的线程寄存器\n* 寄存器里存储了java虚拟机正在执行的字节码指令(线程当前方法)的地址, 字节码解释器工作时就是通过改变这个计数器的值来选取下一条\n  需要执行的字节码指令,分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个计数器来完成\n* 由于java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方法来实现的,在任何一个确定的时刻,一个处理器只会执行一条线程   中的指令.因此为了线程切换后能恢复到正确的执行位置,每条线程都需要有一个独立的程序计数器,各条线程之间的计数器互不影响,独立\n  存储,称这类内存区域为\"线程私有\"的内存\n* 这是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域.\n\n寄存器集成在 CPU 里面,这是最快的数据访问存储区,但是寄存器的数量极其有限,所以寄存器由编译器根据需求进行分配,开发人员不能直接控制,也不能在程序中感觉到寄存器存在的迹象 。\n\n### java虚拟机栈 (线程独有)\n* 与线程同时创建,用于存储栈帧. 它的生命周期与线程相同.\n* 每个方法被执行的时候都会创建一个栈帧,用于存储局部变量表,操作数栈,动态连接,方法出口等信息.\n* 在java虚拟机中.对这个区域规定了俩种异常情况:\n\n   > 1. 如果请求的栈深度大于虚拟机所允许的深度,抛出StackOverflowError.<br>\n   > 2. 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常\n\n位于通用 RAM 中,存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中 。 在堆中产生了一个数组或对象后,还可以在栈中定义一个特殊的变量,让栈中这个变量的取值等于数组或对象在堆内存中的首地址,栈中的这个变量就成了数组或对象的引用变量 。\n\n### java堆\n* 是供各个线程共享的运行时内存\n* 所有类实例和数组对象分配内存的地方\n* 在虚拟机创建的时候该区域就创建了\n* 存储了内存管理系统(GC)\n* java虚拟机中规定,java堆可以处于物理上不连续的内存空间中,逻辑上是连续的即可.在设计时,既可以设计成固定大小的,也可以设计成\n  可拓展的.\n* 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError\n* 需要说明的一点的是,随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上\n  分配也不是那么绝对了\n\n  > 简单介绍一下,java堆内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 如果从内存分配的角都看,线程共享的java对可能还可能划分出多个线程私有的分配缓冲区.\n\n一种通用性的内存池 (也存在于 RAM 中)， 用于存放所以的 JAVA 对象。 Java 的堆是一个运行时数据区 , 对象被存储在堆中 。 这些对象通过 new 等指令建立， 它们不需要程序代码 来显式的释放。 因此， 在堆里分配存储有很大的灵活性 。 堆的缺点是,由于要在运行时动态分配内存,存取速度较慢 。\n\n### 方法区\n* 虚拟机启动时创建\n* 供各个线程共享的运行时内存\n* 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容\n* java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以\n  选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样\"永久存在\". 这个区域的\n  回收目标是针对常量池的回收和对类型的卸载.\n* 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError.\n\n###### 运行时常量池\n\n运行时常量池是方法区的一部分.\n\nClass文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.\n这部分内容将在类加载后存放到方法区的运行时常量池中.\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是`String#intern()`在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示.\n\n它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用\n\njava 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 。 常量池其实也就是一个内存空间,不同于使用 `new` 关键字创建的对象所在的堆空间 。 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型\n\n\n###### 回收方法区\n在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此.\n\n###### 永久代的垃圾回收主要是回收俩部分内容:\n*. 废弃常量\n\n回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串\"ABC\"已经进入了常量池,但是当前系统中没有任何一个String对象是叫做\"ABC\"的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个\"ABC\"常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似.\n\n* 无用的类\n\n判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件:\n\n\t> 1. 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.<br.>\n\t> 2. 加载该类的ClassLoader已经被回收.<br.>\n\t> 3. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类.\n\n虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用`-verbose:Class`及\n`-XX:+TraceClassLoading`,`-XX:+TraceClassUnLoading`查看类的加载和卸载信息.`-verbose:Class`和`-XX:+TraceClassLoading`可以在Product版的虚拟机中使用,但是`-XX:+TraceClassLoading`参数需要fastdebug版的虚拟机支持\n\n### 直接内存\n* 直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致\n  OutOfMemoryError异常出现\n* 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的\n  DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据.\n* 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器\n  寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于\n  物理内存限制,从而导致动态拓展时,出现OutOfMemoryError.\n\n### 本地方法栈\n* 用来支持native方法\n\n### 静态存储\n\n静态存储里存放程序运行时一直存在的数据 。 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 。 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 。\n\n## 栈帧\n* 用来存储数据和部分过程结果的数据结构, 同时也用来处理动态连接, 方法返回值和异常分派\n* 随着方法的调用而创建,随着方法的调用结束而销毁. (结束也包含异常情况)\n* 其内存分配在虚拟机栈之中, 每一个栈帧都有自己的本地变量表, 操作数栈, 和指向当前方法所属的类的运行时常量池.\n\n### 局部变量表\n* 其长度在编译器决定\n* 一个局部变量可以保存boolean, byte, char, short, int, float, reference,returnAddress类型的数据.俩个局部变量可以\n  保存一个long或者double类型的变量.\n* java虚拟机使用局部变量表来完成方法调用时的参数传递. 当调用一个方法时, 它的参数将会传递至从0开始的连续的变量表位置上.\n* 当调用一个实例方法时,第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用.后续的其他参数将会传递至从1开始的连续的\n  局部变量表位置上\n* 虚拟机通过索引定位的方式使用局部变量表,索引值的范围是从0开始到局部变量表最大的Slot数量.\n```\n\t局部变量表中的Slot是可重用的,方法体定义的变量,其作用域并不一定会覆盖整个方法体,如果当前字节码PC计数器的值\n\t已经超出了某个变量的作用域,那么这个变量对应的Slot就可以交给其他变量使用. 这样的设计不仅仅是为了节省栈空间,\n\t在某些情况下Slot的复用会直接影响到系统的垃圾收集行为\n```\n```java\npublic class CollectSlot1 {\n\n    public static void main(String[] args) {\n        byte[] placeholder = new byte[64 * 1024 * 1024];\n        System.gc();\n    }\n}\n\npublic class CollectSlot2 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        System.gc();\n    }\n}\n\npublic class CollectSlot3 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        int a = 0;\n        System.gc();\n    }\n}\n\npublic class CollectSlot4 {\n\n    public static void main(String[] args) {\n        int a = 0;\n        System.gc();\n    }\n}\n\n运行时,加上 -verbose:gc 参数,来查看垃圾收集过程.\n```\n###### 运行结果,CollectSlot1和CollectSlot2并没有执行垃圾回收. 而CollectSlot3却执行了垃圾收集\n###### 运行分析\n\nplaceholder能否被回收的根本原因就是:局部变量表中的Slot是否还存有关于placeholder数组对象的引用.在CollectSlot2中,代码虽然已经离开了placeholder的作用域,但在此之后,没有任何局部变量表的读写操作,placeholder原本所占用的Slot还没有被其他变量所复用,所以作为GC Roots一部分的局部变量表仍然保持着对它的关联.\n\n这种关联没有被及时打断,在绝大部分情况下影响都很轻微.但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了占用了大量内存,实际上已经不会再被使用的变量,手动将其设置为null值就不是一个毫无意义的操作.\n\n这种操作可以作为一种在极特殊情景(对象内存占用大,此方法的栈帧长时间不能被回收,方法调用次数达不到JIT的编译条件)下的奇技来使用. 但不应当对赋null值操作有过多的依赖.\n\n应该以恰当的作用域来控制变量回收时间才是最优雅的解决方法.(如CollectSlot3)\n\n另外赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.字节码被编译为本地代码后,对GC Roots的枚举也与解释执行时期有所差别,CollectSlot2在经过JIT编译后,System.gc() 执行时就可以正确回收掉内存,而无需写成CollectSlot3\n\n关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在\"准备阶段\".类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 所以 CollectSlot4 并不能运行,编译器能在编译器期间检查并提示这一点.\n\n### 操作数栈\n* 每个栈帧内部都包含一个称为操作数栈先进后出栈.\n* 其栈帧长度在编译器决定.\n* 栈帧在刚创建的时候, 操作数栈是空的, java虚拟机提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.\n* 也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈\n* 在调用方法时, 操作数栈也用来准备调用方法的参数以及接受方法返回结果.\n* 每个操作数栈的位置可以保存一个java虚拟机定义的任意数据类型的值,包括long和double类型\n* 在任意时刻,操作数都会有一个确定的栈深度, 一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度\n\n操作数栈也称为操作栈,它是一个先入后出栈.同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double. 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值.\n\n当一个方法开始执行的时候,这个方法的操作数栈是空的,在方法的执行过程中,会有各种字节码指令向操作数栈写入和提取内容,也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.\n\n举个例子,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈.\n\n操作数栈元素的数据类型必须与字节码指令的序列严格匹配,在编译程序代码的时候,编译器要严格保证这一点,在类校验阶段的数据流分析中还要再次验证这一点.再以上的iadd指令为例,这个指令用于整数相加,它在执行时,最接近栈顶的俩个元素的类型必须是int性,不能出现一个long和一个float使用iadd命令相加的情况.\n\n另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递:\n\n![俩个栈帧之间的数据共享]()\n\njava虚拟机解释执行引擎称为\"基于栈的执行引擎\",其中所指的栈就是操作数栈.\n\n\n### 动态连接\n* 每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.\n* 在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.\n* 类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.\n* 由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响\n\n每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的`动态连接`.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接\n\n### 方法正常调用完成\n* 当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等\n* 使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行\n\n### 方法调用非正常完成\n* 指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常\n\n\n### 方法返回地址\n\n当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口.\n\n另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的.\n\n无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息.\n\n方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等.\n\n## 方法调用\n方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用.\n\n### 解析\n继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为`解析(Resolution)`.\n\n在java语言中,符合\"编译器可知,运行期不可变\"这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析.\n\n###### 与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令:\n* `invokestatic`: 调用静态方法\n* `invokespecial`:调用实例构造器`<init>`方法,私有方法和父类方法\n* `invokevirtual`:调用所有的虚方法\n* `invokeinterface`:调用接口方法,会在运行时再确定一个实现此接口的对象\n\n只要能被`invokestatic`, `invokespecial`指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为`非虚方法`,与此相反,其他方法就称为`虚方法`(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法`sayHello()`只可能属于类型`StaticResolution`,没有任何手段可以覆盖或者隐藏这个方法.\n\n```java\npublic class StaticResolution {\n\n    public static void sayHello() {\n        System.out.println(\"hello\");\n    }\n\n    public static void main(String[] args) {\n        StaticResolution.sayHello();\n    }\n}\n\n```\n通过javap查看字节码:\n```java\npublic static void main(java.lang.String[]);\n   descriptor: ([Ljava/lang/String;)V\n   flags: ACC_PUBLIC, ACC_STATIC\n   Code:\n     stack=0, locals=1, args_size=1\n        0: invokestatic  #5                  // Method sayHello:()V\n        3: return\n     LineNumberTable:\n       line 9: 0\n       line 10: 3\n\n```\n\njava中的非虚方法除了使用`invokestatic`和`invokespecial`调用的方法之外还有一种,就是被`final`修饰的方法.虽然`final`方法是使用`invokespecial`指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法.\n\n解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.\n\n\n\n\n\n\n\n\n\n","source":"_posts/jvm7/java虚拟机结构.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: 运行时数据区\n---\n## 运行时数据区\n### PC寄存器 (线程独有)\n* 每一个虚拟机线程都有自己的线程寄存器\n* 寄存器里存储了java虚拟机正在执行的字节码指令(线程当前方法)的地址, 字节码解释器工作时就是通过改变这个计数器的值来选取下一条\n  需要执行的字节码指令,分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个计数器来完成\n* 由于java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方法来实现的,在任何一个确定的时刻,一个处理器只会执行一条线程   中的指令.因此为了线程切换后能恢复到正确的执行位置,每条线程都需要有一个独立的程序计数器,各条线程之间的计数器互不影响,独立\n  存储,称这类内存区域为\"线程私有\"的内存\n* 这是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域.\n\n寄存器集成在 CPU 里面,这是最快的数据访问存储区,但是寄存器的数量极其有限,所以寄存器由编译器根据需求进行分配,开发人员不能直接控制,也不能在程序中感觉到寄存器存在的迹象 。\n\n### java虚拟机栈 (线程独有)\n* 与线程同时创建,用于存储栈帧. 它的生命周期与线程相同.\n* 每个方法被执行的时候都会创建一个栈帧,用于存储局部变量表,操作数栈,动态连接,方法出口等信息.\n* 在java虚拟机中.对这个区域规定了俩种异常情况:\n\n   > 1. 如果请求的栈深度大于虚拟机所允许的深度,抛出StackOverflowError.<br>\n   > 2. 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常\n\n位于通用 RAM 中,存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中 。 在堆中产生了一个数组或对象后,还可以在栈中定义一个特殊的变量,让栈中这个变量的取值等于数组或对象在堆内存中的首地址,栈中的这个变量就成了数组或对象的引用变量 。\n\n### java堆\n* 是供各个线程共享的运行时内存\n* 所有类实例和数组对象分配内存的地方\n* 在虚拟机创建的时候该区域就创建了\n* 存储了内存管理系统(GC)\n* java虚拟机中规定,java堆可以处于物理上不连续的内存空间中,逻辑上是连续的即可.在设计时,既可以设计成固定大小的,也可以设计成\n  可拓展的.\n* 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError\n* 需要说明的一点的是,随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上\n  分配也不是那么绝对了\n\n  > 简单介绍一下,java堆内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 如果从内存分配的角都看,线程共享的java对可能还可能划分出多个线程私有的分配缓冲区.\n\n一种通用性的内存池 (也存在于 RAM 中)， 用于存放所以的 JAVA 对象。 Java 的堆是一个运行时数据区 , 对象被存储在堆中 。 这些对象通过 new 等指令建立， 它们不需要程序代码 来显式的释放。 因此， 在堆里分配存储有很大的灵活性 。 堆的缺点是,由于要在运行时动态分配内存,存取速度较慢 。\n\n### 方法区\n* 虚拟机启动时创建\n* 供各个线程共享的运行时内存\n* 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容\n* java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以\n  选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样\"永久存在\". 这个区域的\n  回收目标是针对常量池的回收和对类型的卸载.\n* 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError.\n\n###### 运行时常量池\n\n运行时常量池是方法区的一部分.\n\nClass文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.\n这部分内容将在类加载后存放到方法区的运行时常量池中.\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是`String#intern()`在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示.\n\n它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用\n\njava 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 。 常量池其实也就是一个内存空间,不同于使用 `new` 关键字创建的对象所在的堆空间 。 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型\n\n\n###### 回收方法区\n在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此.\n\n###### 永久代的垃圾回收主要是回收俩部分内容:\n*. 废弃常量\n\n回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串\"ABC\"已经进入了常量池,但是当前系统中没有任何一个String对象是叫做\"ABC\"的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个\"ABC\"常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似.\n\n* 无用的类\n\n判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件:\n\n\t> 1. 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.<br.>\n\t> 2. 加载该类的ClassLoader已经被回收.<br.>\n\t> 3. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类.\n\n虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用`-verbose:Class`及\n`-XX:+TraceClassLoading`,`-XX:+TraceClassUnLoading`查看类的加载和卸载信息.`-verbose:Class`和`-XX:+TraceClassLoading`可以在Product版的虚拟机中使用,但是`-XX:+TraceClassLoading`参数需要fastdebug版的虚拟机支持\n\n### 直接内存\n* 直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致\n  OutOfMemoryError异常出现\n* 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的\n  DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据.\n* 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器\n  寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于\n  物理内存限制,从而导致动态拓展时,出现OutOfMemoryError.\n\n### 本地方法栈\n* 用来支持native方法\n\n### 静态存储\n\n静态存储里存放程序运行时一直存在的数据 。 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 。 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 。\n\n## 栈帧\n* 用来存储数据和部分过程结果的数据结构, 同时也用来处理动态连接, 方法返回值和异常分派\n* 随着方法的调用而创建,随着方法的调用结束而销毁. (结束也包含异常情况)\n* 其内存分配在虚拟机栈之中, 每一个栈帧都有自己的本地变量表, 操作数栈, 和指向当前方法所属的类的运行时常量池.\n\n### 局部变量表\n* 其长度在编译器决定\n* 一个局部变量可以保存boolean, byte, char, short, int, float, reference,returnAddress类型的数据.俩个局部变量可以\n  保存一个long或者double类型的变量.\n* java虚拟机使用局部变量表来完成方法调用时的参数传递. 当调用一个方法时, 它的参数将会传递至从0开始的连续的变量表位置上.\n* 当调用一个实例方法时,第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用.后续的其他参数将会传递至从1开始的连续的\n  局部变量表位置上\n* 虚拟机通过索引定位的方式使用局部变量表,索引值的范围是从0开始到局部变量表最大的Slot数量.\n```\n\t局部变量表中的Slot是可重用的,方法体定义的变量,其作用域并不一定会覆盖整个方法体,如果当前字节码PC计数器的值\n\t已经超出了某个变量的作用域,那么这个变量对应的Slot就可以交给其他变量使用. 这样的设计不仅仅是为了节省栈空间,\n\t在某些情况下Slot的复用会直接影响到系统的垃圾收集行为\n```\n```java\npublic class CollectSlot1 {\n\n    public static void main(String[] args) {\n        byte[] placeholder = new byte[64 * 1024 * 1024];\n        System.gc();\n    }\n}\n\npublic class CollectSlot2 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        System.gc();\n    }\n}\n\npublic class CollectSlot3 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        int a = 0;\n        System.gc();\n    }\n}\n\npublic class CollectSlot4 {\n\n    public static void main(String[] args) {\n        int a = 0;\n        System.gc();\n    }\n}\n\n运行时,加上 -verbose:gc 参数,来查看垃圾收集过程.\n```\n###### 运行结果,CollectSlot1和CollectSlot2并没有执行垃圾回收. 而CollectSlot3却执行了垃圾收集\n###### 运行分析\n\nplaceholder能否被回收的根本原因就是:局部变量表中的Slot是否还存有关于placeholder数组对象的引用.在CollectSlot2中,代码虽然已经离开了placeholder的作用域,但在此之后,没有任何局部变量表的读写操作,placeholder原本所占用的Slot还没有被其他变量所复用,所以作为GC Roots一部分的局部变量表仍然保持着对它的关联.\n\n这种关联没有被及时打断,在绝大部分情况下影响都很轻微.但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了占用了大量内存,实际上已经不会再被使用的变量,手动将其设置为null值就不是一个毫无意义的操作.\n\n这种操作可以作为一种在极特殊情景(对象内存占用大,此方法的栈帧长时间不能被回收,方法调用次数达不到JIT的编译条件)下的奇技来使用. 但不应当对赋null值操作有过多的依赖.\n\n应该以恰当的作用域来控制变量回收时间才是最优雅的解决方法.(如CollectSlot3)\n\n另外赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.字节码被编译为本地代码后,对GC Roots的枚举也与解释执行时期有所差别,CollectSlot2在经过JIT编译后,System.gc() 执行时就可以正确回收掉内存,而无需写成CollectSlot3\n\n关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在\"准备阶段\".类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 所以 CollectSlot4 并不能运行,编译器能在编译器期间检查并提示这一点.\n\n### 操作数栈\n* 每个栈帧内部都包含一个称为操作数栈先进后出栈.\n* 其栈帧长度在编译器决定.\n* 栈帧在刚创建的时候, 操作数栈是空的, java虚拟机提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.\n* 也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈\n* 在调用方法时, 操作数栈也用来准备调用方法的参数以及接受方法返回结果.\n* 每个操作数栈的位置可以保存一个java虚拟机定义的任意数据类型的值,包括long和double类型\n* 在任意时刻,操作数都会有一个确定的栈深度, 一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度\n\n操作数栈也称为操作栈,它是一个先入后出栈.同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double. 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值.\n\n当一个方法开始执行的时候,这个方法的操作数栈是空的,在方法的执行过程中,会有各种字节码指令向操作数栈写入和提取内容,也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.\n\n举个例子,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈.\n\n操作数栈元素的数据类型必须与字节码指令的序列严格匹配,在编译程序代码的时候,编译器要严格保证这一点,在类校验阶段的数据流分析中还要再次验证这一点.再以上的iadd指令为例,这个指令用于整数相加,它在执行时,最接近栈顶的俩个元素的类型必须是int性,不能出现一个long和一个float使用iadd命令相加的情况.\n\n另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递:\n\n![俩个栈帧之间的数据共享]()\n\njava虚拟机解释执行引擎称为\"基于栈的执行引擎\",其中所指的栈就是操作数栈.\n\n\n### 动态连接\n* 每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.\n* 在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.\n* 类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.\n* 由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响\n\n每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的`动态连接`.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接\n\n### 方法正常调用完成\n* 当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等\n* 使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行\n\n### 方法调用非正常完成\n* 指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常\n\n\n### 方法返回地址\n\n当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口.\n\n另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的.\n\n无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息.\n\n方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等.\n\n## 方法调用\n方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用.\n\n### 解析\n继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为`解析(Resolution)`.\n\n在java语言中,符合\"编译器可知,运行期不可变\"这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析.\n\n###### 与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令:\n* `invokestatic`: 调用静态方法\n* `invokespecial`:调用实例构造器`<init>`方法,私有方法和父类方法\n* `invokevirtual`:调用所有的虚方法\n* `invokeinterface`:调用接口方法,会在运行时再确定一个实现此接口的对象\n\n只要能被`invokestatic`, `invokespecial`指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为`非虚方法`,与此相反,其他方法就称为`虚方法`(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法`sayHello()`只可能属于类型`StaticResolution`,没有任何手段可以覆盖或者隐藏这个方法.\n\n```java\npublic class StaticResolution {\n\n    public static void sayHello() {\n        System.out.println(\"hello\");\n    }\n\n    public static void main(String[] args) {\n        StaticResolution.sayHello();\n    }\n}\n\n```\n通过javap查看字节码:\n```java\npublic static void main(java.lang.String[]);\n   descriptor: ([Ljava/lang/String;)V\n   flags: ACC_PUBLIC, ACC_STATIC\n   Code:\n     stack=0, locals=1, args_size=1\n        0: invokestatic  #5                  // Method sayHello:()V\n        3: return\n     LineNumberTable:\n       line 9: 0\n       line 10: 3\n\n```\n\njava中的非虚方法除了使用`invokestatic`和`invokespecial`调用的方法之外还有一种,就是被`final`修饰的方法.虽然`final`方法是使用`invokespecial`指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法.\n\n解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.\n\n\n\n\n\n\n\n\n\n","slug":"jvm7/java虚拟机结构","published":1,"updated":"2015-10-16T02:39:58.493Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxt6002j0cuffpvfm4fq"},{"date":"2014-10-07T16:00:00.000Z","title":"gc_log","_content":"\n","source":"_posts/jvm7/gc_log.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: gc_log\n---\n\n","slug":"jvm7/gc_log","published":1,"updated":"2015-10-16T07:04:59.372Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxt9002l0cuf5vhvy8ge"},{"date":"2014-10-07T16:00:00.000Z","title":"class文件格式","_content":"# class文件格式\n## ClassFile 结构\n```\n  u4              magic;\n  u2              minor_version;\n  u2              major_version;\n  u2              constant_pool_count;\n  cp_info         constant_pool[constant_pool_count - 1];\n  u2              access_flags;\n  u2              this_class;\n  u2              super_class;\n  u2              interfaces_count;\n  u2              interfaces[interfaces_count];\n  u2              fields_count;\n  field_info      fields[fields_count];\n  u2              methods_count;\n  method_info     methods[methods_count];\n  u2              attributes_count;\n  attribute_info  attributes[attributes_count];\n```\n### magic\n\nMagic的唯一作用是确定这个文件是否是一个能被虚拟机所接受的Class文件.魔数固定值为0xCAFEBABY,不会改变\n\n### minor_version, major_version\n\nminor_version副版本号. major_version主版本号, 二者共同构成Class文件版本号.假设minor_version为m, major_version为M, 那么class文件的版本号为M.m.在JDK版本在1.k(k>=2)以上时, class文件的版本范围为(45.0 ~ 44+k.0)\n\n### constant_pool_count\n\n此值等于常量池中的成员数加1. 常量池表的索引值只有大于0且小于constant_pool_count 时才会被认为是有效的,对于long和double例外\n\n### constant_pool[] (常量池)\n\n是一种表结构, 它包含Class文件结构及其子结构中所引用的所有字符串常量, 类, 或接口名, 字段名和其他常量.如上文所说,常量池主要存放俩大类常量:字面量和符号引用. 字面量包括:文本字符串,被声明为final的常量值.而符号引用则包括了下列三种常量:\n1. 类和接口的全限定名.\n2. 字段的名称和描述符\n3. 方法的名称和描述符\n\n在class文件中并不会保存各个方法和字段的最终内存布局信息.当虚拟机运行时,会从常量池获得对应的符合引用,再在类创建或运行时解析并翻译到具体的内存地址之中.常量池中每一项常量都是一个表,下面列举了这11种表结构\n\n###### 常量池11种表结构\n\n|项目                            |类型|描述                                              |\n|--------------------------------|---:|-------------------------------------------------:|\n|<red>CONSTANT_Utf8_info</red>   |UTF-8编码的字符串                                      |\n|tag                             |u1  |值为1                                             |\n|length                          |u2  |UTF-8编码的字符串占用了字节数                     |\n|bytes                           |u1  |长度为length的UTF-8的字符串                       |\n|CONSTANT_Integer_info           |整型字面量                                             |\n|tag                             |u1  |值为3                                             |\n|bytes                           |u4  |按照高位在前存储的int值                           |\n|CONSTANT_Float_info             |浮点型字面量                                           |\n|tag                             |u1  |值为4                                             |\n|bytes                           |u4  |按照高位在前存储的值float                         |\n|CONSTANT_Long_info              |长整型字面量                                           |\n|tag                             |u1  |值为5                                             |\n|bytes                           |u8  |按照高位在前存储的float值                         |\n|CONSTANT_Double_info            |双精度浮点型字面量                                     |\n|tag                             |u1  |值为6                                             |\n|bytes                           |u8  |按照高位在前存储的double值                        |\n|CONSTANT_Class_info             |类或接口的符号引用                                     |\n|tag                             |u1  |值为7                                             |\n|bytes                           |u2  |指定全限定名常量项的索引                          |\n|CONSTANT_String_info            |字符串型字面量                                         |\n|tag                             |u1  |值为8                                             |\n|bytes                           |u4  |指向字符串字面量的索引                            |\n|CONSTANT_Fieldref_info          |字段的符号引用                                         |\n|tag                             |u1  |值为9                                             |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_Methodref_info         |类中方法的符号引用                                     |\n|tag                             |u1  |值为10                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_InterfaceMethodref_info|接口中方法的引用                                       |\n|tag                             |u1  |值为11                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_NameAndType_info       |字段或方法的部分符号引用                               |\n|tag                             |u1  |值为12                                            |\n|index                           |u2  |指向该字段或方法名称常量项的索引                  |\n|index                           |u2  |指向该字段或方法描述符常量项的索引                |\n\n\n### access_flags\n\n是一种掩码标志, 用于表示某个类或者接口的访问权限及属性.\n\n###### access_flags 的取值范围和相应含义表\n\n|标志名         |值     |含义                                                              |\n|---------------|------:|-----------------------------------------------------------------:|\n|ACC_PUBLIC     |0x0001 |声明为public,可以被包外访问                                       |\n|ACC_FINAL      |0x0010 |声明为final,不允许有子类                                          |\n|ACC_SUPER      |0x0020 |当用到invokespecial指令时,需要特殊处理的父类方法                  |\n|ACC_INTERFACE  |0x0200 |标志定义的是接口而不是类                                          |\n|ACC_ABSTRACT   |0x0400 |声明为abstract, 不能被实例化                                      |\n|ACC_SYNTHETIC  |0x1000 |声明为synthetic, 标志为非java源码生成的                           |\n|ACC_ANNOTATION |0x2000 |标志为注解类型                                                    |\n|ACC_ENUM       |0x4000 |标志为枚举类型,意味着它或者它的父类被声明为枚举                   |\n\n当设置上ACC_INTERFACE意味着它是接口而不是类, 反之是类而不是接口. 当带有该标志,同时也设置了 ACC_ABSTRACT,则不能再设置ACC_FINAL,ACC_SUPER,ACC_ENUM..\n\n\n### this_class\n\n类索引用于确定这个的全限定名, this_class类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.java通过this_class, super_class, interfaces 来确定这个类的继承关系\n\n### super_class\n\n当前类的父类. 由于java是单继承体制, 所以父类索引只有一个.类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量. 而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### interfaces_count\n\n该类实现了接口的数量.\n\n### interfaces\n\n该类实现的接口列表. 类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.\n而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### fields_count\n\n用于描述接口或类中声明的字段数量.\n\n### fields 字段表\n\n用于描述接口或类中声明的字段.字段表中包括了类级变量或实例级变量, 但不包括在方法内部声明的变量.每个表中字段中的信息有:字段的作用域(public, private, protected修饰符), 实例变量还是类变量, 可变性(final),并发可见性(volatile), 可否序列化(transient), 字段数据类型, 字段名称.\n\n字段表中不会出现从父类或者父接口中继承而来的字段, 但有可能列出原本java代码中不存在呃字段, 例如在内部类中为了保持对外部类的访问性, 会自动添加指向外部类实例的字段. 另外在java语言中字段是无法重载的, 无论俩个字段的数据类型,修饰符是否相同, 都必须使用不一样的名称, 但是对于字节码来讲, 如果俩个描述符不同, 那字段重名就是合法的.\n\n######字段表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### access_flags\n\n|标志名称        |标识符   | 二进制           |    含义                       |\n|----------------|--------:|-----------------:|------------------------------:|\n|ACC_PUBLIC      |0x0001   |1                 |字段是否是 public              |\n|ACC_PRIVATE     |0x0002   |10                |字段是否是private              |\n|ACC_PROTECTED   |0x0004   |100               |字段是否是protected            |\n|ACC_STATIC      |0x0008   |1000              |字段是否是static               |\n|ACC_FINAL       |0x0010   |10000             |字段是否是final                |\n|ACC_VOLATILE    |0x0040   |1000000           |字段是否是volatile             |\n|ACC_TRANSIENT   |0x0080   |10000000          |字段是否是transient            |\n|ACC_SYNTHETIC   |0x1000   |1000000000000     |字段是否是由编译器自动产生的   |\n|ACC_ENUM        |0x4000   |100000000000000   |字段是否是enum                 |\n\n\n  通过`access_flags` 我们可以很容易的看出`ACC_PUBLIC, ACC_PRIVATE, ACC_PROTECTED`三个标记中最多只能选择其一.而且`ACC_FINAL` 和 `ACC_VOLATILE` 不能同时选择.\n\n\n### methods_count\n\n方法表中的方法的数量\n\n### methods\n\nClass文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法.\n\n如果父类方法在子类中没有被重写, 方法表集合中就不会出现来自父类的方法信息. 但同样的,有可能出现由编译器自动添加的方法, 最经典的就是类构造器<clinit>和实例构造器<init>\n\n在java语言中重载一个方法,除了要与愿方法具有相同的简单名称之外, 还要求必须拥有一个与原方法不同的签名特征, 签名特征就是一个方法中各个参数在常量池的字段符号引用的集合, 也就是因为\n返回值不会包含在签名特征之中, 因此java语言里无法仅仅靠返回值的不同来对一个方法进行重载.但是在class文件格式之中,签名的范围更大一些,只要描述符不是完全一致的俩个方法也可以共存.\n也就是说俩个方法具有相同的名称和特征签名,但返回值不同,那么也是可以合法共存于一个class文件中.\n\n###### 方法表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### 方法访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                             |\n|----------------|--------:|---------------:|--------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |方法是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |方法是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |方法是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |方法是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |方法是否是final                  |\n|ACC_SYNCHRONIZED|0x0020   |100000          |方法是否是synchronized           |\n|ACC_BRIDGE      |0x0040   |1000000         |方法是否是由编译器产生的桥接方法 |\n|ACC_VARARGS     |0x0080   |10000000        |方法是否是接受不确定参数         |\n|ACC_NATIVE      |0x0100   |100000000       |方法是否是native                 |\n|ACC_ABSTRACT    |0x0400   |10000000000     |方法是否是abstract               |\n|ACC_STRICT      |0x0800   |100000000000    |方法是否是strictfp               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |方法是否是由编译器自动产生的     |\n\n### attributes_count\n\n属性表里的属性数量\n\n### attributes\n\n###### 属性表\n\n|属性名称             |使用位置           |含义                                    |\n|---------------------|------------------:|---------------------------------------:|\n|Code                 |方法表             |java代码编译成的字节码指令              |\n|ConstantValue        |字段表             |final关键字定义的常量值                 |\n|Deprecated           |类,方法表,字段表   |被声明为deprecated的方法和字段          |\n|Exceptions           |方法表             |方法抛出的异常                          |\n|InnerClass           |类文件             |内部类列表                              |\n|LineNumberTable      |Code属性           |java源码的行号和字节码指令的对应关系    |\n|LocalVariableTable   |Code属性           |方法的局部的变量描述                    |\n|SourceFile           |类文件             |原文件名称                              |\n|Synthetic            |类,字段表,方法表   |标志方法或字段为编译器自动生成的        |\n\n\n属性表在Class文件,字段表,方法表中都可以携带自己的属性表集合.\n\n#### Code属性\n\n|类型             |名称                     |数量                  |\n|-----------------|------------------------:|---------------------:|\n|u2               |attribute_name_index     |1                     |\n|u4               |attribute_length         |1                     |\n|u2               |max_stack                |1                     |\n|u2               |max_locals               |1                     |\n|u4               |code_length              |1                     |\n|u1               |code                     |code_length           |\n|u2               |exception_table_length   |1                     |\n|exception_info   |exception_table          |exception_table_length|\n|u2               |attributes_count         |1                     |\n|attribute_info   |attributes               |attributes_count      |\n\n\n1. attribute_name_index  是一项指向CONSTANT_Utf8_info型常量. 常量值固定为\"Code\",它代表了该属性的属性名称.\n2. attribute_length  该值代表了属性值的长度, 由于属性名称索引和属性长度一共是6个字节, 所以属性值的长度固定为整个属性表的长度\n3. max_stack  该值代表了操作数栈深度的最大值.虚拟机运行时需要根据这个值来分配栈帧中的操作数栈深度.\n4. max_locals 该值代表了局部变量所需的存储空间. max_locals的单位是Slot, Slot是虚拟机为局部变量分配空间所使用的最小单位.\n   对应byte, char, float, int, short, boolean, refrence, returnAddress 等长度不超过32位的数据类型,每个局部\n   变量占用一个Slot, 而double和long这俩种64位的数据类型则需要2个solt来存放.\n   方法参数,显式异常处理器的参数,方法体中定义的局部变量都需要使用局部变量来存放.\n   需要注意的是,并不是在方法中用到了多少个局部变量,就把这些局部变量所占的Slot之和作为max_locals的值,\n   原因是局部变量表中的Slot可以重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的Slot就可以被其他的\n   局部变量所使用,编译器会根据变量的作用域来分类Solt并分配给各个变量使用.\n5. code_length 代表字节码长度, 虽然该值是一个u4类型的长度值,但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令。如果超过这个指令,javac编译器会拒绝编译.\n6. code 用于存储字节码指令的一系列字节流. 每个字节码指令都是一个u1类型的单字节,当虚拟机读取到Code中的一个字节码时,就可以相应的找出这个字节码代表的是什么指令, 并且可以知道这条指令后面是否需要跟随参数,以及参数如何理解.\n7. exception_table_length\n8. exception_table\n9. attributes_count\n10. attributes\n\n\n#### Exceptions 属性\n\nExceptions属性是在与方法表中与Code属性平级的一项属性, 这与异常表是不同的. Exceptions属性的作用是列举出方法中\n可能抛出的受检查异常,也就是方法描述时throws关键字后面列举的异常\n\n###### Exceptions属性表结构\n\n|类型  |名称                   |数量                   |\n|------|----------------------:|----------------------:|\n|u2    |attribute_name_index   |1                      |\n|u4    |attribute_length       |1                      |\n|u2    |number_of_exceptions   |1                      |\n|u2    |exception_index_table  |number_of_exceptions   |\n\n```\n   number_of_exceptions 表示方法可能抛出number_of_exceptions种受检查异常, 每一种受检查异常都是要一个\n   exception_index_table表示. exception_index_table指向一个常量池CONSTANT_Class_info类型的常量索引\n```\n#### LineNumberTable属性\n\n\n用于描述java源码行号与字节码之间的对应关系. 它并不是运行时必须的属性. 但默认的会生成到Class文件中,\n可以使用javac中-g:none或者-g:lines选项来取消它. 取消的后果是在抛出异常时,堆栈中将不会显示错的行号,\n并且在断点时,无法按照源码设置断点.\n\n\n#### LocalVariableTable 属性\n\n\n 用于描述栈帧中局部变量表中的变量与java源码中定义的变量之间的关系. 它并不是运行时必须的属性.默认也不会\n 生成到Class文件中, 可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息. 如果没有生成这项信息,\n 最大的影响是当其他人引用这个方法时,所有的参数名都将丢失,IDE可能使用诸如arg0, arg1之类的占位符来代替原有的参数名\n\n###### LocalVarialTable属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |local_variable_table_length  |1                             |\n|local_variable_info  |local_variable_table         |local_variable_table_length   |\n\nlocal_variable_info项目结构\n\n|类型  |名称              |数量|\n|------|-----------------:|---:|\n|u2    |start_pc          |1   |\n|u2    |length            |1   |\n|u2    |name_index        |1   |\n|u2    |descriptor_index  |1   |\n|u2    |index             |1   |\n\n\n1. local_variable_info代表了一个栈帧与源码中的局部变量的联系.\n2. start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,俩者结合起来就是这个局部变量在字节码之中的作用域范围.\n3. name_index和descriptor指向的是常量池中CONSTANT_Utf8_info型常量的索引. 分别代表了局部变量名称及其描述符\n4. index是这个局部变量在栈帧局部变量表中Solt的位置.\n5. 在JDK1.5引入泛型之后,引入了一个LocalVarialTypeTable,这个新增的属性结构和LocalVarialTable非常相似,它仅仅是把记录的字段的描述符descriptor_index换成了字段的特征签名,对于非泛型类型来说,描述符和特征签名能描述的信息基本是一致的. 但是引入泛型之后,由于描述符中泛型化的参数被擦除掉了,描述符就不能准确地描述泛型信息了,因此引入了LocalVarialTypeTable\n\n\n#### SourceFile 属性\n\n\n该属性用来记录生成这个Class文件的源码文件名称,该属性也是可选的,可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息.\n\n###### SourceFile属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |sourcefile_index             |1                             |\n\n#### ConstantValue\n\n1. 该属性的作用是通知虚拟机自动为静态变量赋值. 只有被static修饰的变量才可以使用这项属性.\n2. 对于非static类型变量的赋值是在实例构造器<init>方法中进行的.\n3. 对于static类型的变量,有俩种赋值方式选择:\n   > A: 在类构造器<clinit>中进行\n   > B: 使用ConstantValue属性来赋值\n  \n前Sun Javac编译器的选择是:如果同时使用final和static来修饰一个变量, 并且这个变量的数据类型是基本类型或者String的话, 就生成ConstantValue属性来初始化, 否则在<clinit>中进行初始化.\n\n\n###### ConstantValue属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |constantvalue_index          |1                             |\n\n\nConstantValue属性是一个定长属性,它的attribute_length数据值必须为2. constantvalue_index代表了常量池中一个字面量的音乐,根据字段类型的不同,字面量可以是CONSTANT_Long_info, CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_integer_info,CONSTANT_String_info常量中的一种.\n\n\n#### InnerClass\n\n用于记录内部类和宿主类之间的关系.如果一个类中定义了内部类,那么编译器会为它以及包含的内部类生成InnerClass属性.\n\n###### InnerClass 属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |number_of_classes            |1                             |\n|inner_classes_info   |inner_classes                |number_of_classes             |\n\n###### inner_classes_info表结构\n\n|类型  |名称                        |数量|\n|------|---------------------------:|---:|\n|u2    |inner_class_info_index      |1   |\n|u2    |outer_class_info_index      |1   |\n|u2    |inner_name_index            |1   |\n|u2    |inner_class_access_flags    |1   |\n\n\n1. inner_class_info_index和outer_class_info_index分别指向常量池中CONSTANT_Class_info型常量索引.\n   分别代表内部类和宿主类的符号引用\n2. inner_name_index指向常量池中CONSTANT_Utf8_info型常量索引. 代表这个内部类的名称.如果是匿名内部类则为0\n3. inner_class_access_flags是内部类的访问标志,\n\n###### inner_class_access_flags访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                               |\n|----------------|--------:|---------------:|----------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |内部类是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |内部类是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |内部类是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |内部类是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |内部类是否是final                  |\n|ACC_INTERFACE   |0x0020   |100000          |内部类是否是synchronized           |\n|ACC_ABSTRACT    |0x0400   |10000000000     |内部类是否是abstract               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |内部类是否是由并非用户代码产生的   |\n|ACC_ANNOTATION  |0x2000   |100000000000    |内部类是否是一个注解               |\n|ACC_ENUM        |0x4000   |100000000000    |内部类是否是一个枚举               |\n\n#### Deprecated, Synthetic\n\n\n这俩个属性属于标志型的布尔属性,只有存在不存在的区别.Deprecated 表示某个类或者字段或者方法被作者不再推荐使用,在代码中通过@Deprecated标注Synthetic 代码该字段或者方法并不是由java源码直接产生的,而是由编译器自行添加的.\n\n在JDK1.5以后,标志一个类,字段,方法是编译器自动产生的,也可以设置他们的访问标志中的ACC_SYNTHETIC标志位,最典型的例子就是Bridge Method了. 所有由非用户产生的类,字段,方法都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位,唯一例外的就是<init>和<clinit>方法.\n\n\n","source":"_posts/jvm7/class文件格式.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: class文件格式\n---\n# class文件格式\n## ClassFile 结构\n```\n  u4              magic;\n  u2              minor_version;\n  u2              major_version;\n  u2              constant_pool_count;\n  cp_info         constant_pool[constant_pool_count - 1];\n  u2              access_flags;\n  u2              this_class;\n  u2              super_class;\n  u2              interfaces_count;\n  u2              interfaces[interfaces_count];\n  u2              fields_count;\n  field_info      fields[fields_count];\n  u2              methods_count;\n  method_info     methods[methods_count];\n  u2              attributes_count;\n  attribute_info  attributes[attributes_count];\n```\n### magic\n\nMagic的唯一作用是确定这个文件是否是一个能被虚拟机所接受的Class文件.魔数固定值为0xCAFEBABY,不会改变\n\n### minor_version, major_version\n\nminor_version副版本号. major_version主版本号, 二者共同构成Class文件版本号.假设minor_version为m, major_version为M, 那么class文件的版本号为M.m.在JDK版本在1.k(k>=2)以上时, class文件的版本范围为(45.0 ~ 44+k.0)\n\n### constant_pool_count\n\n此值等于常量池中的成员数加1. 常量池表的索引值只有大于0且小于constant_pool_count 时才会被认为是有效的,对于long和double例外\n\n### constant_pool[] (常量池)\n\n是一种表结构, 它包含Class文件结构及其子结构中所引用的所有字符串常量, 类, 或接口名, 字段名和其他常量.如上文所说,常量池主要存放俩大类常量:字面量和符号引用. 字面量包括:文本字符串,被声明为final的常量值.而符号引用则包括了下列三种常量:\n1. 类和接口的全限定名.\n2. 字段的名称和描述符\n3. 方法的名称和描述符\n\n在class文件中并不会保存各个方法和字段的最终内存布局信息.当虚拟机运行时,会从常量池获得对应的符合引用,再在类创建或运行时解析并翻译到具体的内存地址之中.常量池中每一项常量都是一个表,下面列举了这11种表结构\n\n###### 常量池11种表结构\n\n|项目                            |类型|描述                                              |\n|--------------------------------|---:|-------------------------------------------------:|\n|<red>CONSTANT_Utf8_info</red>   |UTF-8编码的字符串                                      |\n|tag                             |u1  |值为1                                             |\n|length                          |u2  |UTF-8编码的字符串占用了字节数                     |\n|bytes                           |u1  |长度为length的UTF-8的字符串                       |\n|CONSTANT_Integer_info           |整型字面量                                             |\n|tag                             |u1  |值为3                                             |\n|bytes                           |u4  |按照高位在前存储的int值                           |\n|CONSTANT_Float_info             |浮点型字面量                                           |\n|tag                             |u1  |值为4                                             |\n|bytes                           |u4  |按照高位在前存储的值float                         |\n|CONSTANT_Long_info              |长整型字面量                                           |\n|tag                             |u1  |值为5                                             |\n|bytes                           |u8  |按照高位在前存储的float值                         |\n|CONSTANT_Double_info            |双精度浮点型字面量                                     |\n|tag                             |u1  |值为6                                             |\n|bytes                           |u8  |按照高位在前存储的double值                        |\n|CONSTANT_Class_info             |类或接口的符号引用                                     |\n|tag                             |u1  |值为7                                             |\n|bytes                           |u2  |指定全限定名常量项的索引                          |\n|CONSTANT_String_info            |字符串型字面量                                         |\n|tag                             |u1  |值为8                                             |\n|bytes                           |u4  |指向字符串字面量的索引                            |\n|CONSTANT_Fieldref_info          |字段的符号引用                                         |\n|tag                             |u1  |值为9                                             |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_Methodref_info         |类中方法的符号引用                                     |\n|tag                             |u1  |值为10                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_InterfaceMethodref_info|接口中方法的引用                                       |\n|tag                             |u1  |值为11                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_NameAndType_info       |字段或方法的部分符号引用                               |\n|tag                             |u1  |值为12                                            |\n|index                           |u2  |指向该字段或方法名称常量项的索引                  |\n|index                           |u2  |指向该字段或方法描述符常量项的索引                |\n\n\n### access_flags\n\n是一种掩码标志, 用于表示某个类或者接口的访问权限及属性.\n\n###### access_flags 的取值范围和相应含义表\n\n|标志名         |值     |含义                                                              |\n|---------------|------:|-----------------------------------------------------------------:|\n|ACC_PUBLIC     |0x0001 |声明为public,可以被包外访问                                       |\n|ACC_FINAL      |0x0010 |声明为final,不允许有子类                                          |\n|ACC_SUPER      |0x0020 |当用到invokespecial指令时,需要特殊处理的父类方法                  |\n|ACC_INTERFACE  |0x0200 |标志定义的是接口而不是类                                          |\n|ACC_ABSTRACT   |0x0400 |声明为abstract, 不能被实例化                                      |\n|ACC_SYNTHETIC  |0x1000 |声明为synthetic, 标志为非java源码生成的                           |\n|ACC_ANNOTATION |0x2000 |标志为注解类型                                                    |\n|ACC_ENUM       |0x4000 |标志为枚举类型,意味着它或者它的父类被声明为枚举                   |\n\n当设置上ACC_INTERFACE意味着它是接口而不是类, 反之是类而不是接口. 当带有该标志,同时也设置了 ACC_ABSTRACT,则不能再设置ACC_FINAL,ACC_SUPER,ACC_ENUM..\n\n\n### this_class\n\n类索引用于确定这个的全限定名, this_class类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.java通过this_class, super_class, interfaces 来确定这个类的继承关系\n\n### super_class\n\n当前类的父类. 由于java是单继承体制, 所以父类索引只有一个.类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量. 而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### interfaces_count\n\n该类实现了接口的数量.\n\n### interfaces\n\n该类实现的接口列表. 类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.\n而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### fields_count\n\n用于描述接口或类中声明的字段数量.\n\n### fields 字段表\n\n用于描述接口或类中声明的字段.字段表中包括了类级变量或实例级变量, 但不包括在方法内部声明的变量.每个表中字段中的信息有:字段的作用域(public, private, protected修饰符), 实例变量还是类变量, 可变性(final),并发可见性(volatile), 可否序列化(transient), 字段数据类型, 字段名称.\n\n字段表中不会出现从父类或者父接口中继承而来的字段, 但有可能列出原本java代码中不存在呃字段, 例如在内部类中为了保持对外部类的访问性, 会自动添加指向外部类实例的字段. 另外在java语言中字段是无法重载的, 无论俩个字段的数据类型,修饰符是否相同, 都必须使用不一样的名称, 但是对于字节码来讲, 如果俩个描述符不同, 那字段重名就是合法的.\n\n######字段表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### access_flags\n\n|标志名称        |标识符   | 二进制           |    含义                       |\n|----------------|--------:|-----------------:|------------------------------:|\n|ACC_PUBLIC      |0x0001   |1                 |字段是否是 public              |\n|ACC_PRIVATE     |0x0002   |10                |字段是否是private              |\n|ACC_PROTECTED   |0x0004   |100               |字段是否是protected            |\n|ACC_STATIC      |0x0008   |1000              |字段是否是static               |\n|ACC_FINAL       |0x0010   |10000             |字段是否是final                |\n|ACC_VOLATILE    |0x0040   |1000000           |字段是否是volatile             |\n|ACC_TRANSIENT   |0x0080   |10000000          |字段是否是transient            |\n|ACC_SYNTHETIC   |0x1000   |1000000000000     |字段是否是由编译器自动产生的   |\n|ACC_ENUM        |0x4000   |100000000000000   |字段是否是enum                 |\n\n\n  通过`access_flags` 我们可以很容易的看出`ACC_PUBLIC, ACC_PRIVATE, ACC_PROTECTED`三个标记中最多只能选择其一.而且`ACC_FINAL` 和 `ACC_VOLATILE` 不能同时选择.\n\n\n### methods_count\n\n方法表中的方法的数量\n\n### methods\n\nClass文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法.\n\n如果父类方法在子类中没有被重写, 方法表集合中就不会出现来自父类的方法信息. 但同样的,有可能出现由编译器自动添加的方法, 最经典的就是类构造器<clinit>和实例构造器<init>\n\n在java语言中重载一个方法,除了要与愿方法具有相同的简单名称之外, 还要求必须拥有一个与原方法不同的签名特征, 签名特征就是一个方法中各个参数在常量池的字段符号引用的集合, 也就是因为\n返回值不会包含在签名特征之中, 因此java语言里无法仅仅靠返回值的不同来对一个方法进行重载.但是在class文件格式之中,签名的范围更大一些,只要描述符不是完全一致的俩个方法也可以共存.\n也就是说俩个方法具有相同的名称和特征签名,但返回值不同,那么也是可以合法共存于一个class文件中.\n\n###### 方法表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### 方法访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                             |\n|----------------|--------:|---------------:|--------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |方法是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |方法是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |方法是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |方法是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |方法是否是final                  |\n|ACC_SYNCHRONIZED|0x0020   |100000          |方法是否是synchronized           |\n|ACC_BRIDGE      |0x0040   |1000000         |方法是否是由编译器产生的桥接方法 |\n|ACC_VARARGS     |0x0080   |10000000        |方法是否是接受不确定参数         |\n|ACC_NATIVE      |0x0100   |100000000       |方法是否是native                 |\n|ACC_ABSTRACT    |0x0400   |10000000000     |方法是否是abstract               |\n|ACC_STRICT      |0x0800   |100000000000    |方法是否是strictfp               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |方法是否是由编译器自动产生的     |\n\n### attributes_count\n\n属性表里的属性数量\n\n### attributes\n\n###### 属性表\n\n|属性名称             |使用位置           |含义                                    |\n|---------------------|------------------:|---------------------------------------:|\n|Code                 |方法表             |java代码编译成的字节码指令              |\n|ConstantValue        |字段表             |final关键字定义的常量值                 |\n|Deprecated           |类,方法表,字段表   |被声明为deprecated的方法和字段          |\n|Exceptions           |方法表             |方法抛出的异常                          |\n|InnerClass           |类文件             |内部类列表                              |\n|LineNumberTable      |Code属性           |java源码的行号和字节码指令的对应关系    |\n|LocalVariableTable   |Code属性           |方法的局部的变量描述                    |\n|SourceFile           |类文件             |原文件名称                              |\n|Synthetic            |类,字段表,方法表   |标志方法或字段为编译器自动生成的        |\n\n\n属性表在Class文件,字段表,方法表中都可以携带自己的属性表集合.\n\n#### Code属性\n\n|类型             |名称                     |数量                  |\n|-----------------|------------------------:|---------------------:|\n|u2               |attribute_name_index     |1                     |\n|u4               |attribute_length         |1                     |\n|u2               |max_stack                |1                     |\n|u2               |max_locals               |1                     |\n|u4               |code_length              |1                     |\n|u1               |code                     |code_length           |\n|u2               |exception_table_length   |1                     |\n|exception_info   |exception_table          |exception_table_length|\n|u2               |attributes_count         |1                     |\n|attribute_info   |attributes               |attributes_count      |\n\n\n1. attribute_name_index  是一项指向CONSTANT_Utf8_info型常量. 常量值固定为\"Code\",它代表了该属性的属性名称.\n2. attribute_length  该值代表了属性值的长度, 由于属性名称索引和属性长度一共是6个字节, 所以属性值的长度固定为整个属性表的长度\n3. max_stack  该值代表了操作数栈深度的最大值.虚拟机运行时需要根据这个值来分配栈帧中的操作数栈深度.\n4. max_locals 该值代表了局部变量所需的存储空间. max_locals的单位是Slot, Slot是虚拟机为局部变量分配空间所使用的最小单位.\n   对应byte, char, float, int, short, boolean, refrence, returnAddress 等长度不超过32位的数据类型,每个局部\n   变量占用一个Slot, 而double和long这俩种64位的数据类型则需要2个solt来存放.\n   方法参数,显式异常处理器的参数,方法体中定义的局部变量都需要使用局部变量来存放.\n   需要注意的是,并不是在方法中用到了多少个局部变量,就把这些局部变量所占的Slot之和作为max_locals的值,\n   原因是局部变量表中的Slot可以重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的Slot就可以被其他的\n   局部变量所使用,编译器会根据变量的作用域来分类Solt并分配给各个变量使用.\n5. code_length 代表字节码长度, 虽然该值是一个u4类型的长度值,但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令。如果超过这个指令,javac编译器会拒绝编译.\n6. code 用于存储字节码指令的一系列字节流. 每个字节码指令都是一个u1类型的单字节,当虚拟机读取到Code中的一个字节码时,就可以相应的找出这个字节码代表的是什么指令, 并且可以知道这条指令后面是否需要跟随参数,以及参数如何理解.\n7. exception_table_length\n8. exception_table\n9. attributes_count\n10. attributes\n\n\n#### Exceptions 属性\n\nExceptions属性是在与方法表中与Code属性平级的一项属性, 这与异常表是不同的. Exceptions属性的作用是列举出方法中\n可能抛出的受检查异常,也就是方法描述时throws关键字后面列举的异常\n\n###### Exceptions属性表结构\n\n|类型  |名称                   |数量                   |\n|------|----------------------:|----------------------:|\n|u2    |attribute_name_index   |1                      |\n|u4    |attribute_length       |1                      |\n|u2    |number_of_exceptions   |1                      |\n|u2    |exception_index_table  |number_of_exceptions   |\n\n```\n   number_of_exceptions 表示方法可能抛出number_of_exceptions种受检查异常, 每一种受检查异常都是要一个\n   exception_index_table表示. exception_index_table指向一个常量池CONSTANT_Class_info类型的常量索引\n```\n#### LineNumberTable属性\n\n\n用于描述java源码行号与字节码之间的对应关系. 它并不是运行时必须的属性. 但默认的会生成到Class文件中,\n可以使用javac中-g:none或者-g:lines选项来取消它. 取消的后果是在抛出异常时,堆栈中将不会显示错的行号,\n并且在断点时,无法按照源码设置断点.\n\n\n#### LocalVariableTable 属性\n\n\n 用于描述栈帧中局部变量表中的变量与java源码中定义的变量之间的关系. 它并不是运行时必须的属性.默认也不会\n 生成到Class文件中, 可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息. 如果没有生成这项信息,\n 最大的影响是当其他人引用这个方法时,所有的参数名都将丢失,IDE可能使用诸如arg0, arg1之类的占位符来代替原有的参数名\n\n###### LocalVarialTable属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |local_variable_table_length  |1                             |\n|local_variable_info  |local_variable_table         |local_variable_table_length   |\n\nlocal_variable_info项目结构\n\n|类型  |名称              |数量|\n|------|-----------------:|---:|\n|u2    |start_pc          |1   |\n|u2    |length            |1   |\n|u2    |name_index        |1   |\n|u2    |descriptor_index  |1   |\n|u2    |index             |1   |\n\n\n1. local_variable_info代表了一个栈帧与源码中的局部变量的联系.\n2. start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,俩者结合起来就是这个局部变量在字节码之中的作用域范围.\n3. name_index和descriptor指向的是常量池中CONSTANT_Utf8_info型常量的索引. 分别代表了局部变量名称及其描述符\n4. index是这个局部变量在栈帧局部变量表中Solt的位置.\n5. 在JDK1.5引入泛型之后,引入了一个LocalVarialTypeTable,这个新增的属性结构和LocalVarialTable非常相似,它仅仅是把记录的字段的描述符descriptor_index换成了字段的特征签名,对于非泛型类型来说,描述符和特征签名能描述的信息基本是一致的. 但是引入泛型之后,由于描述符中泛型化的参数被擦除掉了,描述符就不能准确地描述泛型信息了,因此引入了LocalVarialTypeTable\n\n\n#### SourceFile 属性\n\n\n该属性用来记录生成这个Class文件的源码文件名称,该属性也是可选的,可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息.\n\n###### SourceFile属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |sourcefile_index             |1                             |\n\n#### ConstantValue\n\n1. 该属性的作用是通知虚拟机自动为静态变量赋值. 只有被static修饰的变量才可以使用这项属性.\n2. 对于非static类型变量的赋值是在实例构造器<init>方法中进行的.\n3. 对于static类型的变量,有俩种赋值方式选择:\n   > A: 在类构造器<clinit>中进行\n   > B: 使用ConstantValue属性来赋值\n  \n前Sun Javac编译器的选择是:如果同时使用final和static来修饰一个变量, 并且这个变量的数据类型是基本类型或者String的话, 就生成ConstantValue属性来初始化, 否则在<clinit>中进行初始化.\n\n\n###### ConstantValue属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |constantvalue_index          |1                             |\n\n\nConstantValue属性是一个定长属性,它的attribute_length数据值必须为2. constantvalue_index代表了常量池中一个字面量的音乐,根据字段类型的不同,字面量可以是CONSTANT_Long_info, CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_integer_info,CONSTANT_String_info常量中的一种.\n\n\n#### InnerClass\n\n用于记录内部类和宿主类之间的关系.如果一个类中定义了内部类,那么编译器会为它以及包含的内部类生成InnerClass属性.\n\n###### InnerClass 属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |number_of_classes            |1                             |\n|inner_classes_info   |inner_classes                |number_of_classes             |\n\n###### inner_classes_info表结构\n\n|类型  |名称                        |数量|\n|------|---------------------------:|---:|\n|u2    |inner_class_info_index      |1   |\n|u2    |outer_class_info_index      |1   |\n|u2    |inner_name_index            |1   |\n|u2    |inner_class_access_flags    |1   |\n\n\n1. inner_class_info_index和outer_class_info_index分别指向常量池中CONSTANT_Class_info型常量索引.\n   分别代表内部类和宿主类的符号引用\n2. inner_name_index指向常量池中CONSTANT_Utf8_info型常量索引. 代表这个内部类的名称.如果是匿名内部类则为0\n3. inner_class_access_flags是内部类的访问标志,\n\n###### inner_class_access_flags访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                               |\n|----------------|--------:|---------------:|----------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |内部类是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |内部类是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |内部类是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |内部类是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |内部类是否是final                  |\n|ACC_INTERFACE   |0x0020   |100000          |内部类是否是synchronized           |\n|ACC_ABSTRACT    |0x0400   |10000000000     |内部类是否是abstract               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |内部类是否是由并非用户代码产生的   |\n|ACC_ANNOTATION  |0x2000   |100000000000    |内部类是否是一个注解               |\n|ACC_ENUM        |0x4000   |100000000000    |内部类是否是一个枚举               |\n\n#### Deprecated, Synthetic\n\n\n这俩个属性属于标志型的布尔属性,只有存在不存在的区别.Deprecated 表示某个类或者字段或者方法被作者不再推荐使用,在代码中通过@Deprecated标注Synthetic 代码该字段或者方法并不是由java源码直接产生的,而是由编译器自行添加的.\n\n在JDK1.5以后,标志一个类,字段,方法是编译器自动产生的,也可以设置他们的访问标志中的ACC_SYNTHETIC标志位,最典型的例子就是Bridge Method了. 所有由非用户产生的类,字段,方法都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位,唯一例外的就是<init>和<clinit>方法.\n\n\n","slug":"jvm7/class文件格式","published":1,"updated":"2015-10-16T02:40:11.253Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtc002n0cuf4g0564cs"},{"date":"2014-10-07T16:00:00.000Z","title":"JVM工具以及日志分析","_content":"# JVM 相关工具\n\n## JPS:虚拟机进程状况工具\n列出正在运行的虚拟机进程,并显示虚拟机执行主类的名称,以及这些进程的本地虚拟机的唯一ID(LVMID). \n\n对于本地虚拟机进程来说,LVMID与操作系统的进程ID是一致的,使用windwos的任务管理器或者Unix的ps命令也可以查询到虚拟机进程的LVMID,但如果同时启动了多个虚拟机进程,无法根据进程名称定位时,那就只能依赖jps命令显示主类的功能才能区分.\n\n### 命令格式:\n```\njps [ options ] [hostid]\n```\njps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,hostid为RMI注册表中注册的主机名\n\n####jps工具主要选项\n* `-q`: 只输出LVMID,省略主类的名称\n* `-m`: 输出虚拟机进程启动时传递给主类main()函数的参数\n* `-l`: 输出主类的全名,如果进程执行的jar包,输出jar路径\n* `-v`: 输出虚拟机进程启动时JVM参数.\n\n##jstat:虚拟机统计信息监视工具\n用于监视虚拟机各种运行状态信息的命令行工具.它可以显示本地或远程虚拟机进程中的类装载,内存,垃圾收集,JIT编译等运行数据.\n\n###jstat命令格式\n```\njstat [ option vmid [interval [s|ms] [count]]]\n```\n对于命令格式中的VMID与LVMID需要特别说明一下:如果是本地虚拟机进程,VMID和LVMID是一致的,如果是远程\n虚拟机进程,那么VMID的格式应该是:\n```\n[protocol:] [//]lvmid[@hostname [:port] /servername]\n```\n选项option代表着用户希望查询的虚拟机信息,主要分为三类:类装载,垃圾收集,运行期编译状况.\n\n#### jstat工具主要选项\n* `-class`: 监视类装载,卸载数量,总空间及类装载所耗费的时间\n* `-gc`: 监视java堆状况,包括Eden区,2个survivor区,老年代,永久代等的容量,已用空间,GC时间合计等信息.\n* `-gccapacity`: 监视内容与-gc基本相同,但输出主要关注java堆各个区域使用到最大和最小空间.\n* `-gcutil`: 监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比.\n* `-gccause`: 与-gcutil功能一样,但是会额外输出导致上一次GC产生的原因.\n* `-gcnew`:监视新生代GC的状况.\n* `-gcnewcapacity`: 监视内容与-gcnew基本相同输出主要关注使用到的最大和最小空间\n* `-gcold`: 监视老年代GC的状况.\n* `-gcoldcapacity`: 监视内容与-gcold基本相同,但输出主要关注使用到的最大和最小空间\n* `-gcpermcapacity`: 输出永久代使用到呃最大和最小空间\n* `-compiler`: 输出JIT编译器编译过的方法,耗时等信息\n* `-printcompilation`: 输出已经被JIT编译的方法.\n\n> E -> Eden. S0 -> Survivor0. S1 -> Survivor1. O -> Old. P -> Permanent. YGC -> YoungGC,Minor GC.\n> FGC  -> Full GC. FGCT -> Full GC Time.\n\n## Jinfo:Java配置\njinfo的作用是实时查看和调整虚拟机的各项参数.\n### jinfo命令格式\n```\njinfo [ option ] pid\n```\n\n## Jmap\njava内存映射工具,用于生成堆转储快照.\n\n如果不使用jmap命令,想要获取java堆转储快照还有一些比较暴力的手段:\n`-XX:+HeapDumpOnOutOfMemoryError`: 可以让虚拟机在OOM异常自动生成dump文件,通过\n`-XX:+HeapDumpOnCtrlBreak`参数则可以使用`[CTRL] + [Break]`: 键让虚拟机生成dump文件,又或者在Linux系统\n下通过`kill -3`命令发送进程退出信号,也能拿到dump文件.\n\njmap的作用并不仅仅是为了获取dump文件,它还可以查询`finalize`执行队列,java堆和永久代的详细信息,如空间使用率,当前使用的是哪种收集器.\n\n和jinfo命令一样,jmap有不少功能是在windows平台下受限的,除了生成dump文件`-dump`选项和用于查看每个类的实例,空间占用统计的`-histo`选项所有系统操作系统都提供之外,其余选项只能在Linux/Solaris下使用.\n\n### jmap命令格式\n```\njmap [ option ] vmid\n```\n\n#### jmap工具主要选项\n* `-dump`: 生成java堆转储快照.格式为:`-dump:[live,]format=b,file=<filename>`.live表示只dump存活对象\n* `-finalizerinfo`: 显示在`F-Queue`中等待`Finalizer`线程执行`finalize`方法的对象.\n* `-heap`: 显示java堆的详细信息,使用哪种回收器,参数配置,分代状况.\n* `-histo`: 显示堆中对象统计信息,包括类,实例数量和合计容量\n* `-permstat`: 以`ClassLoader`为统计口径显示永久代内存状态.\n* `-F`: 当虚拟机进程对`-dump`选项没有响应时,可使用这个选项强制生成dump快照\n\n## jstack\njava堆栈跟踪工具. `jstack`命令用于生成虚拟机当前时刻的线程快照.线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合,生成线程快照的主要目的是定位线程出现长时间停顿的原因,如[线程间死锁](),[死循环](),请求外部资源\n导致长时间等待.\n\njstack命令格式\n```\njstack [ option ] vmid\n```\noption值：\n* `-F`: 当正常输出的请求不被响应时,强制说出线程堆栈\n* `-l`: 除堆栈外,显示关于锁的附加信息\n* `-m`: 如果调用本地方法的话,可以显示c/c++的堆栈\n\n当对线程堆栈分析时，首先查找`BLOCKED`, 找到锁住的线程。\n\n\n\n# 日志分析\n\n## jstack日志\n下面摘抄的是NETTY中空epoll的一段记录\n```\n\"nioEventLoopGroup-2461-1\" #4955 prio=10 os_prio=0 tid=0x00007fd857e9a000 nid=0x5e19 runnable [0x00007fd7374bc000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n\tat sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x00000000e673cf38> (a io.netty.channel.nio.SelectedSelectionKeySet)\n\t- locked <0x00000000e673cd30> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x00000000e673cc58> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- None\n```\n\n第一行数据分析\n```\nnioEventLoopGroup-2461-1 表示的是进程名字\n#4955\nprio=10\nos_prio=0\nnid: 线程ID的16进制表示(可以通过`top -H`查看pid)\ntid:\nrunnable\n[0x00007fd7374bc000]`\n```\n\n线程堆栈信息\n```\njava.lang.Thread.State 线程状态\nlocked` 锁住的资源,分别锁住了  <0x00000000e673cf38>, <0x00000000e673cd30>, <0x00000000e673cc58>\n```\n\n### java.lang.Thread.State 线程状态\n* `Runnable ` : 线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行\n* `waiting for monitor entry` :  在等待进入一个临界区,所以它在`Entry Set`队列中等待.\n> 此时线程状态一般都是 `Blocked`:如果大量线程在`waiting for monitor entry`, 可能是一个全局锁阻塞住了大量线程.如果短时间内打印的 `thread dump` 文件反映,随着时间流逝,`waiting for monitor entry`的线程越来越多,没有减少的趋势,可能意味着某些线程在临界区里呆的时间太长了,以至于越来越多新线程迟迟无法进入临界区.\n\n* `waiting on condition` : 说明它在等待另一个条件的发生,来把自己唤醒,或者干脆它是调用了 `sleep(N)`.\n> 如果大量线程在`waiting on condition`：可能是它们又跑去获取第三方资源,尤其是第三方网络资源,迟迟获取不到`Response`,导致大量线程进入等待状态.所以如果你发现有大量的线程都处在 `Wait on condition`,从线程堆栈看,正等待网络读写,这可能是一个网络瓶颈的征兆,因为网络阻塞导致线程无法执行.  此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: WAITING (parking)`：一直等那个条件发生；\n\t2. `java.lang.Thread.State: TIMED_WAITING` (`parking`或`sleeping`)：定时的,那个条件不到来,也将定时唤醒自己.\n\n\t\n\n* `in Object.wait()` : 说明它获得了监视器之后,又调用了 `java.lang.Object.wait()` 方法.\t\n> 每个 Monitor在某个时刻,只能被一个线程拥有,该线程就是 `Active Thread`,而其它线程都是 `Waiting Thread`,分别在两个队列 `Entry Set`和 `Wait Set`里面等候.在 `Entry Set`中等待的线程状态是 `Waiting for monitor entry`,而在 `Wait Set`中等待的线程状态是 `in Object.wait()`.当线程获得了 `Monitor`,如果发现线程继续运行的条件没有满足,它则调用对象(一般就是被 `synchronized` 的对象)的 `wait()` 方法,放弃了 `Monitor`,进入 `Wait Set`队列. 此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: TIMED_WAITING (on object monitor)`; \n\t2. `java.lang.Thread.State: WAITING (on object monitor)`;\n\n\t\n## gc log\n我使用`-Xmx2048m -Xms2048M  -Xmn1048m`的内存分配方式启动一个JVM,下面是其中一段GC 日志\n```\n{Heap before GC invocations=196 (full 0):\n par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)\n  to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times: user=0.03 sys=0.00, real=0.00 secs]\nHeap after GC invocations=197 (full 0):\n par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)\n  to   space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n}\n```\n\n\n1. `Heap before GC invocations=196 (full 0)`:\n    这一行表示在调用第196GC, 第0次full GC之前的jvm内存分配情况.\n2. `par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    这一行的意思是新生代总共分配了873856K内存,使用了699148K的内存.\n3. `eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)`:\n    新生代的eden区分配了699136K内存,并且使用了100%\n4. `from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)`:\n    survivor1区分配了174720K内存,没有使用\n6. `to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)`:\n    survivor2区分配了174720K内存,没有使用\n5. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`\n    采用并发标记清除算法对新生代共分配1048576K, 其中有3377K大小在使用着\n7. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n    采用并发标记清除算法对永久代共分配21248K大小内存,使用了9252K.\n8. `670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times:`: user=0.03 sys=0.00, real=0.00 secs]`:\n    开始gc,ParNew垃圾收集器的新生代经过0.0047350秒后,将699148K内存进行垃圾收集, gc后有10K内存在使用.\n9. `Heap after GC invocations=197 (full 0)`:\n    在对堆进行197次gc后的内存分配情况：\n10. `par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    新生代分配了873856K大小，使用了10K\n11. `eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)`:\n    新生代eden区分配了699136K大小,使用了0k\n12. `from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)`:\n    新生代的survivor1区分配了174720K,使用了0k\n13. `to space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)`:\n    新生代的survivor2区分配了174720K,使用了0k\n14. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`:\n15. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n\n\n\n","source":"_posts/jvm7/JVM工具以及日志分析.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: JVM工具以及日志分析\n---\n# JVM 相关工具\n\n## JPS:虚拟机进程状况工具\n列出正在运行的虚拟机进程,并显示虚拟机执行主类的名称,以及这些进程的本地虚拟机的唯一ID(LVMID). \n\n对于本地虚拟机进程来说,LVMID与操作系统的进程ID是一致的,使用windwos的任务管理器或者Unix的ps命令也可以查询到虚拟机进程的LVMID,但如果同时启动了多个虚拟机进程,无法根据进程名称定位时,那就只能依赖jps命令显示主类的功能才能区分.\n\n### 命令格式:\n```\njps [ options ] [hostid]\n```\njps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,hostid为RMI注册表中注册的主机名\n\n####jps工具主要选项\n* `-q`: 只输出LVMID,省略主类的名称\n* `-m`: 输出虚拟机进程启动时传递给主类main()函数的参数\n* `-l`: 输出主类的全名,如果进程执行的jar包,输出jar路径\n* `-v`: 输出虚拟机进程启动时JVM参数.\n\n##jstat:虚拟机统计信息监视工具\n用于监视虚拟机各种运行状态信息的命令行工具.它可以显示本地或远程虚拟机进程中的类装载,内存,垃圾收集,JIT编译等运行数据.\n\n###jstat命令格式\n```\njstat [ option vmid [interval [s|ms] [count]]]\n```\n对于命令格式中的VMID与LVMID需要特别说明一下:如果是本地虚拟机进程,VMID和LVMID是一致的,如果是远程\n虚拟机进程,那么VMID的格式应该是:\n```\n[protocol:] [//]lvmid[@hostname [:port] /servername]\n```\n选项option代表着用户希望查询的虚拟机信息,主要分为三类:类装载,垃圾收集,运行期编译状况.\n\n#### jstat工具主要选项\n* `-class`: 监视类装载,卸载数量,总空间及类装载所耗费的时间\n* `-gc`: 监视java堆状况,包括Eden区,2个survivor区,老年代,永久代等的容量,已用空间,GC时间合计等信息.\n* `-gccapacity`: 监视内容与-gc基本相同,但输出主要关注java堆各个区域使用到最大和最小空间.\n* `-gcutil`: 监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比.\n* `-gccause`: 与-gcutil功能一样,但是会额外输出导致上一次GC产生的原因.\n* `-gcnew`:监视新生代GC的状况.\n* `-gcnewcapacity`: 监视内容与-gcnew基本相同输出主要关注使用到的最大和最小空间\n* `-gcold`: 监视老年代GC的状况.\n* `-gcoldcapacity`: 监视内容与-gcold基本相同,但输出主要关注使用到的最大和最小空间\n* `-gcpermcapacity`: 输出永久代使用到呃最大和最小空间\n* `-compiler`: 输出JIT编译器编译过的方法,耗时等信息\n* `-printcompilation`: 输出已经被JIT编译的方法.\n\n> E -> Eden. S0 -> Survivor0. S1 -> Survivor1. O -> Old. P -> Permanent. YGC -> YoungGC,Minor GC.\n> FGC  -> Full GC. FGCT -> Full GC Time.\n\n## Jinfo:Java配置\njinfo的作用是实时查看和调整虚拟机的各项参数.\n### jinfo命令格式\n```\njinfo [ option ] pid\n```\n\n## Jmap\njava内存映射工具,用于生成堆转储快照.\n\n如果不使用jmap命令,想要获取java堆转储快照还有一些比较暴力的手段:\n`-XX:+HeapDumpOnOutOfMemoryError`: 可以让虚拟机在OOM异常自动生成dump文件,通过\n`-XX:+HeapDumpOnCtrlBreak`参数则可以使用`[CTRL] + [Break]`: 键让虚拟机生成dump文件,又或者在Linux系统\n下通过`kill -3`命令发送进程退出信号,也能拿到dump文件.\n\njmap的作用并不仅仅是为了获取dump文件,它还可以查询`finalize`执行队列,java堆和永久代的详细信息,如空间使用率,当前使用的是哪种收集器.\n\n和jinfo命令一样,jmap有不少功能是在windows平台下受限的,除了生成dump文件`-dump`选项和用于查看每个类的实例,空间占用统计的`-histo`选项所有系统操作系统都提供之外,其余选项只能在Linux/Solaris下使用.\n\n### jmap命令格式\n```\njmap [ option ] vmid\n```\n\n#### jmap工具主要选项\n* `-dump`: 生成java堆转储快照.格式为:`-dump:[live,]format=b,file=<filename>`.live表示只dump存活对象\n* `-finalizerinfo`: 显示在`F-Queue`中等待`Finalizer`线程执行`finalize`方法的对象.\n* `-heap`: 显示java堆的详细信息,使用哪种回收器,参数配置,分代状况.\n* `-histo`: 显示堆中对象统计信息,包括类,实例数量和合计容量\n* `-permstat`: 以`ClassLoader`为统计口径显示永久代内存状态.\n* `-F`: 当虚拟机进程对`-dump`选项没有响应时,可使用这个选项强制生成dump快照\n\n## jstack\njava堆栈跟踪工具. `jstack`命令用于生成虚拟机当前时刻的线程快照.线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合,生成线程快照的主要目的是定位线程出现长时间停顿的原因,如[线程间死锁](),[死循环](),请求外部资源\n导致长时间等待.\n\njstack命令格式\n```\njstack [ option ] vmid\n```\noption值：\n* `-F`: 当正常输出的请求不被响应时,强制说出线程堆栈\n* `-l`: 除堆栈外,显示关于锁的附加信息\n* `-m`: 如果调用本地方法的话,可以显示c/c++的堆栈\n\n当对线程堆栈分析时，首先查找`BLOCKED`, 找到锁住的线程。\n\n\n\n# 日志分析\n\n## jstack日志\n下面摘抄的是NETTY中空epoll的一段记录\n```\n\"nioEventLoopGroup-2461-1\" #4955 prio=10 os_prio=0 tid=0x00007fd857e9a000 nid=0x5e19 runnable [0x00007fd7374bc000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n\tat sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x00000000e673cf38> (a io.netty.channel.nio.SelectedSelectionKeySet)\n\t- locked <0x00000000e673cd30> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x00000000e673cc58> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- None\n```\n\n第一行数据分析\n```\nnioEventLoopGroup-2461-1 表示的是进程名字\n#4955\nprio=10\nos_prio=0\nnid: 线程ID的16进制表示(可以通过`top -H`查看pid)\ntid:\nrunnable\n[0x00007fd7374bc000]`\n```\n\n线程堆栈信息\n```\njava.lang.Thread.State 线程状态\nlocked` 锁住的资源,分别锁住了  <0x00000000e673cf38>, <0x00000000e673cd30>, <0x00000000e673cc58>\n```\n\n### java.lang.Thread.State 线程状态\n* `Runnable ` : 线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行\n* `waiting for monitor entry` :  在等待进入一个临界区,所以它在`Entry Set`队列中等待.\n> 此时线程状态一般都是 `Blocked`:如果大量线程在`waiting for monitor entry`, 可能是一个全局锁阻塞住了大量线程.如果短时间内打印的 `thread dump` 文件反映,随着时间流逝,`waiting for monitor entry`的线程越来越多,没有减少的趋势,可能意味着某些线程在临界区里呆的时间太长了,以至于越来越多新线程迟迟无法进入临界区.\n\n* `waiting on condition` : 说明它在等待另一个条件的发生,来把自己唤醒,或者干脆它是调用了 `sleep(N)`.\n> 如果大量线程在`waiting on condition`：可能是它们又跑去获取第三方资源,尤其是第三方网络资源,迟迟获取不到`Response`,导致大量线程进入等待状态.所以如果你发现有大量的线程都处在 `Wait on condition`,从线程堆栈看,正等待网络读写,这可能是一个网络瓶颈的征兆,因为网络阻塞导致线程无法执行.  此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: WAITING (parking)`：一直等那个条件发生；\n\t2. `java.lang.Thread.State: TIMED_WAITING` (`parking`或`sleeping`)：定时的,那个条件不到来,也将定时唤醒自己.\n\n\t\n\n* `in Object.wait()` : 说明它获得了监视器之后,又调用了 `java.lang.Object.wait()` 方法.\t\n> 每个 Monitor在某个时刻,只能被一个线程拥有,该线程就是 `Active Thread`,而其它线程都是 `Waiting Thread`,分别在两个队列 `Entry Set`和 `Wait Set`里面等候.在 `Entry Set`中等待的线程状态是 `Waiting for monitor entry`,而在 `Wait Set`中等待的线程状态是 `in Object.wait()`.当线程获得了 `Monitor`,如果发现线程继续运行的条件没有满足,它则调用对象(一般就是被 `synchronized` 的对象)的 `wait()` 方法,放弃了 `Monitor`,进入 `Wait Set`队列. 此时线程状态大致为以下几种：\n\t1. `java.lang.Thread.State: TIMED_WAITING (on object monitor)`; \n\t2. `java.lang.Thread.State: WAITING (on object monitor)`;\n\n\t\n## gc log\n我使用`-Xmx2048m -Xms2048M  -Xmn1048m`的内存分配方式启动一个JVM,下面是其中一段GC 日志\n```\n{Heap before GC invocations=196 (full 0):\n par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)\n  to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times: user=0.03 sys=0.00, real=0.00 secs]\nHeap after GC invocations=197 (full 0):\n par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)\n  to   space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n}\n```\n\n\n1. `Heap before GC invocations=196 (full 0)`:\n    这一行表示在调用第196GC, 第0次full GC之前的jvm内存分配情况.\n2. `par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    这一行的意思是新生代总共分配了873856K内存,使用了699148K的内存.\n3. `eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)`:\n    新生代的eden区分配了699136K内存,并且使用了100%\n4. `from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)`:\n    survivor1区分配了174720K内存,没有使用\n6. `to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)`:\n    survivor2区分配了174720K内存,没有使用\n5. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`\n    采用并发标记清除算法对新生代共分配1048576K, 其中有3377K大小在使用着\n7. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n    采用并发标记清除算法对永久代共分配21248K大小内存,使用了9252K.\n8. `670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times:`: user=0.03 sys=0.00, real=0.00 secs]`:\n    开始gc,ParNew垃圾收集器的新生代经过0.0047350秒后,将699148K内存进行垃圾收集, gc后有10K内存在使用.\n9. `Heap after GC invocations=197 (full 0)`:\n    在对堆进行197次gc后的内存分配情况：\n10. `par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    新生代分配了873856K大小，使用了10K\n11. `eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)`:\n    新生代eden区分配了699136K大小,使用了0k\n12. `from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)`:\n    新生代的survivor1区分配了174720K,使用了0k\n13. `to space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)`:\n    新生代的survivor2区分配了174720K,使用了0k\n14. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`:\n15. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n\n\n\n","slug":"jvm7/JVM工具以及日志分析","published":1,"updated":"2015-10-16T07:20:56.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxte002p0cuf58cxo9mi"},{"date":"2014-10-07T16:00:00.000Z","title":"java虚拟机参数","_content":"# java虚拟机参数\n\n\n## 内存管理参数\n* `-XDisableExplicitGC`: 忽略来自System.gc()方法触发的垃圾收集\n* `-XExplicitGCInvokesConcurrent`:  当收到System.gc()方法提交的垃圾收集申请时,使用CMS收集器收集\n* `-XUseSerialGC`: 打开此开关后使用Serial + Serial Old的收集器组合进行内存回收.\n* `-XUseParNewGC`: 虚拟机运行在Client模式下的默认值,打开此开关后,使用ParNew+Seial Old的收集器组合进行垃圾收集\n* `-XUseConcMarkSweepGc`:  打开次开关后使用`ParNew+CMS+Serial Old`收集器组合进行垃圾收集.如果CMS收集器出现`Concurrent Mode Failure`,则`Seial Old` 收集器将作为后备收集器.\n* `-XUseParallelGC`: 虚拟机运行在Server模式下的默认值,打开此开关后,使用Parallel Scavenge + Serial Old的收集器组合进行内存回收\n* `-XUseParaelOldGC`: 打开此开关后,使用Parallel Scavenge + Parallel Old的收集器组合进行内存回收\n* `-XSurvivorRatio`:  新生代中Eden区和Survivor区的容量比值(默认为8)\n* `-XPretenureSizeThreshold`: 直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配\n* `-XMaxTenuringThreshold`: 晋升到老年代的对象年龄,每个对象在坚持过一次Minor GC之后,年龄就+1,当超过这个参数值时就进入老年代\n* `-XUseAdaptiveSizePolicy`: 动态调整java堆中各个区域的大小及进入老年代的年龄\n* `-XHandlePromotionFailure`: 是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况\n* `-XParallelGCThreads`: 设置并行GC时进行内存回收的线程数(少于或等于8个CPU时默认值为CPU数量值,多于8个CPU时比CPU数量值小)\n* `-XGCTimeRatio`: GC时间占总时间的比率.仅在使用Parallel Scavenge收集器时生效\n* `-XMaxGCPauseMillis`: 设置GC最大停顿时间.仅在使用Parallel Scavenge收集器时生效\n* `-XCMSInitiatingOccupancyFraction`: 设置CMS收集器在老年代空间被使用多少后触发垃圾收集\n* `-XUseCMSCompactAtFullCollection`: 设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理\n* `-XCMSFullGCBeforeCompaction`: 设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理\n* `-XScavengeBeforeFullGC`: 在Full GC发生之前触发一次Minor GC\n* `-XUseGCOverheadLimit`: 禁止GC过程无限制的执行,如果过于频繁,就直接发生OutOfMemory\n* `-XUseTLAB`: 优先在本地线程缓冲区中分配对象,避免分配内存时的锁定过程\n* `-XMaxHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲大于指定比率时自动收缩\n* `-XMinHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲小于指定比率时自动收缩\n* `-XMaxPermSize`: 永久代的最大值\n* `-Xms` : 初始堆大小\n* `-Xmx` : 最大堆大小\n* `-Xmn` : 设置年轻代大小. 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小.(Xms 必须大于  Xmn)\n\n## 即时编译参数\n* `CompileThreshold`: 触发即时编译的阈值\n* `OnStackReplacePercentage`: OSR比率,它是OSR即时编译阈值计算公司的一个参数,用于代替BackEdgeThreshold参数控制回边计数器的实际溢出阈值\n* `ReservedCodeCacheSize`: 即时编译器编译的代码缓存使得最大值\n\n## 类型加载参数\n* `UseSplitVerifier`: 使用依赖StackMapTable信息的类型检查代替数据流分析,以加快字节码校验速度\n* `FailOverToOldVerier`: 当类型校验失败时,是否允许回到老的类型推到校验方式进行校验,如果开启则允许\n* `RelaxAccessControlCheck`: 在校验阶段放松对类型访问性的限制\n\n## 多线程相关参数\n* `UseSpinning`: 开启自旋锁以免线程频繁的挂起和唤醒\n* `PreBlockSpin`: 使用自旋锁时默认的自旋次数\n* `UseThreadPriorities`: 使用本地线程优先级\n* `UseBiaseLocking`: 是否使用偏向锁,如果开启则使用\n* `UseFastAccessorMethods`: 当频繁反射执行某个方法时,生成字节码来加快反射的执行速度\n\n## 性能参数\n* `AggressiveOpts`: 使用激进的优化特征,这些特征一般是具备正面和负面双重影响的,需要根据具体应用特点分析才能判定是否对性能有好处\n* `UseLargePages`: 如果可能,使用大内存分页,这项特性需要操作系统的支持\n* `LargePageSizeInBytes`: 使用指定大小的内存分页,这项特性需要操作系统的支持\n* `StringCache`: 是否使用字符串缓存,开启则使用\n\n## 调试参数\n* `HeapDumpOnOutOfMemoryError`: 在发生内存溢出异常时是否生成堆转储快照,关闭则不生成\n* `OnOutOfMemoryError`: 当虚拟机抛出内存溢出异常时,执行指令的命令\n* `OnError`: 当虚拟机抛出ERROR异常时,执行指令的命令\n* `PrintClassHistogram`: 使用[ctrl]-[break]快捷键输出类统计状态,相当于jmap-histo的功能\n* `PrintConcurrentLocks`: 打印J.U.C中的状态\n* `PrintCommandLineFlags`: 打印启动虚拟机时输入的非稳定参数\n* `PrintGC`: 打印GC信息\n* `PrintCompilation`: 显示所有可设置的参数及它们的值(***从JDK 6 update 21开始才可以用)\n* `PrintGCDetails`: 打印GC的详细信息\n* `PrintGCTimesStamps`: 打印GC停顿耗时\n* `PrintTenuingDistribution`: 打印GC后新生代各个年龄对象的大小\n* `TraceClassLoading`: 打印类加载信息\n* `TraceClassUnloading`: 打印类卸载信息\n* `PrintInlining`: 打印方法内联信息\n* `PrintCFGToFile`: 将CFG图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `PrintIdealGraphFile`: 将Ideal图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `UnlockDiagnosticVMOptions`: 让虚拟机进入诊断模式,一些参数(如PrintAssembly)需要在诊断模式中才能使用\n* `PrintAssembly`: 打印即时编译后的二进制信息\n\n\n## 参数组合\n* 给远程服务器加debug\n```\n-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10020\n```\n\n###  \n* `-XX:+UseVMInterruptibleIO` : 线程中断前或是EINTR 在OS_INTRPT中对于I/O操作的结果 \n* `-XX:-UseParallelOldGC` :  所有的集合使用并行垃圾收集器。能够自动化地设置这个选项 -XX:+UseParallelGC\n* `-XX:+FailOverToOldVerifier` :  当新的类型检测器失败时切换到旧的认证器\n* `-XX:-AllowUserSignalHandlers` :  允许为java进程安装信号处理器（限于Linux和Solaris，默认关闭）\n\n### \n* `-XX:NewRatio=n` :  老年代与新生代比例(默认是2).\n* `-XX:ConcGCThreads=n` :  `concurrent garbage collectors`使用的线程数. (默认值与JVM所在平台有关).\n* `-XX:+UseG1GC` :  使用`Garbage First (G1) `收集器\n* `-XX:InitiatingHeapOccupancyPercent=n` :  设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。\n* `-XX:G1HeapRegionSize=n` : 设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域.\n* `-XX:G1ReservePercent=n` : 设置作为空闲空间的预留内存百分比，以降低目标空间溢出的风险。默认值是 10%。增加或减少百分比时，请确保对总的 Java 堆调整相同的量。Java HotSpot VM build 23 中没有此设置。\n\n### \n* `-XX:AllocatePrefetchStyle=1` : 预取指令的产生代码风格：0-没有预取指令，1-每一次分配内存就执行预取指令，2-当执行预取代码指令时，用TLAB分配水印指针指向门\n* `-XX:NewSize=2m` :  新生代默认大小(单位是字节) \n* `-XX:AllocatePrefetchLines=1` :  在使用JIT生成的预读取指令分配对象后读取的缓存行数。如果上次分配的对象是一个实例则默认值是1，如果是一个数组则是3\n* `-XX:+OptimizeStringConcat` :  对字符串拼接进行优化\n* `-XX:MaxNewSize=size` : 新生代最大值(单位字节)\n* `-XX:ThreadStackSize=512` : 线程堆栈大小(单位Kbytes，0 使用默认大小) \n* `-XX:+UseCompressedStrings` :  如果可以表示为纯ASCII的话，则用byte[] 代替字符串. \n* `-XX:+UseBiasedLocking` :  使用偏锁.\n\n### \n* `-XX:LoopUnrollLimit=n` :  代表节点数目小于给定值时打开循环体。\n* `-XX:GCLogFileSize=8K` :  gc日志文件大小(必须>= 8K).\n* `-XX:HeapDumpPath=./java_pid<pid>.hprof` :  堆内存溢出存放日志目录.\n* `-XX:+PerfDataSaveToFile` :  Jvm退出时保存jvmstat的二进制数据.\n* `-Xloggc:<filename>` :  gc日志文件\n* `-XX:+AlwaysPreTouch` :  当JVM初始化时预先对Java堆进行预先摸底(堆中每个页归零处理)。\n* `-XX:InlineSmallCode=n` :  当编译的代码小于指定的值时,内联编译的代码。\n* `-XX:InitialTenuringThreshold=7` :  设置初始的对象在新生代中最大存活次数。\n* `-XX:+UseCompressedOops` :  使用compressed pointers。这个参数默认在64bit的环境下默认启动，但是如果JVM的内存达到32G后，这个参数就会默认为不启动，因为32G内存后，压缩就没有多大必要了，要管理那么大的内存指针也需要很大的宽度了\n* `-XX:-PrintAdaptiveSizePolicy` :  打印JVM自动划分新生代和老生代大小信息.\n* `-XX:AllocatePrefetchDistance=n` :  为对象分配设置预取距离。\n* `-XX:MaxInlineSize=35` :  内联函数最大的字节码大小.\n* `-XX:-UseGCLogFileRotation` :  开启GC 日志文件切分功能，前置选项 -Xloggc\n* `-XX:-CITime` :  打印`JIT Compiler`的耗时\n* `-XX:-TraceClassResolution` :  追踪常量池resolutions. \n* `-XX:FreqInlineSize=n` :  经常执行方法内联的最大字节大小\n* `-XX:-TraceLoaderConstraints` : 跟踪加载器的限制记录.\n* `-XX:ErrorFile=./hs_err_pid<pid>.log` :  如果有Error发生,则将Error输入到该日志. \n* `-XX:NumberOfGClogFiles=1` :  设置Gc日志文件的数量(必须大于1)\n* `-XX:-PrintTenuringDistribution` :  打印对象的存活期限信息。\n","source":"_posts/jvm7/JVM 参数.md","raw":"category: jvm7\ndate: 2014-10-08\ntitle: java虚拟机参数\n---\n# java虚拟机参数\n\n\n## 内存管理参数\n* `-XDisableExplicitGC`: 忽略来自System.gc()方法触发的垃圾收集\n* `-XExplicitGCInvokesConcurrent`:  当收到System.gc()方法提交的垃圾收集申请时,使用CMS收集器收集\n* `-XUseSerialGC`: 打开此开关后使用Serial + Serial Old的收集器组合进行内存回收.\n* `-XUseParNewGC`: 虚拟机运行在Client模式下的默认值,打开此开关后,使用ParNew+Seial Old的收集器组合进行垃圾收集\n* `-XUseConcMarkSweepGc`:  打开次开关后使用`ParNew+CMS+Serial Old`收集器组合进行垃圾收集.如果CMS收集器出现`Concurrent Mode Failure`,则`Seial Old` 收集器将作为后备收集器.\n* `-XUseParallelGC`: 虚拟机运行在Server模式下的默认值,打开此开关后,使用Parallel Scavenge + Serial Old的收集器组合进行内存回收\n* `-XUseParaelOldGC`: 打开此开关后,使用Parallel Scavenge + Parallel Old的收集器组合进行内存回收\n* `-XSurvivorRatio`:  新生代中Eden区和Survivor区的容量比值(默认为8)\n* `-XPretenureSizeThreshold`: 直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配\n* `-XMaxTenuringThreshold`: 晋升到老年代的对象年龄,每个对象在坚持过一次Minor GC之后,年龄就+1,当超过这个参数值时就进入老年代\n* `-XUseAdaptiveSizePolicy`: 动态调整java堆中各个区域的大小及进入老年代的年龄\n* `-XHandlePromotionFailure`: 是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况\n* `-XParallelGCThreads`: 设置并行GC时进行内存回收的线程数(少于或等于8个CPU时默认值为CPU数量值,多于8个CPU时比CPU数量值小)\n* `-XGCTimeRatio`: GC时间占总时间的比率.仅在使用Parallel Scavenge收集器时生效\n* `-XMaxGCPauseMillis`: 设置GC最大停顿时间.仅在使用Parallel Scavenge收集器时生效\n* `-XCMSInitiatingOccupancyFraction`: 设置CMS收集器在老年代空间被使用多少后触发垃圾收集\n* `-XUseCMSCompactAtFullCollection`: 设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理\n* `-XCMSFullGCBeforeCompaction`: 设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理\n* `-XScavengeBeforeFullGC`: 在Full GC发生之前触发一次Minor GC\n* `-XUseGCOverheadLimit`: 禁止GC过程无限制的执行,如果过于频繁,就直接发生OutOfMemory\n* `-XUseTLAB`: 优先在本地线程缓冲区中分配对象,避免分配内存时的锁定过程\n* `-XMaxHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲大于指定比率时自动收缩\n* `-XMinHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲小于指定比率时自动收缩\n* `-XMaxPermSize`: 永久代的最大值\n* `-Xms` : 初始堆大小\n* `-Xmx` : 最大堆大小\n* `-Xmn` : 设置年轻代大小. 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小.(Xms 必须大于  Xmn)\n\n## 即时编译参数\n* `CompileThreshold`: 触发即时编译的阈值\n* `OnStackReplacePercentage`: OSR比率,它是OSR即时编译阈值计算公司的一个参数,用于代替BackEdgeThreshold参数控制回边计数器的实际溢出阈值\n* `ReservedCodeCacheSize`: 即时编译器编译的代码缓存使得最大值\n\n## 类型加载参数\n* `UseSplitVerifier`: 使用依赖StackMapTable信息的类型检查代替数据流分析,以加快字节码校验速度\n* `FailOverToOldVerier`: 当类型校验失败时,是否允许回到老的类型推到校验方式进行校验,如果开启则允许\n* `RelaxAccessControlCheck`: 在校验阶段放松对类型访问性的限制\n\n## 多线程相关参数\n* `UseSpinning`: 开启自旋锁以免线程频繁的挂起和唤醒\n* `PreBlockSpin`: 使用自旋锁时默认的自旋次数\n* `UseThreadPriorities`: 使用本地线程优先级\n* `UseBiaseLocking`: 是否使用偏向锁,如果开启则使用\n* `UseFastAccessorMethods`: 当频繁反射执行某个方法时,生成字节码来加快反射的执行速度\n\n## 性能参数\n* `AggressiveOpts`: 使用激进的优化特征,这些特征一般是具备正面和负面双重影响的,需要根据具体应用特点分析才能判定是否对性能有好处\n* `UseLargePages`: 如果可能,使用大内存分页,这项特性需要操作系统的支持\n* `LargePageSizeInBytes`: 使用指定大小的内存分页,这项特性需要操作系统的支持\n* `StringCache`: 是否使用字符串缓存,开启则使用\n\n## 调试参数\n* `HeapDumpOnOutOfMemoryError`: 在发生内存溢出异常时是否生成堆转储快照,关闭则不生成\n* `OnOutOfMemoryError`: 当虚拟机抛出内存溢出异常时,执行指令的命令\n* `OnError`: 当虚拟机抛出ERROR异常时,执行指令的命令\n* `PrintClassHistogram`: 使用[ctrl]-[break]快捷键输出类统计状态,相当于jmap-histo的功能\n* `PrintConcurrentLocks`: 打印J.U.C中的状态\n* `PrintCommandLineFlags`: 打印启动虚拟机时输入的非稳定参数\n* `PrintGC`: 打印GC信息\n* `PrintCompilation`: 显示所有可设置的参数及它们的值(***从JDK 6 update 21开始才可以用)\n* `PrintGCDetails`: 打印GC的详细信息\n* `PrintGCTimesStamps`: 打印GC停顿耗时\n* `PrintTenuingDistribution`: 打印GC后新生代各个年龄对象的大小\n* `TraceClassLoading`: 打印类加载信息\n* `TraceClassUnloading`: 打印类卸载信息\n* `PrintInlining`: 打印方法内联信息\n* `PrintCFGToFile`: 将CFG图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `PrintIdealGraphFile`: 将Ideal图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `UnlockDiagnosticVMOptions`: 让虚拟机进入诊断模式,一些参数(如PrintAssembly)需要在诊断模式中才能使用\n* `PrintAssembly`: 打印即时编译后的二进制信息\n\n\n## 参数组合\n* 给远程服务器加debug\n```\n-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10020\n```\n\n###  \n* `-XX:+UseVMInterruptibleIO` : 线程中断前或是EINTR 在OS_INTRPT中对于I/O操作的结果 \n* `-XX:-UseParallelOldGC` :  所有的集合使用并行垃圾收集器。能够自动化地设置这个选项 -XX:+UseParallelGC\n* `-XX:+FailOverToOldVerifier` :  当新的类型检测器失败时切换到旧的认证器\n* `-XX:-AllowUserSignalHandlers` :  允许为java进程安装信号处理器（限于Linux和Solaris，默认关闭）\n\n### \n* `-XX:NewRatio=n` :  老年代与新生代比例(默认是2).\n* `-XX:ConcGCThreads=n` :  `concurrent garbage collectors`使用的线程数. (默认值与JVM所在平台有关).\n* `-XX:+UseG1GC` :  使用`Garbage First (G1) `收集器\n* `-XX:InitiatingHeapOccupancyPercent=n` :  设置触发标记周期的 Java 堆占用率阈值。默认占用率是整个 Java 堆的 45%。\n* `-XX:G1HeapRegionSize=n` : 设置的 G1 区域的大小。值是 2 的幂，范围是 1 MB 到 32 MB 之间。目标是根据最小的 Java 堆大小划分出约 2048 个区域.\n* `-XX:G1ReservePercent=n` : 设置作为空闲空间的预留内存百分比，以降低目标空间溢出的风险。默认值是 10%。增加或减少百分比时，请确保对总的 Java 堆调整相同的量。Java HotSpot VM build 23 中没有此设置。\n\n### \n* `-XX:AllocatePrefetchStyle=1` : 预取指令的产生代码风格：0-没有预取指令，1-每一次分配内存就执行预取指令，2-当执行预取代码指令时，用TLAB分配水印指针指向门\n* `-XX:NewSize=2m` :  新生代默认大小(单位是字节) \n* `-XX:AllocatePrefetchLines=1` :  在使用JIT生成的预读取指令分配对象后读取的缓存行数。如果上次分配的对象是一个实例则默认值是1，如果是一个数组则是3\n* `-XX:+OptimizeStringConcat` :  对字符串拼接进行优化\n* `-XX:MaxNewSize=size` : 新生代最大值(单位字节)\n* `-XX:ThreadStackSize=512` : 线程堆栈大小(单位Kbytes，0 使用默认大小) \n* `-XX:+UseCompressedStrings` :  如果可以表示为纯ASCII的话，则用byte[] 代替字符串. \n* `-XX:+UseBiasedLocking` :  使用偏锁.\n\n### \n* `-XX:LoopUnrollLimit=n` :  代表节点数目小于给定值时打开循环体。\n* `-XX:GCLogFileSize=8K` :  gc日志文件大小(必须>= 8K).\n* `-XX:HeapDumpPath=./java_pid<pid>.hprof` :  堆内存溢出存放日志目录.\n* `-XX:+PerfDataSaveToFile` :  Jvm退出时保存jvmstat的二进制数据.\n* `-Xloggc:<filename>` :  gc日志文件\n* `-XX:+AlwaysPreTouch` :  当JVM初始化时预先对Java堆进行预先摸底(堆中每个页归零处理)。\n* `-XX:InlineSmallCode=n` :  当编译的代码小于指定的值时,内联编译的代码。\n* `-XX:InitialTenuringThreshold=7` :  设置初始的对象在新生代中最大存活次数。\n* `-XX:+UseCompressedOops` :  使用compressed pointers。这个参数默认在64bit的环境下默认启动，但是如果JVM的内存达到32G后，这个参数就会默认为不启动，因为32G内存后，压缩就没有多大必要了，要管理那么大的内存指针也需要很大的宽度了\n* `-XX:-PrintAdaptiveSizePolicy` :  打印JVM自动划分新生代和老生代大小信息.\n* `-XX:AllocatePrefetchDistance=n` :  为对象分配设置预取距离。\n* `-XX:MaxInlineSize=35` :  内联函数最大的字节码大小.\n* `-XX:-UseGCLogFileRotation` :  开启GC 日志文件切分功能，前置选项 -Xloggc\n* `-XX:-CITime` :  打印`JIT Compiler`的耗时\n* `-XX:-TraceClassResolution` :  追踪常量池resolutions. \n* `-XX:FreqInlineSize=n` :  经常执行方法内联的最大字节大小\n* `-XX:-TraceLoaderConstraints` : 跟踪加载器的限制记录.\n* `-XX:ErrorFile=./hs_err_pid<pid>.log` :  如果有Error发生,则将Error输入到该日志. \n* `-XX:NumberOfGClogFiles=1` :  设置Gc日志文件的数量(必须大于1)\n* `-XX:-PrintTenuringDistribution` :  打印对象的存活期限信息。\n","slug":"jvm7/JVM 参数","published":1,"updated":"2015-10-16T08:39:14.654Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxth002r0cufybtoprty"},{"date":"2015-06-07T16:00:00.000Z","title":"估算java对象大小","_content":"\n要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.\n\n这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.\n\n另外一般内存的使用会被填充为8字节的倍数.\n\n","source":"_posts/java基础/估算java对象大小.md","raw":"category: java基础\ndate: 2015-06-08\ntitle: 估算java对象大小\n---\n\n要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.\n\n这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.\n\n另外一般内存的使用会被填充为8字节的倍数.\n\n","slug":"java基础/估算java对象大小","published":1,"updated":"2015-10-16T02:42:59.209Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtj002t0cuf7u7n140s"},{"date":"2014-06-07T16:00:00.000Z","title":"java集合","_content":"\n这一部分介绍的是不支持多线程的集合.这些集合都在java.util包里.其中一些在Java 1.0的时候就有了(现在已经弃用),其中大多数在Java 1.4中重新发布.枚举集合在Java 1.5中重新发布,并且从这个版本之后所有的集合都支持泛型.PriorityQueue也在Java 1.5中加入.非线程安全的集合架构的最后一个版本是ArrayDeque ,也在Java 1.6中重新发布了.\n\n# List\n\n* `LinkedList`：`Deque`实现：每一个节点都保存着上一个节点和下一个节点的指针.这就意味着数据的存取和更新具有线性复杂度(这也是一个最佳化的实现,每次操作都不会遍历数组一半以上,操作成本最高的元素就是数组中间的那个).如果想写出高效的LinkedList代码可以使用 ListIterators .如果你想用一个Queue/Deque实现的话(你只需读取第一个和最后一个元素就行了)——考虑用ArrayDeque代替.\n\n* `Vector`：一个带有线程同步方法的ArrayList版本.现在直接用ArrayList代替了.\n\n* `ArrayList`： 最有用的List集合实现.由一个整形数字或数组存储了集合的大小(数组中第一个没有使用的元素).像所有的List集合一样,ArrayList可以在必要的时候扩展它的大小.ArrayList访问元素的时间开销固定.在尾部添加元素成本低(为常数复杂度),而在头部添加元素成本很高(线性复杂度).\n\n这是由ArrayList的实现原理——所有的元素的从角标为0开始一个接着一个排列造成的.也就是说,从要插入的元素位置往后,每个元素都要向后移动一个位置.CPU缓存友好的集合是基于数组的.(其实也不是很友好,因为有时数组会包含对象,这样存储的只是指向实际对象的指针).\n\n\n# Maps\n* `HashMap`：最常用的Map实现.只是将一个键和值相对应,并没有其他的功能.对于复杂的hashCode method,get/put方法有固定的复杂度.就是一张hash表,键和值都没有排序.Hashtable的后继者HashMap是作为JDK1.2中的集合框架的一部分出现的,它通过提供一个不同步的基类和一个同步的包装器Collections.synchronizedMap ,解决了线程安全性问题.\n\n* `EnumMap`：枚举作为键值的Map.因为键的数量相对固定,所以在内部用一个数组储存对应值.通常来说,效率要高于HashMap.\n\n* `HashTable`：旧HashMap的同步版本,新的代码中也使用了HashMap.是同步的(而HashMap是不同步的).所以如果在线程安全的环境下应该多使用HashMap,而不是Hashtable,因为Hashtable对同步有额外的开销.提供了一种易于使用的、线程安全的、关联的map功能.然而,线程安全性付出代价是――Hashtable 的所有方法都是同步的.\n\n* `IdentityHashMap`：这是一个特殊的Map版本,它违背了一般Map的规则`：它使用 “==” 来比较引用而不是调用Object.equals来判断相等.这个特性使得此集合在遍历图表的算法中非常实用——可以方便地在IdentityHashMap中存储处理过的节点以及相关的数据.\n\n* `LinkedHashMap `：保存了插入时的顺序.HashMap和LinkedList的结合,所有元素的插入顺序存储在LinkedList中.这就是为什么迭代LinkedHashMap的条目(entry)、键和值的时候总是遵循插入的顺序.在JDK中,这是每元素消耗内存最大的集合.\n\n* `TreeMap`：以红-黑树结构为基础,键值按顺序排列.一种基于已排序且带导向信息Map的红黑树.每次插入都会按照自然顺序或者给定的比较器排序.\n这个Map需要实现equals方法和Comparable/Comparator.compareTo需要前后一致.这个类实现了一个NavigableMap接口`：可以带有与键数量不同的入口,可以得到键的上一个或者下一个入口,可以得到另一Map某一范围的键(大致和SQL的BETWEEN运算符相同),以及其他的一些方法.\n\n* `WeakHashMap`：这种Map通常用在数据缓存中.它将键存储在WeakReference中,就是说,如果没有强引用指向键对象的话,这些键就可以被垃圾回收线程回收.值被保存在强引用中.因此,你要确保没有引用从值指向键或者将值也保存在弱引用中m.put(key, new WeakReference(value)).\n\n\n# Sets\n* `HashSet`：一个基于HashMap的Set实现.其中,所有的值为“假值”(同一个Object对象具备和HashMap同样的性能.基于这个特性,这个数据结构会消耗更多不必要的内存.\n\n* `EnumSet`：值为枚举类型的Set.Java的每一个enum都映射成一个不同的int.这就允许使用BitSet——一个类似的集合结构,其中每一比特都映射成不同的enum.EnumSet有两种实现,RegularEnumSet——由一个单独的long存储(能够存储64个枚举值,99.9%的情况下是够用的),JumboEnumSet——由long[]存储.\n\n* `BitSet`：一个比特Set.需要时常考虑用BitSet处理一组密集的整数Set(比如从一个预先知道的数字开始的id集合).这个类用 long[]来存储bit.\n\n* `LinkedHashMap`：与HashSet一样,这个类基于LinkedHashMap实现.这是唯一一个保持了插入顺序的Set.\n\n* `TreeSet`：与HashSet类似.这个类是基于一个TreeMap实例的.这是在单线程部分唯一一个排序的Set.\n","source":"_posts/java基础/java集合.md","raw":"category: java基础\ndate: 2014-06-08\ntitle: java集合\n---\n\n这一部分介绍的是不支持多线程的集合.这些集合都在java.util包里.其中一些在Java 1.0的时候就有了(现在已经弃用),其中大多数在Java 1.4中重新发布.枚举集合在Java 1.5中重新发布,并且从这个版本之后所有的集合都支持泛型.PriorityQueue也在Java 1.5中加入.非线程安全的集合架构的最后一个版本是ArrayDeque ,也在Java 1.6中重新发布了.\n\n# List\n\n* `LinkedList`：`Deque`实现：每一个节点都保存着上一个节点和下一个节点的指针.这就意味着数据的存取和更新具有线性复杂度(这也是一个最佳化的实现,每次操作都不会遍历数组一半以上,操作成本最高的元素就是数组中间的那个).如果想写出高效的LinkedList代码可以使用 ListIterators .如果你想用一个Queue/Deque实现的话(你只需读取第一个和最后一个元素就行了)——考虑用ArrayDeque代替.\n\n* `Vector`：一个带有线程同步方法的ArrayList版本.现在直接用ArrayList代替了.\n\n* `ArrayList`： 最有用的List集合实现.由一个整形数字或数组存储了集合的大小(数组中第一个没有使用的元素).像所有的List集合一样,ArrayList可以在必要的时候扩展它的大小.ArrayList访问元素的时间开销固定.在尾部添加元素成本低(为常数复杂度),而在头部添加元素成本很高(线性复杂度).\n\n这是由ArrayList的实现原理——所有的元素的从角标为0开始一个接着一个排列造成的.也就是说,从要插入的元素位置往后,每个元素都要向后移动一个位置.CPU缓存友好的集合是基于数组的.(其实也不是很友好,因为有时数组会包含对象,这样存储的只是指向实际对象的指针).\n\n\n# Maps\n* `HashMap`：最常用的Map实现.只是将一个键和值相对应,并没有其他的功能.对于复杂的hashCode method,get/put方法有固定的复杂度.就是一张hash表,键和值都没有排序.Hashtable的后继者HashMap是作为JDK1.2中的集合框架的一部分出现的,它通过提供一个不同步的基类和一个同步的包装器Collections.synchronizedMap ,解决了线程安全性问题.\n\n* `EnumMap`：枚举作为键值的Map.因为键的数量相对固定,所以在内部用一个数组储存对应值.通常来说,效率要高于HashMap.\n\n* `HashTable`：旧HashMap的同步版本,新的代码中也使用了HashMap.是同步的(而HashMap是不同步的).所以如果在线程安全的环境下应该多使用HashMap,而不是Hashtable,因为Hashtable对同步有额外的开销.提供了一种易于使用的、线程安全的、关联的map功能.然而,线程安全性付出代价是――Hashtable 的所有方法都是同步的.\n\n* `IdentityHashMap`：这是一个特殊的Map版本,它违背了一般Map的规则`：它使用 “==” 来比较引用而不是调用Object.equals来判断相等.这个特性使得此集合在遍历图表的算法中非常实用——可以方便地在IdentityHashMap中存储处理过的节点以及相关的数据.\n\n* `LinkedHashMap `：保存了插入时的顺序.HashMap和LinkedList的结合,所有元素的插入顺序存储在LinkedList中.这就是为什么迭代LinkedHashMap的条目(entry)、键和值的时候总是遵循插入的顺序.在JDK中,这是每元素消耗内存最大的集合.\n\n* `TreeMap`：以红-黑树结构为基础,键值按顺序排列.一种基于已排序且带导向信息Map的红黑树.每次插入都会按照自然顺序或者给定的比较器排序.\n这个Map需要实现equals方法和Comparable/Comparator.compareTo需要前后一致.这个类实现了一个NavigableMap接口`：可以带有与键数量不同的入口,可以得到键的上一个或者下一个入口,可以得到另一Map某一范围的键(大致和SQL的BETWEEN运算符相同),以及其他的一些方法.\n\n* `WeakHashMap`：这种Map通常用在数据缓存中.它将键存储在WeakReference中,就是说,如果没有强引用指向键对象的话,这些键就可以被垃圾回收线程回收.值被保存在强引用中.因此,你要确保没有引用从值指向键或者将值也保存在弱引用中m.put(key, new WeakReference(value)).\n\n\n# Sets\n* `HashSet`：一个基于HashMap的Set实现.其中,所有的值为“假值”(同一个Object对象具备和HashMap同样的性能.基于这个特性,这个数据结构会消耗更多不必要的内存.\n\n* `EnumSet`：值为枚举类型的Set.Java的每一个enum都映射成一个不同的int.这就允许使用BitSet——一个类似的集合结构,其中每一比特都映射成不同的enum.EnumSet有两种实现,RegularEnumSet——由一个单独的long存储(能够存储64个枚举值,99.9%的情况下是够用的),JumboEnumSet——由long[]存储.\n\n* `BitSet`：一个比特Set.需要时常考虑用BitSet处理一组密集的整数Set(比如从一个预先知道的数字开始的id集合).这个类用 long[]来存储bit.\n\n* `LinkedHashMap`：与HashSet一样,这个类基于LinkedHashMap实现.这是唯一一个保持了插入顺序的Set.\n\n* `TreeSet`：与HashSet类似.这个类是基于一个TreeMap实例的.这是在单线程部分唯一一个排序的Set.\n","slug":"java基础/java集合","published":1,"updated":"2015-10-16T02:42:47.730Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtl002w0cufyk6uknom"},{"date":"2015-03-07T16:00:00.000Z","title":"JAVA钩子程序","_content":"# java hook\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```\nnohup java HookTest &\n```\n#### 关闭程序\n```\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\t\n\tpublic static void exec() {\n\t\texec();\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\t\t\n\t\tSystem.out.println(\"Main over\");\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试\n```java\n\n```","source":"_posts/java基础/java_hook.md","raw":"category: java基础\ndate: 2015-03-08\ntitle: JAVA钩子程序\n---\n# java hook\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```\nnohup java HookTest &\n```\n#### 关闭程序\n```\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\t\n\tpublic static void exec() {\n\t\texec();\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\t\t\n\t\tSystem.out.println(\"Main over\");\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试\n```java\n\n```","slug":"java基础/java_hook","published":1,"updated":"2015-10-16T02:42:50.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtm002y0cufqebo0a49"},{"date":"2015-06-07T16:00:00.000Z","title":"java泛型","_content":"\n# 泛型\n泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类.\n\n## 泛型类\n我们定义一个简单的泛型类, `T`称为泛型参数, `G`被称为泛型化了\n```java\nclass G<T> {\n\n}\n```\n接着我们在内部定义一个泛型变量\n```\nclass G<T> {\n\tT t;\n}\n```\n然后我们再添加一个泛型方法泛型方法\n```java\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n```\n下来我们来使用一下这个泛型类\n```java\nG<String> g = new G<>();\ng.setValue(\"value\");\n```\n\n### 泛型参数\n\n#### extends\n```java\nclass G<T extends SuperParam> {\n\tT t;\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n```\n我们使用`extends`关键字定义了一个泛型类, 接下来我们实例化这个泛型类\n```java\nG<SuperParam> g = new G<>();\t// compile ok\ng.setValue(new SuperParam());\n\nG<Param> g1 = new G<>();\t\t// compile ok\ng.setValue(new Param());\n\nG<String> g2 = new G<>();\t\t// compile error\ng.setValue(new String());\n```\n当我们将`String`作为泛型参数的时候会提示`Type parameter 'java.lang.String' is not within its bound; should extends 'SuperParam'`. 很显然现在的泛型参数要继承自`SuperParam`.\n\n#### super\n```java\n\n```\n\n#### 通配符\n```java\n\n```\n\n#### 自定义泛型参数\n```java\n\n```\n\n#### 在泛型方法中的使用\n```java\n\n```\n\n### 泛型类的继承关系\n```java\n\n```\n\n#### 在泛型方法中的使用\n```java\n\n```\n\n## 泛型和数组\n```java\n\n```\n\n\n## 泛型在JVM中","source":"_posts/java基础/java 泛型.md","raw":"category: java基础\ndate: 2015-06-08\ntitle: java泛型\n---\n\n# 泛型\n泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类.\n\n## 泛型类\n我们定义一个简单的泛型类, `T`称为泛型参数, `G`被称为泛型化了\n```java\nclass G<T> {\n\n}\n```\n接着我们在内部定义一个泛型变量\n```\nclass G<T> {\n\tT t;\n}\n```\n然后我们再添加一个泛型方法泛型方法\n```java\nclass G<T> {\n\tT t;\n\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n```\n下来我们来使用一下这个泛型类\n```java\nG<String> g = new G<>();\ng.setValue(\"value\");\n```\n\n### 泛型参数\n\n#### extends\n```java\nclass G<T extends SuperParam> {\n\tT t;\n\tpublic void setValue(T t) {\n\t\tthis.t = t;\n\t}\n}\n\nclass SuperParam {}\n\nclass Param extends SuperParam {}\n```\n我们使用`extends`关键字定义了一个泛型类, 接下来我们实例化这个泛型类\n```java\nG<SuperParam> g = new G<>();\t// compile ok\ng.setValue(new SuperParam());\n\nG<Param> g1 = new G<>();\t\t// compile ok\ng.setValue(new Param());\n\nG<String> g2 = new G<>();\t\t// compile error\ng.setValue(new String());\n```\n当我们将`String`作为泛型参数的时候会提示`Type parameter 'java.lang.String' is not within its bound; should extends 'SuperParam'`. 很显然现在的泛型参数要继承自`SuperParam`.\n\n#### super\n```java\n\n```\n\n#### 通配符\n```java\n\n```\n\n#### 自定义泛型参数\n```java\n\n```\n\n#### 在泛型方法中的使用\n```java\n\n```\n\n### 泛型类的继承关系\n```java\n\n```\n\n#### 在泛型方法中的使用\n```java\n\n```\n\n## 泛型和数组\n```java\n\n```\n\n\n## 泛型在JVM中","slug":"java基础/java 泛型","published":1,"updated":"2015-10-16T02:42:53.122Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxto00300cuf8fzt84un"},{"date":"2014-12-07T16:00:00.000Z","title":"JAVA IO","_content":"\n# io#interface\n\n## Closeable \nCloseable 是可以关闭的数据源或目标。调用 close 方法可释放对象保存的资源（如打开文件）。\n\n## DataInput \nDataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据。同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具。\n\n对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）。如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException。尤其在输入流已关闭的情况下，将抛出 IOException。\n\n## DataOutput \nDataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流。同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具。\n对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException。\n\t\n## Externalizable \nExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成。如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段。\n\t\n## FileFilter          \n检测文件是否存在。FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法，而FilenameFilter 是按照目录和文件名的方式来工作的。\n\n## FilenameFilter \n\n## Flushable \n实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中。写入流的所有I/O类都实现了Flushable接口。\n\n## ObjectInputValidation \n序列化流验证机制.一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题。但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息。Java序列化提供一套验证机制。序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n\n## ObjectStreamConstants \nJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值。Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分。现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中。 \n\n# io#class\n\n## BufferedInputStream \nBufferedInputStream是一个带有缓冲区域的InputStream, 支持“mark()标记”和“reset()重置方法”。输入到byte[]数组里.\n```java\n// 读取二进制文件\ntry (BufferedInputStream bf = new BufferedInputStream(\n\t\tnew FileInputStream(IOUtils.newFile(\"\")));) {\n\t\n\tbyte[] data = new byte[bf.available()];\n\tbf.read(data);\n\t\n} catch (final IOException e) {\n\te.printStackTrace();\n}\n```\n\n## BufferedOutputStream \n缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\n\n## BufferedReader \nBufferedReader 从字符输入流中读取文本，缓冲各个字符。提供字符、数组和行的高效读取。\n```\n// 使用带缓冲区的写入器 \nBufferedReader reader = Files.newBufferedReader(IOUtils.newPath(\"new.txt\"), StandardCharsets.UTF_8);\n// 读取UTF-8格式编码的文件\nBufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream(file), StandardCharsets.UTF_8))\n// 从标准IO中输入\n// 按照标准的IO模型,Java提供了System.out, System.out, System.err System.out,System.err 已经被包装成了PrintStream对象 但是System.in作为原生InputStream却没有进行过任何包装\n// 所以在使用System.in时必须对其进行包装,下例中展示了,我们使用InputStreamReader将System.in包装Reader,然后再包装一层BufferedReader\nBufferedReader stdin = new BufferedReader(new InputStreamReader(System.in));\n```\n\n## BufferedWriter \n1. 支持字符串输出\n2. 支持换行输出\n3. 支持文件追加输出\n\n## ByteArrayInputStream \n从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayInputStream in = new ByteArrayInputStream(buff)) {\n\t\n\twhile(in.available() != 0)\n\t\tSystem.out.println(in.read());\n\t\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## ByteArrayOutputStream \n输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何IOException。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n\tout.write(buff);\n\t\n\tbyte[] byteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush before : \" + b);\n\t}\n\t\n\tout.flush();\n\t\n\tbyteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush after : \" + b);\n\t}\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayReader \n与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n```\nchar[] array = {'a', 'z', 'g'};\ntry(CharArrayReader in = new CharArrayReader(array)) {\n\twhile(in.ready())\n\t\tSystem.out.println(in.read());\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayWriter \n向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write \n```java\ntry(CharArrayWriter out = new CharArrayWriter()) {\n\tout.write(\"TestChararray\");\n\tSystem.out.println(out.toString());\n\tout.append(\"test_\");\n\tSystem.out.println(out.toString());\n} catch (IOException e) {\n\te.printStackTrace();\n} \n```\n\n## Console \n专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n```java\nConsole cons = System.console();\nif (cons != null) {\n\t// -------------------------\n\tPrintWriter printWriter = cons.writer();\n\tprintWriter.write(\"input:\");\n\tcons.flush();\n\tString str1 = cons.readLine();\n\tcons.format(\"%s\", str1);\n}\n```\n\t\n## DataInputStream \n用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n\n从DataInputStream一次一个字节地读取字符,那么任何值都是合法的,因此返回值不能用来检测输入是否结束.但是可以使用available()函数来查看还有多少字符可供读取\n\navailable()函数的工作方式会随之所读取的媒介类不同而不同, 该函数从字面上的意思来讲就是\"在没有阻塞的情况下所能读取的字节数\".对于文件这指的是整个文件,而对于其他流可能就不是这样的\n\n格式化的内存输入 当读取格式化数据时可以使用DataInputStream，它是一个面向字节的IO类\n```java\ntry(DataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(TestDataInputStream.class.getCanonicalName())));) {\n\twhile (in.available() != 0)\n\t\tSystem.out.print((char) in.readByte());\n\t\n}\n```\n\n## DataOutputStream \n用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”。\n\n我们可以使用DataOutputStream指定格式存储数据, 然后使用DataInputStream轻松的再次指定读取格式来恢复这些数据.\n```java\nDataOutputStream out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(\"Data.txt\")));\nout.writeDouble(3.14159);\nout.writeUTF(\"That was pi\");\nout.writeDouble(1.41413);\nout.writeUTF(\"Square root of 2\");\nout.close();\n\nDataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(\"Data.txt\")));\nSystem.out.println(in.readDouble());\n// Only readUTF() will recover the Java-UTF String properly:\nSystem.out.println(in.readUTF());\nSystem.out.println(in.readDouble());\nSystem.out.println(in.readUTF());\n\nin.close();\n```\n\n## File \n```\n删除文件\n文件重命名\n创建新的文件\n创建新的文件\n获取文件的最后修改时间\n设置文件只读\n设置文件可写\n获取文件长度(总字节数)\n获取文件路径\n获取绝对文件路径\n文件是否隐藏\n获得剩余磁盘空间？\n拷贝文件夹\n遍历文件夹\n检查文件夹是否为空？\n```\n## FileDescriptor \n用来表示开放文件、开放套接字等。当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。\n\t\n类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件，打开的套接字或其他来源或字节的接收器。以下是关于FileDescriptor要点：\n1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它。\n2. 应用程序不应创建自己的文件描述符。\n\n## FileInputStream \n一个字节一个字节的从文件里读取数据\n\t\n## FileOutputStream \n一个字节一个字节的向文件里输出数据\n\n\n## FileReader \n一个字符一个字符地读取\n\n## FileWriter \n一个字符一个字符地输出\n\n## FilterInputStream \n用来“封装其它的输入流，并为它们提供额外的功能”。它的常用的子类有BufferedInputStream和DataInputStream。\n\n## FilterOutputStream \n作用是用来“封装其它的输出流，并为它们提供额外的功能”。它主要包括BufferedOutputStream, DataOutputStream和PrintStream。\n\n## FilterReader \n用于读取已过滤的字符流的抽象类。抽象类 FilterReader 自身提供了一些将所有请求传递给所包含的流的默认方法。\n\n## FilterWriter \n用于写入已过滤的字符流的抽象类。抽象类 FilterWriter 自身提供了一些将所有请求传递给所包含的流的默认方法\n\n## InputStreamReader \n是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。将“字节输入流”转换成“字符输入流”。它继承于Reader。\n\n## LineNumberInputStream \n此类是一个输入流过滤器，它提供跟踪当前行号的附加功能。行是以回车符 ('\\r')、换行符 ('\\n')或回车符后面紧跟换行符结尾的字节序列。在所有这三种情况下，都以单个换行符形式返回行终止字符。行号以 0 开头，并在 read 返回换行符时递增 1。\n\n## LineNumberReader \n跟踪行号的缓冲字符输入流。此类定义了方法 setLineNumber(int) 和 getLineNumber()，它们可分别用于设置和获取当前行号。默认情况下，行编号从 0 开始。该行号随数据读取在每个行结束符处递增，并且可以通过调用 setLineNumber(int) 更改行号。但要注意的是，setLineNumber(int) 不会实际更改流中的当前位置；它只更改将由getLineNumber() 返回的值。可认为行在遇到以下符号之一时结束：换行符（'\\n'）、回车符（'\\r'）、回车后紧跟换行符。\n```java\n//  获取行数\nint lineCount = 0;\ntry (FileReader reader = new FileReader(IOUtils.newFile(\"\"));\n\t\tLineNumberReader lnr = new LineNumberReader(reader);) {\n\twhile (lnr.readLine() != null) {\n\t\tlineCount++;\n\t}\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## ObjectInputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n## ObjectOutputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n## ObjectStreamField \nSerializable 类中 Serializable 字段的描述。ObjectStreamField 的数组用于声明类的 Serializable 字段。\n\n## OutputStreamWriter \nOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n```java\n// 写入UTF-8格式编码的文件\nStringBuffer buffer = new StringBuffer();\ntry (Writer out = new BufferedWriter(new OutputStreamWriter(\n\t\tnew FileOutputStream(file), \"UTF8\"))) {\n\n\tout.append(\"Website UTF-8\").append(\"\\r\\n\");\n\tout.append(\"中文 UTF-8\").append(\"\\r\\n\");\n\n\tout.flush();\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## PipedInputStream \n管道输入流是让多线程可以通过管道进行线程间的通讯\n\n## PipedOutputStream \n管道输出流是让多线程可以通过管道进行线程间的通讯\n\n## PipedReader \nPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n## PipedWriter \nPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n## PrintStream \n标准IO重定向\n\n打印输出流,用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream永远不会抛出IOException；PrintStream提供了自动flush和字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\nSystem类提供了一些简单的静态方法调用,以允许我们对标准输入,输出和错误IO进行重定向IO重定向是对字节流的操纵而不是字符流,因此在该例中使用的是InputStream和OutputStream而不是Reader和Writer\n\n示例 如果在显示器上创建大量输出,而这些输出滚动地太快而无法阅读时,IO重定向就显得很有用\n```java\nPrintStream console = System.out;\nBufferedInputStream in = new BufferedInputStream(new FileInputStream(\"Redirecting.java\"));\n\nPrintStream out = new PrintStream(new BufferedOutputStream(new FileOutputStream(\"MapDB.test.out\")));\n\nSystem.setIn(in);\nSystem.setOut(out);\nSystem.setErr(out);\n\nBufferedReader br = new BufferedReader(new InputStreamReader(System.in));\nString s;\nwhile ((s = br.readLine()) != null)\n\tSystem.out.println(s);\n\nout.close(); // Remember this!\nSystem.setOut(console);\n```\n\n\n## PrintWriter \n用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\nFileWriter可以向文件输出数据. 首先创建一个与指定文件连接的FileWriter.然后使用BufferedWriter对其进行包装进行性能提升 最后使用PrintWriter提供格式化功能\n```java\ntry (PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(file)));) {\n\tout.println(string);\n}\n```\nSystem.out 是一个PrintStream,而PrintStream是一个OutputStream而PrintWriter有一个参数是接受OutputStream,因此我们可以将System.out转换成PrintWriter\n```java\ntry (PrintWriter out = new PrintWriter(System.out);) {\nout.println(string);\n}\n```\n\t \n## PushbackInputStream \n拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n## PushbackReader \n允许将字符推回到流的字符流 reader。当程序调用推回输入流的unread()方法时，系统会把指定数组的内容推回到该缓冲区中，而推回输入流每次调用read()方法时，总是先从推回缓冲区读取内容，只有完全读取了推回缓冲区里的内容后，但是还没有装满read()所需要的数组时才会从原输入流中读取\n```java\ntry (\n// 创建一个PushbackReader对象，指定推回缓冲区的长度为64\nPushbackReader pr = new PushbackReader(new FileReader(\"PushBackTest.java\"), 64);\nchar[] buf = new char[32];\n// 用以保存上次读取字符串的内容\nString lastContent = \"\";\nint hasRead = 0;\n\n// 循环读取文件内容\nwhile ((hasRead = pr.read(buf)) > 0) {\n\t// 将读取的内容转化为字符串\n\tString content = new String(buf, 0, hasRead);\n\tint targetIndex = 0;\n\n\t// 将上次读取的字符串和本次读取的字符串拼接起来\n\t// 查看是否包含目标字符串，\n\t// 如果包含目标字符串\n\tif ((targetIndex = (lastContent + content)\n\t\t\t.indexOf(\"new PushbackReader\")) > 0) {\n\t\t// 将本次的内容和上次的内容一起推回缓冲区\n\t\tpr.unread((lastContent + content).toCharArray());\n\n\t\t// 重现定义一个长度为targetIndex的char类型的数组\n\t\tif (targetIndex > 32) {\n\t\t\tbuf = new char[targetIndex];\n\t\t}\n\n\t\t// 再次读取指定长度的内容，即目标字符串之前的内容\n\t\tpr.read(buf, 0, targetIndex);\n\n\t\t// 答应读取指定长度的内容\n\t\tSystem.out.println(new String(buf, 0, targetIndex));\n\t\tSystem.exit(0);\n\t} else {\n\n\t\t// 打印上次读取的内容\n\t\tSystem.out.println(lastContent);\n\t\t// 将本次读取的内容设置为上次读取的内容\n\t\tlastContent = content;\n\n\t}\n\n}\n```\n\n## RandomAccessFile  \n读写随机访问文件 RandomAccessFile除了实现了DataInput和DataOutput接口之外,有效地与IO继承层次结构的其他部分实现了分离.因为它不支持装饰模式,所以不能将其与InputStream和OutputStream子类的任何部分组合起来而且必须假定RandomAccessFile已经被正确的缓冲\n\n用来访问那些保存数据记录的文件的，你就可以用seek( )方法来访问记录，并进行读写了。这些记录的大小不必相同；但是其大小和位置必须是可知的。但是该类仅限于操作文件。\n```java\n// 读取所有的行\ntry (RandomAccessFile r = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < r.length(); i++) {\n\t\tr.read();\t// r.readLine();\n\t}\n} \n\n// 写入数据,第二个参数必须为 \"r\", \"rw\", \"rws\", or \"rwd\"\ntry (RandomAccessFile w = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < 1024 * 1024 * 10; i++)\n\t\tw.writeByte(1);\n}\n\ntry (FileChannel fc = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\")\n\t\t.getChannel();) {\n\t\n\tIntBuffer ib = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size())\n\t\t\t.asIntBuffer();\n\t\n\tfor (int i = 1; i < 10000; i++)\n\t\tib.put(ib.get(i - 1));\n\t\n}\n\nRandomAccessFile raf = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\");\nraf.writeInt(1);\n\nfor (int i = 0; i < 2000000; i++) {\n\traf.seek(raf.length() - 4);\n\traf.writeInt(raf.readInt());\n}\n\nraf.close();\n```\n\n## SequenceInputStream \n从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n## StreamTokenizer \n获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n## StringBufferInputStream \n\n\n## StringReader \n\n\n## StringWriter \n\n\n# nio\n\n## Buffer \n\n\n## ByteBuffer \n\n\n## ByteOrder \n\n\n## CharBuffer \n\n\n## DoubleBuffer\n\n\n## FloatBuffer         \n\n\n## IntBuffer          \n\n\n## LongBuffer         \n\n\n## MappedByteBuffer   \n\n\n## ShortBuffer        \n\n\n# nio#channels#Interfaces\n\n## AsynchronousByteChannel \n\n\n## AsynchronousChannel     \n\n\n## ByteChannel     \n\n\n## Channel         \n\n\n## CompletionHandler       \n\n\n## GatheringByteChannel    \n\n\n## InterruptibleChannel    \n\n\n## MulticastChannel        \n\n\n## NetworkChannel          \n\n\n## ReadableByteChannel     \n\n\n## ScatteringByteChannel   \n\n\n## SeekableByteChannel     \n\n\n## WritableByteChannel     \n\n\n# nio#channels#Classes\n\n## AsynchronousChannelGroup\n\n\n## AsynchronousFileChannel \n\n\n## AsynchronousServerSocketChannel\n\n\n## AsynchronousSocketChannel      \n\n\n## Channels          \n\n\n## DatagramChannel     \n\n\n## FileChannel         \n\n\n## FileChannel.MapMode \n\n\n#### FileLock\n锁定文件\n\nByteBuffer.allocate()语句改为ByteBuffer.allocateDirect().用来证实性能之间的差异,但是请注意程序的启动时间是否发生了明显的改变。\n\n修改{@link JGrep}让其使java的nio内存映射文件。\n\nJDK1.4引入了文件加锁机制,它允许我们同步访问某个作为共享资源的文件。不过,竞争同一文件的两个线程可能在不同的Java虚拟机上;或者一个是Java线程,另一个是操作系统中其他的某个本地线程。\n\n文件锁对其他的操作系统进程是可见的,因为Java的文件加锁直接映射到了本地操作系统的加锁工具。通过对FileChannel调用tryLock()或lock(),就可以获得整个文件的FileLock.\n\n(SocketChannel、DatagramChannel和 ServerSocketChannel不需要加锁,因为他们是从单进程实体继承而来;我们通常不在两个进程之间共享网络socket.)\n\ntryLock()是非阻塞式的,它设法获取锁,但是如果不能获得(当其他一些进程已经持有相同的锁,并且不共享时),它将直接从方法调用返回。lock()则是阻塞式的,它要阻塞进程直至锁可以获得,或调用lock()的线程中断,或调用lock()的通道关闭。\n\n使用FileLock.release()可以释放锁。\n\n也可以使用此方法对文件上锁tryLock()或者lock()其中,加锁的区域由size-position决定。第三个参数指定是否是共享锁。\n\n尽管无参数的加锁方法将根据文件尺寸的变化而变化,但是具有固定尺寸的锁不随文件尺寸的变化而变化。如果你获得了某一区域(从position到position+size)上的锁,当文件增大超出position+size时,那么在position+size之外的部分不会被锁定。无参数的加锁方法会对 整个文件进行加锁,甚至文件变大后也是如此。\n\n对独占锁或者共享锁的支持必须由底层的操作系统提供。如果操作系统不支持共享锁并为每一个请求都创建一个锁,那么它就会使用独占锁。\n\n锁的 类型(共享或独占)可以通过FileLock.isShared()进行查询。\n```java\nFileOutputStream fos = new FileOutputStream(\"file.txt\");\nFileLock fl = fos.getChannel().tryLock();\nif (fl != null) {\n\tSystem.out.println(\"Locked File\");\n\tTimeUnit.MILLISECONDS.sleep(100);\n\tfl.release();\n\tSystem.out.println(\"Released Lock\");\n}\nfos.close()\n```\n\n## MembershipKey     \n\n\n## Pipe          \n\n\n## SelectableChannel \n\n\n## SelectionKey      \n\n\n## Selector          \n\n\n## ServerSocketChannel          \nServerSocketChannel 只有一个用途--接受入站连接 它是无法读取,写入或者连接的\n\n## SocketChannel       \n\n\n# nio#file#Interfaces\n\n## CopyOption          \n\n\n## DirectoryStream     \n遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n\n## FileVisitor          FileVisitor \n\n\n## OpenOption          OpenOption \n\n\n## Path          \nPath 类可以在任何文件系统（FileSystem）和任何存储空间 Path 类引用默认文件系统（计算机的文件系统）的文件，但是 NIO.2是完全模块化的—— FileSystem 的具体实现是在内存中的一组数据，因此在网络环境或在虚拟文件系统中，NIO.2 也完全适用。NIO.2提供给我们在文件系统中操作文件、文件夹或链接的所有方法\n\n## PathMatcher          \n\n\n## SecureDirectoryStream\n\n\n## Watchable        \n\n\n## WatchEvent       \n\n\n## WatchEvent.Kind      \n\n\n## WatchEvent.Modifier  \n\n\n## WatchKey    \n\n\n## WatchService\n\n\n# nio#file#Classes\n\n## Files \n\n1. copy\n2. createDirectories\n3. createDirectory\n4. createFile\n5. createLink\n6. createSymbolicLink\n7. createTempDirectory\n8. createTempFile\n9. delete\n10. deleteIfExists\n11. exists\n12. getAttribute\n13. getFileAttributeView\n14. getFileStore\n15. getLastModifiedTime\n16. getOwner\n17. getPosixFilePermissions\n18. isDirectory\n19. isExecutable\n20. isHidden\n21. isReadable\n22. isRegularFile\n23. isSameFile\n24. isSymbolicLink\n25. isWritable\n26. move\n27. newBufferedReader\n28. newBufferedWriter\n29. newByteChannel\n30. newDirectoryStream\n31. newInputStream\n32. newOutputStream\n33. notExists\n34. probeContentType\n35. readAllBytes\n36. readAllLines\n37. readAttributes\n38. readSymbolicLink\n39. setAttribute\n40. setLastModifiedTime\n41. setOwner\n42. setPosixFilePermissions\n43. walkFileTree\n44. write\n\n\n## FileStore \n代表了真正的存储设备，提供了设备的详尽信息\n\n## FileSystem         \n\n\n## FileSystems        \n```java\n// 返回 JVM 默认的 FileSystem – 一般说来，也就是操作系统的默认文件系统\nFileSystems.getDefault();\n// 可以获取远程主机的FileSystem\nFileSystems.getFileSystem(uri);\n// 得到文件系统支持的属性视图列表\nFileSystem system = FileSystems.getDefault();\nSet<String> views = system.supportedFileAttributeViews();\n```\n\n## LinkPermission          \n\n\n## Paths          \n\n\n## SimpleFileVisitor          \n与DirectoryStream 不同的是，这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n\n## StandardWatchEventKinds\n\n\n# nio#charset\n\n## Charset          \n\n\n## CharsetDecoder         \n\n\n## CharsetEncoder         \n\n\n## CoderResult          \n\n\n## CodingErrorAction      \n\n\n## StandardCharsets       \n\n\n\n\n\n","source":"_posts/java基础/java io.md","raw":"category: java基础\ndate: 2014-12-08\ntitle: JAVA IO\n---\n\n# io#interface\n\n## Closeable \nCloseable 是可以关闭的数据源或目标。调用 close 方法可释放对象保存的资源（如打开文件）。\n\n## DataInput \nDataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据。同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具。\n\n对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）。如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException。尤其在输入流已关闭的情况下，将抛出 IOException。\n\n## DataOutput \nDataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流。同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具。\n对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException。\n\t\n## Externalizable \nExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成。如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段。\n\t\n## FileFilter          \n检测文件是否存在。FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法，而FilenameFilter 是按照目录和文件名的方式来工作的。\n\n## FilenameFilter \n\n## Flushable \n实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中。写入流的所有I/O类都实现了Flushable接口。\n\n## ObjectInputValidation \n序列化流验证机制.一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题。但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息。Java序列化提供一套验证机制。序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n\n## ObjectStreamConstants \nJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值。Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分。现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中。 \n\n# io#class\n\n## BufferedInputStream \nBufferedInputStream是一个带有缓冲区域的InputStream, 支持“mark()标记”和“reset()重置方法”。输入到byte[]数组里.\n```java\n// 读取二进制文件\ntry (BufferedInputStream bf = new BufferedInputStream(\n\t\tnew FileInputStream(IOUtils.newFile(\"\")));) {\n\t\n\tbyte[] data = new byte[bf.available()];\n\tbf.read(data);\n\t\n} catch (final IOException e) {\n\te.printStackTrace();\n}\n```\n\n## BufferedOutputStream \n缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\n\n## BufferedReader \nBufferedReader 从字符输入流中读取文本，缓冲各个字符。提供字符、数组和行的高效读取。\n```\n// 使用带缓冲区的写入器 \nBufferedReader reader = Files.newBufferedReader(IOUtils.newPath(\"new.txt\"), StandardCharsets.UTF_8);\n// 读取UTF-8格式编码的文件\nBufferedReader in = new BufferedReader(new InputStreamReader(new FileInputStream(file), StandardCharsets.UTF_8))\n// 从标准IO中输入\n// 按照标准的IO模型,Java提供了System.out, System.out, System.err System.out,System.err 已经被包装成了PrintStream对象 但是System.in作为原生InputStream却没有进行过任何包装\n// 所以在使用System.in时必须对其进行包装,下例中展示了,我们使用InputStreamReader将System.in包装Reader,然后再包装一层BufferedReader\nBufferedReader stdin = new BufferedReader(new InputStreamReader(System.in));\n```\n\n## BufferedWriter \n1. 支持字符串输出\n2. 支持换行输出\n3. 支持文件追加输出\n\n## ByteArrayInputStream \n从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayInputStream in = new ByteArrayInputStream(buff)) {\n\t\n\twhile(in.available() != 0)\n\t\tSystem.out.println(in.read());\n\t\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## ByteArrayOutputStream \n输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何IOException。\n```java\nbyte[] buff = {1, 2, 3, 4, 5};\ntry(ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n\tout.write(buff);\n\t\n\tbyte[] byteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush before : \" + b);\n\t}\n\t\n\tout.flush();\n\t\n\tbyteArray = out.toByteArray();\n\tfor (byte b : byteArray) {\n\t\tSystem.out.println(\"flush after : \" + b);\n\t}\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayReader \n与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n```\nchar[] array = {'a', 'z', 'g'};\ntry(CharArrayReader in = new CharArrayReader(array)) {\n\twhile(in.ready())\n\t\tSystem.out.println(in.read());\n} catch (IOException e) {\n\te.printStackTrace();\n}\n```\n\n## CharArrayWriter \n向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write \n```java\ntry(CharArrayWriter out = new CharArrayWriter()) {\n\tout.write(\"TestChararray\");\n\tSystem.out.println(out.toString());\n\tout.append(\"test_\");\n\tSystem.out.println(out.toString());\n} catch (IOException e) {\n\te.printStackTrace();\n} \n```\n\n## Console \n专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n```java\nConsole cons = System.console();\nif (cons != null) {\n\t// -------------------------\n\tPrintWriter printWriter = cons.writer();\n\tprintWriter.write(\"input:\");\n\tcons.flush();\n\tString str1 = cons.readLine();\n\tcons.format(\"%s\", str1);\n}\n```\n\t\n## DataInputStream \n用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n\n从DataInputStream一次一个字节地读取字符,那么任何值都是合法的,因此返回值不能用来检测输入是否结束.但是可以使用available()函数来查看还有多少字符可供读取\n\navailable()函数的工作方式会随之所读取的媒介类不同而不同, 该函数从字面上的意思来讲就是\"在没有阻塞的情况下所能读取的字节数\".对于文件这指的是整个文件,而对于其他流可能就不是这样的\n\n格式化的内存输入 当读取格式化数据时可以使用DataInputStream，它是一个面向字节的IO类\n```java\ntry(DataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(TestDataInputStream.class.getCanonicalName())));) {\n\twhile (in.available() != 0)\n\t\tSystem.out.print((char) in.readByte());\n\t\n}\n```\n\n## DataOutputStream \n用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”。\n\n我们可以使用DataOutputStream指定格式存储数据, 然后使用DataInputStream轻松的再次指定读取格式来恢复这些数据.\n```java\nDataOutputStream out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(\"Data.txt\")));\nout.writeDouble(3.14159);\nout.writeUTF(\"That was pi\");\nout.writeDouble(1.41413);\nout.writeUTF(\"Square root of 2\");\nout.close();\n\nDataInputStream in = new DataInputStream(new BufferedInputStream(new FileInputStream(\"Data.txt\")));\nSystem.out.println(in.readDouble());\n// Only readUTF() will recover the Java-UTF String properly:\nSystem.out.println(in.readUTF());\nSystem.out.println(in.readDouble());\nSystem.out.println(in.readUTF());\n\nin.close();\n```\n\n## File \n```\n删除文件\n文件重命名\n创建新的文件\n创建新的文件\n获取文件的最后修改时间\n设置文件只读\n设置文件可写\n获取文件长度(总字节数)\n获取文件路径\n获取绝对文件路径\n文件是否隐藏\n获得剩余磁盘空间？\n拷贝文件夹\n遍历文件夹\n检查文件夹是否为空？\n```\n## FileDescriptor \n用来表示开放文件、开放套接字等。当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。\n\t\n类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件，打开的套接字或其他来源或字节的接收器。以下是关于FileDescriptor要点：\n1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它。\n2. 应用程序不应创建自己的文件描述符。\n\n## FileInputStream \n一个字节一个字节的从文件里读取数据\n\t\n## FileOutputStream \n一个字节一个字节的向文件里输出数据\n\n\n## FileReader \n一个字符一个字符地读取\n\n## FileWriter \n一个字符一个字符地输出\n\n## FilterInputStream \n用来“封装其它的输入流，并为它们提供额外的功能”。它的常用的子类有BufferedInputStream和DataInputStream。\n\n## FilterOutputStream \n作用是用来“封装其它的输出流，并为它们提供额外的功能”。它主要包括BufferedOutputStream, DataOutputStream和PrintStream。\n\n## FilterReader \n用于读取已过滤的字符流的抽象类。抽象类 FilterReader 自身提供了一些将所有请求传递给所包含的流的默认方法。\n\n## FilterWriter \n用于写入已过滤的字符流的抽象类。抽象类 FilterWriter 自身提供了一些将所有请求传递给所包含的流的默认方法\n\n## InputStreamReader \n是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。将“字节输入流”转换成“字符输入流”。它继承于Reader。\n\n## LineNumberInputStream \n此类是一个输入流过滤器，它提供跟踪当前行号的附加功能。行是以回车符 ('\\r')、换行符 ('\\n')或回车符后面紧跟换行符结尾的字节序列。在所有这三种情况下，都以单个换行符形式返回行终止字符。行号以 0 开头，并在 read 返回换行符时递增 1。\n\n## LineNumberReader \n跟踪行号的缓冲字符输入流。此类定义了方法 setLineNumber(int) 和 getLineNumber()，它们可分别用于设置和获取当前行号。默认情况下，行编号从 0 开始。该行号随数据读取在每个行结束符处递增，并且可以通过调用 setLineNumber(int) 更改行号。但要注意的是，setLineNumber(int) 不会实际更改流中的当前位置；它只更改将由getLineNumber() 返回的值。可认为行在遇到以下符号之一时结束：换行符（'\\n'）、回车符（'\\r'）、回车后紧跟换行符。\n```java\n//  获取行数\nint lineCount = 0;\ntry (FileReader reader = new FileReader(IOUtils.newFile(\"\"));\n\t\tLineNumberReader lnr = new LineNumberReader(reader);) {\n\twhile (lnr.readLine() != null) {\n\t\tlineCount++;\n\t}\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## ObjectInputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n## ObjectOutputStream \n用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n## ObjectStreamField \nSerializable 类中 Serializable 字段的描述。ObjectStreamField 的数组用于声明类的 Serializable 字段。\n\n## OutputStreamWriter \nOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n```java\n// 写入UTF-8格式编码的文件\nStringBuffer buffer = new StringBuffer();\ntry (Writer out = new BufferedWriter(new OutputStreamWriter(\n\t\tnew FileOutputStream(file), \"UTF8\"))) {\n\n\tout.append(\"Website UTF-8\").append(\"\\r\\n\");\n\tout.append(\"中文 UTF-8\").append(\"\\r\\n\");\n\n\tout.flush();\n} catch (final Exception e) {\n\te.printStackTrace();\n}\n```\n\n## PipedInputStream \n管道输入流是让多线程可以通过管道进行线程间的通讯\n\n## PipedOutputStream \n管道输出流是让多线程可以通过管道进行线程间的通讯\n\n## PipedReader \nPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n## PipedWriter \nPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n## PrintStream \n标准IO重定向\n\n打印输出流,用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream永远不会抛出IOException；PrintStream提供了自动flush和字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\nSystem类提供了一些简单的静态方法调用,以允许我们对标准输入,输出和错误IO进行重定向IO重定向是对字节流的操纵而不是字符流,因此在该例中使用的是InputStream和OutputStream而不是Reader和Writer\n\n示例 如果在显示器上创建大量输出,而这些输出滚动地太快而无法阅读时,IO重定向就显得很有用\n```java\nPrintStream console = System.out;\nBufferedInputStream in = new BufferedInputStream(new FileInputStream(\"Redirecting.java\"));\n\nPrintStream out = new PrintStream(new BufferedOutputStream(new FileOutputStream(\"MapDB.test.out\")));\n\nSystem.setIn(in);\nSystem.setOut(out);\nSystem.setErr(out);\n\nBufferedReader br = new BufferedReader(new InputStreamReader(System.in));\nString s;\nwhile ((s = br.readLine()) != null)\n\tSystem.out.println(s);\n\nout.close(); // Remember this!\nSystem.setOut(console);\n```\n\n\n## PrintWriter \n用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\nFileWriter可以向文件输出数据. 首先创建一个与指定文件连接的FileWriter.然后使用BufferedWriter对其进行包装进行性能提升 最后使用PrintWriter提供格式化功能\n```java\ntry (PrintWriter out = new PrintWriter(new BufferedWriter(new FileWriter(file)));) {\n\tout.println(string);\n}\n```\nSystem.out 是一个PrintStream,而PrintStream是一个OutputStream而PrintWriter有一个参数是接受OutputStream,因此我们可以将System.out转换成PrintWriter\n```java\ntry (PrintWriter out = new PrintWriter(System.out);) {\nout.println(string);\n}\n```\n\t \n## PushbackInputStream \n拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n## PushbackReader \n允许将字符推回到流的字符流 reader。当程序调用推回输入流的unread()方法时，系统会把指定数组的内容推回到该缓冲区中，而推回输入流每次调用read()方法时，总是先从推回缓冲区读取内容，只有完全读取了推回缓冲区里的内容后，但是还没有装满read()所需要的数组时才会从原输入流中读取\n```java\ntry (\n// 创建一个PushbackReader对象，指定推回缓冲区的长度为64\nPushbackReader pr = new PushbackReader(new FileReader(\"PushBackTest.java\"), 64);\nchar[] buf = new char[32];\n// 用以保存上次读取字符串的内容\nString lastContent = \"\";\nint hasRead = 0;\n\n// 循环读取文件内容\nwhile ((hasRead = pr.read(buf)) > 0) {\n\t// 将读取的内容转化为字符串\n\tString content = new String(buf, 0, hasRead);\n\tint targetIndex = 0;\n\n\t// 将上次读取的字符串和本次读取的字符串拼接起来\n\t// 查看是否包含目标字符串，\n\t// 如果包含目标字符串\n\tif ((targetIndex = (lastContent + content)\n\t\t\t.indexOf(\"new PushbackReader\")) > 0) {\n\t\t// 将本次的内容和上次的内容一起推回缓冲区\n\t\tpr.unread((lastContent + content).toCharArray());\n\n\t\t// 重现定义一个长度为targetIndex的char类型的数组\n\t\tif (targetIndex > 32) {\n\t\t\tbuf = new char[targetIndex];\n\t\t}\n\n\t\t// 再次读取指定长度的内容，即目标字符串之前的内容\n\t\tpr.read(buf, 0, targetIndex);\n\n\t\t// 答应读取指定长度的内容\n\t\tSystem.out.println(new String(buf, 0, targetIndex));\n\t\tSystem.exit(0);\n\t} else {\n\n\t\t// 打印上次读取的内容\n\t\tSystem.out.println(lastContent);\n\t\t// 将本次读取的内容设置为上次读取的内容\n\t\tlastContent = content;\n\n\t}\n\n}\n```\n\n## RandomAccessFile  \n读写随机访问文件 RandomAccessFile除了实现了DataInput和DataOutput接口之外,有效地与IO继承层次结构的其他部分实现了分离.因为它不支持装饰模式,所以不能将其与InputStream和OutputStream子类的任何部分组合起来而且必须假定RandomAccessFile已经被正确的缓冲\n\n用来访问那些保存数据记录的文件的，你就可以用seek( )方法来访问记录，并进行读写了。这些记录的大小不必相同；但是其大小和位置必须是可知的。但是该类仅限于操作文件。\n```java\n// 读取所有的行\ntry (RandomAccessFile r = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < r.length(); i++) {\n\t\tr.read();\t// r.readLine();\n\t}\n} \n\n// 写入数据,第二个参数必须为 \"r\", \"rw\", \"rws\", or \"rwd\"\ntry (RandomAccessFile w = new RandomAccessFile(file, \"rw\")) {\n\tfor (int i = 0; i < 1024 * 1024 * 10; i++)\n\t\tw.writeByte(1);\n}\n\ntry (FileChannel fc = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\")\n\t\t.getChannel();) {\n\t\n\tIntBuffer ib = fc.map(FileChannel.MapMode.READ_WRITE, 0, fc.size())\n\t\t\t.asIntBuffer();\n\t\n\tfor (int i = 1; i < 10000; i++)\n\t\tib.put(ib.get(i - 1));\n\t\n}\n\nRandomAccessFile raf = new RandomAccessFile(new File(\"temp.tmp\"), \"rw\");\nraf.writeInt(1);\n\nfor (int i = 0; i < 2000000; i++) {\n\traf.seek(raf.length() - 4);\n\traf.writeInt(raf.readInt());\n}\n\nraf.close();\n```\n\n## SequenceInputStream \n从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n## StreamTokenizer \n获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n## StringBufferInputStream \n\n\n## StringReader \n\n\n## StringWriter \n\n\n# nio\n\n## Buffer \n\n\n## ByteBuffer \n\n\n## ByteOrder \n\n\n## CharBuffer \n\n\n## DoubleBuffer\n\n\n## FloatBuffer         \n\n\n## IntBuffer          \n\n\n## LongBuffer         \n\n\n## MappedByteBuffer   \n\n\n## ShortBuffer        \n\n\n# nio#channels#Interfaces\n\n## AsynchronousByteChannel \n\n\n## AsynchronousChannel     \n\n\n## ByteChannel     \n\n\n## Channel         \n\n\n## CompletionHandler       \n\n\n## GatheringByteChannel    \n\n\n## InterruptibleChannel    \n\n\n## MulticastChannel        \n\n\n## NetworkChannel          \n\n\n## ReadableByteChannel     \n\n\n## ScatteringByteChannel   \n\n\n## SeekableByteChannel     \n\n\n## WritableByteChannel     \n\n\n# nio#channels#Classes\n\n## AsynchronousChannelGroup\n\n\n## AsynchronousFileChannel \n\n\n## AsynchronousServerSocketChannel\n\n\n## AsynchronousSocketChannel      \n\n\n## Channels          \n\n\n## DatagramChannel     \n\n\n## FileChannel         \n\n\n## FileChannel.MapMode \n\n\n#### FileLock\n锁定文件\n\nByteBuffer.allocate()语句改为ByteBuffer.allocateDirect().用来证实性能之间的差异,但是请注意程序的启动时间是否发生了明显的改变。\n\n修改{@link JGrep}让其使java的nio内存映射文件。\n\nJDK1.4引入了文件加锁机制,它允许我们同步访问某个作为共享资源的文件。不过,竞争同一文件的两个线程可能在不同的Java虚拟机上;或者一个是Java线程,另一个是操作系统中其他的某个本地线程。\n\n文件锁对其他的操作系统进程是可见的,因为Java的文件加锁直接映射到了本地操作系统的加锁工具。通过对FileChannel调用tryLock()或lock(),就可以获得整个文件的FileLock.\n\n(SocketChannel、DatagramChannel和 ServerSocketChannel不需要加锁,因为他们是从单进程实体继承而来;我们通常不在两个进程之间共享网络socket.)\n\ntryLock()是非阻塞式的,它设法获取锁,但是如果不能获得(当其他一些进程已经持有相同的锁,并且不共享时),它将直接从方法调用返回。lock()则是阻塞式的,它要阻塞进程直至锁可以获得,或调用lock()的线程中断,或调用lock()的通道关闭。\n\n使用FileLock.release()可以释放锁。\n\n也可以使用此方法对文件上锁tryLock()或者lock()其中,加锁的区域由size-position决定。第三个参数指定是否是共享锁。\n\n尽管无参数的加锁方法将根据文件尺寸的变化而变化,但是具有固定尺寸的锁不随文件尺寸的变化而变化。如果你获得了某一区域(从position到position+size)上的锁,当文件增大超出position+size时,那么在position+size之外的部分不会被锁定。无参数的加锁方法会对 整个文件进行加锁,甚至文件变大后也是如此。\n\n对独占锁或者共享锁的支持必须由底层的操作系统提供。如果操作系统不支持共享锁并为每一个请求都创建一个锁,那么它就会使用独占锁。\n\n锁的 类型(共享或独占)可以通过FileLock.isShared()进行查询。\n```java\nFileOutputStream fos = new FileOutputStream(\"file.txt\");\nFileLock fl = fos.getChannel().tryLock();\nif (fl != null) {\n\tSystem.out.println(\"Locked File\");\n\tTimeUnit.MILLISECONDS.sleep(100);\n\tfl.release();\n\tSystem.out.println(\"Released Lock\");\n}\nfos.close()\n```\n\n## MembershipKey     \n\n\n## Pipe          \n\n\n## SelectableChannel \n\n\n## SelectionKey      \n\n\n## Selector          \n\n\n## ServerSocketChannel          \nServerSocketChannel 只有一个用途--接受入站连接 它是无法读取,写入或者连接的\n\n## SocketChannel       \n\n\n# nio#file#Interfaces\n\n## CopyOption          \n\n\n## DirectoryStream     \n遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n\n## FileVisitor          FileVisitor \n\n\n## OpenOption          OpenOption \n\n\n## Path          \nPath 类可以在任何文件系统（FileSystem）和任何存储空间 Path 类引用默认文件系统（计算机的文件系统）的文件，但是 NIO.2是完全模块化的—— FileSystem 的具体实现是在内存中的一组数据，因此在网络环境或在虚拟文件系统中，NIO.2 也完全适用。NIO.2提供给我们在文件系统中操作文件、文件夹或链接的所有方法\n\n## PathMatcher          \n\n\n## SecureDirectoryStream\n\n\n## Watchable        \n\n\n## WatchEvent       \n\n\n## WatchEvent.Kind      \n\n\n## WatchEvent.Modifier  \n\n\n## WatchKey    \n\n\n## WatchService\n\n\n# nio#file#Classes\n\n## Files \n\n1. copy\n2. createDirectories\n3. createDirectory\n4. createFile\n5. createLink\n6. createSymbolicLink\n7. createTempDirectory\n8. createTempFile\n9. delete\n10. deleteIfExists\n11. exists\n12. getAttribute\n13. getFileAttributeView\n14. getFileStore\n15. getLastModifiedTime\n16. getOwner\n17. getPosixFilePermissions\n18. isDirectory\n19. isExecutable\n20. isHidden\n21. isReadable\n22. isRegularFile\n23. isSameFile\n24. isSymbolicLink\n25. isWritable\n26. move\n27. newBufferedReader\n28. newBufferedWriter\n29. newByteChannel\n30. newDirectoryStream\n31. newInputStream\n32. newOutputStream\n33. notExists\n34. probeContentType\n35. readAllBytes\n36. readAllLines\n37. readAttributes\n38. readSymbolicLink\n39. setAttribute\n40. setLastModifiedTime\n41. setOwner\n42. setPosixFilePermissions\n43. walkFileTree\n44. write\n\n\n## FileStore \n代表了真正的存储设备，提供了设备的详尽信息\n\n## FileSystem         \n\n\n## FileSystems        \n```java\n// 返回 JVM 默认的 FileSystem – 一般说来，也就是操作系统的默认文件系统\nFileSystems.getDefault();\n// 可以获取远程主机的FileSystem\nFileSystems.getFileSystem(uri);\n// 得到文件系统支持的属性视图列表\nFileSystem system = FileSystems.getDefault();\nSet<String> views = system.supportedFileAttributeViews();\n```\n\n## LinkPermission          \n\n\n## Paths          \n\n\n## SimpleFileVisitor          \n与DirectoryStream 不同的是，这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n\n## StandardWatchEventKinds\n\n\n# nio#charset\n\n## Charset          \n\n\n## CharsetDecoder         \n\n\n## CharsetEncoder         \n\n\n## CoderResult          \n\n\n## CodingErrorAction      \n\n\n## StandardCharsets       \n\n\n\n\n\n","slug":"java基础/java io","published":1,"updated":"2015-10-16T02:42:55.618Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtp00320cuflw29dprm"},{"date":"2014-09-07T16:00:00.000Z","title":"java网络","_content":"# Java里使用的是TCP/IP\n* 应用层协议：(例如Http协议) 该层数据由下三层协议共同制定\n* 传输层协议：(常用TCP,UDP)(ICMP Ping命令基于该协议). 该层协议用于确保数据报以发送时的顺序接受,并且不会丢包. 如果发现顺序有误,或者数据丢失,则可要求对方重新发送数据(TCP会要求这一点, 但是UDP协议只是检查数据发送顺序,以及数据是否丢失并不要求对方重传数据)\n* 网络层协议：(使用最广泛的是IP协议)\n> 网络层第一任务是对数据位或者字节进行分组,打成包(包内数据称为数据报).网络层第二任务定义了主机彼此间的寻址方式(例如IPV4用四个字节来标识一个地址).在JAVA里,IP协议是它唯一理解的网络层协议.\n\n## IP数据报格式.\n链路层协议：定义了网络接口(以太网接口或者环牌接口)\n\n谈一下Internet地址分类 (具体定义参考 WIKI IP地址), IP地址分为A,B,C,D,E,F类 (E,F分别作为广播地址这里不说了)\n* A类地址 第一个字节固定\n* B类地址 前俩个地址固定\n* C类地址 前三个地址固定\n这里所说的固定指的是ISP给你的时候就固定了,你只能使用固定之后几位的地址.例如给了你一个C类地址 那么你只有256个地址可以使用.\n\n后来为了节约地址,出现了CIDR  用/nn 指定前几位为固定的.例如/24 为前24位即前三个字节是固定的也就是一个c类地址.这么着就拟补了有的组织使用的IP大于c类却远远小于B类而造成的地址浪费.\n\n在这里需要特殊说明的是有一些非路由地址,例如10; 192.16或者172.16到172.31 开头的地址.这些地址用于构建组织内部网路(例如家里只有一个IP但是却有很多设备,这时就需要通过路由为这些设备分配IP地址了),或者一些大型组织使用C类地址时非常有用\n路由器会将非路由地址转换为外部地址\n\n# URI\n```\nscheme:scheme-specific-part (模式:模式特有部分)\n```\n## 模式\n模式包含 data, file, ftp, http, news, telnet, urn (还有基于JAVA的rmi, jndi 等非标准模式,也称为protocol)\n例如：`http://www.ming15.wang/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`这个例子中模式为`http`, 负责解析该URI的机构`ming15.wang` 负责将`/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`地址映射到主机资源\n\n还有的URI路径中含有? 这是URI的查询部分.后面紧跟查询参数,多个参数用&分割. 例如：`git@github.com:ming15/VertxServer.git`该URI中模式为`git` 解析结构为`github.com` 还可以在git和@之间加上用户名和密码`git://username:password@github.com:ming15/VertxServer.git`\n\nURI一般由以下组成\n* 模式 \n* URI解析结构 \n* 资源路径 \n* 查询参数构成\n\n\n## URI分为类\n1. URL ： 指向Internet上某个位置的某个文件.用于标识Internet上的资源位置. 指定访问服务器的协议, 服务器名, 文件在次服务器上的位置`protocol://username@hostname:port/path/filename?query#fragment`协议可以看成是模式但是它不包含URN.\n2. URN ：不指向位置的资源名.  (具体的内容参考例子磁力链接)`urn:namespace:resource_name`. `namespace`:某个授权机构维护的某类资源的集合名.  `resource_name` 集合中的资源名\n\n\n这里简述一下相对URL. 举例来说<a href=\"java.html\"> 这个超链接会继承父文档(当前文档)的协议, 主机名, 资源路径.java.html会替换掉,父文档里最后的文件名,还有例如<a href=\"/demo/java.html\"> 那这个超链接会将主机名后的资源路径一起换掉 ，用该路径替换\n\n# Java网卡信息获取\n网络接口的命名\n* eth0: ethernet的简写，一般用于以太网接口。\n* wifi0:wifi是无线局域网，因此wifi0一般指无线网络接口。\n* ath0: Atheros的简写，一般指Atheros芯片所包含的无线网络接口。\n*　lo: local的简写，一般指本地环回接口。\n\nlo: 虚拟网络接口,其并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序.硬件网卡的网络接口由驱动程序创建。而虚拟的网络接口由系统创建或通过应用层程序创建。假如包是由一个本地进程为另一个本地进程产生的, 它们将通过外出链的’lo’接口,然后返回进入链的’lo’接口\n\n```java\n\nimport java.net.Inet4Address;\nimport java.net.InetAddress;\nimport java.net.NetworkInterface;\nimport java.util.Enumeration;\n\npublic class PrintNet {\n\n\n\tpublic static void main() throws Exception {\n\t\t// 获取全部的网络接口(由操作系统设置,每个硬件网卡(一个MAC)对应一个网络接口)\n\t\tEnumeration<?> nets = NetworkInterface.getNetworkInterfaces();\n\t\twhile (nets.hasMoreElements()) {\n\t\t\tNetworkInterface net = (NetworkInterface) nets.nextElement();\n\t\t\tprintNetworkInterface(net);\n\t\t\tEnumeration<?> addresses = net.getInetAddresses();  // 返回该接口中所有绑定的ip\n\t\t\tSystem.out.println(\"该接口下所有的ip:\");\n\t\t\twhile (addresses.hasMoreElements()) {\n\t\t\t\tInetAddress ip = (InetAddress) addresses.nextElement();\n                pickUpHosyAddress(ip);\n\t\t\t\tprintInetAddress(ip);\n\t\t\t}\n\t\t\tSystem.out.println();\n\t\t\tSystem.out.println();\n\t\t}\n\t}\n\n\tprivate static void printNetworkInterface(NetworkInterface net) throws Exception{\n\t\tSystem.out.println(\"网络接口的显示名称   :\" + net.getDisplayName());\n\t\tSystem.out.println(\"网络接口的名称       :\" + net.getName());\n\t\tSystem.out.println(\"idx                \t:\" + net.getIndex());\n\t\tSystem.out.println(\"最大传输单元         :\" + net.getMTU());\n\t\tSystem.out.println(\"mac地址              :\" + displayMac(net.getHardwareAddress()));\n\t\tSystem.out.println(\"是否是回送接口       :\" + net.isLoopback());\n\t\tSystem.out.println(\"是否是点对点接口     :\" + net.isPointToPoint());\n\t\tSystem.out.println(\"是否已经开启并运行   :\" + net.isUp());\n\t}\n\n\t/**\n\t * 输出ip地址\n\t * @param ip\n\t */\n\tprivate static void pickUpHosyAddress(InetAddress ip) {\n\t\tif (!ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"外网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"内网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip != null && !ip.isLoopbackAddress() && ip instanceof Inet4Address) {\n\t\t\tSystem.out.println(\"HostAddress        :\" + ip.getHostAddress());\n\t\t}\n\t}\n\n\t/**\n\t * 打印InetAddress 相关信息\n\t * @param ip\n\t * @throws Exception\n\t */\n\tprivate static void printInetAddress(InetAddress ip) throws Exception{\n\t\tSystem.out.println(\"远程主机的主机名         :\" + ip.getCanonicalHostName());\n\t\tSystem.out.println(\"主机地址                 :\" + ip.getHostAddress());\n\t\tSystem.out.println(\"远程主机的别名           :\" + ip.getHostName());\n\t\tSystem.out.println(\"mac Address             :\" + displayMac(ip.getAddress()));\n\t\tSystem.out.println(\"本机主机名               :\" + ip.getLocalHost().getHostName());\n\t\tSystem.out.println(\"回环地址 主机名          :\" + ip.getLoopbackAddress().getHostName());\n\t\t// (127.0.0.0 ~ 127.255.255.255)\n\t\tSystem.out.println(\"是否是本机的IP地址       :\" + ip.isLoopbackAddress());\n\t\t//(10.0.0.0 ~ 10.255.255.255)(172.16.0.0 ~ 172.31.255.255)(192.168.0.0 ~ 192.168.255.255)\n\t\tSystem.out.println(\"是否是地区本地地址       :\" + ip.isSiteLocalAddress());\n\t\t// 允许服务器主机接受来自任何网络接口的客户端连接\n\t\tSystem.out.println(\"是否是通配符地址         :\" + ip.isAnyLocalAddress());\n\t\t// (169.254.0.0 ~ 169.254.255.255)\n\t\tSystem.out.println(\"是否是本地连接地址       :\" + ip.isLinkLocalAddress());\n\t\t// (224.0.0.0 ~ 239.255.255.255)广播地址可以向网络中的所有计算机发送信息\n\t\tSystem.out.println(\"是否是 广播地址           :\" + ip.isMulticastAddress());\n\t\t//  除了(224.0.0.0)和第一个字节是239的IP地址都是全球范围的广播地址\n\t\tSystem.out.println(\"是否是全球范围的广播地址:\" + ip.isMCGlobal());\n\t\t// (224.0.0.0 ~ 224.0.0.255)\n\t\tSystem.out.println(\"是否是子网广播地址         :\" + ip.isMCLinkLocal());\n\t\t// 本地接口广播地址不能将广播信息发送到产生广播信息的网络接口\n\t\t// 所有的IPv4广播地址都不是本地接口广播地址。\n\t\tSystem.out.println(\"是否是本地接口广播地址      :\" + ip.isMCNodeLocal());\n\t\t// 可以向公司或企业内部的所有的计算机发送广播信息\n\t\t// IPv4的组织范围广播地址的第一个字节是239，第二个字节不小于192，第三个字节不大于195\n\t\tSystem.out.println(\"是否是组织范围的广播地址:\" + ip.isMCOrgLocal());\n\t}\n\n\tprivate static String displayMac(byte[] mac) {\n\t\tif (mac == null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tStringBuilder bufferBuilder = new StringBuilder();\n\t\tfor (int i = 0; i < mac.length; i++) {\n\t\t\tbyte b = mac[i];\n\t\t\tint intValue = 0;\n\t\t\tif (b >= 0)\n\t\t\t\tintValue = b;\n\t\t\telse\n\t\t\t\tintValue = 256 + b;\n\t\t\tbufferBuilder.append(Integer.toHexString(intValue));\n\n\t\t\tif (i != mac.length - 1)\n\t\t\t\tbufferBuilder.append(\"-\");\n\t\t}\n\t\treturn bufferBuilder.toString();\n\t}\n}\n\n```","source":"_posts/java基础/Java网络.md","raw":"category: java基础\ndate: 2014-09-08\ntitle: java网络\n---\n# Java里使用的是TCP/IP\n* 应用层协议：(例如Http协议) 该层数据由下三层协议共同制定\n* 传输层协议：(常用TCP,UDP)(ICMP Ping命令基于该协议). 该层协议用于确保数据报以发送时的顺序接受,并且不会丢包. 如果发现顺序有误,或者数据丢失,则可要求对方重新发送数据(TCP会要求这一点, 但是UDP协议只是检查数据发送顺序,以及数据是否丢失并不要求对方重传数据)\n* 网络层协议：(使用最广泛的是IP协议)\n> 网络层第一任务是对数据位或者字节进行分组,打成包(包内数据称为数据报).网络层第二任务定义了主机彼此间的寻址方式(例如IPV4用四个字节来标识一个地址).在JAVA里,IP协议是它唯一理解的网络层协议.\n\n## IP数据报格式.\n链路层协议：定义了网络接口(以太网接口或者环牌接口)\n\n谈一下Internet地址分类 (具体定义参考 WIKI IP地址), IP地址分为A,B,C,D,E,F类 (E,F分别作为广播地址这里不说了)\n* A类地址 第一个字节固定\n* B类地址 前俩个地址固定\n* C类地址 前三个地址固定\n这里所说的固定指的是ISP给你的时候就固定了,你只能使用固定之后几位的地址.例如给了你一个C类地址 那么你只有256个地址可以使用.\n\n后来为了节约地址,出现了CIDR  用/nn 指定前几位为固定的.例如/24 为前24位即前三个字节是固定的也就是一个c类地址.这么着就拟补了有的组织使用的IP大于c类却远远小于B类而造成的地址浪费.\n\n在这里需要特殊说明的是有一些非路由地址,例如10; 192.16或者172.16到172.31 开头的地址.这些地址用于构建组织内部网路(例如家里只有一个IP但是却有很多设备,这时就需要通过路由为这些设备分配IP地址了),或者一些大型组织使用C类地址时非常有用\n路由器会将非路由地址转换为外部地址\n\n# URI\n```\nscheme:scheme-specific-part (模式:模式特有部分)\n```\n## 模式\n模式包含 data, file, ftp, http, news, telnet, urn (还有基于JAVA的rmi, jndi 等非标准模式,也称为protocol)\n例如：`http://www.ming15.wang/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`这个例子中模式为`http`, 负责解析该URI的机构`ming15.wang` 负责将`/2015/10/13/%E5%B7%A5%E5%85%B7/2015-10-12-AWK/`地址映射到主机资源\n\n还有的URI路径中含有? 这是URI的查询部分.后面紧跟查询参数,多个参数用&分割. 例如：`git@github.com:ming15/VertxServer.git`该URI中模式为`git` 解析结构为`github.com` 还可以在git和@之间加上用户名和密码`git://username:password@github.com:ming15/VertxServer.git`\n\nURI一般由以下组成\n* 模式 \n* URI解析结构 \n* 资源路径 \n* 查询参数构成\n\n\n## URI分为类\n1. URL ： 指向Internet上某个位置的某个文件.用于标识Internet上的资源位置. 指定访问服务器的协议, 服务器名, 文件在次服务器上的位置`protocol://username@hostname:port/path/filename?query#fragment`协议可以看成是模式但是它不包含URN.\n2. URN ：不指向位置的资源名.  (具体的内容参考例子磁力链接)`urn:namespace:resource_name`. `namespace`:某个授权机构维护的某类资源的集合名.  `resource_name` 集合中的资源名\n\n\n这里简述一下相对URL. 举例来说<a href=\"java.html\"> 这个超链接会继承父文档(当前文档)的协议, 主机名, 资源路径.java.html会替换掉,父文档里最后的文件名,还有例如<a href=\"/demo/java.html\"> 那这个超链接会将主机名后的资源路径一起换掉 ，用该路径替换\n\n# Java网卡信息获取\n网络接口的命名\n* eth0: ethernet的简写，一般用于以太网接口。\n* wifi0:wifi是无线局域网，因此wifi0一般指无线网络接口。\n* ath0: Atheros的简写，一般指Atheros芯片所包含的无线网络接口。\n*　lo: local的简写，一般指本地环回接口。\n\nlo: 虚拟网络接口,其并不真实地从外界接收和发送数据包，而是在系统内部接收和发送数据包，因此虚拟网络接口不需要驱动程序.硬件网卡的网络接口由驱动程序创建。而虚拟的网络接口由系统创建或通过应用层程序创建。假如包是由一个本地进程为另一个本地进程产生的, 它们将通过外出链的’lo’接口,然后返回进入链的’lo’接口\n\n```java\n\nimport java.net.Inet4Address;\nimport java.net.InetAddress;\nimport java.net.NetworkInterface;\nimport java.util.Enumeration;\n\npublic class PrintNet {\n\n\n\tpublic static void main() throws Exception {\n\t\t// 获取全部的网络接口(由操作系统设置,每个硬件网卡(一个MAC)对应一个网络接口)\n\t\tEnumeration<?> nets = NetworkInterface.getNetworkInterfaces();\n\t\twhile (nets.hasMoreElements()) {\n\t\t\tNetworkInterface net = (NetworkInterface) nets.nextElement();\n\t\t\tprintNetworkInterface(net);\n\t\t\tEnumeration<?> addresses = net.getInetAddresses();  // 返回该接口中所有绑定的ip\n\t\t\tSystem.out.println(\"该接口下所有的ip:\");\n\t\t\twhile (addresses.hasMoreElements()) {\n\t\t\t\tInetAddress ip = (InetAddress) addresses.nextElement();\n                pickUpHosyAddress(ip);\n\t\t\t\tprintInetAddress(ip);\n\t\t\t}\n\t\t\tSystem.out.println();\n\t\t\tSystem.out.println();\n\t\t}\n\t}\n\n\tprivate static void printNetworkInterface(NetworkInterface net) throws Exception{\n\t\tSystem.out.println(\"网络接口的显示名称   :\" + net.getDisplayName());\n\t\tSystem.out.println(\"网络接口的名称       :\" + net.getName());\n\t\tSystem.out.println(\"idx                \t:\" + net.getIndex());\n\t\tSystem.out.println(\"最大传输单元         :\" + net.getMTU());\n\t\tSystem.out.println(\"mac地址              :\" + displayMac(net.getHardwareAddress()));\n\t\tSystem.out.println(\"是否是回送接口       :\" + net.isLoopback());\n\t\tSystem.out.println(\"是否是点对点接口     :\" + net.isPointToPoint());\n\t\tSystem.out.println(\"是否已经开启并运行   :\" + net.isUp());\n\t}\n\n\t/**\n\t * 输出ip地址\n\t * @param ip\n\t */\n\tprivate static void pickUpHosyAddress(InetAddress ip) {\n\t\tif (!ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"外网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip.isLoopbackAddress() && !ip.isSiteLocalAddress() && ip.getHostAddress().indexOf(\":\") == -1) {\n\t\t\tSystem.out.println(\"内网 HostAddress   :\" + ip.getHostAddress());\n\t\t}\n\t\tif (ip != null && !ip.isLoopbackAddress() && ip instanceof Inet4Address) {\n\t\t\tSystem.out.println(\"HostAddress        :\" + ip.getHostAddress());\n\t\t}\n\t}\n\n\t/**\n\t * 打印InetAddress 相关信息\n\t * @param ip\n\t * @throws Exception\n\t */\n\tprivate static void printInetAddress(InetAddress ip) throws Exception{\n\t\tSystem.out.println(\"远程主机的主机名         :\" + ip.getCanonicalHostName());\n\t\tSystem.out.println(\"主机地址                 :\" + ip.getHostAddress());\n\t\tSystem.out.println(\"远程主机的别名           :\" + ip.getHostName());\n\t\tSystem.out.println(\"mac Address             :\" + displayMac(ip.getAddress()));\n\t\tSystem.out.println(\"本机主机名               :\" + ip.getLocalHost().getHostName());\n\t\tSystem.out.println(\"回环地址 主机名          :\" + ip.getLoopbackAddress().getHostName());\n\t\t// (127.0.0.0 ~ 127.255.255.255)\n\t\tSystem.out.println(\"是否是本机的IP地址       :\" + ip.isLoopbackAddress());\n\t\t//(10.0.0.0 ~ 10.255.255.255)(172.16.0.0 ~ 172.31.255.255)(192.168.0.0 ~ 192.168.255.255)\n\t\tSystem.out.println(\"是否是地区本地地址       :\" + ip.isSiteLocalAddress());\n\t\t// 允许服务器主机接受来自任何网络接口的客户端连接\n\t\tSystem.out.println(\"是否是通配符地址         :\" + ip.isAnyLocalAddress());\n\t\t// (169.254.0.0 ~ 169.254.255.255)\n\t\tSystem.out.println(\"是否是本地连接地址       :\" + ip.isLinkLocalAddress());\n\t\t// (224.0.0.0 ~ 239.255.255.255)广播地址可以向网络中的所有计算机发送信息\n\t\tSystem.out.println(\"是否是 广播地址           :\" + ip.isMulticastAddress());\n\t\t//  除了(224.0.0.0)和第一个字节是239的IP地址都是全球范围的广播地址\n\t\tSystem.out.println(\"是否是全球范围的广播地址:\" + ip.isMCGlobal());\n\t\t// (224.0.0.0 ~ 224.0.0.255)\n\t\tSystem.out.println(\"是否是子网广播地址         :\" + ip.isMCLinkLocal());\n\t\t// 本地接口广播地址不能将广播信息发送到产生广播信息的网络接口\n\t\t// 所有的IPv4广播地址都不是本地接口广播地址。\n\t\tSystem.out.println(\"是否是本地接口广播地址      :\" + ip.isMCNodeLocal());\n\t\t// 可以向公司或企业内部的所有的计算机发送广播信息\n\t\t// IPv4的组织范围广播地址的第一个字节是239，第二个字节不小于192，第三个字节不大于195\n\t\tSystem.out.println(\"是否是组织范围的广播地址:\" + ip.isMCOrgLocal());\n\t}\n\n\tprivate static String displayMac(byte[] mac) {\n\t\tif (mac == null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tStringBuilder bufferBuilder = new StringBuilder();\n\t\tfor (int i = 0; i < mac.length; i++) {\n\t\t\tbyte b = mac[i];\n\t\t\tint intValue = 0;\n\t\t\tif (b >= 0)\n\t\t\t\tintValue = b;\n\t\t\telse\n\t\t\t\tintValue = 256 + b;\n\t\t\tbufferBuilder.append(Integer.toHexString(intValue));\n\n\t\t\tif (i != mac.length - 1)\n\t\t\t\tbufferBuilder.append(\"-\");\n\t\t}\n\t\treturn bufferBuilder.toString();\n\t}\n}\n\n```","slug":"java基础/Java网络","published":1,"updated":"2015-10-20T01:47:13.987Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtr00340cufunf4lckz"},{"date":"2014-11-07T16:00:00.000Z","title":"非对称加密","_content":"# 非对称密码\n\n非对称密码与对称密码体制相对,他们的主要区别在于：非对称密码体制的加密密钥和解密密钥不相同,分为俩个密钥,一个公开(公钥),一个保密(密钥).\n\n![非对称密码体制的保密通信模型]()\n\n在非对称密码体制中,公玥与私钥均可用于加密与解密操作,但它与对称密码体制有极大的不同. 公玥与私钥分属通信双方,一份消息的加密与解密需要公玥和私钥共同参与. 公玥加密需要私钥解密, 反之, 私钥加密需要公玥解密.\n\n![公玥加密-私钥解密的保密通信模型]()\n\n非对称密码的体制的主要优点是可以适应于开放性的使用环境, 秘钥管理相对简单, 可以方便安全地实现数字签名和验证. RSA是非对称密码体制的典范,它不仅仅可以完成一般的数据加密操作,同时也支持数字签名和验证. 除了数字签名非对称密码体制还支持数字信封等技术.\n\n非对称密码算法的安全性完全依赖于基于计算机复杂度上的难题,通常来自于数论.例如：\n* RSA来源于整数因子分解问题.\n* DSA-数字签名算法源于离散对数问题.\n* ECC-椭圆曲线加密算法源于离散对数问题.\n由于这些数学难题的实现多涉及底层模数乘法和指数运算,相比分组密码需要更多的计算机资源, 为了尼补这一缺陷, 非对称密码系统通常是复合式的:用高效率的对称密码算法进行加密解密处理; 用非对称密钥加密对称密码系统所使用的密钥, 通过这种复合方式增进效率.\n\n# RSACoder\n\n```java\n/**\n * RSA安全编码组件\n * \n */\npublic enum RSACoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 \n\t * 默认1024位，\n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 私钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ElGamalCoder\n\n```java\n\n/**\n * ElGamal安全编码组件\n * \n */\npublic enum ElGamalCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"ElGamal\";\n\n\t/**\n\t * 密钥长度\n\t * \n\t * ElGamal算法默认密钥长度为1024 \n\t * 密钥长度范围在160位至16,384位不等。\n\t */\n\tprivate static final int KEY_SIZE = 256;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"ElGamalPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"ElGamalPrivateKey\";\n\n\t/**\n\t * 用私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 私钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 用公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 公钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化算法参数生成器\n\t\tAlgorithmParameterGenerator apg = AlgorithmParameterGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化算法参数生成器\n\t\tapg.init(KEY_SIZE);\n\n\t\t// 生成算法参数\n\t\tAlgorithmParameters params = apg.generateParameters();\n\n\t\t// 构建参数材料\n\t\tDHParameterSpec elParams = (DHParameterSpec) params.getParameterSpec(DHParameterSpec.class);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(elParams, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keys = kpg.genKeyPair();\n\n\t\t// 取得密钥\n\t\tPublicKey publicKey = keys.getPublic();\n\n\t\tPrivateKey privateKey = keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```\n\n# DHCoder\n\n```java\n\n/**\n * DH安全编码组件\n * \n */\npublic enum DHCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"DH\";\n\n\t/**\n\t * 本地密钥算法，即对称加密密钥算法，可选DES、DESede和AES算法\n\t */\n\tprivate static final String SECRET_KEY_ALGORITHM = \"AES\";\n\n\t/**\n\t * 默认密钥长度\n\t * \n\t * DH算法默认密钥长度为1024 密钥长度必须是64的倍数，其范围在512到1024位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DHPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DHPrivateKey\";\n\n\t/**\n\t * 初始化甲方密钥\n\t * \n\t * @return Map 甲方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGenerator.generateKeyPair();\n\n\t\t// 甲方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 甲方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 初始化乙方密钥\n\t * \n\t * @param key\n\t *            甲方公钥\n\t * @return Map 乙方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey(byte[] key) throws Exception {\n\n\t\t// 解析甲方公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 由甲方公钥构建乙方密钥\n\t\tDHParameterSpec dhParamSpec = ((DHPublicKey) pubKey).getParams();\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(keyFactory.getAlgorithm());\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(dhParamSpec);\n\n\t\t// 产生密钥对\n\t\tKeyPair keyPair = keyPairGenerator.genKeyPair();\n\n\t\t// 乙方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 乙方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据加密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 解密<br>\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据解密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 构建密钥\n\t * \n\t * @param publicKey\n\t *            公钥\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 本地密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getSecretKey(byte[] publicKey, byte[] privateKey)\n\t\t\tthrows Exception {\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化公钥\n\t\t// 密钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 初始化私钥\n\t\t// 密钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 产生私钥\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化\n\t\tKeyAgreement keyAgree = KeyAgreement.getInstance(keyFactory\n\t\t\t\t.getAlgorithm());\n\n\t\t// 初始化\n\t\tkeyAgree.init(priKey);\n\n\t\tkeyAgree.doPhase(pubKey, true);\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = keyAgree.generateSecret(SECRET_KEY_ALGORITHM);\n\n\t\treturn secretKey.getEncoded();\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","source":"_posts/java加密解密/非对称加密实现.md","raw":"category: java加密解密\ndate: 2014-11-08\ntitle: 非对称加密\n---\n# 非对称密码\n\n非对称密码与对称密码体制相对,他们的主要区别在于：非对称密码体制的加密密钥和解密密钥不相同,分为俩个密钥,一个公开(公钥),一个保密(密钥).\n\n![非对称密码体制的保密通信模型]()\n\n在非对称密码体制中,公玥与私钥均可用于加密与解密操作,但它与对称密码体制有极大的不同. 公玥与私钥分属通信双方,一份消息的加密与解密需要公玥和私钥共同参与. 公玥加密需要私钥解密, 反之, 私钥加密需要公玥解密.\n\n![公玥加密-私钥解密的保密通信模型]()\n\n非对称密码的体制的主要优点是可以适应于开放性的使用环境, 秘钥管理相对简单, 可以方便安全地实现数字签名和验证. RSA是非对称密码体制的典范,它不仅仅可以完成一般的数据加密操作,同时也支持数字签名和验证. 除了数字签名非对称密码体制还支持数字信封等技术.\n\n非对称密码算法的安全性完全依赖于基于计算机复杂度上的难题,通常来自于数论.例如：\n* RSA来源于整数因子分解问题.\n* DSA-数字签名算法源于离散对数问题.\n* ECC-椭圆曲线加密算法源于离散对数问题.\n由于这些数学难题的实现多涉及底层模数乘法和指数运算,相比分组密码需要更多的计算机资源, 为了尼补这一缺陷, 非对称密码系统通常是复合式的:用高效率的对称密码算法进行加密解密处理; 用非对称密钥加密对称密码系统所使用的密钥, 通过这种复合方式增进效率.\n\n# RSACoder\n\n```java\n/**\n * RSA安全编码组件\n * \n */\npublic enum RSACoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 \n\t * 默认1024位，\n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得公钥\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\tPublicKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 私钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 取得私钥\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tPrivateKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ElGamalCoder\n\n```java\n\n/**\n * ElGamal安全编码组件\n * \n */\npublic enum ElGamalCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"ElGamal\";\n\n\t/**\n\t * 密钥长度\n\t * \n\t * ElGamal算法默认密钥长度为1024 \n\t * 密钥长度范围在160位至16,384位不等。\n\t */\n\tprivate static final int KEY_SIZE = 256;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"ElGamalPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"ElGamalPrivateKey\";\n\n\t/**\n\t * 用私钥解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            私钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decryptByPrivateKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 私钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成私钥\n\t\tKey privateKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 对数据解密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, privateKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 用公钥加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            公钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encryptByPublicKey(byte[] data, byte[] key)\n\t\t\tthrows Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 公钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tKey publicKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 对数据加密\n\t\tCipher cipher = Cipher.getInstance(keyFactory.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, publicKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化算法参数生成器\n\t\tAlgorithmParameterGenerator apg = AlgorithmParameterGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化算法参数生成器\n\t\tapg.init(KEY_SIZE);\n\n\t\t// 生成算法参数\n\t\tAlgorithmParameters params = apg.generateParameters();\n\n\t\t// 构建参数材料\n\t\tDHParameterSpec elParams = (DHParameterSpec) params.getParameterSpec(DHParameterSpec.class);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(elParams, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keys = kpg.genKeyPair();\n\n\t\t// 取得密钥\n\t\tPublicKey publicKey = keys.getPublic();\n\n\t\tPrivateKey privateKey = keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```\n\n# DHCoder\n\n```java\n\n/**\n * DH安全编码组件\n * \n */\npublic enum DHCoder {\n\n\tINSTANCE;\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 非对称加密密钥算法\n\t */\n\tprivate static final String KEY_ALGORITHM = \"DH\";\n\n\t/**\n\t * 本地密钥算法，即对称加密密钥算法，可选DES、DESede和AES算法\n\t */\n\tprivate static final String SECRET_KEY_ALGORITHM = \"AES\";\n\n\t/**\n\t * 默认密钥长度\n\t * \n\t * DH算法默认密钥长度为1024 密钥长度必须是64的倍数，其范围在512到1024位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DHPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DHPrivateKey\";\n\n\t/**\n\t * 初始化甲方密钥\n\t * \n\t * @return Map 甲方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对\n\t\tKeyPair keyPair = keyPairGenerator.generateKeyPair();\n\n\t\t// 甲方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 甲方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 初始化乙方密钥\n\t * \n\t * @param key\n\t *            甲方公钥\n\t * @return Map 乙方密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey(byte[] key) throws Exception {\n\n\t\t// 解析甲方公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(key);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 由甲方公钥构建乙方密钥\n\t\tDHParameterSpec dhParamSpec = ((DHPublicKey) pubKey).getParams();\n\n\t\t// 实例化密钥对生成器\n\t\tKeyPairGenerator keyPairGenerator = KeyPairGenerator\n\t\t\t\t.getInstance(keyFactory.getAlgorithm());\n\n\t\t// 初始化密钥对生成器\n\t\tkeyPairGenerator.initialize(dhParamSpec);\n\n\t\t// 产生密钥对\n\t\tKeyPair keyPair = keyPairGenerator.genKeyPair();\n\n\t\t// 乙方公钥\n\t\tDHPublicKey publicKey = (DHPublicKey) keyPair.getPublic();\n\n\t\t// 乙方私钥\n\t\tDHPrivateKey privateKey = (DHPrivateKey) keyPair.getPrivate();\n\n\t\t// 将密钥对存储在Map中\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据加密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.ENCRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 解密<br>\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, SECRET_KEY_ALGORITHM);\n\n\t\t// 数据解密\n\t\tCipher cipher = Cipher.getInstance(secretKey.getAlgorithm());\n\n\t\tcipher.init(Cipher.DECRYPT_MODE, secretKey);\n\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 构建密钥\n\t * \n\t * @param publicKey\n\t *            公钥\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 本地密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getSecretKey(byte[] publicKey, byte[] privateKey)\n\t\t\tthrows Exception {\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化公钥\n\t\t// 密钥材料转换\n\t\tX509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 产生公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(x509KeySpec);\n\n\t\t// 初始化私钥\n\t\t// 密钥材料转换\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 产生私钥\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化\n\t\tKeyAgreement keyAgree = KeyAgreement.getInstance(keyFactory\n\t\t\t\t.getAlgorithm());\n\n\t\t// 初始化\n\t\tkeyAgree.init(priKey);\n\n\t\tkeyAgree.doPhase(pubKey, true);\n\n\t\t// 生成本地密钥\n\t\tSecretKey secretKey = keyAgree.generateSecret(SECRET_KEY_ALGORITHM);\n\n\t\treturn secretKey.getEncoded();\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","slug":"java加密解密/非对称加密实现","published":1,"updated":"2015-10-16T02:41:52.462Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtt00360cufa56ya0ff"},{"date":"2014-11-07T16:00:00.000Z","title":"辅助工具","_content":"## Bouncy Castle\n在[官网](http://www.bouncycastle.org/latest_releases.html) 下载 `bcprov-jdk15on-151.jar` 和 `bcprov-ext-jdk15on-151.jar`\n\n对于Bouncy Castle 提供的扩充算法支持,有俩种方案可选\n* 配置方式,通过配置JRE环境,使其作为提供者提供相应的算法支持,在代码实现层面只需指定要扩展的算法名称\n> 1. 修改JDK\n\t修改java.security配置文件(jdk1.7.0_75\\jre\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jdk1.7.0_75\\jre\\lib\\ext\n  2. 修改JRE\n\t修改java.security配置文件(jre7\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jre7\\lib\\ext\n\n* 调用方式 : 直接将`bcprov-ext-jdk15on-151.jar` 导入到项目工程文件\n\nJCE工具将其拓展包：仅包括`org.bouncycastle.jce`包. 这是对JCE框架的支持\n\n\n## Base64\n\nBase64是一种基于64个字符的编码算法,根据RFC 2045的定义：Base64内容传送编码是一种以任意8位字节序列组合的描述形式, 这种形式不易被人直接识别.经过Base64编码后的数据会比原始数据略长,为原来的4/3,经Base64编码后的字符串的字符数是以4为单位的整数倍\n\nBase64算法有编码和解码操作可充当加密和解密操作,还有一张字符映射表充当了秘钥.由于字符映射表公开且Base64加密强度并不高,因此不能将其看作现代加密算法.但是如果将字符映射表调整,保密,改造后的Base64就具备了加密算法的意义而且Base64常作为密钥, 密文 和证书的一种通用存储编码格式\n\n###实现原理\n\n1. 将给定的字符串以字符为单位转换为对应的字符编码(如ASCII码)\n2. 将获得的字符编码转换为二进制码\n3. 对获得的二进制码做分组转换操作,每3个8位二进制码为1组,转换为每4个6位二进制码为1组(不足6位时低位补0)这是一个分组变化的过程, 3个8位二进制码和4个6位二进制码的长度都是24位\n4. 对获得的4个6位二进制码补位,向6位二进制码添加2位 高位0,组成4个8位二进制码\n5. 将获得的4个8位二进制码转换为10进制码\n6. 将获得的十进制码转换为base64字符表中对应的字符\n\n```\n对A进行Base64编码\n字符\t\t\t\tA\nASCII码\t\t\t65\n二进制码\t\t\t01000001\n4-6二进制码\t\t010000\t\t010000\n4-8二进制码\t\t00010000\t00010000\n十进制\t\t\t16\t\t\t16\n字符表映射码\t\tQ\t\t\tQ\t\t\t=\t=\n\n字符A编码之后就变成了QQ==\n\nbase64 映射表\nV E\t\t\t  V E\t\t\tV E\t\t\t  V E\n0 A            17 R            34 i            51 z\n1 B            18 S            35 j            52 0\n2 C            19 T            36 k            53 1\n3 D            20 U            37 l            54 2\n4 E            21 V            38 m            55 3\n5 F            22 W            39 n            56 4\n6 G            23 X            40 o            57 5\n7 H            24 Y            41 p            58 6\n8 I            25 Z            42 q            59 7\n9 J            26 a            43 r            60 8\n10 K           27 b            44 s            61 9\n11 L           28 c            45 t            62 +\n12 M           29 d            46 u            63 /\n13 N           30 e            47 v\n14 O           31 f            48 w         (pad) =\n15 P           32 g            49 x\n16 Q           33 h            50 y\n```\n\n\n### 代码举例\n\n```java\npublic class TestBase64 {\n\n\tstatic final String base64 = \"base64编码!@#$%^&*()+_=-{}[];:'<>,./?|\";\n\t\n\t@before\n\tpublic void before () {\n\t\tSystem.out.println(base64);\n\t}\n\t\n\t@Test\n\tpublic void testUrlBase64() {\n\t\t// 不能编码空格\n\t\tbyte[] encode = UrlBase64.encode(base64.getBytes());\n\t\tSystem.out.println(\"UrlBase64 : \" + new String(encode));\n\t\t\n\t\tbyte[] decode = UrlBase64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\t\n\t@Test\n\tpublic void testJavaBase64() {\n\t\tSystem.out.println();\n\t\tbyte[] encode = java.util.Base64.getEncoder().encode(base64.getBytes());\n\t\tSystem.out.println(\"JavaBase64 : \" + new String(encode));\n\t\tbyte[] decode = java.util.Base64.getDecoder().decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\t\n\t@Test\n\tpublic void testApacheBase64() {\n\t\tString encode = org.apache.commons.codec.binary.Base64.encodeBase64String(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 : \" + encode);\n\t\tbyte[] decode = org.apache.commons.codec.binary.Base64.decodeBase64(encode.getBytes());\n\t\tAssert.assertEquals(base64, new String(decode));\n\t\t\n\t\tString url = org.apache.commons.codec.binary.Base64.encodeBase64URLSafeString(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 url : \" + url);\n\t\tbyte[] decoded = org.apache.commons.codec.binary.Base64.decodeBase64(url);\n\t\tAssert.assertEquals(base64, new String(decoded));\n\t}\n\t\n\t\n\t@Test\n\tpublic void testBouncycastleBase64() {\n\t\tbyte[] encode = org.bouncycastle.util.encoders.Base64.encode(base64.getBytes());\n\t\tSystem.out.println(\"BouncycastleBase64 : \" + new String(encode));\n\t\tbyte[] decode = org.bouncycastle.util.encoders.Base64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\t\n\t\n\t@Test\n\tpublic void testSpace() {\n\t\tString base64 = \"wKOS4FsxiFvE48KGGSuSkRui9Iap1ukgl1+eVqZiGhXQYYiP8KGCV%2FRIeTEyMLsWxE%2FEx6jhuW3DPUt4JYX+cohUOqFVVaQ%2FioGZCAge3ygaCz%2Fe4q8o9XQzOEtcdXPywGZ0e5sgE787ij4dRZy2ILK2cxsVvC8yrlIPGZ3LUg8nOj8oEg5l2AnQnA3i+Sxbgqmwe1OjIXVZqPZWb+Y4SVQL8EpWlmEjXb4HjgmGTgVYzwJ64QO7HUPP1yuQHkS0PLS%2FpbPrgL5vqTF7h%2FPvMw=%3D\"; \n\t\tString decoded = URLDecoder.decode(base64);\n\t\tSystem.out.println(decoded);\n\t\tbyte[] decode = UrlBase64.decode(base64);\n\t\tSystem.out.println(new String(decode));\n\t}\n}\n\n```","source":"_posts/java加密解密/辅助工具.md","raw":"category: java加密解密\ndate: 2014-11-08\ntitle: 辅助工具\n---\n## Bouncy Castle\n在[官网](http://www.bouncycastle.org/latest_releases.html) 下载 `bcprov-jdk15on-151.jar` 和 `bcprov-ext-jdk15on-151.jar`\n\n对于Bouncy Castle 提供的扩充算法支持,有俩种方案可选\n* 配置方式,通过配置JRE环境,使其作为提供者提供相应的算法支持,在代码实现层面只需指定要扩展的算法名称\n> 1. 修改JDK\n\t修改java.security配置文件(jdk1.7.0_75\\jre\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jdk1.7.0_75\\jre\\lib\\ext\n  2. 修改JRE\n\t修改java.security配置文件(jre7\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jre7\\lib\\ext\n\n* 调用方式 : 直接将`bcprov-ext-jdk15on-151.jar` 导入到项目工程文件\n\nJCE工具将其拓展包：仅包括`org.bouncycastle.jce`包. 这是对JCE框架的支持\n\n\n## Base64\n\nBase64是一种基于64个字符的编码算法,根据RFC 2045的定义：Base64内容传送编码是一种以任意8位字节序列组合的描述形式, 这种形式不易被人直接识别.经过Base64编码后的数据会比原始数据略长,为原来的4/3,经Base64编码后的字符串的字符数是以4为单位的整数倍\n\nBase64算法有编码和解码操作可充当加密和解密操作,还有一张字符映射表充当了秘钥.由于字符映射表公开且Base64加密强度并不高,因此不能将其看作现代加密算法.但是如果将字符映射表调整,保密,改造后的Base64就具备了加密算法的意义而且Base64常作为密钥, 密文 和证书的一种通用存储编码格式\n\n###实现原理\n\n1. 将给定的字符串以字符为单位转换为对应的字符编码(如ASCII码)\n2. 将获得的字符编码转换为二进制码\n3. 对获得的二进制码做分组转换操作,每3个8位二进制码为1组,转换为每4个6位二进制码为1组(不足6位时低位补0)这是一个分组变化的过程, 3个8位二进制码和4个6位二进制码的长度都是24位\n4. 对获得的4个6位二进制码补位,向6位二进制码添加2位 高位0,组成4个8位二进制码\n5. 将获得的4个8位二进制码转换为10进制码\n6. 将获得的十进制码转换为base64字符表中对应的字符\n\n```\n对A进行Base64编码\n字符\t\t\t\tA\nASCII码\t\t\t65\n二进制码\t\t\t01000001\n4-6二进制码\t\t010000\t\t010000\n4-8二进制码\t\t00010000\t00010000\n十进制\t\t\t16\t\t\t16\n字符表映射码\t\tQ\t\t\tQ\t\t\t=\t=\n\n字符A编码之后就变成了QQ==\n\nbase64 映射表\nV E\t\t\t  V E\t\t\tV E\t\t\t  V E\n0 A            17 R            34 i            51 z\n1 B            18 S            35 j            52 0\n2 C            19 T            36 k            53 1\n3 D            20 U            37 l            54 2\n4 E            21 V            38 m            55 3\n5 F            22 W            39 n            56 4\n6 G            23 X            40 o            57 5\n7 H            24 Y            41 p            58 6\n8 I            25 Z            42 q            59 7\n9 J            26 a            43 r            60 8\n10 K           27 b            44 s            61 9\n11 L           28 c            45 t            62 +\n12 M           29 d            46 u            63 /\n13 N           30 e            47 v\n14 O           31 f            48 w         (pad) =\n15 P           32 g            49 x\n16 Q           33 h            50 y\n```\n\n\n### 代码举例\n\n```java\npublic class TestBase64 {\n\n\tstatic final String base64 = \"base64编码!@#$%^&*()+_=-{}[];:'<>,./?|\";\n\t\n\t@before\n\tpublic void before () {\n\t\tSystem.out.println(base64);\n\t}\n\t\n\t@Test\n\tpublic void testUrlBase64() {\n\t\t// 不能编码空格\n\t\tbyte[] encode = UrlBase64.encode(base64.getBytes());\n\t\tSystem.out.println(\"UrlBase64 : \" + new String(encode));\n\t\t\n\t\tbyte[] decode = UrlBase64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\t\n\t@Test\n\tpublic void testJavaBase64() {\n\t\tSystem.out.println();\n\t\tbyte[] encode = java.util.Base64.getEncoder().encode(base64.getBytes());\n\t\tSystem.out.println(\"JavaBase64 : \" + new String(encode));\n\t\tbyte[] decode = java.util.Base64.getDecoder().decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\t\n\t@Test\n\tpublic void testApacheBase64() {\n\t\tString encode = org.apache.commons.codec.binary.Base64.encodeBase64String(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 : \" + encode);\n\t\tbyte[] decode = org.apache.commons.codec.binary.Base64.decodeBase64(encode.getBytes());\n\t\tAssert.assertEquals(base64, new String(decode));\n\t\t\n\t\tString url = org.apache.commons.codec.binary.Base64.encodeBase64URLSafeString(base64.getBytes());\n\t\tSystem.out.println(\"apacheBase64 url : \" + url);\n\t\tbyte[] decoded = org.apache.commons.codec.binary.Base64.decodeBase64(url);\n\t\tAssert.assertEquals(base64, new String(decoded));\n\t}\n\t\n\t\n\t@Test\n\tpublic void testBouncycastleBase64() {\n\t\tbyte[] encode = org.bouncycastle.util.encoders.Base64.encode(base64.getBytes());\n\t\tSystem.out.println(\"BouncycastleBase64 : \" + new String(encode));\n\t\tbyte[] decode = org.bouncycastle.util.encoders.Base64.decode(encode);\n\t\tAssert.assertEquals(base64, new String(decode));\n\t}\n\t\n\t\n\t@Test\n\tpublic void testSpace() {\n\t\tString base64 = \"wKOS4FsxiFvE48KGGSuSkRui9Iap1ukgl1+eVqZiGhXQYYiP8KGCV%2FRIeTEyMLsWxE%2FEx6jhuW3DPUt4JYX+cohUOqFVVaQ%2FioGZCAge3ygaCz%2Fe4q8o9XQzOEtcdXPywGZ0e5sgE787ij4dRZy2ILK2cxsVvC8yrlIPGZ3LUg8nOj8oEg5l2AnQnA3i+Sxbgqmwe1OjIXVZqPZWb+Y4SVQL8EpWlmEjXb4HjgmGTgVYzwJ64QO7HUPP1yuQHkS0PLS%2FpbPrgL5vqTF7h%2FPvMw=%3D\"; \n\t\tString decoded = URLDecoder.decode(base64);\n\t\tSystem.out.println(decoded);\n\t\tbyte[] decode = UrlBase64.decode(base64);\n\t\tSystem.out.println(new String(decode));\n\t}\n}\n\n```","slug":"java加密解密/辅助工具","published":1,"updated":"2015-10-16T04:06:04.362Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtv00390cufd8kqfwkl"},{"date":"2014-11-07T16:00:00.000Z","title":"消息摘要","_content":"\n# 消息摘要算法三大类：\n## MessageDigest 消息摘要算法\n* MD2 (1989)\n* MD4 (1990)\n* MD5 (1991)\n## SHA 安全散列算法 (基于MD4算法改进而来)\n* SHA-1 (名字简称为SHA, 长度为160)\n* SHA-2(包含SHA-224,SHA-256,SHA-384,SHA-512)\n## MAC 消息认证码算法\n* HmacMD2\t(Bouncy Castle)\n* HmacMD3\n* HmacMD4 (Bouncy Castle)\n* HmacMD5 (Sun)\n* HmacSHA1 (Sun)\n* HmacSHA224 (Bouncy Castle)\n* HmacSHA256 (Sun)\n* HmacSHA384 (Sun)\n* HmacSHA512 (Sun)\n## RipeMD(1996)\t对MD4和MD5缺陷的基础上提出的算法   (Bouncy Castle)\n* RipeMD128\n* RipeMD160\n* RipeMD256\n* RipeMD320\n## MAC+RipeMD\t(Bouncy Castle)\n* HmacRipeMD128\n* HmacRipeMD160\n## Tiger\t\n号称最快的Hash算法,专门为64位机器做了优化,其消息长度为192\n## GOST3411\t\n被列入IDO标准,由于使用了和AES算法相同的转化技术,被称为最安全的摘要算法\n## Whirlpool\t\n摘要长度为256位\n##CRC\t循环冗余校验算法\nCRC是可以根据数据产生剪短固定位数的一种散列函数 ,主要用来检测或校验数据传输/保存后出现的错误.\n\n生成的散列值在传输或储存之前计算出来并且附加到数据后面.在使用数据之前对数据的完整性做校验.\n一般来说,循环荣誉校验的值都是32位的2进制数,以8位16进制字符形式表示.它是一类重要的线性分组码.\n\n消息摘要算法和CRC算法同属散列函数,并且CRC算法很可能就是消息摘要算法的前身\n\n\n## MD系 实现选择\n* Sun：Sun提供的算法较为底层, 支持MD2和MD5俩种算法. 但缺少了缺少了相应的进制转换实现,不能讲字节数组形式的摘要信息转换为十六进制字符串\n* Bouncy Castle：提供了对MD4算法的支持. 支持多种形式的参数, 支持16进制字符串形式的摘要信息\n* Commons Codec：如果仅仅需要MD5,使用它则是一个不错的选择\n\nSHA与MD不同之处在于SHA算法的摘要更长,安全性更高. 通常作为MD5算法的继任者\n\n## MAC \n是含有密钥散列函数算法,兼容MD和SHA算法的特性,并在此基础上加入了密钥. 因为MAC算法融合了密钥散列函数(keyed-hash), 所以通常也把MAC称为HMAC\n\n\n```java\npublic enum SHACoder {\n\t\n\tINSTANCE;\n\n\tSHACoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tsha224 = MessageDigest.getInstance(\"SHA-224\");\n\t\t\tsha = MessageDigest.getInstance(\"SHA\");\n\t\t\tsha256 = MessageDigest.getInstance(\"SHA-256\");\n\t\t\tsha384 = MessageDigest.getInstance(\"SHA-384\");\n\t\t\tsha512 = MessageDigest.getInstance(\"SHA-512\");\n\t\t\t\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate MessageDigest sha224;\n\tprivate MessageDigest sha;\n\tprivate MessageDigest sha256;\n\tprivate MessageDigest sha384;\n\tprivate MessageDigest sha512;\n\t\n\t/**\n\t * SHA加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA1ByCodec(byte[] data)  {\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1(data);\n\t}\n\n\t/**\n\t * SHAHex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHAHexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1Hex(data);\n\t}\n\n\t/**\n\t * SHA256加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA256ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256(data);\n\t}\n\n\t/**\n\t * SHA256Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHA256HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256Hex(data);\n\t}\n\n\t/**\n\t * SHA384加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic byte[] encodeSHA384ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384(data);\n\t}\n\n\t/**\n\t * SHA384Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic String encodeSHA384HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384Hex(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic byte[] encodeSHA512ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic String encodeSHA512HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512Hex(data);\n\t}\n\t\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\tpublic byte[] encodeSHA224(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha224.digest(data);\n\t}\n\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t */\n\tpublic String encodeSHA224Hex(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeSHA224(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\n\t}\n\t\n\t/**\n\t * SHA-1加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha.digest(data);\n\t}\n\n\n\t/**\n\t * SHA-256加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA256(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha256.digest(data);\n\t}\n\n\t/**\n\t * SHA-384加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA384(byte[] data)  {\n\t\t\n\t\t// 执行消息摘要\n\t\treturn sha384.digest(data);\n\t}\n\n\t/**\n\t * SHA-512加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA512(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha512.digest(data);\n\t}\n}\n```\n\n# SHACoder\n```java\n/**\n * RipeMD系列消息摘要组件<br>\n * 包含RipeMD128、RipeMD160、RipeMD256和RipeMD320共4种RipeMD系列算法，<br>\n * \n */\npublic enum RipeMDCoder {\n\n\tINSTANCE;\n\t\n\tRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t// 初始化MessageDigest\n\t\ttry {\n\t\t\tripeMD160 = MessageDigest.getInstance(\"RipeMD160\");\n\t\t\tripeMD256 = MessageDigest.getInstance(\"RipeMD256\");\n\t\t\tripeMD320 = MessageDigest.getInstance(\"RipeMD320\");\n\t\t\tripeMD128 = MessageDigest.getInstance(\"RipeMD128\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate MessageDigest ripeMD128;\n\tprivate MessageDigest ripeMD160;\n\tprivate MessageDigest ripeMD256;\n\tprivate MessageDigest ripeMD320;\n\t\n\t/**\n\t * RipeMD128消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD128.digest(data);\n\t}\n\n\t/**\n\t * RipeMD128Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD128(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD160消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD160.digest(data);\n\t}\n\n\t/**\n\t * RipeMD160Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD160(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD256消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD256(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD256.digest(data);\n\t}\n\n\t/**\n\t * RipeMD256Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD256Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD256(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD320消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD320(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD320.digest(data);\n\t}\n\n\t/**\n\t * RipeMD320Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD320Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD320(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n}\n```\n# MessageDigestCoder\n```java\n\npublic enum MessageDigestCoder {\n\n\tINSTANCE;\n\t\n\tprivate MessageDigestCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tmd2 = MessageDigest.getInstance(\"MD2\");\n\t\t\tmd4 = MessageDigest.getInstance(\"MD4\");\n\t\t\tmd5 = MessageDigest.getInstance(\"MD5\");\n\t\t\ttiger = MessageDigest.getInstance(\"Tiger\");\n\t\t\tgost3411 = MessageDigest.getInstance(\"GOST3411\");\n\t\t\twhirlpool = MessageDigest.getInstance(\"Whirlpool\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate  MessageDigest md2;\n\tprivate  MessageDigest md4;\n\tprivate  MessageDigest md5;\n\tprivate  MessageDigest tiger;\n\tprivate  MessageDigest gost3411;\n\tprivate  MessageDigest whirlpool;\n\t\n\tpublic byte[] encodeMD2(byte[] input) {\n\t\treturn md2.digest(input);\n\t}\n\t\n\tpublic byte[] encodeMD4(byte[] input) {\n\t\treturn md4.digest(input);\n\t}\n\n\tpublic byte[] encodeMD5(byte[] input) {\n\t\treturn md5.digest(input);\n\t}\n\n\tpublic byte[] encodeTIGER(byte[] input) {\n\t\treturn tiger.digest(input);\n\t}\n\n\tpublic byte[] encodeGOST3411(byte[] input) {\n\t\treturn gost3411.digest(input);\n\t}\n\n\tpublic byte[] encodeWHIRLPOOL(byte[] input) {\n\t\treturn whirlpool.digest(input);\n\t}\n\n\tpublic String encodeMD2Hex(byte[] input) {\n\t\treturn Hex.toHexString(md2.digest(input));\n\t}\n\n\tpublic String encodeMD4Hex(byte[] input) {\n\t\treturn Hex.toHexString(md4.digest(input));\n\t}\n\n\tpublic String encodeMD5Hex(byte[] input) {\n\t\treturn Hex.toHexString(md5.digest(input));\n\t}\n\n\tpublic String encodeTigerHex(byte[] input) {\n\t\treturn Hex.toHexString(tiger.digest(input));\n\t}\n\n\tpublic String encodeGOST3411Hex(byte[] input) {\n\t\treturn Hex.toHexString(gost3411.digest(input));\n\t}\n\n\tpublic String encodeWhirlpoolHex(byte[] input) {\n\t\treturn Hex.toHexString(whirlpool.digest(input));\n\t}\n}\n```\n\n# MACCoder\n---\n```java\n\n/**\n * MAC消息摘要组件\n * \n */\npublic enum MACCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacMD2;\n\tprivate Mac hmacMD4;\n\tprivate Mac hmacMD5;\n\tprivate Mac hmacSHA1;\n\tprivate Mac hmacSHA224;\n\tprivate Mac hmacSHA256;\n\tprivate Mac hmacSHA384;\n\tprivate Mac hmacSHA512;\n\n\tMACCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\thmacMD2 = getMacBy(\"HmacMD2\");\n\t\thmacMD4 = getMacBy(\"HmacMD4\");\n\t\thmacMD5 = getMacBy(\"HmacMD5\");\n\t\thmacSHA1 = getMacBy(\"HmacSHA1\");\n\t\thmacSHA224 = getMacBy(\"HmacSHA224\");\n\t\thmacSHA256 = getMacBy(\"HmacSHA256\");\n\t\thmacSHA384 = getMacBy(\"HmacSHA384\");\n\t\thmacSHA512 = getMacBy(\"HmacSHA512\");\n\t}\n\n\tpublic Mac getMacBy(String ar) {\n\n\t\t// 初始化KeyGenerator\n\t\tKeyGenerator keyGenerator;\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tkeyGenerator = KeyGenerator.getInstance(ar);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 加入BouncyCastleProvider支持\n\t\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, ar);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacMD2消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD2(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD2.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD2Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD2Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD2(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD4消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD4(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD4.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD4Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD4Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD4(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacSHA224消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA224(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA224.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA224Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacSHA224Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA224(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD5加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD5(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacMD5\");\n\t\t//\n\t\t// // 实例化Mac \"SslMacMD5\"\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD5.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA1加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HMacTiger\");\n\t\t//\n\t\t// // 实例化Mac SslMacMD5\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA1.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA256加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA256(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA256\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA256.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA384加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA384(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA384\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA384.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA512加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA512(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA512\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA512.doFinal(data);\n\t}\n\n\tpublic String encodeHmacMD5Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD5(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA1Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA256Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA256(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA384Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA384(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA512Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA512(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# HmacRipeMDCoder\n```java\n\n/**\n * HmacRipeMD系列加密组件<br>\n * HmacRipeMD128、HmacRipeMD160共2种算法。<br>\n * \n */\npublic enum HmacRipeMDCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacRipeMD128;\n\tprivate Mac hmacRipeMD160;\n\n\tHmacRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\thmacRipeMD128 = getMac(\"HmacRipeMD128\");\n\t\thmacRipeMD160 = getMac(\"HmacRipeMD160\");\n\t}\n\n\t/**\n\t * 初始化HmacRipeMD128密钥\n\t * \n\t * @return byte[] 密钥\n\t * \n\t */\n\tpublic Mac getMac(String key1) {\n\n\t\t// 初始化KeyGenerator\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tKeyGenerator keyGenerator;\n\t\t\tkeyGenerator = KeyGenerator.getInstance(key1);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, key1);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacRipeMD128消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD128.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD128Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD128(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacRipeMD160消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD160.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD160Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD160(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# CRCCoder\n---\n```java\n\npublic enum CRCCoder {\n\n\tINSTANCE;\n\t\n\tprivate final CRC32 crc32 = new CRC32();\n\t\n\tpublic synchronized long encodeByCRC32(byte[] input) {\n\t\tcrc32.update(input);\n\t\t\n\t\tfinal long value = crc32.getValue();\n\t\tcrc32.reset();\n\t\t\n\t\treturn value;\n\t}\n\t\n\tpublic String encodeByCRC32Hex(byte[] input) {\n\t\tlong value = encodeByCRC32(input);\n\t\t\n\t\treturn Long.toHexString(value);\n\t}\n}\n```","source":"_posts/java加密解密/消息摘要实现.md","raw":"category: java加密解密\ndate: 2014-11-08\ntitle: 消息摘要\n---\n\n# 消息摘要算法三大类：\n## MessageDigest 消息摘要算法\n* MD2 (1989)\n* MD4 (1990)\n* MD5 (1991)\n## SHA 安全散列算法 (基于MD4算法改进而来)\n* SHA-1 (名字简称为SHA, 长度为160)\n* SHA-2(包含SHA-224,SHA-256,SHA-384,SHA-512)\n## MAC 消息认证码算法\n* HmacMD2\t(Bouncy Castle)\n* HmacMD3\n* HmacMD4 (Bouncy Castle)\n* HmacMD5 (Sun)\n* HmacSHA1 (Sun)\n* HmacSHA224 (Bouncy Castle)\n* HmacSHA256 (Sun)\n* HmacSHA384 (Sun)\n* HmacSHA512 (Sun)\n## RipeMD(1996)\t对MD4和MD5缺陷的基础上提出的算法   (Bouncy Castle)\n* RipeMD128\n* RipeMD160\n* RipeMD256\n* RipeMD320\n## MAC+RipeMD\t(Bouncy Castle)\n* HmacRipeMD128\n* HmacRipeMD160\n## Tiger\t\n号称最快的Hash算法,专门为64位机器做了优化,其消息长度为192\n## GOST3411\t\n被列入IDO标准,由于使用了和AES算法相同的转化技术,被称为最安全的摘要算法\n## Whirlpool\t\n摘要长度为256位\n##CRC\t循环冗余校验算法\nCRC是可以根据数据产生剪短固定位数的一种散列函数 ,主要用来检测或校验数据传输/保存后出现的错误.\n\n生成的散列值在传输或储存之前计算出来并且附加到数据后面.在使用数据之前对数据的完整性做校验.\n一般来说,循环荣誉校验的值都是32位的2进制数,以8位16进制字符形式表示.它是一类重要的线性分组码.\n\n消息摘要算法和CRC算法同属散列函数,并且CRC算法很可能就是消息摘要算法的前身\n\n\n## MD系 实现选择\n* Sun：Sun提供的算法较为底层, 支持MD2和MD5俩种算法. 但缺少了缺少了相应的进制转换实现,不能讲字节数组形式的摘要信息转换为十六进制字符串\n* Bouncy Castle：提供了对MD4算法的支持. 支持多种形式的参数, 支持16进制字符串形式的摘要信息\n* Commons Codec：如果仅仅需要MD5,使用它则是一个不错的选择\n\nSHA与MD不同之处在于SHA算法的摘要更长,安全性更高. 通常作为MD5算法的继任者\n\n## MAC \n是含有密钥散列函数算法,兼容MD和SHA算法的特性,并在此基础上加入了密钥. 因为MAC算法融合了密钥散列函数(keyed-hash), 所以通常也把MAC称为HMAC\n\n\n```java\npublic enum SHACoder {\n\t\n\tINSTANCE;\n\n\tSHACoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tsha224 = MessageDigest.getInstance(\"SHA-224\");\n\t\t\tsha = MessageDigest.getInstance(\"SHA\");\n\t\t\tsha256 = MessageDigest.getInstance(\"SHA-256\");\n\t\t\tsha384 = MessageDigest.getInstance(\"SHA-384\");\n\t\t\tsha512 = MessageDigest.getInstance(\"SHA-512\");\n\t\t\t\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate MessageDigest sha224;\n\tprivate MessageDigest sha;\n\tprivate MessageDigest sha256;\n\tprivate MessageDigest sha384;\n\tprivate MessageDigest sha512;\n\t\n\t/**\n\t * SHA加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA1ByCodec(byte[] data)  {\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1(data);\n\t}\n\n\t/**\n\t * SHAHex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHAHexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha1Hex(data);\n\t}\n\n\t/**\n\t * SHA256加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic byte[] encodeSHA256ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256(data);\n\t}\n\n\t/**\n\t * SHA256Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t */\n\tpublic String encodeSHA256HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha256Hex(data);\n\t}\n\n\t/**\n\t * SHA384加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic byte[] encodeSHA384ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384(data);\n\t}\n\n\t/**\n\t * SHA384Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要 \n\t */\n\tpublic String encodeSHA384HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha384Hex(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic byte[] encodeSHA512ByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512(data);\n\t}\n\n\t/**\n\t * SHA512Hex加密\n\t * \n\t * @param data 待加密数据\n\t * @return byte[] 消息摘要\n\t * @\n\t */\n\tpublic String encodeSHA512HexByCodec(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn DigestUtils.sha512Hex(data);\n\t}\n\t\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\tpublic byte[] encodeSHA224(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha224.digest(data);\n\t}\n\n\t/**\n\t * SHA-224加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t */\n\tpublic String encodeSHA224Hex(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeSHA224(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\n\t}\n\t\n\t/**\n\t * SHA-1加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha.digest(data);\n\t}\n\n\n\t/**\n\t * SHA-256加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA256(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha256.digest(data);\n\t}\n\n\t/**\n\t * SHA-384加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA384(byte[] data)  {\n\t\t\n\t\t// 执行消息摘要\n\t\treturn sha384.digest(data);\n\t}\n\n\t/**\n\t * SHA-512加密\n\t * 使用Codec\n\t * @param data\n\t *            待加密数据\n\t * @return byte[] 消息摘要\n\t * @throws NoSuchAlgorithmException \n\t * \n\t */\n\t@Deprecated\n\tpublic byte[] encodeSHA512(byte[] data)  {\n\n\t\t// 执行消息摘要\n\t\treturn sha512.digest(data);\n\t}\n}\n```\n\n# SHACoder\n```java\n/**\n * RipeMD系列消息摘要组件<br>\n * 包含RipeMD128、RipeMD160、RipeMD256和RipeMD320共4种RipeMD系列算法，<br>\n * \n */\npublic enum RipeMDCoder {\n\n\tINSTANCE;\n\t\n\tRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t// 初始化MessageDigest\n\t\ttry {\n\t\t\tripeMD160 = MessageDigest.getInstance(\"RipeMD160\");\n\t\t\tripeMD256 = MessageDigest.getInstance(\"RipeMD256\");\n\t\t\tripeMD320 = MessageDigest.getInstance(\"RipeMD320\");\n\t\t\tripeMD128 = MessageDigest.getInstance(\"RipeMD128\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate MessageDigest ripeMD128;\n\tprivate MessageDigest ripeMD160;\n\tprivate MessageDigest ripeMD256;\n\tprivate MessageDigest ripeMD320;\n\t\n\t/**\n\t * RipeMD128消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD128.digest(data);\n\t}\n\n\t/**\n\t * RipeMD128Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD128(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD160消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD160.digest(data);\n\t}\n\n\t/**\n\t * RipeMD160Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD160(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD256消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD256(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD256.digest(data);\n\t}\n\n\t/**\n\t * RipeMD256Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD256Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD256(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * RipeMD320消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic byte[] encodeRipeMD320(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn ripeMD320.digest(data);\n\t}\n\n\t/**\n\t * RipeMD320Hex消息摘要\n\t * \n\t * @param data 待做消息摘要处理的数据\n\t * @return byte[] 消息摘要 \n\t * \n\t */\n\tpublic String encodeRipeMD320Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeRipeMD320(data);\n\n\t\t// 做十六进制编码处理\n\t\treturn new String(Hex.encode(b));\n\t}\n\n}\n```\n# MessageDigestCoder\n```java\n\npublic enum MessageDigestCoder {\n\n\tINSTANCE;\n\t\n\tprivate MessageDigestCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\t\n\t\ttry {\n\t\t\tmd2 = MessageDigest.getInstance(\"MD2\");\n\t\t\tmd4 = MessageDigest.getInstance(\"MD4\");\n\t\t\tmd5 = MessageDigest.getInstance(\"MD5\");\n\t\t\ttiger = MessageDigest.getInstance(\"Tiger\");\n\t\t\tgost3411 = MessageDigest.getInstance(\"GOST3411\");\n\t\t\twhirlpool = MessageDigest.getInstance(\"Whirlpool\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\t\n\tprivate  MessageDigest md2;\n\tprivate  MessageDigest md4;\n\tprivate  MessageDigest md5;\n\tprivate  MessageDigest tiger;\n\tprivate  MessageDigest gost3411;\n\tprivate  MessageDigest whirlpool;\n\t\n\tpublic byte[] encodeMD2(byte[] input) {\n\t\treturn md2.digest(input);\n\t}\n\t\n\tpublic byte[] encodeMD4(byte[] input) {\n\t\treturn md4.digest(input);\n\t}\n\n\tpublic byte[] encodeMD5(byte[] input) {\n\t\treturn md5.digest(input);\n\t}\n\n\tpublic byte[] encodeTIGER(byte[] input) {\n\t\treturn tiger.digest(input);\n\t}\n\n\tpublic byte[] encodeGOST3411(byte[] input) {\n\t\treturn gost3411.digest(input);\n\t}\n\n\tpublic byte[] encodeWHIRLPOOL(byte[] input) {\n\t\treturn whirlpool.digest(input);\n\t}\n\n\tpublic String encodeMD2Hex(byte[] input) {\n\t\treturn Hex.toHexString(md2.digest(input));\n\t}\n\n\tpublic String encodeMD4Hex(byte[] input) {\n\t\treturn Hex.toHexString(md4.digest(input));\n\t}\n\n\tpublic String encodeMD5Hex(byte[] input) {\n\t\treturn Hex.toHexString(md5.digest(input));\n\t}\n\n\tpublic String encodeTigerHex(byte[] input) {\n\t\treturn Hex.toHexString(tiger.digest(input));\n\t}\n\n\tpublic String encodeGOST3411Hex(byte[] input) {\n\t\treturn Hex.toHexString(gost3411.digest(input));\n\t}\n\n\tpublic String encodeWhirlpoolHex(byte[] input) {\n\t\treturn Hex.toHexString(whirlpool.digest(input));\n\t}\n}\n```\n\n# MACCoder\n---\n```java\n\n/**\n * MAC消息摘要组件\n * \n */\npublic enum MACCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacMD2;\n\tprivate Mac hmacMD4;\n\tprivate Mac hmacMD5;\n\tprivate Mac hmacSHA1;\n\tprivate Mac hmacSHA224;\n\tprivate Mac hmacSHA256;\n\tprivate Mac hmacSHA384;\n\tprivate Mac hmacSHA512;\n\n\tMACCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\thmacMD2 = getMacBy(\"HmacMD2\");\n\t\thmacMD4 = getMacBy(\"HmacMD4\");\n\t\thmacMD5 = getMacBy(\"HmacMD5\");\n\t\thmacSHA1 = getMacBy(\"HmacSHA1\");\n\t\thmacSHA224 = getMacBy(\"HmacSHA224\");\n\t\thmacSHA256 = getMacBy(\"HmacSHA256\");\n\t\thmacSHA384 = getMacBy(\"HmacSHA384\");\n\t\thmacSHA512 = getMacBy(\"HmacSHA512\");\n\t}\n\n\tpublic Mac getMacBy(String ar) {\n\n\t\t// 初始化KeyGenerator\n\t\tKeyGenerator keyGenerator;\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tkeyGenerator = KeyGenerator.getInstance(ar);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 加入BouncyCastleProvider支持\n\t\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, ar);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacMD2消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD2(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD2.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD2Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD2Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD2(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD4消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD4(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD4.doFinal(data);\n\t}\n\n\t/**\n\t * HmacMD4Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacMD4Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD4(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacSHA224消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA224(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA224.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA224Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * @throws Exception\n\t */\n\tpublic String encodeHmacSHA224Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA224(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacMD5加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacMD5(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacMD5\");\n\t\t//\n\t\t// // 实例化Mac \"SslMacMD5\"\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacMD5.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA1加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HMacTiger\");\n\t\t//\n\t\t// // 实例化Mac SslMacMD5\n\t\t// Mac mac = Mac.getInstance(\"SslMacMD5\");// secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA1.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA256加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA256(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA256\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA256.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA384加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA384(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA384\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA384.doFinal(data);\n\t}\n\n\t/**\n\t * HmacSHA512加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t * @throws Exception\n\t */\n\tpublic byte[] encodeHmacSHA512(byte[] data) {\n\n\t\t// // 还原密钥\n\t\t// SecretKey secretKey = new SecretKeySpec(key, \"HmacSHA512\");\n\t\t//\n\t\t// // 实例化Mac\n\t\t// Mac mac = Mac.getInstance(secretKey.getAlgorithm());\n\t\t//\n\t\t// // 初始化Mac\n\t\t// mac.init(secretKey);\n\n\t\t// 执行消息摘要\n\t\treturn hmacSHA512.doFinal(data);\n\t}\n\n\tpublic String encodeHmacMD5Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacMD5(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA1Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA256Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA256(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA384Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA384(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\tpublic String encodeHmacSHA512Hex(byte[] data) {\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacSHA512(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# HmacRipeMDCoder\n```java\n\n/**\n * HmacRipeMD系列加密组件<br>\n * HmacRipeMD128、HmacRipeMD160共2种算法。<br>\n * \n */\npublic enum HmacRipeMDCoder {\n\n\tINSTANCE;\n\n\tprivate Mac hmacRipeMD128;\n\tprivate Mac hmacRipeMD160;\n\n\tHmacRipeMDCoder() {\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t\thmacRipeMD128 = getMac(\"HmacRipeMD128\");\n\t\thmacRipeMD160 = getMac(\"HmacRipeMD160\");\n\t}\n\n\t/**\n\t * 初始化HmacRipeMD128密钥\n\t * \n\t * @return byte[] 密钥\n\t * \n\t */\n\tpublic Mac getMac(String key1) {\n\n\t\t// 初始化KeyGenerator\n\t\tMac mac = null;\n\t\ttry {\n\t\t\tKeyGenerator keyGenerator;\n\t\t\tkeyGenerator = KeyGenerator.getInstance(key1);\n\t\t\t// 产生秘密密钥\n\t\t\tSecretKey secretKey = keyGenerator.generateKey();\n\n\t\t\t// 获得密钥\n\t\t\tbyte[] key = secretKey.getEncoded();\n\n\t\t\t// 还原密钥\n\t\t\tSecretKey secretKey1 = new SecretKeySpec(key, key1);\n\n\t\t\t// 实例化Mac\n\t\t\tmac = Mac.getInstance(secretKey1.getAlgorithm());\n\n\t\t\t// 初始化Mac\n\t\t\tmac.init(secretKey1);\n\t\t} catch (final Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\n\t\treturn mac;\n\t}\n\n\t/**\n\t * HmacRipeMD128消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD128(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD128.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD128Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param String\n\t *            密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD128Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD128(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n\n\t/**\n\t * HmacRipeMD160消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return byte[] 消息摘要\n\t * \n\t */\n\tpublic byte[] encodeHmacRipeMD160(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\treturn hmacRipeMD160.doFinal(data);\n\t}\n\n\t/**\n\t * HmacRipeMD160Hex消息摘要\n\t * \n\t * @param data\n\t *            待做消息摘要处理的数据\n\t * @param byte[] 密钥\n\t * @return String 消息摘要\n\t * \n\t */\n\tpublic String encodeHmacRipeMD160Hex(byte[] data) {\n\n\t\t// 执行消息摘要\n\t\tbyte[] b = encodeHmacRipeMD160(data);\n\n\t\t// 做十六进制转换\n\t\treturn new String(Hex.encode(b));\n\t}\n}\n```\n\n# CRCCoder\n---\n```java\n\npublic enum CRCCoder {\n\n\tINSTANCE;\n\t\n\tprivate final CRC32 crc32 = new CRC32();\n\t\n\tpublic synchronized long encodeByCRC32(byte[] input) {\n\t\tcrc32.update(input);\n\t\t\n\t\tfinal long value = crc32.getValue();\n\t\tcrc32.reset();\n\t\t\n\t\treturn value;\n\t}\n\t\n\tpublic String encodeByCRC32Hex(byte[] input) {\n\t\tlong value = encodeByCRC32(input);\n\t\t\n\t\treturn Long.toHexString(value);\n\t}\n}\n```","slug":"java加密解密/消息摘要实现","published":1,"updated":"2015-10-16T02:42:04.317Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxtw003b0cufj37991gr"},{"date":"2014-11-07T16:00:00.000Z","title":"数字证书","_content":"# 散列函数\n\n散列函数又称为哈希函数,消息摘要函数,单向函数或者杂凑函数. 与上述密码体制不同的是, 散列函数的主要作用不是完成数据加密解密操作, 它主要是用来验证数据的完整性. 散列值是一个短的随机字母和数字组成的字符串.\n\n![消息认证流程]()\n\n在上述认证流程中,信息收发双发在通信前已经商定了具体的散列算法,并且该算法是公开的.\n散列函数具有以下特性:\n* 消息的长度不受限制.\n* 对于给定的消息,其散列值的计算是很容易的.\n* 如果两个散列值不相同,则这两个散列值的原始输入消息也不相同,这个特性使得散列函数具有确定性的结果.\n* 散列函数的运算过程是不可逆的,这个特性称为函数的单向性.这也是单向函数命名的由来.\n* 对于一个已知的消息及其散列值,要找到另一个消息使其获得相同的散列值是不可能的,这个特性称为抗弱碰撞性.这被用来防止伪造.\n* 任意两个不同的消息的散列值一定不同,这个特性称为抗强碰撞性.\n\n\n# 数字签名\n\n通过散列函数可以确保数据内容的完整性,但这还远远不够. 此外,还需要确保数据来源的可认证性和数据发送行为的不可否任性. 完整性,可认证性和不可否认性是数字签名的主要特征. 数字签名针对以数字形式存储的消息进行处理, 产生一种带有操作者身份信息的编码.执行数字签名的实体称为签名者,签名过程中所使用的算法称为签名算法, 签名过程中生成的编码称为签名者对该消息的数字签名. 发送者通过网络连同数字签名一齐发送给接受者. 接受者在得到该消息及数字签名后,可以通过一个算法来验证签名的真伪以及识别相应的签名者. 这一过程称为验证过程, 其过程使用的算法称为验证算法. 数字签名离不开非对称密码体制, 签名算法受私钥控制,且由签名者保密. 验证算法受公玥控制,且对外公开.\nRSA算法既是最为常用的非对称加密算法,又是最为常用的签名算法.DSA算法是典型的数字签名算法,其本身属于非对称加密算法不具备数据加密与解密的功能.\n数字签名满足以下三个基本要求\n* 签名者任何时候都无法否认自己曾经签发的数字签名.\n* 信息接受者能够验证和确认收到的数字签名,但任何人无法伪造信息发送者的数字签名.\n* 当收发双发对数字签名的真伪产生争议时,可通过仲裁机构进行仲裁.\n\n![数字签名认证流程]()\n\n暂定甲方拥有私钥并且奖罚将公玥发布给乙方, 当甲方作为消息的发送方时, 甲方使用私钥对消息做签名处理,然后将加密的消息连同数字签名发送给乙方.乙方使用已获得的公玥对接收到的加密消息做解密处理,然后使用公玥及数字签名对原始消息做验证处理.\n\n当然我们可以对消息先加密,然后对加密后的消息做签名处理,这样乙方获得消息后,先做验证处理,如果验证通过则对消息解密.反之,验证消息失败则抛弃消息.这样做显然可以提高系统的处理速度,但即便如此,仍建议大家先对消息做签名,再做加密处理.加密与签名都应该只针对原始消息做处理.加密是为了确保消息在传送过程中避免被破解,签名是为了确保消息的有效性.消息本身就可能是一个可执行文件,消息的接收方通过对消息的验证判断该文件是由有权执行,而这个文件本身是不需要加密的.\n\n由于签名的不可伪造,甲方不能否认自己已经发送的消息,而乙方可验证消息的来源以及消息是否完整.数字签名可提供OSI参考模型5种安全服务中的3种：认证服务,抗否认性服务,数据完整性服务. 正因为如此,数字签名称为公玥基础设施以及许多网络安全机制的基础.\n\n当乙方作为发送方,通过公玥将消息加密后发送给甲方时,由于算法,公玥公开,任何一个已获得公玥的窃密者都可以截获乙方发送的消息,替换成自己的消息发送给甲方,而甲方无法辨别消息来源是否是乙方.也就是说,上述的认证方式是单向的,属于单向认证. 如果拥有俩套公私玥,甲乙双方都对数据做签名及验证就可以避免这一问题. 没错这种认证方式是双向认证.以网银交易事宜的都是单向认证方式,无法验证使用者的身份. 而要求较高的网银交易都是双向认证方式,交易双方身份都可以得到验证.\n\n# 公玥基础设施\n\n公钥基础设施（Public Key Infrastructure,PKI）是一个基于X.509的、用于创建、分配和撤回证书的模型.PKI能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系.换言之,PKI利用公钥密码技术构建基础设施,为网上电子商务、电子政务等应用提供安全服务.PKI技术是信息安全技术的核心,也是电子商务的关键和基础技术.如今大家所熟悉的网银交易系统就是PKI技术的具体体现.\n\nPKI由公钥密码技术、数字证书、证书认证中心和关于公钥的安全策略等基本成分共同组成,对密钥和证书进行管理.因此,PKI技术涉及对称加密算法、非对称加密算法、消息摘要算法和数字签名等密码学算法.\n\n我们目前所使用到的电子商务平台大部分都是基于PKI技术实现的.\n\n## 2.9.1 PKI的标准\n\nRSA公司定义了PKCS（Public Key Cryptography Standards,公钥加密标准）,并定义了许多PKI基础组件,如数字签名和证书请求格式；IETF（Internet Engineering Task Force,互联网工程任务组）和PKIWG（Public Key Infrastructure Working Group,PKI工作组）定义了一组具有可操作性的公钥基础设施协议PKIX（Public Key Infrastructure Using X.509,公钥基础设施X.509）.\n\n## PKCS共有15项标准:\n\n1. PKCS#1：RSA公钥算法加密和签名机制\n2. PKCS#3：DH密钥交换协议\n3. PKCS#5：PBE加密标准\n4. PKCS#6：公钥证书（X.509证书的扩展格式）标准语法\n5. PKCS#7：加密消息语法标准\n6. PKCS#8：私钥信息格式\n7. PKCS#9：选择属性格式\n8. PKCS#10：证书请求语法\n9. PKCS#11：密码装置标准接口\n10. PKCS#12：个人信息交换语法标准\n11. PKCS#13：椭圆曲线密码体制标准\n12. PKCS#14：伪随机数生成标准\n13. PKCS#15：密码令牌信息格式标准\n\n其中,PKCS#2和PKCS#4标准已被撤销,合并至PKCS#1中；较为常用的是PKCS#7、PKCS#10和PKCS#12.\n\n上述标准主要用于用户实体通过注册机构（RA）进行证书申请、用户证书更新等过程.当证书作废时,注册机构通过认证中心向目录服务器发布证书撤销列表.上述标准还用于扩展证书内容、数字签名、数字签名验证和定义数字信封格式等情况.在构建密钥填充方式时,考虑到不同的安全等级,也会选择不同PKCS标准.\n\nPKIX作为操作性标准涉及证书管理协议(Certificate Management Protocol,CMP)、安全多用途邮件扩展（S/MIME）和在线证书状态协议（Online Certificate Status Protocol,OCSP）等.\n\n### PKI系统的组成\n\nPKI系统由认证中心（Certificate Authority,CA）、数字证书库（Certificate Repository,CR）、密钥备份及恢复系统、证书作废系统,以及应用程序接口（Application Programming Interface,API）五部分组成.其中,认证中心CA和数字证书库是PKI技术的核心.\n\n1. 认证中心\n\nCA是PKI的核心之一,是数字证书的申请及签发机构,且机构必须具有权威性,以确保公钥管理公开透明.\n\n### 认证中心的主要功能如下：\n* 证书发放\n* 证书更新\n* 证书撤销\n* 证书验证\n\n认证中心主要由注册服务器、注册机构（Registry Authority,RA）,和认证中心服务器三部分组成.\n\n2. 数字证书库. 数字证书库用于存储已签发的数字证书及公钥,包括LDAP（Light Direct Access Protocol,轻量级目录访问协议）目录服务器和普通数据库.用户可通过数字证书库进行证书查询,并可获得其他用户的证书及公钥.\n\n3. 密钥备份及恢复系统. 若用户丢失密钥则无法对数据解密,这将造成数据的丢失.为避免此类情况,PKI技术提供密钥备份及恢复功能.密钥的备份与恢复需要可信的权威机构来完成,这也是认证机构存在的必要条件.\n\n4. 证书作废系统. 为了确保证书的有效性,证书具有使用时效性,以确保证书所属环境的安全性.从另一个角度来讲,如果证书持有机构存在一定的安全性问题,即便证书未超过有效期,亦需要作废.PKI技术通过将证书列入作废证书列表（Certificate Revocation List,CRL）来完成证书作废操作.用户可以通过查询CRL来验证证书的有效性.\n\n5. 应用程序接口API. PKI技术必须提供良好的应用程序接口,使得各式各样的应用,不同的系统架构都能以安全、一致、可信的方式与PKI进行交互,且能快速完成交互过程,以确保安全网络环境的完整性和易用性.\n\n### 数字证书\n\n数字证书是网络用户的身份标表,包含ID、公钥和颁发机构的数字签名等内容.其形式主要有X.509公钥证书、SPKI（Simple Public Key Infrastructure,简单PKI）证书、PGP（Pretty Good Privacy,译为“很好的私密”）证书和属性（Attribute）证书.其中,X.509证书最为常见.我们俗称的数字证书,通常指的是X.509公钥证书.\n\n目前,我们所使用的X.509证书通常由VeriSign、GeoTrust和Thawte三大国际权威认证机构签发.VeriSign由RSA控股,借助RSA成熟的安全技术提供了较为广泛的PKI产品,其产品活跃在电子商务平台中.当我们在淘宝或者亚马逊上购物时,总能看到熟悉的VeriSign字样.\n\n由于证书存在时效性,证书持有机构需要定期向认证机构申请证书签发.根据证书持有机构的证书使用范畴,认证机构会对不同的证书签发收取不同的费用.由此,证书持有机构需要每年向认证机构缴纳高额的年费.为了加强系统安全性,证书的密钥长度也会随着其费用递增.其中,价格最高的是商业网站的证书认证费用.上述的费用是认证机构得以生存的经济来源,同时也是电子商务平台等机构构建系统架构必须支付的安全成本之一.\n\n\n# RSACoder\n```java\n\n/**\n * RSA安全编码组件\n * \n */\npublic abstract class RSACoder {\n\t\n\t/**\n\t * 数字签名\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withRSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 默认1024位，\n\t *  密钥长度必须是64的倍数， \n\t *  范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥对儿 Map\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ECDSACoder\n---\n```java\n\n/**\n * ECDSA安全编码组件\n * \n */\npublic enum ECDSACoder {\n\n\tNONEwithECDSA(\"NONEwithECDSA\"), \n\tRIPEMD160withECDSA(\"RIPEMD160withECDSA\"), \n\tSHA1withECDSA(\"SHA1withECDSA\"),   \n\tSHA224withECDSA(\"SHA224withECDSA\"),  \n\tSHA256withECDSA(\"SHA256withECDSA\"),\n\tSHA384withECDSA(\"SHA384withECDSA\"), \n\tSHA512withECDSA(\"SHA512withECDSA\");\n\t\n\t/**\n\t * 数字签名 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"ECDSA\";\n\n\tECDSACoder(String algo) {\n\t\tthis.SIGNATURE_ALGORITHM = algo;\n\t}\n\t\n\tprivate String SIGNATURE_ALGORITHM ;\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate final String PUBLIC_KEY = \"ECDSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate final String PRIVATE_KEY = \"ECDSAPrivateKey\";\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\tBigInteger p = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308885314476597252960362792450860609699839\");\n \n\t\tECFieldFp ecFieldFp = new ECFieldFp(p);\n\n\t\tBigInteger a = new BigInteger(\n\t\t\t\t\"7fffffffffffffffffffffff7fffffffffff8000000000007ffffffffffc\",\n\t\t\t\t16);\n \n\t\tBigInteger b = new BigInteger(\n\t\t\t\t\"6b016c3bdcf18941d0d654921475ca71a9db2fb27d1d37796185c2942c0a\",\n\t\t\t\t16);\n \n\t\tEllipticCurve ellipticCurve = new EllipticCurve(ecFieldFp, a, b);\n\n\t\tBigInteger x = new BigInteger(\n\t\t\t\t\"110282003749548856476348533541186204577905061504881242240149511594420911\");\n \n\t\tBigInteger y = new BigInteger(\n\t\t\t\t\"869078407435509378747351873793058868500210384946040694651368759217025454\");\n \n\t\tECPoint g = new ECPoint(x, y);\n\n\t\tBigInteger n = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308884807550341691627752275345424702807307\");\n\n\t\tECParameterSpec ecParameterSpec = new ECParameterSpec(ellipticCurve, g,\n\t\t\t\tn, 1);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(ecParameterSpec, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keypair = kpg.generateKeyPair();\n\n\t\tECPublicKey publicKey = (ECPublicKey) keypair.getPublic();\n\n\t\tECPrivateKey privateKey = (ECPrivateKey) keypair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n}\n```\n\n# DSACoder\n---\n```java\n/**\n * DSA安全编码组件\n * \n */\npublic abstract class DSACoder {\n\n\t/**\n\t * 数字签名密钥算法\n\t */\n\tpublic static final String ALGORITHM = \"DSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withDSA\";\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DSAPrivateKey\";\n\t\n\t/**\n\t * DSA密钥长度 \n\t * 默认1024位， \n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至1024位之间（含）\n\t */\n\tprivate static final int KEY_SIZE = 1024;\n\t\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 还原私钥\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成私钥对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 还原公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 取公钥匙对象\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例话Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return 密钥对象\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 初始化密钥对儿生成器\n\t\tKeyPairGenerator keygen = KeyPairGenerator.getInstance(ALGORITHM);\n\n\t\t// 实例化密钥对儿生成器\n\t\tkeygen.initialize(KEY_SIZE, new SecureRandom());\n\n\t\t// 实例化密钥对儿\n\t\tKeyPair keys = keygen.genKeyPair();\n\n\t\tDSAPublicKey publicKey = (DSAPublicKey) keys.getPublic();\n\n\t\tDSAPrivateKey privateKey = (DSAPrivateKey) keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","source":"_posts/java加密解密/数字证书实现.md","raw":"category: java加密解密\ndate: 2014-11-08\ntitle: 数字证书 \n---\n# 散列函数\n\n散列函数又称为哈希函数,消息摘要函数,单向函数或者杂凑函数. 与上述密码体制不同的是, 散列函数的主要作用不是完成数据加密解密操作, 它主要是用来验证数据的完整性. 散列值是一个短的随机字母和数字组成的字符串.\n\n![消息认证流程]()\n\n在上述认证流程中,信息收发双发在通信前已经商定了具体的散列算法,并且该算法是公开的.\n散列函数具有以下特性:\n* 消息的长度不受限制.\n* 对于给定的消息,其散列值的计算是很容易的.\n* 如果两个散列值不相同,则这两个散列值的原始输入消息也不相同,这个特性使得散列函数具有确定性的结果.\n* 散列函数的运算过程是不可逆的,这个特性称为函数的单向性.这也是单向函数命名的由来.\n* 对于一个已知的消息及其散列值,要找到另一个消息使其获得相同的散列值是不可能的,这个特性称为抗弱碰撞性.这被用来防止伪造.\n* 任意两个不同的消息的散列值一定不同,这个特性称为抗强碰撞性.\n\n\n# 数字签名\n\n通过散列函数可以确保数据内容的完整性,但这还远远不够. 此外,还需要确保数据来源的可认证性和数据发送行为的不可否任性. 完整性,可认证性和不可否认性是数字签名的主要特征. 数字签名针对以数字形式存储的消息进行处理, 产生一种带有操作者身份信息的编码.执行数字签名的实体称为签名者,签名过程中所使用的算法称为签名算法, 签名过程中生成的编码称为签名者对该消息的数字签名. 发送者通过网络连同数字签名一齐发送给接受者. 接受者在得到该消息及数字签名后,可以通过一个算法来验证签名的真伪以及识别相应的签名者. 这一过程称为验证过程, 其过程使用的算法称为验证算法. 数字签名离不开非对称密码体制, 签名算法受私钥控制,且由签名者保密. 验证算法受公玥控制,且对外公开.\nRSA算法既是最为常用的非对称加密算法,又是最为常用的签名算法.DSA算法是典型的数字签名算法,其本身属于非对称加密算法不具备数据加密与解密的功能.\n数字签名满足以下三个基本要求\n* 签名者任何时候都无法否认自己曾经签发的数字签名.\n* 信息接受者能够验证和确认收到的数字签名,但任何人无法伪造信息发送者的数字签名.\n* 当收发双发对数字签名的真伪产生争议时,可通过仲裁机构进行仲裁.\n\n![数字签名认证流程]()\n\n暂定甲方拥有私钥并且奖罚将公玥发布给乙方, 当甲方作为消息的发送方时, 甲方使用私钥对消息做签名处理,然后将加密的消息连同数字签名发送给乙方.乙方使用已获得的公玥对接收到的加密消息做解密处理,然后使用公玥及数字签名对原始消息做验证处理.\n\n当然我们可以对消息先加密,然后对加密后的消息做签名处理,这样乙方获得消息后,先做验证处理,如果验证通过则对消息解密.反之,验证消息失败则抛弃消息.这样做显然可以提高系统的处理速度,但即便如此,仍建议大家先对消息做签名,再做加密处理.加密与签名都应该只针对原始消息做处理.加密是为了确保消息在传送过程中避免被破解,签名是为了确保消息的有效性.消息本身就可能是一个可执行文件,消息的接收方通过对消息的验证判断该文件是由有权执行,而这个文件本身是不需要加密的.\n\n由于签名的不可伪造,甲方不能否认自己已经发送的消息,而乙方可验证消息的来源以及消息是否完整.数字签名可提供OSI参考模型5种安全服务中的3种：认证服务,抗否认性服务,数据完整性服务. 正因为如此,数字签名称为公玥基础设施以及许多网络安全机制的基础.\n\n当乙方作为发送方,通过公玥将消息加密后发送给甲方时,由于算法,公玥公开,任何一个已获得公玥的窃密者都可以截获乙方发送的消息,替换成自己的消息发送给甲方,而甲方无法辨别消息来源是否是乙方.也就是说,上述的认证方式是单向的,属于单向认证. 如果拥有俩套公私玥,甲乙双方都对数据做签名及验证就可以避免这一问题. 没错这种认证方式是双向认证.以网银交易事宜的都是单向认证方式,无法验证使用者的身份. 而要求较高的网银交易都是双向认证方式,交易双方身份都可以得到验证.\n\n# 公玥基础设施\n\n公钥基础设施（Public Key Infrastructure,PKI）是一个基于X.509的、用于创建、分配和撤回证书的模型.PKI能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系.换言之,PKI利用公钥密码技术构建基础设施,为网上电子商务、电子政务等应用提供安全服务.PKI技术是信息安全技术的核心,也是电子商务的关键和基础技术.如今大家所熟悉的网银交易系统就是PKI技术的具体体现.\n\nPKI由公钥密码技术、数字证书、证书认证中心和关于公钥的安全策略等基本成分共同组成,对密钥和证书进行管理.因此,PKI技术涉及对称加密算法、非对称加密算法、消息摘要算法和数字签名等密码学算法.\n\n我们目前所使用到的电子商务平台大部分都是基于PKI技术实现的.\n\n## 2.9.1 PKI的标准\n\nRSA公司定义了PKCS（Public Key Cryptography Standards,公钥加密标准）,并定义了许多PKI基础组件,如数字签名和证书请求格式；IETF（Internet Engineering Task Force,互联网工程任务组）和PKIWG（Public Key Infrastructure Working Group,PKI工作组）定义了一组具有可操作性的公钥基础设施协议PKIX（Public Key Infrastructure Using X.509,公钥基础设施X.509）.\n\n## PKCS共有15项标准:\n\n1. PKCS#1：RSA公钥算法加密和签名机制\n2. PKCS#3：DH密钥交换协议\n3. PKCS#5：PBE加密标准\n4. PKCS#6：公钥证书（X.509证书的扩展格式）标准语法\n5. PKCS#7：加密消息语法标准\n6. PKCS#8：私钥信息格式\n7. PKCS#9：选择属性格式\n8. PKCS#10：证书请求语法\n9. PKCS#11：密码装置标准接口\n10. PKCS#12：个人信息交换语法标准\n11. PKCS#13：椭圆曲线密码体制标准\n12. PKCS#14：伪随机数生成标准\n13. PKCS#15：密码令牌信息格式标准\n\n其中,PKCS#2和PKCS#4标准已被撤销,合并至PKCS#1中；较为常用的是PKCS#7、PKCS#10和PKCS#12.\n\n上述标准主要用于用户实体通过注册机构（RA）进行证书申请、用户证书更新等过程.当证书作废时,注册机构通过认证中心向目录服务器发布证书撤销列表.上述标准还用于扩展证书内容、数字签名、数字签名验证和定义数字信封格式等情况.在构建密钥填充方式时,考虑到不同的安全等级,也会选择不同PKCS标准.\n\nPKIX作为操作性标准涉及证书管理协议(Certificate Management Protocol,CMP)、安全多用途邮件扩展（S/MIME）和在线证书状态协议（Online Certificate Status Protocol,OCSP）等.\n\n### PKI系统的组成\n\nPKI系统由认证中心（Certificate Authority,CA）、数字证书库（Certificate Repository,CR）、密钥备份及恢复系统、证书作废系统,以及应用程序接口（Application Programming Interface,API）五部分组成.其中,认证中心CA和数字证书库是PKI技术的核心.\n\n1. 认证中心\n\nCA是PKI的核心之一,是数字证书的申请及签发机构,且机构必须具有权威性,以确保公钥管理公开透明.\n\n### 认证中心的主要功能如下：\n* 证书发放\n* 证书更新\n* 证书撤销\n* 证书验证\n\n认证中心主要由注册服务器、注册机构（Registry Authority,RA）,和认证中心服务器三部分组成.\n\n2. 数字证书库. 数字证书库用于存储已签发的数字证书及公钥,包括LDAP（Light Direct Access Protocol,轻量级目录访问协议）目录服务器和普通数据库.用户可通过数字证书库进行证书查询,并可获得其他用户的证书及公钥.\n\n3. 密钥备份及恢复系统. 若用户丢失密钥则无法对数据解密,这将造成数据的丢失.为避免此类情况,PKI技术提供密钥备份及恢复功能.密钥的备份与恢复需要可信的权威机构来完成,这也是认证机构存在的必要条件.\n\n4. 证书作废系统. 为了确保证书的有效性,证书具有使用时效性,以确保证书所属环境的安全性.从另一个角度来讲,如果证书持有机构存在一定的安全性问题,即便证书未超过有效期,亦需要作废.PKI技术通过将证书列入作废证书列表（Certificate Revocation List,CRL）来完成证书作废操作.用户可以通过查询CRL来验证证书的有效性.\n\n5. 应用程序接口API. PKI技术必须提供良好的应用程序接口,使得各式各样的应用,不同的系统架构都能以安全、一致、可信的方式与PKI进行交互,且能快速完成交互过程,以确保安全网络环境的完整性和易用性.\n\n### 数字证书\n\n数字证书是网络用户的身份标表,包含ID、公钥和颁发机构的数字签名等内容.其形式主要有X.509公钥证书、SPKI（Simple Public Key Infrastructure,简单PKI）证书、PGP（Pretty Good Privacy,译为“很好的私密”）证书和属性（Attribute）证书.其中,X.509证书最为常见.我们俗称的数字证书,通常指的是X.509公钥证书.\n\n目前,我们所使用的X.509证书通常由VeriSign、GeoTrust和Thawte三大国际权威认证机构签发.VeriSign由RSA控股,借助RSA成熟的安全技术提供了较为广泛的PKI产品,其产品活跃在电子商务平台中.当我们在淘宝或者亚马逊上购物时,总能看到熟悉的VeriSign字样.\n\n由于证书存在时效性,证书持有机构需要定期向认证机构申请证书签发.根据证书持有机构的证书使用范畴,认证机构会对不同的证书签发收取不同的费用.由此,证书持有机构需要每年向认证机构缴纳高额的年费.为了加强系统安全性,证书的密钥长度也会随着其费用递增.其中,价格最高的是商业网站的证书认证费用.上述的费用是认证机构得以生存的经济来源,同时也是电子商务平台等机构构建系统架构必须支付的安全成本之一.\n\n\n# RSACoder\n```java\n\n/**\n * RSA安全编码组件\n * \n */\npublic abstract class RSACoder {\n\t\n\t/**\n\t * 数字签名\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"RSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withRSA\";\n\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"RSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"RSAPrivateKey\";\n\n\t/**\n\t * RSA密钥长度 默认1024位，\n\t *  密钥长度必须是64的倍数， \n\t *  范围在512至65536位之间。\n\t */\n\tprivate static final int KEY_SIZE = 512;\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t * @return\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥对儿 Map\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator keyPairGen = KeyPairGenerator\n\t\t\t\t.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkeyPairGen.initialize(KEY_SIZE);\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keyPair = keyPairGen.generateKeyPair();\n\n\t\t// 公钥\n\t\tRSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic();\n\n\t\t// 私钥\n\t\tRSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> keyMap = new HashMap<String, Object>(2);\n\n\t\tkeyMap.put(PUBLIC_KEY, publicKey);\n\t\tkeyMap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn keyMap;\n\t}\n}\n```\n\n# ECDSACoder\n---\n```java\n\n/**\n * ECDSA安全编码组件\n * \n */\npublic enum ECDSACoder {\n\n\tNONEwithECDSA(\"NONEwithECDSA\"), \n\tRIPEMD160withECDSA(\"RIPEMD160withECDSA\"), \n\tSHA1withECDSA(\"SHA1withECDSA\"),   \n\tSHA224withECDSA(\"SHA224withECDSA\"),  \n\tSHA256withECDSA(\"SHA256withECDSA\"),\n\tSHA384withECDSA(\"SHA384withECDSA\"), \n\tSHA512withECDSA(\"SHA512withECDSA\");\n\t\n\t/**\n\t * 数字签名 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"ECDSA\";\n\n\tECDSACoder(String algo) {\n\t\tthis.SIGNATURE_ALGORITHM = algo;\n\t}\n\t\n\tprivate String SIGNATURE_ALGORITHM ;\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate final String PUBLIC_KEY = \"ECDSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate final String PRIVATE_KEY = \"ECDSAPrivateKey\";\n\n\t/**\n\t * 初始化密钥\n\t * \n\t * @return Map 密钥Map\n\t * @throws Exception\n\t */\n\tpublic Map<String, Object> initKey() throws Exception {\n\n\t\tBigInteger p = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308885314476597252960362792450860609699839\");\n \n\t\tECFieldFp ecFieldFp = new ECFieldFp(p);\n\n\t\tBigInteger a = new BigInteger(\n\t\t\t\t\"7fffffffffffffffffffffff7fffffffffff8000000000007ffffffffffc\",\n\t\t\t\t16);\n \n\t\tBigInteger b = new BigInteger(\n\t\t\t\t\"6b016c3bdcf18941d0d654921475ca71a9db2fb27d1d37796185c2942c0a\",\n\t\t\t\t16);\n \n\t\tEllipticCurve ellipticCurve = new EllipticCurve(ecFieldFp, a, b);\n\n\t\tBigInteger x = new BigInteger(\n\t\t\t\t\"110282003749548856476348533541186204577905061504881242240149511594420911\");\n \n\t\tBigInteger y = new BigInteger(\n\t\t\t\t\"869078407435509378747351873793058868500210384946040694651368759217025454\");\n \n\t\tECPoint g = new ECPoint(x, y);\n\n\t\tBigInteger n = new BigInteger(\n\t\t\t\t\"883423532389192164791648750360308884807550341691627752275345424702807307\");\n\n\t\tECParameterSpec ecParameterSpec = new ECParameterSpec(ellipticCurve, g,\n\t\t\t\tn, 1);\n\n\t\t// 实例化密钥对儿生成器\n\t\tKeyPairGenerator kpg = KeyPairGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化密钥对儿生成器\n\t\tkpg.initialize(ecParameterSpec, new SecureRandom());\n\n\t\t// 生成密钥对儿\n\t\tKeyPair keypair = kpg.generateKeyPair();\n\n\t\tECPublicKey publicKey = (ECPublicKey) keypair.getPublic();\n\n\t\tECPrivateKey privateKey = (ECPrivateKey) keypair.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 取私钥匙对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM);\n\n\t\t// 生成公钥\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n}\n```\n\n# DSACoder\n---\n```java\n/**\n * DSA安全编码组件\n * \n */\npublic abstract class DSACoder {\n\n\t/**\n\t * 数字签名密钥算法\n\t */\n\tpublic static final String ALGORITHM = \"DSA\";\n\n\t/**\n\t * 数字签名\n\t * 签名/验证算法\n\t */\n\tpublic static final String SIGNATURE_ALGORITHM = \"SHA1withDSA\";\n\t\n\t/**\n\t * 公钥\n\t */\n\tprivate static final String PUBLIC_KEY = \"DSAPublicKey\";\n\n\t/**\n\t * 私钥\n\t */\n\tprivate static final String PRIVATE_KEY = \"DSAPrivateKey\";\n\t\n\t/**\n\t * DSA密钥长度 \n\t * 默认1024位， \n\t * 密钥长度必须是64的倍数， \n\t * 范围在512至1024位之间（含）\n\t */\n\tprivate static final int KEY_SIZE = 1024;\n\t\n\t/**\n\t * 签名\n\t * \n\t * @param data\n\t *            待签名数据\n\t * @param privateKey\n\t *            私钥\n\t * @return byte[] 数字签名\n\t * @throws Exception\n\t */\n\tpublic static byte[] sign(byte[] data, byte[] privateKey) throws Exception {\n\n\t\t// 还原私钥\n\t\t// 转换私钥材料\n\t\tPKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(privateKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成私钥对象\n\t\tPrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec);\n\n\t\t// 实例化Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initSign(priKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 签名\n\t\treturn signature.sign();\n\t}\n\n\t/**\n\t * 校验\n\t * \n\t * @param data\n\t *            待校验数据\n\t * @param publicKey\n\t *            公钥\n\t * @param sign\n\t *            数字签名\n\t * \n\t * @return boolean 校验成功返回true 失败返回false\n\t * @throws Exception\n\t * \n\t */\n\tpublic static boolean verify(byte[] data, byte[] publicKey, byte[] sign)\n\t\t\tthrows Exception {\n\n\t\t// 还原公钥\n\t\t// 转换公钥材料\n\t\tX509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKey);\n\n\t\t// 实例化密钥工厂\n\t\tKeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM);\n\n\t\t// 取公钥匙对象\n\t\tPublicKey pubKey = keyFactory.generatePublic(keySpec);\n\n\t\t// 实例话Signature\n\t\tSignature signature = Signature.getInstance(SIGNATURE_ALGORITHM);\n\n\t\t// 初始化Signature\n\t\tsignature.initVerify(pubKey);\n\n\t\t// 更新\n\t\tsignature.update(data);\n\n\t\t// 验证\n\t\treturn signature.verify(sign);\n\t}\n\n\t/**\n\t * 生成密钥\n\t * \n\t * @return 密钥对象\n\t * @throws Exception\n\t */\n\tpublic static Map<String, Object> initKey() throws Exception {\n\n\t\t// 初始化密钥对儿生成器\n\t\tKeyPairGenerator keygen = KeyPairGenerator.getInstance(ALGORITHM);\n\n\t\t// 实例化密钥对儿生成器\n\t\tkeygen.initialize(KEY_SIZE, new SecureRandom());\n\n\t\t// 实例化密钥对儿\n\t\tKeyPair keys = keygen.genKeyPair();\n\n\t\tDSAPublicKey publicKey = (DSAPublicKey) keys.getPublic();\n\n\t\tDSAPrivateKey privateKey = (DSAPrivateKey) keys.getPrivate();\n\n\t\t// 封装密钥\n\t\tMap<String, Object> map = new HashMap<String, Object>(2);\n\n\t\tmap.put(PUBLIC_KEY, publicKey);\n\t\tmap.put(PRIVATE_KEY, privateKey);\n\n\t\treturn map;\n\t}\n\n\t/**\n\t * 取得私钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 私钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPrivateKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PRIVATE_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n\n\t/**\n\t * 取得公钥\n\t * \n\t * @param keyMap\n\t *            密钥Map\n\t * @return byte[] 公钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] getPublicKey(Map<String, Object> keyMap)\n\t\t\tthrows Exception {\n\n\t\tKey key = (Key) keyMap.get(PUBLIC_KEY);\n\n\t\treturn key.getEncoded();\n\t}\n}\n```","slug":"java加密解密/数字证书实现","published":1,"updated":"2015-10-16T02:42:08.774Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxty003d0cuf29p3tq0k"},{"date":"2014-11-07T16:00:00.000Z","title":"对称加密","_content":"# 对称加密\n\n## 对称加密算法的由来\n目前可知的可通过Java语言实现的对称加密算法大约20多种. java7仅提供部分算法实现,如DES,DESede,AES,Blowfish以及RC2和RC4算法.其他算法通过第三方加密软件包Bouncy Castle实现.在对称加密算法中,DES最具有代表性,堪称典范; DESede是DES算法的变种; AES算法则作为DES算法的替代者;IDEA算法作为一种强加密算法,成为邮件加密软件PGP的核心算法之一.\n\n## 数据加密标准-DES\nDES算法和DESede算法统称为DES系列算法. DESede算法是基于DES算法进行三重迭代,增加了算法的安全性.1998年,实用化DES算法破译机的出现彻底宣告DES算法已不具备安全性. 1999年NIST版本新标准,规定\n\n## 分组密码\n下面介绍了分组密码的各种工作模式\n\n###  电子密码本模式-ECB\n![]()\n```\n优点：易于理解且简单易行;便于实现并行操作;没有误差产传递的问题\n缺点：不能隐藏明文模式,如果明文重复,则对于的密文也会重复,密文内容很容易被替换,重拍,删除,重放;\n对明文主动攻击的可能性较高\n用途：适用于加密密钥,随机数等短数据.例如安全地传递DES秘药,ECB是最合适的模式\n```\n\n###  密文连接模式-CBC\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCBC.jpg)\n```\n优点：密文连接模式加密后的密文上下文关联,即使在明文中出现重复的信息也不会产生相同的密文;\n密文内容如果被替换,重拍,删除,重放或网络传输过程中发生错误,后续密文即被破坏,\n无法完成还原;对明文的主动攻击性较低\n缺点：不利于并行计算,目前没有已知的并行运算算法;误差传递,如果在加密过程中发生错误,则错误将被无限放大,\n导致加密失败;需要初始化向量\n用途：可加密任意长度的数据;适用于计算产生检测数据完整性的消息认证码Mac\n```\n\n###  密文反馈模式-CFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCFB.jpg)\n```\n优点：隐藏了明文的模式,每一个分组的加密结果必受其前面所有分组内容的影响,即使出现许多次相同的明文,\n也均产生不同的密文;分组密码转化为流模式,可产生密钥流;可以及时加密传送小于分组的数据\n缺点：与CBC相似.不利于并行计算,目前没有已知的并行运算算法;存在误差传递,一个单元损坏影响多个单元;\n需要初始化向量.\n用途：因错误传播无界,可用于检查发现明文密文的篡改\n```\n\n###  输出反馈模式-OFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FOFB.jpg)\n```\n优点：隐藏了明文的模式;分组密码转化为流模式;无误差传递问题;可以及时加密传送小于分组的数据\n缺点：不利于并行计算;对明文的主动攻击是可能的,安全性较CFB差\n用途：适用于加密冗余性较大的数据,比如语音和图像数据\n```\n\n###  计数器模式-CTR\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCTR.jpg)\n```\n优点：可并行计算;安全性至少与CBC模式一样好;加密与解密仅涉及密码算法的加密\n缺点：没有错误传播,因此不易确保数据完整性\n用途：适用于各种加密应用\n```\n\n## 流密码\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E6%B5%81%E6%A8%A1%E5%BC%8F.jpg)\n```\n同步流密码\n自同步流密码\n主要用于军事和外交\n常用算法 ： RC4,  SEAL\n```\n\n# RCCoder\n```java\n\npublic enum RCCoder {\n\n\tINSTANCE;\n\t\n\tpublic byte[] encrypt(byte[] data) {\n\t\t\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\t\t\n\t\treturn encoded;\n\t}\n\t\n\tpublic byte[] decrypt(byte[] data) {\n\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\t\t\n\t\treturn encoded;\n\t}\n}\n```\n\n# PBECoder\n```java\n\n/**\n * PBE安全编码组件 * Java 6 支持以下任意一种算法\n */\npublic enum PBECoder {\n\n\tPBEWithMD5AndDES(\"PBEWithMD5AndDES\"), \n\tPBEWithMD5AndTripleDES(\"PBEWithMD5AndTripleDES\"), \n\tPBEWithSHA1AndDESede(\"PBEWithSHA1AndDESede\"), \n\tPBEWithSHA1AndRC2_40(\"PBEWithSHA1AndRC2_40\");\n\n\tPBECoder(String algothrim) {\n\t\tALGORITHM = algothrim;\n\t}\n\n\tpublic String ALGORITHM = \"PBEWithMD5AndTripleDES\";\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 盐初始化<br>\n\t * 盐长度必须为8字节\n\t * \n\t * @return byte[] 盐\n\t * @throws Exception\n\t */\n\tpublic byte[] initSalt() throws Exception {\n\n\t\tSecureRandom random = new SecureRandom();\n\n\t\treturn random.generateSeed(8);\n\t}\n\n\t/**\n\t * 转换密钥\n\t * \n\t * @param password\n\t *            密码\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(String password) throws Exception {\n\n\t\t// 密钥材料转换\n\t\tPBEKeySpec keySpec = new PBEKeySpec(password.toCharArray());\n\n\t\t// 实例化\n\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成密钥\n\t\tSecretKey secretKey = keyFactory.generateSecret(keySpec);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.ENCRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.DECRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n}\n```\n\n# IDEACoder\n```java\n\n/**\n * IDEA安全编码组件\n * \n */\npublic abstract class IDEACoder {\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"IDEA\";\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tpublic static final String CIPHER_ALGORITHM = \"IDEA/ECB/PKCS5Padding\";\n\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate static Key toKey(byte[] key) throws Exception {\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为解密模式\n\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为加密模式\n\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化\n\t\tKeyGenerator kg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化\n\t\tkg.init(128);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n}\n```\n\n# DESedeCoder\n\n```java\n\n/**\n * DESede安全编码组件\n * 加密/解密算法 / 工作模式 / 填充方式\n * Java 6支持PKCS5PADDING填充方式\n * Bouncy Castle支持PKCS7Padding填充方式\n */\npublic enum DESedeCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\t\n\tDESedeCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"DESede\";\n\n\tprivate String CIPHER_ALGORITHM = \"DESede/ECB/PKCS5Padding\";\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化DES密钥材料\n\t\tDESedeKeySpec dks = null;\n\t\ttry {\n\t\t\tdks = new DESedeKeySpec(key);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 实例化秘密密钥工厂\n\t\tSecretKeyFactory keyFactory = null;\n\t\ttry {\n\t\t\tkeyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (InvalidKeySpecException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/* \n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为解密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (IllegalStateException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/* \n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为加密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn null;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * DESede 要求密钥长度为 112位或168位\n\t\t */\n\t\tkg.init(168);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n}\n```\n\n# DESCoder\n\n```java\n\n/**\n * DES安全编码组件\n * 密钥算法 <br>\n * Java 6 只支持56bit密钥 <br>\n * Bouncy Castle 支持64bit密钥\n */\npublic enum DESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\t\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tDESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\tprivate final String KEY_ALGORITHM = \"DES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\t// 实例化DES密钥材料\n\t\t\tDESKeySpec dks = new DESKeySpec(key);\n\t\t\t// 实例化秘密密钥工厂\n\t\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t\t// 生成秘密密钥\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"toKey : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t\t\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"decrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn result;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * 加密数据在下面几种情况下,必须满足长度和倍数关系, 否则会抛出下面异常\n\t * CTS_NoPadding\tinput is too short!\n\t * CTS_PKCS5Padding\tinput is too short!\n\t * CBC_NoPadding\tInput length not multiple of 8 bytes\n\t * PCBC_NoPadding\tInput length not multiple of 8 bytes\n\t * ECB_NoPadding\tInput length not multiple of 8 bytes\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\t\t\t\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t\t\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"encrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * Java 6 只支持56bit密钥 <br>\n\t * Bouncy Castle 支持64bit密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t/*\n\t\t * 实例化密钥生成器\n\t\t * \n\t\t * 若要使用64bit密钥注意替换 将下述代码中的KeyGenerator.getInstance(CIPHER_ALGORITHM);\n\t\t * 替换为KeyGenerator.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM, \"BC\");\n\t\t} catch (NoSuchAlgorithmException | NoSuchProviderException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * 初始化密钥生成器 若要使用64bit密钥注意替换 将下述代码kg.init(56); 替换为kg.init(64);\n\t\t */\n\t\tkg.init(64, new SecureRandom());\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n\n}\n```\n\n# AESCoder\n\n```java\n\n/**\n * AES安全编码组件\n * \n */\npublic enum AESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\t;\n\t\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式 \n\t * Java 6支持PKCS5Padding填充方式 \n\t * Bouncy Castle支持PKCS7Padding填充方式\n\t */\n\tAESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"AES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key 二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化AES密钥材料\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data 待解密数据\n\t * @param key 密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化 \n\t\t * 使用PKCS7Padding填充方式，按如下方式实现 \n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - decrypt - \" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data 待加密数据\n\t * @param key 密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化 \n\t\t * 使用PKCS7Padding填充方式，按如下方式实现\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - encrypt - \" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"  \" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * AES 要求密钥长度为 128位、192位或 256位\n\t\t */\n\t\tkg.init(256);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n}\n```\n\n","source":"_posts/java加密解密/对称加密.md","raw":"category: java加密解密\ndate: 2014-11-08\ntitle: 对称加密\n---\n# 对称加密\n\n## 对称加密算法的由来\n目前可知的可通过Java语言实现的对称加密算法大约20多种. java7仅提供部分算法实现,如DES,DESede,AES,Blowfish以及RC2和RC4算法.其他算法通过第三方加密软件包Bouncy Castle实现.在对称加密算法中,DES最具有代表性,堪称典范; DESede是DES算法的变种; AES算法则作为DES算法的替代者;IDEA算法作为一种强加密算法,成为邮件加密软件PGP的核心算法之一.\n\n## 数据加密标准-DES\nDES算法和DESede算法统称为DES系列算法. DESede算法是基于DES算法进行三重迭代,增加了算法的安全性.1998年,实用化DES算法破译机的出现彻底宣告DES算法已不具备安全性. 1999年NIST版本新标准,规定\n\n## 分组密码\n下面介绍了分组密码的各种工作模式\n\n###  电子密码本模式-ECB\n![]()\n```\n优点：易于理解且简单易行;便于实现并行操作;没有误差产传递的问题\n缺点：不能隐藏明文模式,如果明文重复,则对于的密文也会重复,密文内容很容易被替换,重拍,删除,重放;\n对明文主动攻击的可能性较高\n用途：适用于加密密钥,随机数等短数据.例如安全地传递DES秘药,ECB是最合适的模式\n```\n\n###  密文连接模式-CBC\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCBC.jpg)\n```\n优点：密文连接模式加密后的密文上下文关联,即使在明文中出现重复的信息也不会产生相同的密文;\n密文内容如果被替换,重拍,删除,重放或网络传输过程中发生错误,后续密文即被破坏,\n无法完成还原;对明文的主动攻击性较低\n缺点：不利于并行计算,目前没有已知的并行运算算法;误差传递,如果在加密过程中发生错误,则错误将被无限放大,\n导致加密失败;需要初始化向量\n用途：可加密任意长度的数据;适用于计算产生检测数据完整性的消息认证码Mac\n```\n\n###  密文反馈模式-CFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCFB.jpg)\n```\n优点：隐藏了明文的模式,每一个分组的加密结果必受其前面所有分组内容的影响,即使出现许多次相同的明文,\n也均产生不同的密文;分组密码转化为流模式,可产生密钥流;可以及时加密传送小于分组的数据\n缺点：与CBC相似.不利于并行计算,目前没有已知的并行运算算法;存在误差传递,一个单元损坏影响多个单元;\n需要初始化向量.\n用途：因错误传播无界,可用于检查发现明文密文的篡改\n```\n\n###  输出反馈模式-OFB\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FOFB.jpg)\n```\n优点：隐藏了明文的模式;分组密码转化为流模式;无误差传递问题;可以及时加密传送小于分组的数据\n缺点：不利于并行计算;对明文的主动攻击是可能的,安全性较CFB差\n用途：适用于加密冗余性较大的数据,比如语音和图像数据\n```\n\n###  计数器模式-CTR\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E5%88%86%E7%BB%84%E6%A8%A1%E5%BC%8FCTR.jpg)\n```\n优点：可并行计算;安全性至少与CBC模式一样好;加密与解密仅涉及密码算法的加密\n缺点：没有错误传播,因此不易确保数据完整性\n用途：适用于各种加密应用\n```\n\n## 流密码\n![](https://raw.githubusercontent.com/wanggnim/blog-website/images/secure/%E6%B5%81%E6%A8%A1%E5%BC%8F.jpg)\n```\n同步流密码\n自同步流密码\n主要用于军事和外交\n常用算法 ： RC4,  SEAL\n```\n\n# RCCoder\n```java\n\npublic enum RCCoder {\n\n\tINSTANCE;\n\t\n\tpublic byte[] encrypt(byte[] data) {\n\t\t\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\t\t\n\t\treturn encoded;\n\t}\n\t\n\tpublic byte[] decrypt(byte[] data) {\n\n\t\tbyte[] encoded = new byte[data.length];\n\t\tfor(int i = 0; i < data.length; i++) {\n\t\t\tencoded[i] = (byte) ((data[i]) ^ (byte)'a');\n\t\t}\n\t\t\n\t\treturn encoded;\n\t}\n}\n```\n\n# PBECoder\n```java\n\n/**\n * PBE安全编码组件 * Java 6 支持以下任意一种算法\n */\npublic enum PBECoder {\n\n\tPBEWithMD5AndDES(\"PBEWithMD5AndDES\"), \n\tPBEWithMD5AndTripleDES(\"PBEWithMD5AndTripleDES\"), \n\tPBEWithSHA1AndDESede(\"PBEWithSHA1AndDESede\"), \n\tPBEWithSHA1AndRC2_40(\"PBEWithSHA1AndRC2_40\");\n\n\tPBECoder(String algothrim) {\n\t\tALGORITHM = algothrim;\n\t}\n\n\tpublic String ALGORITHM = \"PBEWithMD5AndTripleDES\";\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 盐初始化<br>\n\t * 盐长度必须为8字节\n\t * \n\t * @return byte[] 盐\n\t * @throws Exception\n\t */\n\tpublic byte[] initSalt() throws Exception {\n\n\t\tSecureRandom random = new SecureRandom();\n\n\t\treturn random.generateSeed(8);\n\t}\n\n\t/**\n\t * 转换密钥\n\t * \n\t * @param password\n\t *            密码\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(String password) throws Exception {\n\n\t\t// 密钥材料转换\n\t\tPBEKeySpec keySpec = new PBEKeySpec(password.toCharArray());\n\n\t\t// 实例化\n\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(ALGORITHM);\n\n\t\t// 生成密钥\n\t\tSecretKey secretKey = keyFactory.generateSecret(keySpec);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.ENCRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            数据\n\t * @param password\n\t *            密码\n\t * @param salt\n\t *            盐\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, String password, byte[] salt)\n\t\t\tthrows Exception {\n\n\t\t// 转换密钥\n\t\tKey key = toKey(password);\n\n\t\t// 实例化PBE参数材料\n\t\tPBEParameterSpec paramSpec = new PBEParameterSpec(salt, 100);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(ALGORITHM);\n\n\t\t// 初始化\n\t\tcipher.init(Cipher.DECRYPT_MODE, key, paramSpec);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\n\t}\n\n}\n```\n\n# IDEACoder\n```java\n\n/**\n * IDEA安全编码组件\n * \n */\npublic abstract class IDEACoder {\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"IDEA\";\n\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tpublic static final String CIPHER_ALGORITHM = \"IDEA/ECB/PKCS5Padding\";\n\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate static Key toKey(byte[] key) throws Exception {\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] decrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为解密模式\n\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic static byte[] encrypt(byte[] data, byte[] key) throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t// 实例化\n\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\n\t\t// 初始化，设置为加密模式\n\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\n\t\t// 执行操作\n\t\treturn cipher.doFinal(data);\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic static byte[] initKey() throws Exception {\n\n\t\t// 加入BouncyCastleProvider支持\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\n\t\t// 实例化\n\t\tKeyGenerator kg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\n\t\t// 初始化\n\t\tkg.init(128);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n}\n```\n\n# DESedeCoder\n\n```java\n\n/**\n * DESede安全编码组件\n * 加密/解密算法 / 工作模式 / 填充方式\n * Java 6支持PKCS5PADDING填充方式\n * Bouncy Castle支持PKCS7Padding填充方式\n */\npublic enum DESedeCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\t\n\tDESedeCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\t/**\n\t * 密钥算法\n\t */\n\tprivate final String KEY_ALGORITHM = \"DESede\";\n\n\tprivate String CIPHER_ALGORITHM = \"DESede/ECB/PKCS5Padding\";\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化DES密钥材料\n\t\tDESedeKeySpec dks = null;\n\t\ttry {\n\t\t\tdks = new DESedeKeySpec(key);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 实例化秘密密钥工厂\n\t\tSecretKeyFactory keyFactory = null;\n\t\ttry {\n\t\t\tkeyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (InvalidKeySpecException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/* \n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为解密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (IllegalStateException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/* \n\t\t * 实例化\n\t\t * 使用PKCS7Padding填充方式\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tCipher cipher = null;\n\t\ttry {\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (NoSuchPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 初始化，设置为加密模式\n\t\ttry {\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t} catch (InvalidKeyException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t// 执行操作\n\t\ttry {\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (IllegalBlockSizeException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t} catch (BadPaddingException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn null;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * DESede 要求密钥长度为 112位或168位\n\t\t */\n\t\tkg.init(168);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n}\n```\n\n# DESCoder\n\n```java\n\n/**\n * DES安全编码组件\n * 密钥算法 <br>\n * Java 6 只支持56bit密钥 <br>\n * Bouncy Castle 支持64bit密钥\n */\npublic enum DESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\tOFB_NoPadding(WorkModel.OFB, Padding.NoPadding),\n\tOFB_PKCS5Padding(WorkModel.OFB, Padding.PKCS5Padding),\n\tOFB_ISO10126Padding(WorkModel.OFB, Padding.ISO10126Padding),\n\t;\n\t\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式\n\t */\n\tDESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\tprivate final String KEY_ALGORITHM = \"DES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key\n\t *            二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\tSecretKey secretKey = null;\n\t\ttry {\n\t\t\t// 实例化DES密钥材料\n\t\t\tDESKeySpec dks = new DESKeySpec(key);\n\t\t\t// 实例化秘密密钥工厂\n\t\t\tSecretKeyFactory keyFactory = SecretKeyFactory.getInstance(KEY_ALGORITHM);\n\t\t\t// 生成秘密密钥\n\t\t\tsecretKey = keyFactory.generateSecret(dks);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"toKey : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data\n\t *            待解密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t\t\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"decrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn result;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * 加密数据在下面几种情况下,必须满足长度和倍数关系, 否则会抛出下面异常\n\t * CTS_NoPadding\tinput is too short!\n\t * CTS_PKCS5Padding\tinput is too short!\n\t * CBC_NoPadding\tInput length not multiple of 8 bytes\n\t * PCBC_NoPadding\tInput length not multiple of 8 bytes\n\t * ECB_NoPadding\tInput length not multiple of 8 bytes\n\t * \n\t * @param data\n\t *            待加密数据\n\t * @param key\n\t *            密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\t// 还原密钥\n\t\t\tKey k = toKey(key);\n\t\t\t\n\t\t\t// 实例化\n\t\t\tCipher cipher;\n\t\t\tcipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t\t\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(\"encrypt : \" + this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * Java 6 只支持56bit密钥 <br>\n\t * Bouncy Castle 支持64bit密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initEncodedSecretKey() {\n\n\t\t/*\n\t\t * 实例化密钥生成器\n\t\t * \n\t\t * 若要使用64bit密钥注意替换 将下述代码中的KeyGenerator.getInstance(CIPHER_ALGORITHM);\n\t\t * 替换为KeyGenerator.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM, \"BC\");\n\t\t} catch (NoSuchAlgorithmException | NoSuchProviderException e) {\n\t\t\tSystem.out.println(this + \"\\t\" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * 初始化密钥生成器 若要使用64bit密钥注意替换 将下述代码kg.init(56); 替换为kg.init(64);\n\t\t */\n\t\tkg.init(64, new SecureRandom());\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n\n}\n```\n\n# AESCoder\n\n```java\n\n/**\n * AES安全编码组件\n * \n */\npublic enum AESCoder {\n\n\tECB_NoPadding(WorkModel.ECB, Padding.NoPadding),\n\tECB_PKCS5Padding(WorkModel.ECB, Padding.PKCS5Padding),\n\tECB_ISO10126Padding(WorkModel.ECB, Padding.ISO10126Padding),\n\tCBC_NoPadding(WorkModel.CBC, Padding.NoPadding),\n\tCBC_PKCS5Padding(WorkModel.CBC, Padding.PKCS5Padding),\n\tCBC_ISO10126Padding(WorkModel.CBC, Padding.ISO10126Padding),\n\tPCBC_NoPadding(WorkModel.PCBC, Padding.NoPadding),\n\tPCBC_PKCS5Padding(WorkModel.PCBC, Padding.PKCS5Padding),\n\tPCBC_ISO10126Padding(WorkModel.PCBC, Padding.ISO10126Padding),\n\tCTR_NoPadding(WorkModel.CTR, Padding.NoPadding),\n\tCTR_PKCS5Padding(WorkModel.CTR, Padding.PKCS5Padding),\n\tCTR_ISO10126Padding(WorkModel.CTR, Padding.ISO10126Padding),\n\tCTS_NoPadding(WorkModel.CTS, Padding.NoPadding),\n\tCTS_PKCS5Padding(WorkModel.CTS, Padding.PKCS5Padding),\n\tCTS_ISO10126Padding(WorkModel.CTS, Padding.ISO10126Padding),\n\tCFB_NoPadding(WorkModel.CFB, Padding.NoPadding),\n\tCFB_PKCS5Padding(WorkModel.CFB, Padding.PKCS5Padding),\n\tCFB_ISO10126Padding(WorkModel.CFB, Padding.ISO10126Padding),\n\t;\n\t\n\t/**\n\t * 加密/解密算法 / 工作模式 / 填充方式 \n\t * Java 6支持PKCS5Padding填充方式 \n\t * Bouncy Castle支持PKCS7Padding填充方式\n\t */\n\tAESCoder(WorkModel workModel, Padding padding) {\n\t\tCIPHER_ALGORITHM = KEY_ALGORITHM + \"/\" + workModel.name() + \"/\" + padding.name();\n\t\tthis.padding = padding;\n\t\tthis.workModel = workModel;\n\t}\n\t\n\t{\n\t\tSecurity.addProvider(new BouncyCastleProvider());\n\t}\n\t\n\tprivate Padding padding;\n\tprivate WorkModel workModel;\n\t\n\t/**\n\t * 密钥算法\n\t */\n\tpublic static final String KEY_ALGORITHM = \"AES\";\n\n\tprivate String CIPHER_ALGORITHM;\n\n\t/**\n\t * 转换密钥\n\t * \n\t * @param key 二进制密钥\n\t * @return Key 密钥\n\t * @throws Exception\n\t */\n\tprivate Key toKey(byte[] key) {\n\n\t\t// 实例化AES密钥材料\n\t\tSecretKey secretKey = new SecretKeySpec(key, KEY_ALGORITHM);\n\n\t\treturn secretKey;\n\t}\n\n\t/**\n\t * 解密\n\t * \n\t * @param data 待解密数据\n\t * @param key 密钥\n\t * @return byte[] 解密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] decrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化 \n\t\t * 使用PKCS7Padding填充方式，按如下方式实现 \n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为解密模式\n\t\t\tcipher.init(Cipher.DECRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\treturn cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - decrypt - \" + e.getMessage());\n\t\t}\n\n\t\treturn null;\n\t}\n\n\t/**\n\t * 加密\n\t * \n\t * @param data 待加密数据\n\t * @param key 密钥\n\t * @return byte[] 加密数据\n\t * @throws Exception\n\t */\n\tpublic byte[] encrypt(byte[] data, byte[] key) {\n\n\t\t// 还原密钥\n\t\tKey k = toKey(key);\n\n\t\t/*\n\t\t * 实例化 \n\t\t * 使用PKCS7Padding填充方式，按如下方式实现\n\t\t * Cipher.getInstance(CIPHER_ALGORITHM, \"BC\");\n\t\t */\n\t\tbyte[] result = null;\n\t\ttry {\n\t\t\tCipher cipher = Cipher.getInstance(CIPHER_ALGORITHM);\n\t\t\t// 初始化，设置为加密模式\n\t\t\tcipher.init(Cipher.ENCRYPT_MODE, k);\n\t\t\t// 执行操作\n\t\t\tresult = cipher.doFinal(data);\n\t\t} catch (final Exception e) {\n\t\t\tSystem.out.println(this + \" - encrypt - \" + e.getMessage());\n\t\t}\n\t\t\n\t\treturn result;\n\t}\n\n\t/**\n\t * 生成密钥 <br>\n\t * \n\t * @return byte[] 二进制密钥\n\t * @throws Exception\n\t */\n\tpublic byte[] initKey() {\n\n\t\t// 实例化\n\t\tKeyGenerator kg = null;\n\t\ttry {\n\t\t\tkg = KeyGenerator.getInstance(KEY_ALGORITHM);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\tSystem.out.println(this + \"  \" + e.getMessage());\n\t\t}\n\n\t\t/*\n\t\t * AES 要求密钥长度为 128位、192位或 256位\n\t\t */\n\t\tkg.init(256);\n\n\t\t// 生成秘密密钥\n\t\tSecretKey secretKey = kg.generateKey();\n\n\t\t// 获得密钥的二进制编码形式\n\t\treturn secretKey.getEncoded();\n\t}\n\t\n}\n```\n\n","slug":"java加密解密/对称加密","published":1,"updated":"2015-10-16T02:41:57.630Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxu0003f0cufx1dppnyr"},{"date":"2014-11-07T16:00:00.000Z","title":"Java加密","_content":"# Java加密\n\n## Java安全领域组成部分\n\nJava安全领域总共分为4个部分:\n* `JCA`(`Java Cryptography Architecture`,Java加密体系结构). JCA提供基本的加密框架,如证书、数字签名、消息摘要和密钥对产生器.\n\n* `JCE`(`Java Cryptography Extension`,Java加密扩展包).JCE在JCA的基础上作了扩展,提供了各种加密算法、消息摘要算法和密钥管理等功能.我们已经有所了解的DES算法、AES算法、RSA算法、DSA算法等就是通过JCE来提供的.有关JCE的实现主要在javax.crypto包(及其子包)中.\n\n* `JSSE`(`Java Secure Sockets Extension`,Java安全套接字扩展包). JSSE提供了基于SSL(Secure Sockets Layer,安全套接字层)的加密功能.在网络的传输过程中,信息会经过多个主机(很有可能其中一台就被窃听),最终传送给接收者,这是不安全的.这种确保网络通信安全的服务就是由JSSE来提供的.\n\n* `JAAS`(`Java Authentication and Authentication Service`,Java鉴别与安全服务).JAAS提供了在Java平台上进行用户身份鉴别的功能.如何提供一个符合标准安全机制的登录模块,通过可配置的方式集成至各个系统中呢？这是由JAAS来提供的.\n\nJCA和JCE是Java平台提供的用于安全和加密服务的两组API.它们并不执行任何算法,它们只是连接应用和实际算法实现程序的一组接口.软件开发商可以根据JCE接口(又称安全提供者接口)将各种算法实现后,打包成一个Provider(安全提供者),动态地加载到Java运行环境中.\n\n根据美国出口限制规定,JCA可出口(JCA和Sun的一些默认实现包含在Java发行版中),但JCE对部分国家是限制出口的.因此,要实现一个完整的安全结构,就需要一个或多个第三方厂商提供的JCE产品,称为安全提供者.BouncyCastle JCE就是其中的一个安全提供者.\n\n安全提供者是承担特定安全机制实现的第三方.有些提供者是完全免费的,而另一些提供者则需要付费.提供安全提供者的公司有Sun、Bouncy Castle等,Sun提供了如何开发安全提供者的细节.Bouncy Castle提供了可以在J2ME/J2EE/J2SE平台得到支持的API,而且Bouncy Castle的API是免费的.\n\nJDK 1.4版本及其后续版本中包含了上述扩展包,无须进行配置.在此之前,安装JDK后需要对上述扩展包进行相应配置.\n\n##  安全提供者体系结构\n\nJava安全体系结构通过扩展的方式,加入了更多的算法实现及相应的安全机制.我们把这些提供者称为安全提供者(以下简称“提供者”).\n\n### 以下内容是JDK 1.7所提供的安全提供者的配置信息.\n* security.provider.1=sun.security.provider.Sun\n* security.provider.2=sun.security.rsa.SunRsaSign\n* security.provider.3=sun.security.ec.SunEC\n* security.provider.4=com.sun.net.ssl.internal.ssl.Provider\n* security.provider.5=com.sun.crypto.provider.SunJCE\n* security.provider.6=sun.security.jgss.SunProvider\n* security.provider.7=com.sun.security.sasl.Provider\n* security.provider.8=org.jcp.xml.dsig.internal.dom.XMLDSigRI\n* security.provider.9=sun.security.smartcardio.SunPCSC\n* security.provider.10=sun.security.mscapi.SunMSCAPI\n\n> 上述这些提供者均是`Provider`类(`java.security.Provider`)的子类.其中`sun.security.provider.Sun`是基本安全提供者,`sun.security.rsa.SunRsaSign`是实现RSA算法的提供者.\n>\n> 与上一版本对比,Java 7新增了EC算法安全提供者—`sun.security.ec.SunEC`,暗示在该版本中可能支持相应的算法实现.\n>\n> Java安全体系不仅支持来自Sun官方提供的安全提供者,同时也可配置第三方安全提供者以扩展相应的算法实现等.\n\n### 安全提供者实现了两个概念的抽象:\n* 引擎:\t可以理解为操作,如加密、解密等.\n* 算法: 定义了操作如何执行,如一个算法可以理解为一个引擎的具体实现.当然,一个算法可以有多种实现方式,这就意味着同一个算法可能与多个引擎的具体实现相对应.\n\n> 安全提供者接口的目的就是提供一个简单的机制,从而可以很方便地改变或替换算法及其实现.在实际开发中,程序员只需要用引擎类实现特定的操作,而不需要关心实际进行运算的类是哪一个.\n>\n> `Provider`类和`Security`类(`java.security.Security`)共同构成了安全提供者的概念.\n\n### 本文全貌\n\n* 主要详解了`java.security`包与`javax.crypto包`,这两个包中包含了Java加密与解密的核心部分.\n* 在`java.security.interfaces`包和`javax.crypto.interfaces`包中包含了密钥相关的接口.\n* 在`java.security.spec`包和`javax.crypto.spec`包中包含了密钥规范和算法参数规范的类和接口.\n\n#java7支持的算法\n## 消息摘要算法\n\n## MD系列\n* MD2             128位\n* MD5             128位\n\n## SHA系列\n* SHA-1           160位\n* SHA-256         256位\n* SHA-384         384位\n* SHA-512         512位\n\n## Hmac系列\n* HmacMD5        128位\n* HmacSHA1       160位\n* HmacSHA256     256位\n* HmacSHA384     384位\n* HmacSHA512     512位\n\n\n##  对称加密算法\n\n* DES\n```\n56(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* DESede\n```\n112,168(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* AES\n```\n128(默认值),192,256\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* Blowfish\n```\n32z至448(8的倍数,默认值128)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* RC2\n```\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n* RC4\n```\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n## 对称加密算法-PBE\n* PBEWithMD5AndDES\n```\n56\nCBC\nPKCS5Padding\n```\n* PBEWithMD5AndTripleDES\n```\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndRC2_40\n```\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndDESede\n```\n40至1024(8的整数倍,默认值128)\nCBC\nPKCS5Padding\n```\n## 非对称加密算法\n* DH\n```\n512-1024(64的整数倍)\n```\n* RSA\n```\n512-65536(64的整数倍)\nECB\n```\n* ECDH\n```\n112-571\n```\n\n","source":"_posts/java加密解密/Java加密.md","raw":"category: java加密解密\ndate: 2014-11-08\ntitle: Java加密\n---\n# Java加密\n\n## Java安全领域组成部分\n\nJava安全领域总共分为4个部分:\n* `JCA`(`Java Cryptography Architecture`,Java加密体系结构). JCA提供基本的加密框架,如证书、数字签名、消息摘要和密钥对产生器.\n\n* `JCE`(`Java Cryptography Extension`,Java加密扩展包).JCE在JCA的基础上作了扩展,提供了各种加密算法、消息摘要算法和密钥管理等功能.我们已经有所了解的DES算法、AES算法、RSA算法、DSA算法等就是通过JCE来提供的.有关JCE的实现主要在javax.crypto包(及其子包)中.\n\n* `JSSE`(`Java Secure Sockets Extension`,Java安全套接字扩展包). JSSE提供了基于SSL(Secure Sockets Layer,安全套接字层)的加密功能.在网络的传输过程中,信息会经过多个主机(很有可能其中一台就被窃听),最终传送给接收者,这是不安全的.这种确保网络通信安全的服务就是由JSSE来提供的.\n\n* `JAAS`(`Java Authentication and Authentication Service`,Java鉴别与安全服务).JAAS提供了在Java平台上进行用户身份鉴别的功能.如何提供一个符合标准安全机制的登录模块,通过可配置的方式集成至各个系统中呢？这是由JAAS来提供的.\n\nJCA和JCE是Java平台提供的用于安全和加密服务的两组API.它们并不执行任何算法,它们只是连接应用和实际算法实现程序的一组接口.软件开发商可以根据JCE接口(又称安全提供者接口)将各种算法实现后,打包成一个Provider(安全提供者),动态地加载到Java运行环境中.\n\n根据美国出口限制规定,JCA可出口(JCA和Sun的一些默认实现包含在Java发行版中),但JCE对部分国家是限制出口的.因此,要实现一个完整的安全结构,就需要一个或多个第三方厂商提供的JCE产品,称为安全提供者.BouncyCastle JCE就是其中的一个安全提供者.\n\n安全提供者是承担特定安全机制实现的第三方.有些提供者是完全免费的,而另一些提供者则需要付费.提供安全提供者的公司有Sun、Bouncy Castle等,Sun提供了如何开发安全提供者的细节.Bouncy Castle提供了可以在J2ME/J2EE/J2SE平台得到支持的API,而且Bouncy Castle的API是免费的.\n\nJDK 1.4版本及其后续版本中包含了上述扩展包,无须进行配置.在此之前,安装JDK后需要对上述扩展包进行相应配置.\n\n##  安全提供者体系结构\n\nJava安全体系结构通过扩展的方式,加入了更多的算法实现及相应的安全机制.我们把这些提供者称为安全提供者(以下简称“提供者”).\n\n### 以下内容是JDK 1.7所提供的安全提供者的配置信息.\n* security.provider.1=sun.security.provider.Sun\n* security.provider.2=sun.security.rsa.SunRsaSign\n* security.provider.3=sun.security.ec.SunEC\n* security.provider.4=com.sun.net.ssl.internal.ssl.Provider\n* security.provider.5=com.sun.crypto.provider.SunJCE\n* security.provider.6=sun.security.jgss.SunProvider\n* security.provider.7=com.sun.security.sasl.Provider\n* security.provider.8=org.jcp.xml.dsig.internal.dom.XMLDSigRI\n* security.provider.9=sun.security.smartcardio.SunPCSC\n* security.provider.10=sun.security.mscapi.SunMSCAPI\n\n> 上述这些提供者均是`Provider`类(`java.security.Provider`)的子类.其中`sun.security.provider.Sun`是基本安全提供者,`sun.security.rsa.SunRsaSign`是实现RSA算法的提供者.\n>\n> 与上一版本对比,Java 7新增了EC算法安全提供者—`sun.security.ec.SunEC`,暗示在该版本中可能支持相应的算法实现.\n>\n> Java安全体系不仅支持来自Sun官方提供的安全提供者,同时也可配置第三方安全提供者以扩展相应的算法实现等.\n\n### 安全提供者实现了两个概念的抽象:\n* 引擎:\t可以理解为操作,如加密、解密等.\n* 算法: 定义了操作如何执行,如一个算法可以理解为一个引擎的具体实现.当然,一个算法可以有多种实现方式,这就意味着同一个算法可能与多个引擎的具体实现相对应.\n\n> 安全提供者接口的目的就是提供一个简单的机制,从而可以很方便地改变或替换算法及其实现.在实际开发中,程序员只需要用引擎类实现特定的操作,而不需要关心实际进行运算的类是哪一个.\n>\n> `Provider`类和`Security`类(`java.security.Security`)共同构成了安全提供者的概念.\n\n### 本文全貌\n\n* 主要详解了`java.security`包与`javax.crypto包`,这两个包中包含了Java加密与解密的核心部分.\n* 在`java.security.interfaces`包和`javax.crypto.interfaces`包中包含了密钥相关的接口.\n* 在`java.security.spec`包和`javax.crypto.spec`包中包含了密钥规范和算法参数规范的类和接口.\n\n#java7支持的算法\n## 消息摘要算法\n\n## MD系列\n* MD2             128位\n* MD5             128位\n\n## SHA系列\n* SHA-1           160位\n* SHA-256         256位\n* SHA-384         384位\n* SHA-512         512位\n\n## Hmac系列\n* HmacMD5        128位\n* HmacSHA1       160位\n* HmacSHA256     256位\n* HmacSHA384     384位\n* HmacSHA512     512位\n\n\n##  对称加密算法\n\n* DES\n```\n56(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* DESede\n```\n112,168(默认值)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* AES\n```\n128(默认值),192,256\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* Blowfish\n```\n32z至448(8的倍数,默认值128)\nECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\nNoPadding,PKCS5Padding,ISO10126Padding\n```\n* RC2\n```\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n* RC4\n```\n40至1024(8的倍数,默认值128)\nECB\nNoPadding\n```\n## 对称加密算法-PBE\n* PBEWithMD5AndDES\n```\n56\nCBC\nPKCS5Padding\n```\n* PBEWithMD5AndTripleDES\n```\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndRC2_40\n```\n112,168(默认值)\nCBC\nPKCS5Padding\n```\n* PBEWithSHA1AndDESede\n```\n40至1024(8的整数倍,默认值128)\nCBC\nPKCS5Padding\n```\n## 非对称加密算法\n* DH\n```\n512-1024(64的整数倍)\n```\n* RSA\n```\n512-65536(64的整数倍)\nECB\n```\n* ECDH\n```\n112-571\n```\n\n","slug":"java加密解密/Java加密","published":1,"updated":"2015-10-16T02:42:01.583Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxu2003h0cuf8li8y7km"},{"date":"2015-09-07T16:00:00.000Z","title":"java8 流","_content":"# 流\njava8中新添加的流又称为`Streams API`. 它是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation).\n\n接下来我们构建一个流:\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .count();\n```\n我们通过上述代码构建流一个流,这里有俩个概念要说:\n* 惰性求值方法:像`filter`方法,它只是在刻画Stream,它并不会被调用.(在Stream方法中凡事返回Stream对象的都是这种方法)\n* 及早求值方法:像`count`方法,它会从Stream中最终产生值.(在Stream方法中凡事返回空或者另一个值都是这种方法)\n\n## 常用的流操作\n\n### collect()\n\n该方法会产生一个列表,是一个及早求值方法.\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .collect(Collectors.toList());\n```\n当然我们还可以调用`Collectors.toSet()`等其他方法,构建其他集合\n\n### map\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/map.jpg)\n该操作会将一个流中的值转换为一个新的流\n```java\nStream.of(1, 2, 3)\n      .map(num -> {\n          if (num > 1) {\n             return 0;\n          } else {\n             return 1;\n          }\n       })\n       .collect(Collectors.toSet())\n       .forEach(ele -> System.out.println(ele));\n```\n\n### filter\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/filter.jpg)\n遍历数据并检查其中的元素是否符合某种条件\n\n这个操作看起来和`map`很像, 但是`map`是根据操作的结果产生新的流,而`filter`是判断流中的数据是否符合条件保留下来\n```java\n Stream.of(1, 2, 3)\n                .filter(ele -> {\n                    if (ele > 1) {\n                        return true;\n                    } else {\n                        return false;\n                    }\n                })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n\n### flatMap\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/flatMap.jpg)\n用于Stream替换值然后将多个流连接到一起\n\n首先我们看一种情况,流里有俩个列表\n```\n Stream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n                \n输出的结果是:\n[1, 2, 3]\n[7, 8, 9]\n```\n如果我们想将这俩个列表组合到一起呢?\n```java\nStream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                    .flatMap(list -> {\n                        return list.stream();\n                    })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n看到了吧,我们首先讲列表转换成流,然后由`flatMap`操作将流组合到一起\n\n### max\n查找流中的最大值\n```java\nInteger max = Stream.of(1, 2, 3)\n                .max(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(max);\n```\n我们需要向`max`操作中传递一个排序的动作. `Comparator.comparing()`这个静态方法是java8新添加的方法,它实现流一个方便的比较器.以前我们需要比较俩个对象的某项属性的值,现在只需要提供一个取值方法就好了.\n\n\n### min\n查找流中的最小值\n```java\nInteger min = Stream.of(1, 2, 3)\n                .min(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(min);\n```\n和`max`相似\n\n\n### reduce\n从一组值生成一个值.\n```java\nInteger sum = Stream.of(1, 2, 3)\n                .reduce((inSum, element) -> {\n                    return inSum + element;\n                }).get();\n        System.out.println(sum);\n```\n`reduce`中的`BinaryOperator`类型的lambda表达式第一个参数是上个元素执行`reduce`操作的结果, 第二个参数是流中的每个元素. \n\n另外Stream中还有其他的`reduce`操作,可以指定开始结束的的位置\n\n\n# 元素顺序\n在一个有序集合中创建一个流时，流中元素就按照出现的顺序进行排列:\n```java\nArrays.asList(1, 2, 3).stream().forEach(ele -> System.out.println(ele));\n```\n上面这个输出顺序总是`1, 2, 3`.\n\n而如果一个集合本身是无序的话，那么生成的流也是无序的，最后由流生成的集合也是无序的\n\n\n# 使用收集器\n`java.util.stream.Collectors`这是java提供的一种通用的，从流生成复杂值结构的收集器.\n\n## 转换成其他集合\nCollectors提供了转换成其他集合的方式\n\n* `Collectors.toCollection()`： 接受一个函数作为参数，来创建集合\n* `Collectors.toConcurrentMap()`\n* `Collectors.toList()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n* `Collectors.toMap()`\n* `Collectors.toSet()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n\n## groupingBy\n数据分组\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\n\t\tMap<Integer, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\treturn 2;\n\t\t\t}\n\t\t}));\n\n// 最后结果为\n{1:[\n\t\t10,\n\t\t9,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\n 2:[\n\t\t1,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t4,\n\t\t5\n\t]\n}\n```\n当然分组的key,我们还可以取其他的类型,这完全取决于我们的返回值\n```java\nMap<String, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn \"1\";\n\t\t\t} else {\n\t\t\t\treturn \"2\";\n\t\t\t}\n\t\t}));\n```\n\n## groupingByConcurrent\n并发版本的`group by`实现\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nConcurrentMap<Integer, List<Integer>> result = list.stream().collect(Collectors.groupingByConcurrent(ele -> ele - 3));\n\n// 结果\n{-2:[1],\n -1:[\n\t\t2,\n\t\t2\n\t],\n  0:[3],\n  7:[10]\n}\n```\n\n## partitioningBy\n数据分组,key为`True`和`False`\n\nlambda表达式类型\n```java\npublic interface Predicate<T> {\n    boolean test(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nMap<Boolean, List<Integer>> result = list.stream().collect(Collectors.partitioningBy(ele -> ele == 1));\nSystem.out.println(JSON.toJSONString(result, true));\n\n// 结果为\n{false:[\n\t\t10,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t9,\n\t\t4,\n\t\t5,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\ntrue:[1]\n}\n```\n\n## averagingDouble\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingDouble(ele -> ele - 3));\n\n// 结果\n0.6\n```\n\n## averagingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingInt(ele -> ele - 3));\n// 结果\n0.6\n```\n\n## averagingLong\n对流中数据进行进行平均数操作\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.averagingLong(ele -> ele));\n```\n\n## summarizingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nIntSummaryStatistics result = list.stream().collect(Collectors.summarizingInt(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingLong\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLongSummaryStatistics result = list.stream().collect(Collectors.summarizingLong(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingDouble\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDoubleSummaryStatistics result = list.stream().collect(Collectors.summarizingDouble(ele -> ele));\n\n// 结果\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## counting\n统计流中数据数量\n\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.counting());\n```\n\n## maxBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.maxBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## minBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.minBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## summingDouble\n对列表数据取和操作,结果为`Double`\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.summingDouble(ele -> ele));\n// 结果为68\n\n```\n\n## summingInt\n对列表数据取和操作,结果为`Int`\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nInteger result = list.stream().collect(Collectors.summingInt(ele -> ele));\n```\n\n## summingLong\n对列表数据取和操作,结果为`Long`\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.summingLong(ele -> ele));\n```\n\n## joining\n将流中的数据拼接成一个字符串. 需要注意的是如果流中的数据不是`String`类型的数据,可以通过`map`操作将流中数据转换成`String`类型\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nString result = list.stream().collect(Collectors.joining(\",\", \"(\", \")\"));\n// 结果\n\"(1,10,2,3,2)\"\n```\n\n## reducing\n\nlambda表达式类型\n```java\nR apply(T t, U u);\n```\n示例：\n```java\n\n```\n\n\n## mapping\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nList<String> result = list.stream().collect(Collectors.mapping(ele -> ele + 1, Collectors.toList()));\n// 结果\n[\n\t\"11\",\n\t\"101\",\n\t\"21\",\n\t\"31\",\n\t\"21\"\n]\n```\n\n## distinct\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/distinct.jpg)\n\n## limit\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/limit.jpg)\n\n## peek\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/peek.jpg)\n\n## skip\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/skip.jpg)","source":"_posts/java8/java8 流.md","raw":"category: java8\ndate: 2015-09-08\ntitle: java8 流\n---\n# 流\njava8中新添加的流又称为`Streams API`. 它是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation).\n\n接下来我们构建一个流:\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .count();\n```\n我们通过上述代码构建流一个流,这里有俩个概念要说:\n* 惰性求值方法:像`filter`方法,它只是在刻画Stream,它并不会被调用.(在Stream方法中凡事返回Stream对象的都是这种方法)\n* 及早求值方法:像`count`方法,它会从Stream中最终产生值.(在Stream方法中凡事返回空或者另一个值都是这种方法)\n\n## 常用的流操作\n\n### collect()\n\n该方法会产生一个列表,是一个及早求值方法.\n```java\nStream.of(1, 2, 3)\n      .filter(ele -> ele.equals(\"123\"))\n      .collect(Collectors.toList());\n```\n当然我们还可以调用`Collectors.toSet()`等其他方法,构建其他集合\n\n### map\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/map.jpg)\n该操作会将一个流中的值转换为一个新的流\n```java\nStream.of(1, 2, 3)\n      .map(num -> {\n          if (num > 1) {\n             return 0;\n          } else {\n             return 1;\n          }\n       })\n       .collect(Collectors.toSet())\n       .forEach(ele -> System.out.println(ele));\n```\n\n### filter\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/filter.jpg)\n遍历数据并检查其中的元素是否符合某种条件\n\n这个操作看起来和`map`很像, 但是`map`是根据操作的结果产生新的流,而`filter`是判断流中的数据是否符合条件保留下来\n```java\n Stream.of(1, 2, 3)\n                .filter(ele -> {\n                    if (ele > 1) {\n                        return true;\n                    } else {\n                        return false;\n                    }\n                })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n\n### flatMap\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/flatMap.jpg)\n用于Stream替换值然后将多个流连接到一起\n\n首先我们看一种情况,流里有俩个列表\n```\n Stream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n                \n输出的结果是:\n[1, 2, 3]\n[7, 8, 9]\n```\n如果我们想将这俩个列表组合到一起呢?\n```java\nStream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9))\n                    .flatMap(list -> {\n                        return list.stream();\n                    })\n                .collect(Collectors.toSet())\n                .forEach(ele -> System.out.println(ele));\n```\n看到了吧,我们首先讲列表转换成流,然后由`flatMap`操作将流组合到一起\n\n### max\n查找流中的最大值\n```java\nInteger max = Stream.of(1, 2, 3)\n                .max(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(max);\n```\n我们需要向`max`操作中传递一个排序的动作. `Comparator.comparing()`这个静态方法是java8新添加的方法,它实现流一个方便的比较器.以前我们需要比较俩个对象的某项属性的值,现在只需要提供一个取值方法就好了.\n\n\n### min\n查找流中的最小值\n```java\nInteger min = Stream.of(1, 2, 3)\n                .min(Comparator.comparing(ele -> ele))\n                .get();\n        System.out.println(min);\n```\n和`max`相似\n\n\n### reduce\n从一组值生成一个值.\n```java\nInteger sum = Stream.of(1, 2, 3)\n                .reduce((inSum, element) -> {\n                    return inSum + element;\n                }).get();\n        System.out.println(sum);\n```\n`reduce`中的`BinaryOperator`类型的lambda表达式第一个参数是上个元素执行`reduce`操作的结果, 第二个参数是流中的每个元素. \n\n另外Stream中还有其他的`reduce`操作,可以指定开始结束的的位置\n\n\n# 元素顺序\n在一个有序集合中创建一个流时，流中元素就按照出现的顺序进行排列:\n```java\nArrays.asList(1, 2, 3).stream().forEach(ele -> System.out.println(ele));\n```\n上面这个输出顺序总是`1, 2, 3`.\n\n而如果一个集合本身是无序的话，那么生成的流也是无序的，最后由流生成的集合也是无序的\n\n\n# 使用收集器\n`java.util.stream.Collectors`这是java提供的一种通用的，从流生成复杂值结构的收集器.\n\n## 转换成其他集合\nCollectors提供了转换成其他集合的方式\n\n* `Collectors.toCollection()`： 接受一个函数作为参数，来创建集合\n* `Collectors.toConcurrentMap()`\n* `Collectors.toList()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n* `Collectors.toMap()`\n* `Collectors.toSet()`： 不需要指定具体的类型，Stream会自动挑选出合适的类型\n\n## groupingBy\n数据分组\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\n\t\tMap<Integer, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn 1;\n\t\t\t} else {\n\t\t\t\treturn 2;\n\t\t\t}\n\t\t}));\n\n// 最后结果为\n{1:[\n\t\t10,\n\t\t9,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\n 2:[\n\t\t1,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t4,\n\t\t5\n\t]\n}\n```\n当然分组的key,我们还可以取其他的类型,这完全取决于我们的返回值\n```java\nMap<String, List<Integer>> group = list.stream().collect(Collectors.groupingBy(ele -> {\n\t\t\tif (ele > 5) {\n\t\t\t\treturn \"1\";\n\t\t\t} else {\n\t\t\t\treturn \"2\";\n\t\t\t}\n\t\t}));\n```\n\n## groupingByConcurrent\n并发版本的`group by`实现\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nConcurrentMap<Integer, List<Integer>> result = list.stream().collect(Collectors.groupingByConcurrent(ele -> ele - 3));\n\n// 结果\n{-2:[1],\n -1:[\n\t\t2,\n\t\t2\n\t],\n  0:[3],\n  7:[10]\n}\n```\n\n## partitioningBy\n数据分组,key为`True`和`False`\n\nlambda表达式类型\n```java\npublic interface Predicate<T> {\n    boolean test(T t);\n｝\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nMap<Boolean, List<Integer>> result = list.stream().collect(Collectors.partitioningBy(ele -> ele == 1));\nSystem.out.println(JSON.toJSONString(result, true));\n\n// 结果为\n{false:[\n\t\t10,\n\t\t2,\n\t\t3,\n\t\t2,\n\t\t9,\n\t\t4,\n\t\t5,\n\t\t11,\n\t\t6,\n\t\t7,\n\t\t8\n\t],\ntrue:[1]\n}\n```\n\n## averagingDouble\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingDouble(ele -> ele - 3));\n\n// 结果\n0.6\n```\n\n## averagingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2);\nDouble result = list.stream().collect(Collectors.averagingInt(ele -> ele - 3));\n// 结果\n0.6\n```\n\n## averagingLong\n对流中数据进行进行平均数操作\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.averagingLong(ele -> ele));\n```\n\n## summarizingInt\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nIntSummaryStatistics result = list.stream().collect(Collectors.summarizingInt(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingLong\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLongSummaryStatistics result = list.stream().collect(Collectors.summarizingLong(ele -> ele));\n\n// 结果为\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## summarizingDouble\n统计流中数据分布\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDoubleSummaryStatistics result = list.stream().collect(Collectors.summarizingDouble(ele -> ele));\n\n// 结果\n{\n\t\"average\":5.666666666666667,\n\t\"count\":12,\n\t\"max\":11,\n\t\"min\":1,\n\t\"sum\":68\n}\n```\n\n## counting\n统计流中数据数量\n\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.counting());\n```\n\n## maxBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.maxBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## minBy\n取出一个列表中的最大值,不过我们要自己定义一个对比规则\n\nlambda表达式类型\n```java\npublic interface Comparator<T> {\n    int compare(T o1, T o2);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nOptional<Integer> result = list.stream().collect(Collectors.minBy((ele1, ele2) -> ele1 - ele2));\n```\n\n## summingDouble\n对列表数据取和操作,结果为`Double`\n\nlambda表达式类型\n```java\npublic interface ToDoubleFunction<T> {\n    double applyAsDouble(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nDouble result = list.stream().collect(Collectors.summingDouble(ele -> ele));\n// 结果为68\n\n```\n\n## summingInt\n对列表数据取和操作,结果为`Int`\n\nlambda表达式类型\n```java\npublic interface ToIntFunction<T> {\n    int applyAsInt(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nInteger result = list.stream().collect(Collectors.summingInt(ele -> ele));\n```\n\n## summingLong\n对列表数据取和操作,结果为`Long`\n\nlambda表达式类型\n```java\npublic interface ToLongFunction<T> {\n    long applyAsLong(T value);\n}\n```\n示例：\n```java\nList<Integer> list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);\nLong result = list.stream().collect(Collectors.summingLong(ele -> ele));\n```\n\n## joining\n将流中的数据拼接成一个字符串. 需要注意的是如果流中的数据不是`String`类型的数据,可以通过`map`操作将流中数据转换成`String`类型\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nString result = list.stream().collect(Collectors.joining(\",\", \"(\", \")\"));\n// 结果\n\"(1,10,2,3,2)\"\n```\n\n## reducing\n\nlambda表达式类型\n```java\nR apply(T t, U u);\n```\n示例：\n```java\n\n```\n\n\n## mapping\n\nlambda表达式类型\n```java\npublic interface Function<T, R> {\n    R apply(T t);\n}\n```\n示例：\n```java\nList<String> list = Arrays.asList(\"1\", \"10\", \"2\", \"3\", \"2\");\nList<String> result = list.stream().collect(Collectors.mapping(ele -> ele + 1, Collectors.toList()));\n// 结果\n[\n\t\"11\",\n\t\"101\",\n\t\"21\",\n\t\"31\",\n\t\"21\"\n]\n```\n\n## distinct\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/distinct.jpg)\n\n## limit\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/limit.jpg)\n\n## peek\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/peek.jpg)\n\n## skip\n![](https://raw.githubusercontent.com/ming15/blog-website/images/java8/skip.jpg)","slug":"java8/java8 流","published":1,"updated":"2015-10-20T02:14:49.843Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxu4003j0cufu1krt6pg"},{"date":"2015-09-07T16:00:00.000Z","title":"Java8 时间处理","_content":"\n# LocalDate\n表示日期的不可变类型，不包含时间和时区。\n```java\n// 获取当天的日期\nLocalDate now = LocalDate.now();\n// 2015-09-21\nSystem.out.println(now.toString());\n// 获取当前日期的月份,注意这个值是一个英文月份：例如,SEPTEMBER\nSystem.out.println(now.getMonth());\n// 这个方式用来获取数字月份\nSystem.out.println(now.getMonth().getValue());\n// 获取今天是这个月中的第几天\nSystem.out.println(now.getDayOfMonth());\n// 获取今天是这周中的第几天\nSystem.out.println(now.getDayOfWeek());\n// 获取今天是今年当中第几天\nSystem.out.println(now.getDayOfYear());\n// 这个方式用来获取数字月份 等同于 System.out.println(now.getMonth().getValue());\nSystem.out.println(now.getMonthValue());\n// 获取今年年份\nSystem.out.println(now.getYear());\n// 根据指定日期生成一个LocalDate 对象\nLocalDate someDay = LocalDate.of(2015, 8, 16);\nSystem.out.println(someDay.toString());\n\n// 在当前日期行指定一个时间\nSystem.out.println(now.atTime(12, 59, 59));\n\nLocalDate someDay1 = LocalDate.of(2015, 8, 16);\nLocalDate someDay2 = LocalDate.of(2015, 8, 17);\n// 判断俩天是否是同一天\nSystem.out.println(someDay1.equals(someDay2));\n\n// 我们获取明天的日期\nLocalDate tomorrow = now.plusDays(1);\n// 判断今天是否在明天之前\nSystem.out.println(now.isBefore(tomorrow));\n```\n\n# LocalTime\n```java\n\n```\n\n# LocalDateTime\n\n# Period\n\n# DateTimeFormatter","source":"_posts/java8/java8 time.md","raw":"category: java8\ndate: 2015-09-08\ntitle: Java8 时间处理\n---\n\n# LocalDate\n表示日期的不可变类型，不包含时间和时区。\n```java\n// 获取当天的日期\nLocalDate now = LocalDate.now();\n// 2015-09-21\nSystem.out.println(now.toString());\n// 获取当前日期的月份,注意这个值是一个英文月份：例如,SEPTEMBER\nSystem.out.println(now.getMonth());\n// 这个方式用来获取数字月份\nSystem.out.println(now.getMonth().getValue());\n// 获取今天是这个月中的第几天\nSystem.out.println(now.getDayOfMonth());\n// 获取今天是这周中的第几天\nSystem.out.println(now.getDayOfWeek());\n// 获取今天是今年当中第几天\nSystem.out.println(now.getDayOfYear());\n// 这个方式用来获取数字月份 等同于 System.out.println(now.getMonth().getValue());\nSystem.out.println(now.getMonthValue());\n// 获取今年年份\nSystem.out.println(now.getYear());\n// 根据指定日期生成一个LocalDate 对象\nLocalDate someDay = LocalDate.of(2015, 8, 16);\nSystem.out.println(someDay.toString());\n\n// 在当前日期行指定一个时间\nSystem.out.println(now.atTime(12, 59, 59));\n\nLocalDate someDay1 = LocalDate.of(2015, 8, 16);\nLocalDate someDay2 = LocalDate.of(2015, 8, 17);\n// 判断俩天是否是同一天\nSystem.out.println(someDay1.equals(someDay2));\n\n// 我们获取明天的日期\nLocalDate tomorrow = now.plusDays(1);\n// 判断今天是否在明天之前\nSystem.out.println(now.isBefore(tomorrow));\n```\n\n# LocalTime\n```java\n\n```\n\n# LocalDateTime\n\n# Period\n\n# DateTimeFormatter","slug":"java8/java8 time","published":1,"updated":"2015-10-16T02:41:00.785Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxu5003m0cuflib8dpg2"},{"date":"2015-09-07T16:00:00.000Z","title":"java lambda","_content":"\n# 函数接口\n\n## 函数接口定义\n函数接口只是一个抽象方法的接口,用作lambda表达式类型.\n\n注意, 上面这个定义有三个需要注意的地方\n1. 函数接口是一个接口\n2. 函数接口有且只有一个抽象方法(只有一个表示数量上是唯一的,重载也是不可以)\n3. 函数接口用作lambda表达式类型\n\n## 函数接口示例:\n```java\n// 定义一个非泛型没有返回值没有参数的函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n// 定义一个非泛型没有返回值有参数的函数接口\ninterface Run2 {\n\tpublic void runFast(int seconds);\n}\n// 定义一个非泛型有返回值有参数的函数接口\ninterface Run3 {\n\tpublic int runFast(int seconds);\n}\n// 定义一个泛型有返回值有参数的函数接口\ninterface Run4<T> {\n\tpublic int runFast(T t, int seconds);\n}\n```\n\n## 默认方法\n我们知道java8对核心集合类进行了大幅度修改,例如`Collection`接口添加了`stream()`方法. 那么所有的`Collection`实现类都必须来实现该方法. 为了保持二进制接口的兼容性,java8提供了默认方法,来保证这一兼容性(例如来源在java1到jav7平台写出的代码仍然可以在java8平台上编译运行)\n```java\ninterface Run10 {\n\tpublic void runFast();\n\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run11  extends Run10 {\n\n}\n\n// 调用\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\n```\n那么所有的子类都可以来调用这个默认方法, 而不必实现它。\n\n> 如果接口中只有一个默认方法,那么这个接口就不是接口函数.\n\n### 继承默认方法\n```java\ninterface Run11 extends Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run11 runAt9Clock\");\n\t}\n}\n\nclass Run12 implements Run10 {\n\t@Override\n\tpublic void runFast() {}\n\n\tpublic void runAt9Clock() {\n\t\tSystem.out.println(\"run12 runAt9Clock\");\n\t}\n}\n```\n从上面的例子中我们可以看到如果接口`Run11`继承了接口`Run10`, 同时重载了默认方法, 那么`Run11`中的默认方法也必须含有`default`关键字. 但是在类中重载的话,就可以不必存在了.\n```java\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\nRun12 run12 = new Run12();\nrun12.runAt9Clock();\n\n//result\nrun11 runAt9Clock\nrun12 runAt9Clock\n```\n接着我们都调用默认方法,我们发现当调用默认方法时都会优先调用子类中的方法.\n\n### 多重继承\n```java\ninterface Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run13 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run13 runAt9Clock\");\n\t}\n}\n\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\n\t}\n}\n```\n在上面这个情况下,我们需要手动在`Run14`这个类中指定重载哪个方法, 否则会产生编译错误：\n```java\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\t\tRun10.super.runAt9Clock();\n\t}\n}\n```\n\n## 接口静态方法\n我们定义一个接口静态方法\n```\ninterface Run1 {\n\tpublic void runFast();\n\n\tpublic static void runSlowly() {\n\t\tSystem.out.println(\"run1 run slowly\");\n\t}\n}\n\n// \nRun1.runSlowly();\n```\n需要注意的是：\n* 接口静态方法不会被继承到子接口或者子类中\n\n## @FunctionalInterface\n所有的函数接口都应该添加`@FunctionalInterface`注释. 该注释会强制检查javac检查一个接口是否符合函数接口的标准. 如果将这个注释添加给类，枚举，多个方法的接口都会产生编译错误.\n\n# lambda表达式\n\n## lambda表达式定义\n接下来我们根据上面定义的函数接口来定义一下lambda表达式\n```java\n// 不带参数的版本\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n\n// 参数要指定\nRun2 run2 = seconds -> {\n\tSystem.out.println(\"I am running \" + seconds + \" seconds\");\n};\n\n// 下面这个版本就必须要有个返回值了\nRun3 run3 = seconds -> {\n\tSystem.out.println(\"I am running\");\n\treturn 0;\n};\n\n// 我们在下面的版本中指定了它的泛型信息\nRun4<String> run4 = (name, seconds) -> {\n\tSystem.out.println(name + \" is running\");\n\treturn 0;\n};\n```\n\n## lambda表达式使用\n\n接下来我们使用上面定义的lambda表达式\n```java\nrun1.runFast();\n-> I am running\n\nrun2.runFast(10);\n-> I am running 10 seconds\n\nint result = run3.runFast(10);\n-> I am running\n\nrun4.runFast(\"小狗\", 10); 小狗 is running\n-> \n```\n\n### 注意\n\n我们引用lambda表达式外部的一个变量\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n\n编译运行通过没有问题,但是如果我们将name在lambda表达式内部重新赋值的话\n\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tname = \"\";\n\tSystem.out.println(name + \" am running\");\n};\n```\n会提示`variable used in lambda expression shouble be final`, 这说明lambda其实内部引用的是值而不是变量.\n\n好,接下来我们换种方式再次验证一下我们的结果：\n```java\nString name = \"sam\";\nname = \"Jams\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n同样的产生了编译错误.\n\n### java中重要的函数接口\n* `Predicate<T>`: `boolean test(T t)` 判断输入的对象是否符合某个条件\n* `Consumer<T>`: `void accept(T t);`  接收一个输入参数并且没有返回值\n* `Supplier<T>`: `T get();`  可以看成一个对象的工厂，每次调用返回一个给定类型的对象\n* `UnaryOperator<T>`: ``\n* `BinaryOperator<T>`: ``\n\n# 函数\n在Java8中什么是函数呢？\n```java\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n```\n上面`run1`这个就代表一个函数. 一般我们把属于某个类的函数称为方法, 而不依赖于类而存在的函数称之为方法. \n\n## 高阶函数\n如果某个函数A作为函数B的参数或者返回值, 那么我们称函数B为高阶函数,像下面的`run6`就是一个高级函数\n```java\ninterface Run6 {\n\tpublic void run(Run1 run1);\n}\n\nRun6 run6 = run1Param -> {\n\t\t\tSystem.out.println(\"run6\");\n\t\t\trun1Param.runFast();\n\t\t};\n\nrun6.run(run1);\n```\n我们将`run1`这个函数作为方法传递给了`run6`.\n\n### 返回函数\n```java\ninterface Run8 {\n\tpublic void run(String name, int second, int mils);\n}\n\ninterface Run9 {\n\tpublic Run8 run(Run8 run8);\n}\n\nRun8 run8 = (name, second, mils) -> {\n\tSystem.out.println();\n};\n\nRun9 run9 = run8Param -> {\n\treturn run8Param.run(\"lily\");\n};\n```\n在上述的例子中产生了编译错误, 在`Haskell`这种纯FP语言中可以将一个调用函数但是参数不完整的函数从某个参数中返回或者定义一个参数不完整的函数值.\n\n## 重载解析\n我们使用函数接口作为方法参数,然后进行重载\n```java\n// 定义函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 {\n\tpublic void runFast();\n}\n\n\n// 定义重载代码\n\tpublic static void run(Run1 run1){\n\t\tSystem.out.println(\"run1\");\n\t}\n\n\tpublic static void run(Run2 run2){\n\t\tSystem.out.println(\"run2\");\n\t}\n\n// 定义运行代码\npublic static void main(String[] args) {\n\trun(() -> System.out.println());\n}\n```\n当我们进行如上定义时,javac提示了编译错误：不确定的方法调用,`run(Run1 run1)`和`run(Run2 run2)`都符合.\n\n但是如果`Run2`继承了`Run1`这个接口之后\n```java\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 extends Run1 {\n\tpublic void runFast();\n}\n```\n当我们运行测试代码之后,我们发现输出的`run2`. \n\n当Lambda表达式作为参数时,其类型由它的目标类型推导得出,推导过程遵循如下规则：\n* 如果只有一个可能的目标类型,由相应的函数接口里的参数类型推导得出\n* 如果有多个可能的目标类型，由最具体的类型推导得出\n* 如果有多个可能的目标类型且最具体的类型不明确，则需要人为指定类型\n\n# 方法引用\n方法引用是简洁的Lambda表达式，能够用于已经拥有名称的方法。\n\n* 静态方法 (ClassName::methName)\n* 对象实例方法 (instanceRef::methName)\n* 类型的实例方法 (ClassName::methName, 引用时和静态方法是一样的，但这里的 methName 是个实例方法)\n* 构造方法 (ClassName::new)\n* 数组的构造方法 (TypeName[]::new)\n\n## 静态方法引用\n```\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::p;\n\t\tf.m();\n\t}\n\n\tpublic static void p() {\n\t\tSystem.out.println(\"Print\");\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tvoid m();\n}\n\n```\n\n## 类型实例方法引用\n```\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = String::length;\n\t\tint len = f.m(\"12\");\n\t\tSystem.out.println(len);\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tint m(String p);\n}\n```\n\n## 构造方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::new;\n\t\tPrint p = f.m();\n\t\tSystem.out.println(p == null);\t// 结果为null\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tPrint m();\n}\n```\n\n## 数组的构造方法","source":"_posts/java8/java8 lambda.md","raw":"category: java8\ndate: 2015-09-08\ntitle: java lambda\n---\n\n# 函数接口\n\n## 函数接口定义\n函数接口只是一个抽象方法的接口,用作lambda表达式类型.\n\n注意, 上面这个定义有三个需要注意的地方\n1. 函数接口是一个接口\n2. 函数接口有且只有一个抽象方法(只有一个表示数量上是唯一的,重载也是不可以)\n3. 函数接口用作lambda表达式类型\n\n## 函数接口示例:\n```java\n// 定义一个非泛型没有返回值没有参数的函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n// 定义一个非泛型没有返回值有参数的函数接口\ninterface Run2 {\n\tpublic void runFast(int seconds);\n}\n// 定义一个非泛型有返回值有参数的函数接口\ninterface Run3 {\n\tpublic int runFast(int seconds);\n}\n// 定义一个泛型有返回值有参数的函数接口\ninterface Run4<T> {\n\tpublic int runFast(T t, int seconds);\n}\n```\n\n## 默认方法\n我们知道java8对核心集合类进行了大幅度修改,例如`Collection`接口添加了`stream()`方法. 那么所有的`Collection`实现类都必须来实现该方法. 为了保持二进制接口的兼容性,java8提供了默认方法,来保证这一兼容性(例如来源在java1到jav7平台写出的代码仍然可以在java8平台上编译运行)\n```java\ninterface Run10 {\n\tpublic void runFast();\n\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run11  extends Run10 {\n\n}\n\n// 调用\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\n```\n那么所有的子类都可以来调用这个默认方法, 而不必实现它。\n\n> 如果接口中只有一个默认方法,那么这个接口就不是接口函数.\n\n### 继承默认方法\n```java\ninterface Run11 extends Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run11 runAt9Clock\");\n\t}\n}\n\nclass Run12 implements Run10 {\n\t@Override\n\tpublic void runFast() {}\n\n\tpublic void runAt9Clock() {\n\t\tSystem.out.println(\"run12 runAt9Clock\");\n\t}\n}\n```\n从上面的例子中我们可以看到如果接口`Run11`继承了接口`Run10`, 同时重载了默认方法, 那么`Run11`中的默认方法也必须含有`default`关键字. 但是在类中重载的话,就可以不必存在了.\n```java\nRun11 run11 = () -> {\n\tSystem.out.println();\n};\nrun11.runAt9Clock();\n\nRun12 run12 = new Run12();\nrun12.runAt9Clock();\n\n//result\nrun11 runAt9Clock\nrun12 runAt9Clock\n```\n接着我们都调用默认方法,我们发现当调用默认方法时都会优先调用子类中的方法.\n\n### 多重继承\n```java\ninterface Run10 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run10 runAt9Clock\");\n\t}\n}\n\ninterface Run13 {\n\tpublic default void runAt9Clock() {\n\t\tSystem.out.println(\"run13 runAt9Clock\");\n\t}\n}\n\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\n\t}\n}\n```\n在上面这个情况下,我们需要手动在`Run14`这个类中指定重载哪个方法, 否则会产生编译错误：\n```java\nclass Run14 implements Run10, Run13 {\n\t@Override\n\tpublic void runAt9Clock() {\n\t\tRun10.super.runAt9Clock();\n\t}\n}\n```\n\n## 接口静态方法\n我们定义一个接口静态方法\n```\ninterface Run1 {\n\tpublic void runFast();\n\n\tpublic static void runSlowly() {\n\t\tSystem.out.println(\"run1 run slowly\");\n\t}\n}\n\n// \nRun1.runSlowly();\n```\n需要注意的是：\n* 接口静态方法不会被继承到子接口或者子类中\n\n## @FunctionalInterface\n所有的函数接口都应该添加`@FunctionalInterface`注释. 该注释会强制检查javac检查一个接口是否符合函数接口的标准. 如果将这个注释添加给类，枚举，多个方法的接口都会产生编译错误.\n\n# lambda表达式\n\n## lambda表达式定义\n接下来我们根据上面定义的函数接口来定义一下lambda表达式\n```java\n// 不带参数的版本\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n\n// 参数要指定\nRun2 run2 = seconds -> {\n\tSystem.out.println(\"I am running \" + seconds + \" seconds\");\n};\n\n// 下面这个版本就必须要有个返回值了\nRun3 run3 = seconds -> {\n\tSystem.out.println(\"I am running\");\n\treturn 0;\n};\n\n// 我们在下面的版本中指定了它的泛型信息\nRun4<String> run4 = (name, seconds) -> {\n\tSystem.out.println(name + \" is running\");\n\treturn 0;\n};\n```\n\n## lambda表达式使用\n\n接下来我们使用上面定义的lambda表达式\n```java\nrun1.runFast();\n-> I am running\n\nrun2.runFast(10);\n-> I am running 10 seconds\n\nint result = run3.runFast(10);\n-> I am running\n\nrun4.runFast(\"小狗\", 10); 小狗 is running\n-> \n```\n\n### 注意\n\n我们引用lambda表达式外部的一个变量\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n\n编译运行通过没有问题,但是如果我们将name在lambda表达式内部重新赋值的话\n\n```java\nString name = \"sam\";\nRun1 run1 = () -> {\n\tname = \"\";\n\tSystem.out.println(name + \" am running\");\n};\n```\n会提示`variable used in lambda expression shouble be final`, 这说明lambda其实内部引用的是值而不是变量.\n\n好,接下来我们换种方式再次验证一下我们的结果：\n```java\nString name = \"sam\";\nname = \"Jams\";\nRun1 run1 = () -> {\n\tSystem.out.println(name + \" am running\");\n};\n```\n同样的产生了编译错误.\n\n### java中重要的函数接口\n* `Predicate<T>`: `boolean test(T t)` 判断输入的对象是否符合某个条件\n* `Consumer<T>`: `void accept(T t);`  接收一个输入参数并且没有返回值\n* `Supplier<T>`: `T get();`  可以看成一个对象的工厂，每次调用返回一个给定类型的对象\n* `UnaryOperator<T>`: ``\n* `BinaryOperator<T>`: ``\n\n# 函数\n在Java8中什么是函数呢？\n```java\nRun1 run1 = () -> {\n\tSystem.out.println(\"I am running\");\n};\n```\n上面`run1`这个就代表一个函数. 一般我们把属于某个类的函数称为方法, 而不依赖于类而存在的函数称之为方法. \n\n## 高阶函数\n如果某个函数A作为函数B的参数或者返回值, 那么我们称函数B为高阶函数,像下面的`run6`就是一个高级函数\n```java\ninterface Run6 {\n\tpublic void run(Run1 run1);\n}\n\nRun6 run6 = run1Param -> {\n\t\t\tSystem.out.println(\"run6\");\n\t\t\trun1Param.runFast();\n\t\t};\n\nrun6.run(run1);\n```\n我们将`run1`这个函数作为方法传递给了`run6`.\n\n### 返回函数\n```java\ninterface Run8 {\n\tpublic void run(String name, int second, int mils);\n}\n\ninterface Run9 {\n\tpublic Run8 run(Run8 run8);\n}\n\nRun8 run8 = (name, second, mils) -> {\n\tSystem.out.println();\n};\n\nRun9 run9 = run8Param -> {\n\treturn run8Param.run(\"lily\");\n};\n```\n在上述的例子中产生了编译错误, 在`Haskell`这种纯FP语言中可以将一个调用函数但是参数不完整的函数从某个参数中返回或者定义一个参数不完整的函数值.\n\n## 重载解析\n我们使用函数接口作为方法参数,然后进行重载\n```java\n// 定义函数接口\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 {\n\tpublic void runFast();\n}\n\n\n// 定义重载代码\n\tpublic static void run(Run1 run1){\n\t\tSystem.out.println(\"run1\");\n\t}\n\n\tpublic static void run(Run2 run2){\n\t\tSystem.out.println(\"run2\");\n\t}\n\n// 定义运行代码\npublic static void main(String[] args) {\n\trun(() -> System.out.println());\n}\n```\n当我们进行如上定义时,javac提示了编译错误：不确定的方法调用,`run(Run1 run1)`和`run(Run2 run2)`都符合.\n\n但是如果`Run2`继承了`Run1`这个接口之后\n```java\ninterface Run1 {\n\tpublic void runFast();\n}\n\ninterface Run2 extends Run1 {\n\tpublic void runFast();\n}\n```\n当我们运行测试代码之后,我们发现输出的`run2`. \n\n当Lambda表达式作为参数时,其类型由它的目标类型推导得出,推导过程遵循如下规则：\n* 如果只有一个可能的目标类型,由相应的函数接口里的参数类型推导得出\n* 如果有多个可能的目标类型，由最具体的类型推导得出\n* 如果有多个可能的目标类型且最具体的类型不明确，则需要人为指定类型\n\n# 方法引用\n方法引用是简洁的Lambda表达式，能够用于已经拥有名称的方法。\n\n* 静态方法 (ClassName::methName)\n* 对象实例方法 (instanceRef::methName)\n* 类型的实例方法 (ClassName::methName, 引用时和静态方法是一样的，但这里的 methName 是个实例方法)\n* 构造方法 (ClassName::new)\n* 数组的构造方法 (TypeName[]::new)\n\n## 静态方法引用\n```\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::p;\n\t\tf.m();\n\t}\n\n\tpublic static void p() {\n\t\tSystem.out.println(\"Print\");\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tvoid m();\n}\n\n```\n\n## 类型实例方法引用\n```\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = String::length;\n\t\tint len = f.m(\"12\");\n\t\tSystem.out.println(len);\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tint m(String p);\n}\n```\n\n## 构造方法引用\n```java\npublic class Print {\n\tpublic static void main(String[] args) throws Exception {\n\t\tF f = Print::new;\n\t\tPrint p = f.m();\n\t\tSystem.out.println(p == null);\t// 结果为null\n\t}\n}\n\n@FunctionalInterface\ninterface F {\n\tPrint m();\n}\n```\n\n## 数组的构造方法","slug":"java8/java8 lambda","published":1,"updated":"2015-10-20T05:57:23.983Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxu7003o0cufif4q2ay4"},{"date":"2015-10-19T16:00:00.000Z","title":"java DSL","_content":"","source":"_posts/java8/Java8 DSL.md","raw":"category: java8\ndate: 2015-10-20\ntitle: java DSL\n---\n","slug":"java8/Java8 DSL","published":1,"updated":"2015-10-20T06:10:22.795Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxuf003q0cuf6dyf60sd"},{"date":"2015-07-04T16:00:00.000Z","title":"项目CheckList","_content":"\n## 数据接口都尽量做成数组形式\n这是为了提高拓展性,以防策划将模块提出批处理\n\n## 代码中不要出现中文\n当要出现中文的时候,可以根据个英文索引到表里查国际化文字.\n\n服务器向客户端提示的时候发送错误号,由客户端进行国际化\n\n## 客户端打包\n在打包的时候，加上时间和svn版本号，方便渠道确定客户端的版本是一致的\n\n## 交易类模块\n交易类模块要慎重考虑,玩家可能刷元宝\n\n## 玩家使用模拟器登录\n这个要做技术处理\n\n## id\n项目里边每个模块的ID要是全区唯一的,保证合服顺利\n\n## GWF的问题\n参考[记今天域名和GWF的问题](http://blog.zhukunqian.com/?p=1377)\n\n## 模块次数\n每个模块活动都加一个每日次数限制。例如扫荡类的功能，加一个每日最大扫荡次数，避免出现角色刷货币的情况.","source":"_posts/Bug库/项目CheckList.md","raw":"category: Bug库\ndate: 2015-07-05\ntitle: 项目CheckList\n---\n\n## 数据接口都尽量做成数组形式\n这是为了提高拓展性,以防策划将模块提出批处理\n\n## 代码中不要出现中文\n当要出现中文的时候,可以根据个英文索引到表里查国际化文字.\n\n服务器向客户端提示的时候发送错误号,由客户端进行国际化\n\n## 客户端打包\n在打包的时候，加上时间和svn版本号，方便渠道确定客户端的版本是一致的\n\n## 交易类模块\n交易类模块要慎重考虑,玩家可能刷元宝\n\n## 玩家使用模拟器登录\n这个要做技术处理\n\n## id\n项目里边每个模块的ID要是全区唯一的,保证合服顺利\n\n## GWF的问题\n参考[记今天域名和GWF的问题](http://blog.zhukunqian.com/?p=1377)\n\n## 模块次数\n每个模块活动都加一个每日次数限制。例如扫荡类的功能，加一个每日最大扫荡次数，避免出现角色刷货币的情况.","slug":"Bug库/项目CheckList","published":1,"updated":"2015-10-31T03:56:01.730Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxug003s0cufn2g45dvz"},{"date":"2015-10-14T16:00:00.000Z","title":"技术CheckList","_content":"\n## FastJSON\n\n### 序列化bug\n在项目中运营团队给出了下面这样的一个公告\n```\n================================================\n官方QQ群： 467027422\n官方微信号：gm-xyxmp\n微信订阅号：xyxmpsy\n\n亲爱的小伙伴：\n\n大家好，老猪给各位请安了！\n\n首款能交易的3D卡牌游戏，星爷独家正版授权《西游降魔篇3D》\n自2015年7月21日正式登陆iOS平台后，大量玩家热情涌入游戏\n，老猪我面对此景喜极而泣，为了让更多小伙伴加入到咱们的\n大团队中，老猪我决定[FFFF00]10月16日11：00开启新服N23-物华天宝 [-]，\n诚邀各位新老玩家的加入！\n\n\n新服开启，精彩纷呈的活动期待各位的参与，丰厚的大礼拿到手\n抽筋，在《西游降魔篇3D》西行的途中，让我们一同感受友情，\n感受激情，感受无限快乐！\n\n服务器名称：[FFFF00]N23-物华天宝 [-]\n开服时间：[FFFF00]2015年10月16日11：00（周五）[-]\n\n\n伴随开服的同时，多个活动前来助阵！\n[FFFF00]活动一：连续登陆送豪礼[-]\n[FFFF00]活动二：冲级领元宝[-]\n[FFFF00]活动三：战力大比拼[-]\n[FFFF00]活动四：五星神将双倍抽[-]\n[FFFF00]活动五：天天有礼送段小姐[-]\n[FFFF00]活动六：累积充值送玉帝[-]\n[FFFF00]活动七：每日礼包大回馈[-]\n[FFFF00]活动八：首充翻倍送豪礼[-]\n[FFFF00]活动九：签到送好礼[-]\n\n\n活动详情请查看游戏内公告！\n================================================\n                                                            《西游降魔篇3D》运营团队\n```\n当我将其赋值到一个对象`obj#value`时,然后使用`JSON.toJSONString(obj)`的时候遇到了下面的异常:\n```\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 160\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:868)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:602)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeString(SerializeWriter.java:1366)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:49)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:34)\n\tat com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:369)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:430)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:418)\n\tat Print1.main(Print1.java:52)\n```\n出现的原因是:`服务器名称：[FFFF00]N23-物华天宝 [-]`物华天宝后面跟的空格，不是我们常用的ascii码为32的空格，而是一个ascii码为160特殊的空格符,导致JSON序列化时失败.\n\n## 用户名字符集\n用户可能输入emoji表情符号,这种符号普遍存在iOS与android系统中,这种表情不处理直接存储到MySQL5.5以下的版本会报错\n> 这种符号采用Unicode 6标准4个bytes作为存储单元,MySQL存储这种字符需要修改数据库字符集为utf8mb4,但数据回传给网页或者移动客户端时则需要做兼容处理\n\n","source":"_posts/Bug库/技术CheckList.md","raw":"category: Bug库\ndate: 2015-10-15\ntitle: 技术CheckList\n---\n\n## FastJSON\n\n### 序列化bug\n在项目中运营团队给出了下面这样的一个公告\n```\n================================================\n官方QQ群： 467027422\n官方微信号：gm-xyxmp\n微信订阅号：xyxmpsy\n\n亲爱的小伙伴：\n\n大家好，老猪给各位请安了！\n\n首款能交易的3D卡牌游戏，星爷独家正版授权《西游降魔篇3D》\n自2015年7月21日正式登陆iOS平台后，大量玩家热情涌入游戏\n，老猪我面对此景喜极而泣，为了让更多小伙伴加入到咱们的\n大团队中，老猪我决定[FFFF00]10月16日11：00开启新服N23-物华天宝 [-]，\n诚邀各位新老玩家的加入！\n\n\n新服开启，精彩纷呈的活动期待各位的参与，丰厚的大礼拿到手\n抽筋，在《西游降魔篇3D》西行的途中，让我们一同感受友情，\n感受激情，感受无限快乐！\n\n服务器名称：[FFFF00]N23-物华天宝 [-]\n开服时间：[FFFF00]2015年10月16日11：00（周五）[-]\n\n\n伴随开服的同时，多个活动前来助阵！\n[FFFF00]活动一：连续登陆送豪礼[-]\n[FFFF00]活动二：冲级领元宝[-]\n[FFFF00]活动三：战力大比拼[-]\n[FFFF00]活动四：五星神将双倍抽[-]\n[FFFF00]活动五：天天有礼送段小姐[-]\n[FFFF00]活动六：累积充值送玉帝[-]\n[FFFF00]活动七：每日礼包大回馈[-]\n[FFFF00]活动八：首充翻倍送豪礼[-]\n[FFFF00]活动九：签到送好礼[-]\n\n\n活动详情请查看游戏内公告！\n================================================\n                                                            《西游降魔篇3D》运营团队\n```\n当我将其赋值到一个对象`obj#value`时,然后使用`JSON.toJSONString(obj)`的时候遇到了下面的异常:\n```\nException in thread \"main\" java.lang.ArrayIndexOutOfBoundsException: 160\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:868)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeStringWithDoubleQuote(SerializeWriter.java:602)\n\tat com.alibaba.fastjson.serializer.SerializeWriter.writeString(SerializeWriter.java:1366)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:49)\n\tat com.alibaba.fastjson.serializer.StringCodec.write(StringCodec.java:34)\n\tat com.alibaba.fastjson.serializer.JSONSerializer.write(JSONSerializer.java:369)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:430)\n\tat com.alibaba.fastjson.JSON.toJSONString(JSON.java:418)\n\tat Print1.main(Print1.java:52)\n```\n出现的原因是:`服务器名称：[FFFF00]N23-物华天宝 [-]`物华天宝后面跟的空格，不是我们常用的ascii码为32的空格，而是一个ascii码为160特殊的空格符,导致JSON序列化时失败.\n\n## 用户名字符集\n用户可能输入emoji表情符号,这种符号普遍存在iOS与android系统中,这种表情不处理直接存储到MySQL5.5以下的版本会报错\n> 这种符号采用Unicode 6标准4个bytes作为存储单元,MySQL存储这种字符需要修改数据库字符集为utf8mb4,但数据回传给网页或者移动客户端时则需要做兼容处理\n\n","slug":"Bug库/技术CheckList","published":1,"updated":"2015-10-31T04:08:05.147Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cigipyxuj003v0cuf4ncsog8u"}],"PostAsset":[],"PostCategory":[{"post_id":"cigipyxqw000c0cuff6m35hsx","category_id":"cigipyxqz000d0cufww9eeq0f","_id":"cigipyxr1000e0cuf0gnhvtax"},{"post_id":"cigipyxr2000f0cuf34qrtk9q","category_id":"cigipyxqz000d0cufww9eeq0f","_id":"cigipyxr4000g0cufhju2nfrd"},{"post_id":"cigipyxr6000h0cufpocz8tcp","category_id":"cigipyxqz000d0cufww9eeq0f","_id":"cigipyxr6000i0cufhguvo05d"},{"post_id":"cigipyxr9000j0cuf6h9w6wxz","category_id":"cigipyxqz000d0cufww9eeq0f","_id":"cigipyxr9000k0cufvur7rptx"},{"post_id":"cigipyxrb000l0cuf52agev6s","category_id":"cigipyxqz000d0cufww9eeq0f","_id":"cigipyxrc000m0cufukhbdtaf"},{"post_id":"cigipyxrd000n0cufjhlv7wmy","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxre000p0cufck0u7ce6"},{"post_id":"cigipyxrf000q0cufoyk496l8","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxrg000r0cufahzkid9x"},{"post_id":"cigipyxrh000s0cufo72frwtl","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxri000t0cufi7zvczvr"},{"post_id":"cigipyxri000u0cufu1pvrjxr","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxrl000v0cuf1c5l5dqx"},{"post_id":"cigipyxrn000w0cufnbcyfvvy","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxrp000x0cufhjwbdqjr"},{"post_id":"cigipyxrr000y0cufynuy64q4","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxrr000z0cuf7z1l6bpy"},{"post_id":"cigipyxrs00100cufpv2imt5q","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxru00110cuf2y88qmi4"},{"post_id":"cigipyxrv00120cufc3npp1lm","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxrw00130cuf8b4yolwh"},{"post_id":"cigipyxrx00140cuftcmr1039","category_id":"cigipyxrd000o0cuf9ge6gf96","_id":"cigipyxry00150cuf2wsihtzq"},{"post_id":"cigipyxrz00160cufrd2n6v4c","category_id":"cigipyxs000170cufe7o02999","_id":"cigipyxs000180cufspamuc0i"},{"post_id":"cigipyxs100190cufvik6x0fm","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxs3001b0cuf6kqaqtj0"},{"post_id":"cigipyxs4001c0cufchbed4da","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxs4001d0cuf2zuij0f8"},{"post_id":"cigipyxs5001e0cufu5xi7938","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxs6001f0cuf9kwp0tst"},{"post_id":"cigipyxs7001g0cufzdvl039b","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxs8001h0cuf01ixgxbd"},{"post_id":"cigipyxs9001i0cufubasqvja","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsa001j0cufyxvxmvyf"},{"post_id":"cigipyxsc001k0cufgsht9j6d","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsd001l0cufk68olmw3"},{"post_id":"cigipyxsd001m0cufwulc425a","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxse001n0cufrgggrgp6"},{"post_id":"cigipyxsf001o0cufafthzbn1","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsg001p0cufkijp890v"},{"post_id":"cigipyxsh001q0cuftbe4c2hp","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsi001r0cuf9kn65n5n"},{"post_id":"cigipyxsi001s0cuffjcdapmr","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsj001t0cuf6od8wous"},{"post_id":"cigipyxsk001u0cuf4yu3nnup","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsl001v0cufnkjl8hsi"},{"post_id":"cigipyxsm001w0cufmvzxthqr","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsn001x0cuf89yj9mkt"},{"post_id":"cigipyxso001y0cufg9y7miea","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsp001z0cufbshk4mc9"},{"post_id":"cigipyxsq00200cufa19el8jz","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsr00210cufopy6smyl"},{"post_id":"cigipyxss00220cuf45ij4ona","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxss00230cufub7ljb8z"},{"post_id":"cigipyxst00240cufuf22qp37","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsu00250cuf2oyta31b"},{"post_id":"cigipyxsv00260cufo382c9ap","category_id":"cigipyxs2001a0cuffx9nsurz","_id":"cigipyxsw00270cuf52jmn0a2"},{"post_id":"cigipyxsx00280cufapklena7","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxsy002a0cufu3b00tyf"},{"post_id":"cigipyxsz002b0cufdellf96j","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxsz002c0cuf1iplcf18"},{"post_id":"cigipyxt0002d0cuftp51ffwf","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxt1002e0cufyv7amkt0"},{"post_id":"cigipyxt2002f0cuf7j4rulgf","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxt3002g0cufzm33y0ok"},{"post_id":"cigipyxt4002h0cufk3etx2sq","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxt5002i0cuft9aq91cw"},{"post_id":"cigipyxt6002j0cuffpvfm4fq","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxt7002k0cufh1rcqxzc"},{"post_id":"cigipyxt9002l0cuf5vhvy8ge","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxta002m0cufwlp8qmjg"},{"post_id":"cigipyxtc002n0cuf4g0564cs","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxtd002o0cufotzek3sq"},{"post_id":"cigipyxte002p0cuf58cxo9mi","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxtf002q0cufn3unmuaf"},{"post_id":"cigipyxth002r0cufybtoprty","category_id":"cigipyxsy00290cufd2w26rwo","_id":"cigipyxti002s0cuf4fwmrozz"},{"post_id":"cigipyxtj002t0cuf7u7n140s","category_id":"cigipyxtk002u0cuf4db0rui1","_id":"cigipyxtk002v0cufqacrbx5o"},{"post_id":"cigipyxtl002w0cufyk6uknom","category_id":"cigipyxtk002u0cuf4db0rui1","_id":"cigipyxtl002x0cufptu8ggz7"},{"post_id":"cigipyxtm002y0cufqebo0a49","category_id":"cigipyxtk002u0cuf4db0rui1","_id":"cigipyxtn002z0cufolqvit70"},{"post_id":"cigipyxto00300cuf8fzt84un","category_id":"cigipyxtk002u0cuf4db0rui1","_id":"cigipyxto00310cufw05mwc6w"},{"post_id":"cigipyxtp00320cuflw29dprm","category_id":"cigipyxtk002u0cuf4db0rui1","_id":"cigipyxtq00330cufud677k48"},{"post_id":"cigipyxtr00340cufunf4lckz","category_id":"cigipyxtk002u0cuf4db0rui1","_id":"cigipyxts00350cufq5fwuqd2"},{"post_id":"cigipyxtt00360cufa56ya0ff","category_id":"cigipyxtu00370cufx725ojkq","_id":"cigipyxtu00380cuf3ug88hq0"},{"post_id":"cigipyxtv00390cufd8kqfwkl","category_id":"cigipyxtu00370cufx725ojkq","_id":"cigipyxtv003a0cufw0ubfs9q"},{"post_id":"cigipyxtw003b0cufj37991gr","category_id":"cigipyxtu00370cufx725ojkq","_id":"cigipyxtx003c0cuf13xg0jy4"},{"post_id":"cigipyxty003d0cuf29p3tq0k","category_id":"cigipyxtu00370cufx725ojkq","_id":"cigipyxtz003e0cufm9oegxkt"},{"post_id":"cigipyxu0003f0cufx1dppnyr","category_id":"cigipyxtu00370cufx725ojkq","_id":"cigipyxu1003g0cufgp8ma3da"},{"post_id":"cigipyxu2003h0cuf8li8y7km","category_id":"cigipyxtu00370cufx725ojkq","_id":"cigipyxu3003i0cufnpdccmgo"},{"post_id":"cigipyxu4003j0cufu1krt6pg","category_id":"cigipyxu4003k0cufp9aptpzn","_id":"cigipyxu5003l0cufin3i48gg"},{"post_id":"cigipyxu5003m0cuflib8dpg2","category_id":"cigipyxu4003k0cufp9aptpzn","_id":"cigipyxu6003n0cufdnmwy1yy"},{"post_id":"cigipyxu7003o0cufif4q2ay4","category_id":"cigipyxu4003k0cufp9aptpzn","_id":"cigipyxud003p0cufj2rm0gbq"},{"post_id":"cigipyxuf003q0cuf6dyf60sd","category_id":"cigipyxu4003k0cufp9aptpzn","_id":"cigipyxuf003r0cufilgdsi17"},{"post_id":"cigipyxug003s0cufn2g45dvz","category_id":"cigipyxuh003t0cufrmywi81h","_id":"cigipyxui003u0cufwzugz35o"},{"post_id":"cigipyxuj003v0cuf4ncsog8u","category_id":"cigipyxuh003t0cufrmywi81h","_id":"cigipyxuk003w0cuf1k5prqbi"}],"PostTag":[],"Tag":[]}}