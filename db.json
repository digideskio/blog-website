{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1},{"_id":"themes/hueman/source/scrollLoading/style.css","path":"scrollLoading/style.css","modified":1},{"_id":"themes/hueman/source/scrollLoading/main.js","path":"scrollLoading/main.js","modified":1},{"_id":"themes/hueman/source/scrollLoading/jquery.scrollLoading.js","path":"scrollLoading/jquery.scrollLoading.js","modified":1},{"_id":"themes/hueman/source/scrollLoading/images/preloader@2x.gif","path":"scrollLoading/images/preloader@2x.gif","modified":1},{"_id":"themes/hueman/source/scrollLoading/images/preloader.gif","path":"scrollLoading/images/preloader.gif","modified":1},{"_id":"themes/hueman/source/js/script.js","path":"js/script.js","modified":1},{"_id":"themes/hueman/source/js/html-patch.js","path":"js/html-patch.js","modified":1},{"_id":"themes/hueman/source/fancybox/title.png","path":"fancybox/title.png","modified":1},{"_id":"themes/hueman/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1},{"_id":"themes/hueman/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1},{"_id":"themes/hueman/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1},{"_id":"themes/hueman/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1},{"_id":"themes/hueman/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1},{"_id":"themes/hueman/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1},{"_id":"themes/hueman/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1},{"_id":"themes/hueman/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1},{"_id":"themes/hueman/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1},{"_id":"themes/hueman/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1},{"_id":"themes/hueman/source/css/style.styl","path":"css/style.styl","modified":1},{"_id":"themes/hueman/source/css/images/thumb-default.png","path":"css/images/thumb-default.png","modified":1},{"_id":"themes/hueman/source/css/images/thumb-default-small.png","path":"css/images/thumb-default-small.png","modified":1},{"_id":"themes/hueman/source/css/images/s-left.png","path":"css/images/s-left.png","modified":1},{"_id":"themes/hueman/source/css/images/opacity-10.png","path":"css/images/opacity-10.png","modified":1},{"_id":"themes/hueman/source/css/images/logo-header.png","path":"css/images/logo-header.png","modified":1},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1},{"_id":"themes/hueman/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1}],"Cache":[{"_id":"source/CNAME","shasum":"e8afbfc153d8646cc8ca9239cd55302520f821e1","modified":1434173657728},{"_id":"source/_posts/Flick Ticket Server.md","shasum":"852bde5d92d7f20d32bfae3c5d8fe89e76dc1b13","modified":1435106847245},{"_id":"source/_posts/MemoryUsage.md","shasum":"8ac5ef24f5aacb678eb17cb2d7f03f7aeec6c625","modified":1434338620100},{"_id":"source/_posts/docker命令.md","shasum":"d5c441b78722cd883ebcaf1160d730f234d07ae6","modified":1434343589100},{"_id":"source/_posts/docker搭建日志分析.md","shasum":"3ab01a0583cbd9198e3eabc23567de71b1d5d7f7","modified":1434343575389},{"_id":"source/_posts/gitbook.md","shasum":"d0df7c10982e70f3494b18b698abee6854cf02d7","modified":1434343690862},{"_id":"source/_posts/io_models.md","shasum":"832953f4a976692c59f996fc0d0472dd7265df98","modified":1435384385468},{"_id":"source/_posts/java_hook.md","shasum":"224988be64f26af1d389bc8e600e73cf58c692f5","modified":1434343673735},{"_id":"source/_posts/java集合.md","shasum":"7c23c5271f676b7455d7cb2c2f7f6779f64b9630","modified":1435125058352},{"_id":"source/_posts/windows rust.md","shasum":"296a69cc1c73e32ddb6fb51bad809f3a1449f45b","modified":1435124775956},{"_id":"themes/hueman/Gruntfile.js","shasum":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1432866167000},{"_id":"themes/hueman/LICENSE","shasum":"3975b7883caeb33f61fada7c0ef4add7ab189849","modified":1432866167000},{"_id":"themes/hueman/README.md","shasum":"cb0615f198b8b322d77452aa9fd2924189995855","modified":1432866167000},{"_id":"themes/hueman/_config.yml","shasum":"ea0d8e76d6d6b5618bbe20665aa8480ade9e92b9","modified":1434543451517},{"_id":"themes/hueman/languages/en.yml","shasum":"d48c4b24d25245d99d26e67496701c8ba85c6f38","modified":1432866167000},{"_id":"themes/hueman/languages/zh-CN.yml","shasum":"cd77a9c743c75fbae8e00f7f052acbbf8dc43e99","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/after-footer.ejs","shasum":"4c1afa7c23b1c20cbd0445ee2734a78a4e5ac774","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/archive.ejs","shasum":"d503cd2de2ad6c569d6cc47208987e00536231be","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/article.ejs","shasum":"9f9bb63d55b384f377bcf23e6084c03f734924f4","modified":1434333379544},{"_id":"themes/hueman/layout/_partial/footer.ejs","shasum":"badb01bc45dc40f305ffce29798fa19066d169a6","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/google-analytics.ejs","shasum":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/head.ejs","shasum":"d27da77c892559b7ab13e36a84db791a2cdec7bf","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/header.ejs","shasum":"48244d5bb465ece2a047dec0dd6176cc3980a0a7","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/category.ejs","shasum":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/date.ejs","shasum":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/gallery.ejs","shasum":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/nav.ejs","shasum":"025a7695be81126dff4fcbeff1face60118da600","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/tag.ejs","shasum":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/thumbnail.ejs","shasum":"a1d68ad1eb9092aca74321aff3c9fd42029c9ba6","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/post/title.ejs","shasum":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1432866167000},{"_id":"themes/hueman/layout/_partial/sidebar.ejs","shasum":"566ec2c9f9051a9489ef1de0b0c15f5765ca14ad","modified":1432866167000},{"_id":"themes/hueman/layout/_widget/archive.ejs","shasum":"92fcfd830c011f1ff6e7d95443fe65067d3161f8","modified":1432866167000},{"_id":"themes/hueman/layout/_widget/category.ejs","shasum":"f0bb4be5c625003c0e38312f5079667be3a09ab7","modified":1432866167000},{"_id":"themes/hueman/layout/_widget/links.ejs","shasum":"e24c5bebe3e9f0bbaaf3b44bce8ef5ce56ae348b","modified":1432866167000},{"_id":"themes/hueman/layout/_widget/recent_posts.ejs","shasum":"0c4c97131131e5d06a886f9dc6e00f5de34e2bd3","modified":1432866167000},{"_id":"themes/hueman/layout/_widget/tag.ejs","shasum":"7b35103049fd0480f2631327b9381b7f4c9f5bcb","modified":1432866167000},{"_id":"themes/hueman/layout/_widget/tagcloud.ejs","shasum":"f4ac20c48e4bd6202e263efc9d320de1ad48d608","modified":1432866167000},{"_id":"themes/hueman/layout/archive.ejs","shasum":"2d86ef0f908b57af4ebf007eb8c6624def84f82a","modified":1432866167000},{"_id":"themes/hueman/layout/category.ejs","shasum":"85f2f7e0fdc16c496927511206364304ec364abe","modified":1432866167000},{"_id":"themes/hueman/layout/index.ejs","shasum":"2d86ef0f908b57af4ebf007eb8c6624def84f82a","modified":1432866167000},{"_id":"themes/hueman/layout/layout.ejs","shasum":"93aae2d158bd5855ca0d29cba80c1d39a39315e5","modified":1432866167000},{"_id":"themes/hueman/layout/page.ejs","shasum":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1432866167000},{"_id":"themes/hueman/layout/post.ejs","shasum":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1432866167000},{"_id":"themes/hueman/layout/tag.ejs","shasum":"2d86ef0f908b57af4ebf007eb8c6624def84f82a","modified":1432866167000},{"_id":"themes/hueman/package.json","shasum":"47c5adba0477e92e742349bf86f28bfeb701b3c1","modified":1432866167000},{"_id":"themes/hueman/scripts/fancybox.js","shasum":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1432866167000},{"_id":"themes/hueman/source/css/_extend.styl","shasum":"41c5b46a19627571bd592eb4b071e2e279333252","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/archive.styl","shasum":"c611142866096da7c7428d2ef8fd4079a781f57c","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/article.styl","shasum":"8917e23af967971318d05252e7e03cc205fc5f16","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/assets.styl","shasum":"38e578af64f98e30fba8dadd5a4699a0972eda8e","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/comment.styl","shasum":"2683cecb7d69e23a3fb1e80f10141454fb4cb232","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/footer.styl","shasum":"5758e93569a1baf63de1e65ab7746df1d3130624","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/header.styl","shasum":"57db2edb99734989ee147226dc952506cb8f73e2","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/highlight.styl","shasum":"9332816d92370cff8e252631ef65cb78c53ebb2a","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/nav.styl","shasum":"ea1d621a570dec9833dcc6519d039821c72e1d8c","modified":1432866167000},{"_id":"themes/hueman/source/css/_partial/sidebar.styl","shasum":"494e9ba779f4d9ad023135baf76a270b2a6d8c94","modified":1432866167000},{"_id":"themes/hueman/source/css/_responsive.styl","shasum":"7518d511dee2f0f4da85ff635ff0da20060dc9b8","modified":1432866167000},{"_id":"themes/hueman/source/css/_retina.styl","shasum":"e0445c7caa049250fe3811f55cc82f389009e90f","modified":1432866167000},{"_id":"themes/hueman/source/css/_variables.styl","shasum":"350d1134f92fbf175a7a783baebf9cb3d85adbeb","modified":1432866167000},{"_id":"themes/hueman/source/css/fonts/FontAwesome.otf","shasum":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1432866167000},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.eot","shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1432866167000},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.woff","shasum":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1432866167000},{"_id":"themes/hueman/source/css/images/logo-header.png","shasum":"a874be8f3e33831614a421d1a74d2c13bd5eba59","modified":1432866167000},{"_id":"themes/hueman/source/css/images/opacity-10.png","shasum":"bbc979866c5b50e8adb348419154b28b1ff44d78","modified":1432866167000},{"_id":"themes/hueman/source/css/images/s-left.png","shasum":"c8cac4f4e3492606fab93196364bd0f87d93bb98","modified":1432866167000},{"_id":"themes/hueman/source/css/images/thumb-default-small.png","shasum":"e8403b97ed9251f9f5207765b0ce796c5000b4ba","modified":1432866167000},{"_id":"themes/hueman/source/css/images/thumb-default.png","shasum":"2d0ba175d958d342494241c616a74d37f48059fb","modified":1432866167000},{"_id":"themes/hueman/source/css/style.styl","shasum":"0c9a533dacb73437543256f398e31ce8189ab970","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-buttons.js","shasum":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-media.js","shasum":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/helpers/jquery.fancybox-thumbs.js","shasum":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/jquery.fancybox.css","shasum":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/jquery.fancybox.js","shasum":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/jquery.fancybox.pack.js","shasum":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1432866167000},{"_id":"themes/hueman/source/fancybox/title.png","shasum":"767e5a74f309dca3e0bf82bf58d362e0943a44a2","modified":1434542986215},{"_id":"themes/hueman/source/js/html-patch.js","shasum":"3317f440bb17076538b9f94929f8f907f0546b7b","modified":1432866167000},{"_id":"themes/hueman/source/js/script.js","shasum":"3a882ecf9ed0a1a921090d954037f90d4e5089e8","modified":1432866167000},{"_id":"themes/hueman/source/scrollLoading/images/preloader.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1432866167000},{"_id":"themes/hueman/source/scrollLoading/images/preloader@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1432866167000},{"_id":"themes/hueman/source/scrollLoading/jquery.scrollLoading.js","shasum":"1a3eab1ab2c4644fe1ada921bd1bdb083268a751","modified":1432866167000},{"_id":"themes/hueman/source/scrollLoading/main.js","shasum":"9bc8cc83b73a4aa90d75340a03a6a1e39a8c35e2","modified":1432866167000},{"_id":"themes/hueman/source/scrollLoading/style.css","shasum":"4ee06b1478b786aed0817b629cf58f336e5eff62","modified":1432866167000},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.ttf","shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1432866167000},{"_id":"themes/hueman/source/css/fonts/fontawesome-webfont.svg","shasum":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1432866167000},{"_id":"public/CNAME","modified":1435384746381,"shasum":"e8afbfc153d8646cc8ca9239cd55302520f821e1"},{"_id":"public/scrollLoading/style.css","modified":1435384746384,"shasum":"4ee06b1478b786aed0817b629cf58f336e5eff62"},{"_id":"public/scrollLoading/main.js","modified":1435384746386,"shasum":"9bc8cc83b73a4aa90d75340a03a6a1e39a8c35e2"},{"_id":"public/scrollLoading/jquery.scrollLoading.js","modified":1435384746387,"shasum":"1a3eab1ab2c4644fe1ada921bd1bdb083268a751"},{"_id":"public/scrollLoading/images/preloader@2x.gif","modified":1435384746389,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/scrollLoading/images/preloader.gif","modified":1435384746390,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/js/script.js","modified":1435384746392,"shasum":"3a882ecf9ed0a1a921090d954037f90d4e5089e8"},{"_id":"public/js/html-patch.js","modified":1435384746395,"shasum":"3317f440bb17076538b9f94929f8f907f0546b7b"},{"_id":"public/fancybox/title.png","modified":1435384746396,"shasum":"767e5a74f309dca3e0bf82bf58d362e0943a44a2"},{"_id":"public/fancybox/jquery.fancybox.pack.js","modified":1435384746397,"shasum":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e"},{"_id":"public/fancybox/jquery.fancybox.js","modified":1435384746398,"shasum":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed"},{"_id":"public/fancybox/jquery.fancybox.css","modified":1435384746400,"shasum":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6"},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","modified":1435384746402,"shasum":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c"},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","modified":1435384746403,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","modified":1435384746404,"shasum":"294420f9ff20f4e3584d212b0c262a00a96ecdb3"},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","modified":1435384746406,"shasum":"dc3645529a4bf72983a39fa34c1eb9146e082019"},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","modified":1435384746408,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/fancybox/helpers/fancybox_buttons.png","modified":1435384746410,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/fancybox/fancybox_sprite@2x.png","modified":1435384746412,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/fancybox/fancybox_sprite.png","modified":1435384746414,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/fancybox/fancybox_overlay.png","modified":1435384746416,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/fancybox/fancybox_loading@2x.gif","modified":1435384746418,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/fancybox/fancybox_loading.gif","modified":1435384746420,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/fancybox/blank.gif","modified":1435384746421,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/css/style.css","modified":1435384747243,"shasum":"38bf0534eb06193af17b01e4eae09571537fa4f7"},{"_id":"public/css/images/thumb-default.png","modified":1435384747459,"shasum":"2d0ba175d958d342494241c616a74d37f48059fb"},{"_id":"public/css/images/thumb-default-small.png","modified":1435384747461,"shasum":"e8403b97ed9251f9f5207765b0ce796c5000b4ba"},{"_id":"public/css/images/s-left.png","modified":1435384747462,"shasum":"c8cac4f4e3492606fab93196364bd0f87d93bb98"},{"_id":"public/css/images/opacity-10.png","modified":1435384747464,"shasum":"bbc979866c5b50e8adb348419154b28b1ff44d78"},{"_id":"public/css/images/logo-header.png","modified":1435384747466,"shasum":"a874be8f3e33831614a421d1a74d2c13bd5eba59"},{"_id":"public/css/fonts/fontawesome-webfont.woff","modified":1435384747467,"shasum":"04c3bf56d87a0828935bd6b4aee859995f321693"},{"_id":"public/css/fonts/fontawesome-webfont.ttf","modified":1435384747469,"shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f"},{"_id":"public/css/fonts/fontawesome-webfont.svg","modified":1435384747472,"shasum":"46fcc0194d75a0ddac0a038aee41b23456784814"},{"_id":"public/css/fonts/fontawesome-webfont.eot","modified":1435384747474,"shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e"},{"_id":"public/css/fonts/FontAwesome.otf","modified":1435384747475,"shasum":"b5b4f9be85f91f10799e87a083da1d050f842734"},{"_id":"public/2015/06/27/io_models/index.html","modified":1435384747532,"shasum":"148d2cbadf2b863c6f3bed11a71b096cded2bbf5"},{"_id":"public/2015/06/24/windows rust/index.html","modified":1435384747544,"shasum":"fc4a2631fb03d9aab05a4b06c0acd0af473e17ba"},{"_id":"public/2015/06/24/java集合/index.html","modified":1435384747557,"shasum":"50b1ab3d5336b4316141d1cfc68099e71ca57b73"},{"_id":"public/2015/06/24/Flick Ticket Server/index.html","modified":1435384747570,"shasum":"5d4b00459496bd65140cc23667b718a6b45f5f44"},{"_id":"public/2015/06/15/java_hook/index.html","modified":1435384747584,"shasum":"3ddc554cb4161ed463d4957fbc7dab098c91b0aa"},{"_id":"public/2015/06/15/gitbook/index.html","modified":1435384747595,"shasum":"39da7854e4830119f78b14f1a730c4c92b353e17"},{"_id":"public/2015/06/15/docker搭建日志分析/index.html","modified":1435384747613,"shasum":"da98786115b6a0243d00b8ec1ffce4ee15e7c033"},{"_id":"public/2015/06/15/docker命令/index.html","modified":1435384747626,"shasum":"04716c84958b507e4818c6b3af3dcdd27f559fec"},{"_id":"public/2015/06/15/MemoryUsage/index.html","modified":1435384747637,"shasum":"b42f0267ddc32b387beabbc1cfab83242d53efe9"},{"_id":"public/archives/index.html","modified":1435384747651,"shasum":"ca22c05f01eee1500160714a8737301bb3b6152c"},{"_id":"public/archives/2015/index.html","modified":1435384747665,"shasum":"2cbf178c65e673fba5cdb6210ce7f1e4fa8bce76"},{"_id":"public/archives/2015/06/index.html","modified":1435384747686,"shasum":"544073af45b2c17b85506eceb7c304fa64185029"},{"_id":"public/index.html","modified":1435384747700,"shasum":"3d0ba757c17b802be2e292dd77f498e03539a3a8"}],"Category":[],"Data":[],"Page":[],"Post":[{"_content":"在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","source":"_posts/windows rust.md","raw":"在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","slug":"windows rust","published":1,"date":"2015-06-24T05:57:40.365Z","updated":"2015-06-24T05:46:15.956Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lyu0000kwuf9c3fqohi"},{"title":"java集合","_content":"\n##### 单线程集合\n这一部分介绍的是不支持多线程的集合.这些集合都在java.util包里.其中一些在Java 1.0的时候就有了(现在已经弃用),其中大多数在Java 1.4中重新发布.枚举集合在Java 1.5中重新发布,\n并且从这个版本之后所有的集合都支持泛型.PriorityQueue也在Java 1.5中加入.非线程安全的集合架构的最后一个版本是ArrayDeque ,也在Java 1.6中重新发布了.\n\n\n### List\n\n* `LinkedList`：\n\t`Deque`实现：每一个节点都保存着上一个节点和下一个节点的指针.这就意味着数据的存取和更新具有线性复杂度(这也是一个最佳化的实现,每次操作都不会遍历数组一半以上,操作成本最高的元素就是数组中间的那个).如果想写出高效的LinkedList代码可以使用 ListIterators .如果你想用一个Queue/Deque实现的话(你只需读取第一个和最后一个元素就行了)——考虑用ArrayDeque代替.\n\n* `Vector`：\n\n\t一个带有线程同步方法的ArrayList版本.现在直接用ArrayList代替了.\n\n* `ArrayList`：\n\t最有用的List集合实现.由一个整形数字或数组存储了集合的大小(数组中第一个没有使用的元素).像所有的List集合一样,ArrayList可以在必要的时候扩展它的大小.ArrayList访问元素的时间开销固定.在尾部添加元素成本低(为常数复杂度),而在头部添加元素成本很高(线性复杂度).\n\t这是由ArrayList的实现原理——所有的元素的从角标为0开始一个接着一个排列造成的.也就是说,从要插入的元素位置往后,每个元素都要向后移动一个位置.CPU缓存友好的集合是基于数组的.(其实也不是很友好,因为有时数组会包含对象,这样存储的只是指向实际对象的指针).\n\n\n### Maps\n* `HashMap`：\n\t最常用的Map实现.只是将一个键和值相对应,并没有其他的功能.对于复杂的hashCode method,get/put方法有固定的复杂度.就是一张hash表,键和值都没有排序.Hashtable 的后继者HashMap 是作为JDK1.2中的集合框架的一部分出现的,它通过提供一个不同步的基类和一个同步的包装器Collections.synchronizedMap ,解决了线程安全性问题.\n\n* `EnumMap`：\n\n\t枚举作为键值的Map.因为键的数量相对固定,所以在内部用一个数组储存对应值.通常来说,效率要高于HashMap.\n\n* `HashTable`：\n\n\t旧HashMap的同步版本,新的代码中也使用了HashMap.是同步的(而HashMap是不同步的).所以如果在线程安全的环境下应该多使用HashMap,而不是Hashtable,因为Hashtable对同步有额外的开销.提供了一种易于使用的、线程安全的、关联的map功能.然而,线程安全性付出代价是――Hashtable 的所有方法都是同步的.\n\n* `IdentityHashMap`：\n\n\t这是一个特殊的Map版本,它违背了一般Map的规则`：它使用 “==” 来比较引用而不是调用Object.equals来判断相等.这个特性使得此集合在遍历图表的算法中非常实用——可以方便地在IdentityHashMap中存储处理过的节点以及相关的数据.\n\n* `LinkedHashMap `：\n\n\t保存了插入时的顺序.HashMap和LinkedList的结合,所有元素的插入顺序存储在LinkedList中.这就是为什么迭代LinkedHashMap的条目(entry)、键和值的时候总是遵循插入的顺序.在JDK中,这是每元素消耗内存最大的集合.\n\n* `TreeMap`：\n\n\t以红-黑树结构为基础,键值按顺序排列.一种基于已排序且带导向信息Map的红黑树.每次插入都会按照自然顺序或者给定的比较器排序.\n这个Map需要实现equals方法和Comparable/Comparator.compareTo需要前后一致.这个类实现了一个NavigableMap接口`：可以带有与键数量不同的入口,可以得到键的上一个或者下一个入口,可以得到另一Map某一范围的键(大致和SQL的BETWEEN运算符相同),以及其他的一些方法.\n\n* `WeakHashMap`：\n\n\t这种Map通常用在数据缓存中.它将键存储在WeakReference中,就是说,如果没有强引用指向键对象的话,这些键就可以被垃圾回收线程回收.值被保存在强引用中.因此,你要确保没有引用从值指向键或者将值也保存在弱引用中m.put(key, new WeakReference(value)).\n\n\n### Sets\n* `HashSet`：\n\n\t一个基于HashMap的Set实现.其中,所有的值为“假值”(同一个Object对象具备和HashMap同样的性能.基于这个特性,这个数据结构会消耗更多不必要的内存.\n\n* `EnumSet`：\n\n\t值为枚举类型的Set.Java的每一个enum都映射成一个不同的int.这就允许使用BitSet——一个类似的集合结构,其中每一比特都映射成不同的enum. EnumSet有两种实现,RegularEnumSet——由一个单独的long存储(能够存储64个枚举值,99.9%的情况下是够用的),JumboEnumSet——由long[]存储.\n\n* `BitSet`：\n\n\t一个比特Set.需要时常考虑用BitSet处理一组密集的整数Set(比如从一个预先知道的数字开始的id集合).这个类用 long[]来存储bit.\n\n* `LinkedHashMap`：\n\n\t与HashSet一样,这个类基于LinkedHashMap实现.这是唯一一个保持了插入顺序的Set.\n\n* `TreeSet`：\n\n\t与HashSet类似.这个类是基于一个TreeMap实例的.这是在单线程部分唯一一个排序的Set.\n","source":"_posts/java集合.md","raw":"title: java集合\n---\n\n##### 单线程集合\n这一部分介绍的是不支持多线程的集合.这些集合都在java.util包里.其中一些在Java 1.0的时候就有了(现在已经弃用),其中大多数在Java 1.4中重新发布.枚举集合在Java 1.5中重新发布,\n并且从这个版本之后所有的集合都支持泛型.PriorityQueue也在Java 1.5中加入.非线程安全的集合架构的最后一个版本是ArrayDeque ,也在Java 1.6中重新发布了.\n\n\n### List\n\n* `LinkedList`：\n\t`Deque`实现：每一个节点都保存着上一个节点和下一个节点的指针.这就意味着数据的存取和更新具有线性复杂度(这也是一个最佳化的实现,每次操作都不会遍历数组一半以上,操作成本最高的元素就是数组中间的那个).如果想写出高效的LinkedList代码可以使用 ListIterators .如果你想用一个Queue/Deque实现的话(你只需读取第一个和最后一个元素就行了)——考虑用ArrayDeque代替.\n\n* `Vector`：\n\n\t一个带有线程同步方法的ArrayList版本.现在直接用ArrayList代替了.\n\n* `ArrayList`：\n\t最有用的List集合实现.由一个整形数字或数组存储了集合的大小(数组中第一个没有使用的元素).像所有的List集合一样,ArrayList可以在必要的时候扩展它的大小.ArrayList访问元素的时间开销固定.在尾部添加元素成本低(为常数复杂度),而在头部添加元素成本很高(线性复杂度).\n\t这是由ArrayList的实现原理——所有的元素的从角标为0开始一个接着一个排列造成的.也就是说,从要插入的元素位置往后,每个元素都要向后移动一个位置.CPU缓存友好的集合是基于数组的.(其实也不是很友好,因为有时数组会包含对象,这样存储的只是指向实际对象的指针).\n\n\n### Maps\n* `HashMap`：\n\t最常用的Map实现.只是将一个键和值相对应,并没有其他的功能.对于复杂的hashCode method,get/put方法有固定的复杂度.就是一张hash表,键和值都没有排序.Hashtable 的后继者HashMap 是作为JDK1.2中的集合框架的一部分出现的,它通过提供一个不同步的基类和一个同步的包装器Collections.synchronizedMap ,解决了线程安全性问题.\n\n* `EnumMap`：\n\n\t枚举作为键值的Map.因为键的数量相对固定,所以在内部用一个数组储存对应值.通常来说,效率要高于HashMap.\n\n* `HashTable`：\n\n\t旧HashMap的同步版本,新的代码中也使用了HashMap.是同步的(而HashMap是不同步的).所以如果在线程安全的环境下应该多使用HashMap,而不是Hashtable,因为Hashtable对同步有额外的开销.提供了一种易于使用的、线程安全的、关联的map功能.然而,线程安全性付出代价是――Hashtable 的所有方法都是同步的.\n\n* `IdentityHashMap`：\n\n\t这是一个特殊的Map版本,它违背了一般Map的规则`：它使用 “==” 来比较引用而不是调用Object.equals来判断相等.这个特性使得此集合在遍历图表的算法中非常实用——可以方便地在IdentityHashMap中存储处理过的节点以及相关的数据.\n\n* `LinkedHashMap `：\n\n\t保存了插入时的顺序.HashMap和LinkedList的结合,所有元素的插入顺序存储在LinkedList中.这就是为什么迭代LinkedHashMap的条目(entry)、键和值的时候总是遵循插入的顺序.在JDK中,这是每元素消耗内存最大的集合.\n\n* `TreeMap`：\n\n\t以红-黑树结构为基础,键值按顺序排列.一种基于已排序且带导向信息Map的红黑树.每次插入都会按照自然顺序或者给定的比较器排序.\n这个Map需要实现equals方法和Comparable/Comparator.compareTo需要前后一致.这个类实现了一个NavigableMap接口`：可以带有与键数量不同的入口,可以得到键的上一个或者下一个入口,可以得到另一Map某一范围的键(大致和SQL的BETWEEN运算符相同),以及其他的一些方法.\n\n* `WeakHashMap`：\n\n\t这种Map通常用在数据缓存中.它将键存储在WeakReference中,就是说,如果没有强引用指向键对象的话,这些键就可以被垃圾回收线程回收.值被保存在强引用中.因此,你要确保没有引用从值指向键或者将值也保存在弱引用中m.put(key, new WeakReference(value)).\n\n\n### Sets\n* `HashSet`：\n\n\t一个基于HashMap的Set实现.其中,所有的值为“假值”(同一个Object对象具备和HashMap同样的性能.基于这个特性,这个数据结构会消耗更多不必要的内存.\n\n* `EnumSet`：\n\n\t值为枚举类型的Set.Java的每一个enum都映射成一个不同的int.这就允许使用BitSet——一个类似的集合结构,其中每一比特都映射成不同的enum. EnumSet有两种实现,RegularEnumSet——由一个单独的long存储(能够存储64个枚举值,99.9%的情况下是够用的),JumboEnumSet——由long[]存储.\n\n* `BitSet`：\n\n\t一个比特Set.需要时常考虑用BitSet处理一组密集的整数Set(比如从一个预先知道的数字开始的id集合).这个类用 long[]来存储bit.\n\n* `LinkedHashMap`：\n\n\t与HashSet一样,这个类基于LinkedHashMap实现.这是唯一一个保持了插入顺序的Set.\n\n* `TreeSet`：\n\n\t与HashSet类似.这个类是基于一个TreeMap实例的.这是在单线程部分唯一一个排序的Set.\n","slug":"java集合","published":1,"date":"2015-06-24T05:57:40.362Z","updated":"2015-06-24T05:50:58.352Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzp0001kwuf9nbu6u6y"},{"title":"JAVA钩子程序","_content":"# java hook\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```\nnohup java HookTest &\n```\n#### 关闭程序\n```\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\t\n\tpublic static void exec() {\n\t\texec();\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\t\t\n\t\tSystem.out.println(\"Main over\");\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试\n```java\n\n```","source":"_posts/java_hook.md","raw":"title: JAVA钩子程序\n---\n# java hook\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```\nnohup java HookTest &\n```\n#### 关闭程序\n```\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\t\n\tpublic static void exec() {\n\t\texec();\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\t\t\n\t\tSystem.out.println(\"Main over\");\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试\n```java\n\n```","slug":"java_hook","published":1,"date":"2015-06-15T05:14:56.191Z","updated":"2015-06-15T04:47:53.735Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzr0002kwuf5i45b66n"},{"title":"JAVA IO","_content":"# IO模型\n\n\n## IO概念\n\nLinux的内核将所有外部设备都可以看做一个文件来操作。那么我们对与外部设备的操作都可以看做对文件进行操作。我们对一个文件的读写，都通过调用内核提供的系统调用；内核给我们返回一个file descriptor（fd,文件描述符）。而对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符）。描述符就是一个数字，指向内核中一个结构体（文件路径，数据区，等一些属性）。那么我们的应用程序对文件的读写就通过对描述符的读写完成。\n\nlinux将内存分为内核区，用户区。linux内核给我们管理所有的硬件资源，应用程序通过调用系统调用和内核交互，达到使用硬件资源的目的。应用程序通过系统调用read发起一个读操作，这时候内核创建一个文件描述符，并通过驱动程序向硬件发送读指令，并将读的的数据放在这个描述符对应结构体的内核缓存区中，然后再把这个数据读到用户进程空间中，这样完成了一次读操作；但是大家都知道I/O设备相比cpu的速度是极慢的。linux提供的read系统调用，也是一个阻塞函数。这样我们的应用进程在发起read系统调用时，就必须阻塞，就进程被挂起而等待文件描述符的读就绪，那么什么是文件描述符读就绪，什么是写就绪？\n\n* 读就绪：就是这个文件描述符的接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的当前大小；\n* 写就绪：该描述符发送缓冲区的可用空间字节数大于等于描述符发送缓冲区低水位标记的当前大小。（如果是socket fd，说明上一个数据已经发送完成）。\n\n接收低水位标记和发送低水位标记：由应用程序指定，比如应用程序指定接收低水位为64个字节。那么接收缓冲区有64个字节，才算fd读就绪；\n综上所述，一个基本的IO，它会涉及到两个系统对象，一个是调用这个IO的进程对象，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：\n\n* 通过read系统调用想内核发起读请求。\n* 内核向硬件发送读指令，并等待读就绪。 \n* 内核把将要读取的数据复制到描述符所指向的内核缓存区中。\n* 将数据从内核缓存区拷贝到用户进程空间中。\n\n### 整个I/O流经历一下几个节点:\n\n1. File System – 文件系统会根据文件与Block的映射关系,通过`File System Manager`将文件划分为多个Block,请求发送给HBA.\n2. HBA  – HBA执行对这一系列的更小的工作单元进行操作,将这部分I/O转换为Fibre Channel协议,包装成不超过2KB的Frame传输到下一个连接节点FC Switch.\n3. FC Switch          – FC Switch会通过FC Fabric网络将这些Frame发送到存储系统的前端口（Front Adapter）.\n4. Storage FA         – 存储前端口会将这些FC 的Frame重新封装成和HBA初始发送I/O一致,然后FA会将数据传输到阵列缓存Storage Array Cache）\n5. Storage Array Cache – 阵列缓存处理I/O通常有两种情况:\n    * 直接返回数据已经写入的讯号给HBA,这种叫作回写,也是大多数存储阵列处理的方式.\n    * 数据写入缓存然后再刷新到物理磁盘,叫做写透.I/O存放在缓存中以后,交由后端控制器（Disk Adapter）继续处理,完成后再返回数据已经写入的讯号给HBA.\n6. Disk Adapter       – 上述两种方式,最后都会将I/O最后写入到物理磁盘中.这个过程由后端Disk Adapter控制,一个I/O会变成两个或者多个实际的I/O.\n\n##### 根据上述的I/O流向的来看,一个完整的I/O传输,经过的会消耗时间的节点可以概括为以下几个:\n\n1. CPU – RAM, 完成主机文件系统到HBA的操作.\n2. HBA – FA,完成在光纤网络中的传输过程.\n3. FA – Cache,存储前端卡将数据写入到缓存的时间.\n4. DA – Drive,存储后端卡将数据从缓存写入到物理磁盘的时间.\n\n## IO类型\n\n### 阻塞IO\n最流行的I/O模型是阻塞I/O模型，缺省情形下，所有文件操作都是阻塞的。我们以套接口为例来讲解此模型。在进程空间中调用recvfrom，其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回，期间一直在等待。我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的。\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n进程把一个套接口设置成非阻塞是在通知内核：当所请求的I/O操作不能满足要求时候，不把本进程投入睡眠，而是返回一个错误。也就是说当数据没有到达时并不等待，而是以一个错误返回。\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n\n通过上面，我们知道，所有的IO操作在默认情况下，都是属于阻塞IO。尽管上图中所示的反复请求的非阻塞IO的效率底下（需要反复在用户空间和进程空间切换和判断，把一个原本属于IO密集的操作变为IO密集和计算密集的操作），但是在后面IO复用中，需要把IO的操作设置为非阻塞的，此时程序将会阻塞在select和poll系统调用中。把一个IO设置为非阻塞IO有两种方式：在创建文件描述符时，指定该文件描述符的操作为非阻塞；在创建文件描述符以后，调用fcntl()函数设置相应的文件描述符为非阻塞。\n创建描述符时，利用open函数和socket函数的标志设置返回的fd/socket描述符为O_NONBLOCK。\n\n```c\nint sd=socket(int domain, int type|O_NONBLOCK, int protocol);  \nint fd=open(const char *pathname, int flags|O_NONBLOCK);  \n```\n创建描述符后，通过调用fcntl函数设置描述符的属性为O_NONBLOCK\n```c\n#include <unistd.h>  \n#include <fcntl.h>  \n  \nint fcntl(int fd, int cmd, ... /* arg */ );  \n  \n//例子  \nif (fcntl(fd, F_SETFL, fcntl(sockfd, F_GETFL, 0)|O_NONBLOCK) == -1) {  \n    return -1;  \n}  \n    return 0;  \n}  \n```\n\n### SIGIO\n首先开启套接口信号驱动I/O功能, 并通过系统调用sigaction安装一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据报准备好被读时，就为该进程生成一个SIGIO信号。随即可以在信号处理程序中调用recvfrom来读数据报，井通知主循环数据已准备好被处理中。也可以通知主循环，让它来读数据报。\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### select and poll\nlinux提供select/poll，进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select;这样select/poll可以帮我们侦测许多fd是否就绪。但是select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限。linux还提供了一个epoll系统调用，epoll是基于事件驱动方式，而不是顺序扫描,当有fd就绪时，立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n##### IO复用详解\n\n在IO编程过程中，当需要处理多个请求的时，可以使用多线程和IO复用的方式进行处理。上面的图介绍了整个IO复用的过程，它通过把多个IO的阻塞复用到一个select之类的阻塞上，从而使得系统在单线程的情况下同时支持处理多个请求。和多线程/进程比较，I/O多路复用的最大优势是系统开销小，系统不需要建立新的进程或者线程，也不必维护这些线程和进程。IO复用常见的应用场景：\n1. 客户程序需要同时处理交互式的输入和服务器之间的网络连接。\n2. 客户端需要对多个网络连接作出反应。\n3. 服务器需要同时处理多个处于监听状态和多个连接状态的套接字\n4. 服务器需要处理多种网络协议的套接字。\n\n### windows的IOCP\n告知内核启动某个操作，并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们。这种模型与信号驱动模型的主要区别是：信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；异步I/O模型：由内核通知我们I/O操作何时完成。\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝。可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上，数据无需流经应用程序。本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销，然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能。\n\n\n###### 数据传输：传统方法\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换。在内部，发出 `sys_read()`(或等效内容)以从文件中读取数据。直接内存存取(`direct memory access`，DMA)引擎执行了第一次拷贝，它从磁盘中读取文件内容，然后将它们存储到一个内核地址空间缓存区中。\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区，read() 调用返回。该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换)。现在数据被储存在用户地址空间缓冲区。\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换。数据被第三次拷贝，并被再次放置在内核地址空间缓冲区。但是这一次放置的缓冲区不同，该缓冲区与目标套接字相关联。\n4. `send()` 系统调用返回，结果导致了第四次的上下文切换。DMA 引擎将数据从内核缓冲区传到协议引擎，第四次拷贝独立地、异步地发生 。\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下。但是之所以引入中间内核缓冲区的目的是想提高性能。在读取方面使用中间内核缓冲区，可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时，充当 “预读高速缓存(readahead cache)” 的角色。这在所需数据量小于内核缓冲区大小时极大地提高了性能。在写入方面的中间缓冲区则可以让写入过程异步完成。\n\n不幸的是，如果所需数据量远大于内核缓冲区大小的话，这个方法本身可能成为一个性能瓶颈。数据在被最终传入到应用程序前，在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次。\n\n零拷贝通过消除这些冗余的数据拷贝而提高了性能。\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区。然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区。\n\n2. 数据的第三次复制发生在 DMA 引擎将数据从内核套接字缓冲区传到协议引擎时。\n\t改进的地方：我们将上下文切换的次数从四次减少到了两次，将数据复制的次数从四次减少到了三次(其中只有一次涉及到了 CPU)。但是这个代码尚未达到我们的零拷贝要求。如果底层网络接口卡支持收集操作 的话，那么我们就可以进一步减少内核的数据复制。在 Linux 内核 2.4 及后期版本中，套接字缓冲区描述符就做了相应调整，以满足该需求。这种方法不仅可以减少多个上下文切换，还可以消除需要涉及 CPU 的重复的数据拷贝。对于用户方面，用法还是一样的，但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区。\nB. 数据未被拷贝到套接字缓冲区。取而代之的是，只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区。DMA 引擎直接把数据从内核缓冲区传输到协议引擎，从而消除了剩下的最后一次 CPU 拷贝。\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n\n\n\n## JAVA IO\n### io#interface\n\n* [Closeable]()\n\tCloseable 是可以关闭的数据源或目标。调用 close 方法可释放对象保存的资源（如打开文件）。\n* [DataInput]()\n\tDataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据。同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具。\n\n\t对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）。如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException。尤其在输入流已关闭的情况下，将抛出 IOException。\n* [DataOutput]()\n\t\n\tDataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流。同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具。\n\t\n\t对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException。\n\t\n* [Externalizable]()\n\t\n\tExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成。如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段。\n\t\n* [FileFilter](TestFileFilter.java)\n\n\t检测文件是否存在。FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法，\n\t而FilenameFilter 是按照目录和文件名的方式来工作的。\n\n* [FilenameFilter]()\n\n* [Flushable]()\n\t实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中。写入流的所有I/O类都实现了Flushable接口。\n* [ObjectInput]()\n* [ObjectInputValidation]()\n\t序列化流验证机制. 一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题。但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息。Java序列化提供一套验证机制。序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n* [ObjectOutput]()\n* [ObjectStreamConstants]()\n\tJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值。Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分。现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中。 \n* [Serializable]()\n\n### io#class\n\n* [BufferedInputStream]()\n\n\tBufferedInputStream是一个带有缓冲区域的InputStream, 支持“mark()标记”和“reset()重置方法”。输入到byte[]数组里.\n* [BufferedOutputStream]()\n\t缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\n\n* [BufferedReader]()\n\n\tBufferedReader 从字符输入流中读取文本，缓冲各个字符。提供字符、数组和行的高效读取。\n\n* [BufferedWriter]()\n\n\t>1. 支持字符串输出\n\t2. 支持换行输出\n\t3. 支持文件追加输出\n\n* [ByteArrayInputStream]()\n\n\t从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。\n* [ByteArrayOutputStream]()\n\n\t输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何IOException。\n\n* [CharArrayReader]()\n\t与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n\n* [CharArrayWriter]()\n\t向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write \n* [Console]()\n\t专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n\t\n* [DataInputStream]()\n\t用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n* [DataOutputStream]()\n\t用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”。\n* [File]()\n```\n\t1. 删除文件\n\t2. 文件重命名\n\t3. 创建新的文件\n\t4. 创建新的文件\n\t5. 获取文件的最后修改时间\n\t6. 设置文件只读\n\t7. 设置文件可写\n\t8. 获取文件长度(总字节数)\n\t9. 获取文件路径\n\t10. 获取绝对文件路径\n\t11. 文件是否隐藏\n\t12. 获得剩余磁盘空间？\n\t13. 拷贝文件夹\n\t14. 遍历文件夹\n\t15. 检查文件夹是否为空？\n```\n* [FileDescriptor]()\n\t用来表示开放文件、开放套接字等。当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。\n\t\n\t类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件，打开的套接字或其他来源或字节的接收器。以下是关于FileDescriptor要点：\n\t1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它。\n\t2. 应用程序不应创建自己的文件描述符。\n\n* [FileInputStream]()\n\t一个字节一个字节的从文件里读取数据\n\t\n* [FileOutputStream]()\n\t一个字节一个字节的向文件里输出数据\n\n* [FilePermission]()\n\n* [FileReader]()\n\t一个字符一个字符地读取\n\n* [FileWriter]()\n\n\t一个字符一个字符地输出\n\n* [FilterInputStream]()\n\n\t用来“封装其它的输入流，并为它们提供额外的功能”。它的常用的子类有BufferedInputStream和DataInputStream。\n\n* [FilterOutputStream]()\n\n\t作用是用来“封装其它的输出流，并为它们提供额外的功能”。它主要包括BufferedOutputStream, \n\tDataOutputStream和PrintStream。\n\n* [FilterReader]()\n\n\t用于读取已过滤的字符流的抽象类。抽象类 FilterReader 自身提供了一些将所有请求传递给所包含的流的默认方法。\n\n* [FilterWriter]()\n\n\t用于写入已过滤的字符流的抽象类。抽象类 FilterWriter 自身提供了一些将所有请求传递给所包含的流的默认方法\n\n* [InputStream]()\n\n\n* [InputStreamReader]()\n\n\t是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。\n\t将“字节输入流”转换成“字符输入流”。它继承于Reader。\n\n* [LineNumberInputStream]()\n\n\t此类是一个输入流过滤器，它提供跟踪当前行号的附加功能。行是以回车符 ('\\r')、换行符 ('\\n')或回车符后面紧跟换行符结尾的字节序列。在所有这三种情况下，都以单个换行符形式返回行终止字符。行号以 0 开头，并在 read 返回换行符时递增 1。\n\n* [LineNumberReader]()\n\n\t跟踪行号的缓冲字符输入流。此类定义了方法 setLineNumber(int) 和 getLineNumber()，它们可分别用于设置和获取当前行号。默认情况下，行编号从 0 开始。该行号随数据读取在每个行结束符处递增，并且可以通过调用 \n\tsetLineNumber(int) 更改行号。但要注意的是，setLineNumber(int) 不会实际更改流中的当前位置；它只更改将由getLineNumber() 返回的值。可认为行在遇到以下符号之一时结束：换行符（'\\n'）、回车符（'\\r'）、回车后紧跟换行符。\n\n* [ObjectInputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectOutputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectStreamField]()\n\n\tSerializable 类中 Serializable 字段的描述。ObjectStreamField 的数组用于声明类的 Serializable 字段。\n\n* [OutputStream]()\n\n\n* [OutputStreamWriter]()\n\n\tOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n\n* [PipedInputStream]()\n\n\t管道输入流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedOutputStream]()\n\n\t管道输出流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedReader]()\n\n\tPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n* [PipedWriter]()\n\n\tPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n* [PrintStream]()\n\n\t打印输出流, 用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream 永远不会抛出 IOException；PrintStream 提供了自动flush 和 字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\n* [PrintWriter]()\n\n\t用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\n* [PushbackInputStream]()\n\n\t拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n* [PushbackReader]()\n\n\t允许将字符推回到流的字符流 reader。\n\n* [RandomAccessFile]()\n\n\t用来访问那些保存数据记录的文件的，你就可以用seek( )方法来访问记录，并进行读写了。这些记录的大小不必相同；但是其大小和位置必须是可知的。但是该类仅限于操作文件。\n\n* [SequenceInputStream]()\n\n\t从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。 SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，\n\t接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n* [SerializablePermission]()\n\n\n* [StreamTokenizer]()\n\n\t获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。\n\t该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n* [StringBufferInputStream]()\n\n\n* [StringReader]()\n\n\n* [StringWriter]()\n\n\n### nio\n\n* [Buffer](java/src/test/io/robertsing/cookios/nio/TestBuffer.java)\n\n\n* [ByteBuffer](java/src/test/io/robertsing/cookios/nio/TestByteBuffer.java)\n\n\n* [ByteOrder](java/src/test/io/robertsing/cookios/nio/TestByteOrder.java)\n\n\n* [CharBuffer](java/src/test/io/robertsing/cookios/nio/TestCharBuffer.java)\n\n\n* [DoubleBuffer](java/src/test/io/robertsing/cookios/nio/TestDoubleBuffer.java)\n\n\n* [FloatBuffer](java/src/test/io/robertsing/cookios/nio/TestFloatBuffer.java)\n\n\n* [IntBuffer](java/src/test/io/robertsing/cookios/nio/TestIntBuffer.java)\n\n\n* [LongBuffer](java/src/test/io/robertsing/cookios/nio/TestLongBuffer.java)\n\n\n* [MappedByteBuffer](java/src/test/io/robertsing/cookios/nio/TestMappedByteBuffer.java)\n\n\n* [ShortBuffer](java/src/test/io/robertsing/cookios/nio/TestShortBuffer.java)\n\n\n### nio#channels#Interfaces\n\n* [AsynchronousByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousByteChannel.java)\n\n\n* [AsynchronousChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannel.java)\n\n\n* [ByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestByteChannel.java)\n\n\n* [Channel](java/src/test/io/robertsing/cookios/nio/channels/TestChannel.java)\n\n\n* [CompletionHandler](java/src/test/io/robertsing/cookios/nio/channels/TestCompletionHandler.java)\n\n\n* [GatheringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestGatheringByteChannel.java)\n\n\n* [InterruptibleChannel](java/src/test/io/robertsing/cookios/nio/channels/TestInterruptibleChannel.java)\n\n\n* [MulticastChannel](java/src/test/io/robertsing/cookios/nio/channels/TestMulticastChannel.java)\n\n\n* [NetworkChannel](java/src/test/io/robertsing/cookios/nio/channels/TestNetworkChannel.java)\n\n\n* [ReadableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestReadableByteChannel.java)\n\n\n* [ScatteringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestScatteringByteChannel.java)\n\n\n* [SeekableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSeekableByteChannel.java)\n\n\n* [WritableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestWritableByteChannel.java)\n\n\n### nio#channels#Classes\n\n* [AsynchronousChannelGroup](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannelGroup.java)\n\n\n* [AsynchronousFileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousFileChannel.java)\n\n\n* [AsynchronousServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousServerSocketChannel.java)\n\n\n* [AsynchronousSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousSocketChannel.java)\n\n\n* [Channels](java/src/test/io/robertsing/cookios/nio/channels/TestChannels.java)\n\n\n* [DatagramChannel](java/src/test/io/robertsing/cookios/nio/channels/TestDatagramChannel.java)\n\n\n* [FileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.java)\n\n\n* [FileChannel.MapMode](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.MapMode.java)\n\n\n* [FileLock](java/src/test/io/robertsing/cookios/nio/channels/TestFileLock.java)\n\n\n* [MembershipKey](java/src/test/io/robertsing/cookios/nio/channels/TestMembershipKey.java)\n\n\n* [Pipe](java/src/test/io/robertsing/cookios/nio/channels/TestPipe.java)\n\n\n* [SelectableChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSelectableChannel.java)\n\n\n* [SelectionKey](java/src/test/io/robertsing/cookios/nio/channels/TestSelectionKey.java)\n\n\n* [Selector](java/src/test/io/robertsing/cookios/nio/channels/TestSelector.java)\n\n\n* [ServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestServerSocketChannel.java)\n\n\n* [SocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSocketChannel.java)\n\n\n### nio#file#Interfaces\n\n* [CopyOption](java/src/test/io/robertsing/cookios/nio/file/TestCopyOption.java)\n\n\n* [DirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestDirectoryStream.java)\n\n\t遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n\n* [FileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestFileVisitor.java)\n\n\t@SimpleFileVisitor\n\n* [OpenOption](java/src/test/io/robertsing/cookios/nio/file/TestOpenOption.java)\n\n\n* [Path](java/src/test/io/robertsing/cookios/nio/file/TestPath.java)\n\n\n* [PathMatcher](java/src/test/io/robertsing/cookios/nio/file/TestPathMatcher.java)\n\n\n* [SecureDirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestSecureDirectoryStream.java)\n\n\n* [Watchable](java/src/test/io/robertsing/cookios/nio/file/TestWatchable.java)\n\n\n* [WatchEvent](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.java)\n\n\n* [WatchEvent.Kind](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Kind.java)\n\n\n* [WatchEvent.Modifier](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Modifier.java)\n\n\n* [WatchKey](java/src/test/io/robertsing/cookios/nio/file/TestWatchKey.java)\n\n\n* [WatchService](java/src/test/io/robertsing/cookios/niofile//TestWatchService.java)\n\n\n### nio#file#Classes\n\n* [Files]()\n\n\t1. copy\n\t2. createDirectories\n\t3. createDirectory\n\t4. createFile\n\t5. createLink\n\t6. createSymbolicLink\n\t7. createTempDirectory\n\t8. createTempFile\n\t9. delete\n\t10. deleteIfExists\n\t11. exists\n\t12. getAttribute\n\t13. getFileAttributeView\n\t14. getFileStore\n\t15. getLastModifiedTime\n\t16. getOwner\n\t17. getPosixFilePermissions\n\t18. isDirectory\n\t19. isExecutable\n\t20. isHidden\n\t21. isReadable\n\t22. isRegularFile\n\t23. isSameFile\n\t24. isSymbolicLink\n\t25. isWritable\n\t26. move\n\t27. newBufferedReader\n\t28. newBufferedWriter\n\t29. newByteChannel\n\t30. newDirectoryStream\n\t31. newInputStream\n\t32. newOutputStream\n\t33. notExists\n\t34. probeContentType\n\t35. readAllBytes\n\t36. readAllLines\n\t37. readAttributes\n\t38. readSymbolicLink\n\t39. setAttribute\n\t40. setLastModifiedTime\n\t41. setOwner\n\t42. setPosixFilePermissions\n\t43. walkFileTree\n\t44. write\n\n\n* [FileStore]()\n\n\t代表了真正的存储设备，提供了设备的详尽信息\n\n* [FileSystem](java/src/test/io/robertsing/cookios/nio/file/TestFileSystem.java)\n\n\n* [FileSystems](java/src/test/io/robertsing/cookios/nio/file/TestFileSystems.java)\n\n\n* [LinkPermission](java/src/test/io/robertsing/cookios/nio/file/TestLinkPermission.java)\n\n\n* [Paths](java/src/test/io/robertsing/cookios/nio/file/TestPaths.java)\n\n\n* [SimpleFileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestSimpleFileVisitor.java)\n\n\t与DirectoryStream 不同的是，这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n\n* [StandardWatchEventKinds](java/src/test/io/robertsing/cookios/nio/file/TestStandardWatchEventKinds.java)\n\n\n### nio#charset\n\n* [Charset](java/src/test/io/robertsing/cookios/nio/charset/TestCharset.java)\n\n\n* [CharsetDecoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetDecoder.java)\n\n\n* [CharsetEncoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetEncoder.java)\n\n\n* [CoderResult](java/src/test/io/robertsing/cookios/nio/charset/TestCoderResult.java)\n\n\n* [CodingErrorAction](java/src/test/io/robertsing/cookios/nio/charset/TestCodingErrorAction.java)\n\n\n* [StandardCharsets](java/src/test/io/robertsing/cookios/nio/charset/TestStandardCharsets.java)\n\n\n\n\n","source":"_posts/io_models.md","raw":"title: JAVA IO\n---\n# IO模型\n\n\n## IO概念\n\nLinux的内核将所有外部设备都可以看做一个文件来操作。那么我们对与外部设备的操作都可以看做对文件进行操作。我们对一个文件的读写，都通过调用内核提供的系统调用；内核给我们返回一个file descriptor（fd,文件描述符）。而对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符）。描述符就是一个数字，指向内核中一个结构体（文件路径，数据区，等一些属性）。那么我们的应用程序对文件的读写就通过对描述符的读写完成。\n\nlinux将内存分为内核区，用户区。linux内核给我们管理所有的硬件资源，应用程序通过调用系统调用和内核交互，达到使用硬件资源的目的。应用程序通过系统调用read发起一个读操作，这时候内核创建一个文件描述符，并通过驱动程序向硬件发送读指令，并将读的的数据放在这个描述符对应结构体的内核缓存区中，然后再把这个数据读到用户进程空间中，这样完成了一次读操作；但是大家都知道I/O设备相比cpu的速度是极慢的。linux提供的read系统调用，也是一个阻塞函数。这样我们的应用进程在发起read系统调用时，就必须阻塞，就进程被挂起而等待文件描述符的读就绪，那么什么是文件描述符读就绪，什么是写就绪？\n\n* 读就绪：就是这个文件描述符的接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的当前大小；\n* 写就绪：该描述符发送缓冲区的可用空间字节数大于等于描述符发送缓冲区低水位标记的当前大小。（如果是socket fd，说明上一个数据已经发送完成）。\n\n接收低水位标记和发送低水位标记：由应用程序指定，比如应用程序指定接收低水位为64个字节。那么接收缓冲区有64个字节，才算fd读就绪；\n综上所述，一个基本的IO，它会涉及到两个系统对象，一个是调用这个IO的进程对象，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：\n\n* 通过read系统调用想内核发起读请求。\n* 内核向硬件发送读指令，并等待读就绪。 \n* 内核把将要读取的数据复制到描述符所指向的内核缓存区中。\n* 将数据从内核缓存区拷贝到用户进程空间中。\n\n### 整个I/O流经历一下几个节点:\n\n1. File System – 文件系统会根据文件与Block的映射关系,通过`File System Manager`将文件划分为多个Block,请求发送给HBA.\n2. HBA  – HBA执行对这一系列的更小的工作单元进行操作,将这部分I/O转换为Fibre Channel协议,包装成不超过2KB的Frame传输到下一个连接节点FC Switch.\n3. FC Switch          – FC Switch会通过FC Fabric网络将这些Frame发送到存储系统的前端口（Front Adapter）.\n4. Storage FA         – 存储前端口会将这些FC 的Frame重新封装成和HBA初始发送I/O一致,然后FA会将数据传输到阵列缓存Storage Array Cache）\n5. Storage Array Cache – 阵列缓存处理I/O通常有两种情况:\n    * 直接返回数据已经写入的讯号给HBA,这种叫作回写,也是大多数存储阵列处理的方式.\n    * 数据写入缓存然后再刷新到物理磁盘,叫做写透.I/O存放在缓存中以后,交由后端控制器（Disk Adapter）继续处理,完成后再返回数据已经写入的讯号给HBA.\n6. Disk Adapter       – 上述两种方式,最后都会将I/O最后写入到物理磁盘中.这个过程由后端Disk Adapter控制,一个I/O会变成两个或者多个实际的I/O.\n\n##### 根据上述的I/O流向的来看,一个完整的I/O传输,经过的会消耗时间的节点可以概括为以下几个:\n\n1. CPU – RAM, 完成主机文件系统到HBA的操作.\n2. HBA – FA,完成在光纤网络中的传输过程.\n3. FA – Cache,存储前端卡将数据写入到缓存的时间.\n4. DA – Drive,存储后端卡将数据从缓存写入到物理磁盘的时间.\n\n## IO类型\n\n### 阻塞IO\n最流行的I/O模型是阻塞I/O模型，缺省情形下，所有文件操作都是阻塞的。我们以套接口为例来讲解此模型。在进程空间中调用recvfrom，其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回，期间一直在等待。我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的。\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n进程把一个套接口设置成非阻塞是在通知内核：当所请求的I/O操作不能满足要求时候，不把本进程投入睡眠，而是返回一个错误。也就是说当数据没有到达时并不等待，而是以一个错误返回。\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n\n通过上面，我们知道，所有的IO操作在默认情况下，都是属于阻塞IO。尽管上图中所示的反复请求的非阻塞IO的效率底下（需要反复在用户空间和进程空间切换和判断，把一个原本属于IO密集的操作变为IO密集和计算密集的操作），但是在后面IO复用中，需要把IO的操作设置为非阻塞的，此时程序将会阻塞在select和poll系统调用中。把一个IO设置为非阻塞IO有两种方式：在创建文件描述符时，指定该文件描述符的操作为非阻塞；在创建文件描述符以后，调用fcntl()函数设置相应的文件描述符为非阻塞。\n创建描述符时，利用open函数和socket函数的标志设置返回的fd/socket描述符为O_NONBLOCK。\n\n```c\nint sd=socket(int domain, int type|O_NONBLOCK, int protocol);  \nint fd=open(const char *pathname, int flags|O_NONBLOCK);  \n```\n创建描述符后，通过调用fcntl函数设置描述符的属性为O_NONBLOCK\n```c\n#include <unistd.h>  \n#include <fcntl.h>  \n  \nint fcntl(int fd, int cmd, ... /* arg */ );  \n  \n//例子  \nif (fcntl(fd, F_SETFL, fcntl(sockfd, F_GETFL, 0)|O_NONBLOCK) == -1) {  \n    return -1;  \n}  \n    return 0;  \n}  \n```\n\n### SIGIO\n首先开启套接口信号驱动I/O功能, 并通过系统调用sigaction安装一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据报准备好被读时，就为该进程生成一个SIGIO信号。随即可以在信号处理程序中调用recvfrom来读数据报，井通知主循环数据已准备好被处理中。也可以通知主循环，让它来读数据报。\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### select and poll\nlinux提供select/poll，进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select;这样select/poll可以帮我们侦测许多fd是否就绪。但是select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限。linux还提供了一个epoll系统调用，epoll是基于事件驱动方式，而不是顺序扫描,当有fd就绪时，立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n##### IO复用详解\n\n在IO编程过程中，当需要处理多个请求的时，可以使用多线程和IO复用的方式进行处理。上面的图介绍了整个IO复用的过程，它通过把多个IO的阻塞复用到一个select之类的阻塞上，从而使得系统在单线程的情况下同时支持处理多个请求。和多线程/进程比较，I/O多路复用的最大优势是系统开销小，系统不需要建立新的进程或者线程，也不必维护这些线程和进程。IO复用常见的应用场景：\n1. 客户程序需要同时处理交互式的输入和服务器之间的网络连接。\n2. 客户端需要对多个网络连接作出反应。\n3. 服务器需要同时处理多个处于监听状态和多个连接状态的套接字\n4. 服务器需要处理多种网络协议的套接字。\n\n### windows的IOCP\n告知内核启动某个操作，并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们。这种模型与信号驱动模型的主要区别是：信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；异步I/O模型：由内核通知我们I/O操作何时完成。\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝。可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上，数据无需流经应用程序。本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销，然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能。\n\n\n###### 数据传输：传统方法\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换。在内部，发出 `sys_read()`(或等效内容)以从文件中读取数据。直接内存存取(`direct memory access`，DMA)引擎执行了第一次拷贝，它从磁盘中读取文件内容，然后将它们存储到一个内核地址空间缓存区中。\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区，read() 调用返回。该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换)。现在数据被储存在用户地址空间缓冲区。\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换。数据被第三次拷贝，并被再次放置在内核地址空间缓冲区。但是这一次放置的缓冲区不同，该缓冲区与目标套接字相关联。\n4. `send()` 系统调用返回，结果导致了第四次的上下文切换。DMA 引擎将数据从内核缓冲区传到协议引擎，第四次拷贝独立地、异步地发生 。\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下。但是之所以引入中间内核缓冲区的目的是想提高性能。在读取方面使用中间内核缓冲区，可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时，充当 “预读高速缓存(readahead cache)” 的角色。这在所需数据量小于内核缓冲区大小时极大地提高了性能。在写入方面的中间缓冲区则可以让写入过程异步完成。\n\n不幸的是，如果所需数据量远大于内核缓冲区大小的话，这个方法本身可能成为一个性能瓶颈。数据在被最终传入到应用程序前，在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次。\n\n零拷贝通过消除这些冗余的数据拷贝而提高了性能。\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区。然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区。\n\n2. 数据的第三次复制发生在 DMA 引擎将数据从内核套接字缓冲区传到协议引擎时。\n\t改进的地方：我们将上下文切换的次数从四次减少到了两次，将数据复制的次数从四次减少到了三次(其中只有一次涉及到了 CPU)。但是这个代码尚未达到我们的零拷贝要求。如果底层网络接口卡支持收集操作 的话，那么我们就可以进一步减少内核的数据复制。在 Linux 内核 2.4 及后期版本中，套接字缓冲区描述符就做了相应调整，以满足该需求。这种方法不仅可以减少多个上下文切换，还可以消除需要涉及 CPU 的重复的数据拷贝。对于用户方面，用法还是一样的，但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区。\nB. 数据未被拷贝到套接字缓冲区。取而代之的是，只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区。DMA 引擎直接把数据从内核缓冲区传输到协议引擎，从而消除了剩下的最后一次 CPU 拷贝。\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n\n\n\n## JAVA IO\n### io#interface\n\n* [Closeable]()\n\tCloseable 是可以关闭的数据源或目标。调用 close 方法可释放对象保存的资源（如打开文件）。\n* [DataInput]()\n\tDataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据。同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具。\n\n\t对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）。如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException。尤其在输入流已关闭的情况下，将抛出 IOException。\n* [DataOutput]()\n\t\n\tDataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流。同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具。\n\t\n\t对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException。\n\t\n* [Externalizable]()\n\t\n\tExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成。如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段。\n\t\n* [FileFilter](TestFileFilter.java)\n\n\t检测文件是否存在。FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法，\n\t而FilenameFilter 是按照目录和文件名的方式来工作的。\n\n* [FilenameFilter]()\n\n* [Flushable]()\n\t实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中。写入流的所有I/O类都实现了Flushable接口。\n* [ObjectInput]()\n* [ObjectInputValidation]()\n\t序列化流验证机制. 一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题。但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息。Java序列化提供一套验证机制。序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n* [ObjectOutput]()\n* [ObjectStreamConstants]()\n\tJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值。Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分。现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中。 \n* [Serializable]()\n\n### io#class\n\n* [BufferedInputStream]()\n\n\tBufferedInputStream是一个带有缓冲区域的InputStream, 支持“mark()标记”和“reset()重置方法”。输入到byte[]数组里.\n* [BufferedOutputStream]()\n\t缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\n\n* [BufferedReader]()\n\n\tBufferedReader 从字符输入流中读取文本，缓冲各个字符。提供字符、数组和行的高效读取。\n\n* [BufferedWriter]()\n\n\t>1. 支持字符串输出\n\t2. 支持换行输出\n\t3. 支持文件追加输出\n\n* [ByteArrayInputStream]()\n\n\t从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。\n* [ByteArrayOutputStream]()\n\n\t输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何IOException。\n\n* [CharArrayReader]()\n\t与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n\n* [CharArrayWriter]()\n\t向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write \n* [Console]()\n\t专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n\t\n* [DataInputStream]()\n\t用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n* [DataOutputStream]()\n\t用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”。\n* [File]()\n```\n\t1. 删除文件\n\t2. 文件重命名\n\t3. 创建新的文件\n\t4. 创建新的文件\n\t5. 获取文件的最后修改时间\n\t6. 设置文件只读\n\t7. 设置文件可写\n\t8. 获取文件长度(总字节数)\n\t9. 获取文件路径\n\t10. 获取绝对文件路径\n\t11. 文件是否隐藏\n\t12. 获得剩余磁盘空间？\n\t13. 拷贝文件夹\n\t14. 遍历文件夹\n\t15. 检查文件夹是否为空？\n```\n* [FileDescriptor]()\n\t用来表示开放文件、开放套接字等。当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。\n\t\n\t类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件，打开的套接字或其他来源或字节的接收器。以下是关于FileDescriptor要点：\n\t1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它。\n\t2. 应用程序不应创建自己的文件描述符。\n\n* [FileInputStream]()\n\t一个字节一个字节的从文件里读取数据\n\t\n* [FileOutputStream]()\n\t一个字节一个字节的向文件里输出数据\n\n* [FilePermission]()\n\n* [FileReader]()\n\t一个字符一个字符地读取\n\n* [FileWriter]()\n\n\t一个字符一个字符地输出\n\n* [FilterInputStream]()\n\n\t用来“封装其它的输入流，并为它们提供额外的功能”。它的常用的子类有BufferedInputStream和DataInputStream。\n\n* [FilterOutputStream]()\n\n\t作用是用来“封装其它的输出流，并为它们提供额外的功能”。它主要包括BufferedOutputStream, \n\tDataOutputStream和PrintStream。\n\n* [FilterReader]()\n\n\t用于读取已过滤的字符流的抽象类。抽象类 FilterReader 自身提供了一些将所有请求传递给所包含的流的默认方法。\n\n* [FilterWriter]()\n\n\t用于写入已过滤的字符流的抽象类。抽象类 FilterWriter 自身提供了一些将所有请求传递给所包含的流的默认方法\n\n* [InputStream]()\n\n\n* [InputStreamReader]()\n\n\t是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。\n\t将“字节输入流”转换成“字符输入流”。它继承于Reader。\n\n* [LineNumberInputStream]()\n\n\t此类是一个输入流过滤器，它提供跟踪当前行号的附加功能。行是以回车符 ('\\r')、换行符 ('\\n')或回车符后面紧跟换行符结尾的字节序列。在所有这三种情况下，都以单个换行符形式返回行终止字符。行号以 0 开头，并在 read 返回换行符时递增 1。\n\n* [LineNumberReader]()\n\n\t跟踪行号的缓冲字符输入流。此类定义了方法 setLineNumber(int) 和 getLineNumber()，它们可分别用于设置和获取当前行号。默认情况下，行编号从 0 开始。该行号随数据读取在每个行结束符处递增，并且可以通过调用 \n\tsetLineNumber(int) 更改行号。但要注意的是，setLineNumber(int) 不会实际更改流中的当前位置；它只更改将由getLineNumber() 返回的值。可认为行在遇到以下符号之一时结束：换行符（'\\n'）、回车符（'\\r'）、回车后紧跟换行符。\n\n* [ObjectInputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectOutputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectStreamField]()\n\n\tSerializable 类中 Serializable 字段的描述。ObjectStreamField 的数组用于声明类的 Serializable 字段。\n\n* [OutputStream]()\n\n\n* [OutputStreamWriter]()\n\n\tOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n\n* [PipedInputStream]()\n\n\t管道输入流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedOutputStream]()\n\n\t管道输出流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedReader]()\n\n\tPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n* [PipedWriter]()\n\n\tPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n* [PrintStream]()\n\n\t打印输出流, 用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream 永远不会抛出 IOException；PrintStream 提供了自动flush 和 字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\n* [PrintWriter]()\n\n\t用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\n* [PushbackInputStream]()\n\n\t拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n* [PushbackReader]()\n\n\t允许将字符推回到流的字符流 reader。\n\n* [RandomAccessFile]()\n\n\t用来访问那些保存数据记录的文件的，你就可以用seek( )方法来访问记录，并进行读写了。这些记录的大小不必相同；但是其大小和位置必须是可知的。但是该类仅限于操作文件。\n\n* [SequenceInputStream]()\n\n\t从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。 SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，\n\t接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n* [SerializablePermission]()\n\n\n* [StreamTokenizer]()\n\n\t获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。\n\t该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n* [StringBufferInputStream]()\n\n\n* [StringReader]()\n\n\n* [StringWriter]()\n\n\n### nio\n\n* [Buffer](java/src/test/io/robertsing/cookios/nio/TestBuffer.java)\n\n\n* [ByteBuffer](java/src/test/io/robertsing/cookios/nio/TestByteBuffer.java)\n\n\n* [ByteOrder](java/src/test/io/robertsing/cookios/nio/TestByteOrder.java)\n\n\n* [CharBuffer](java/src/test/io/robertsing/cookios/nio/TestCharBuffer.java)\n\n\n* [DoubleBuffer](java/src/test/io/robertsing/cookios/nio/TestDoubleBuffer.java)\n\n\n* [FloatBuffer](java/src/test/io/robertsing/cookios/nio/TestFloatBuffer.java)\n\n\n* [IntBuffer](java/src/test/io/robertsing/cookios/nio/TestIntBuffer.java)\n\n\n* [LongBuffer](java/src/test/io/robertsing/cookios/nio/TestLongBuffer.java)\n\n\n* [MappedByteBuffer](java/src/test/io/robertsing/cookios/nio/TestMappedByteBuffer.java)\n\n\n* [ShortBuffer](java/src/test/io/robertsing/cookios/nio/TestShortBuffer.java)\n\n\n### nio#channels#Interfaces\n\n* [AsynchronousByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousByteChannel.java)\n\n\n* [AsynchronousChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannel.java)\n\n\n* [ByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestByteChannel.java)\n\n\n* [Channel](java/src/test/io/robertsing/cookios/nio/channels/TestChannel.java)\n\n\n* [CompletionHandler](java/src/test/io/robertsing/cookios/nio/channels/TestCompletionHandler.java)\n\n\n* [GatheringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestGatheringByteChannel.java)\n\n\n* [InterruptibleChannel](java/src/test/io/robertsing/cookios/nio/channels/TestInterruptibleChannel.java)\n\n\n* [MulticastChannel](java/src/test/io/robertsing/cookios/nio/channels/TestMulticastChannel.java)\n\n\n* [NetworkChannel](java/src/test/io/robertsing/cookios/nio/channels/TestNetworkChannel.java)\n\n\n* [ReadableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestReadableByteChannel.java)\n\n\n* [ScatteringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestScatteringByteChannel.java)\n\n\n* [SeekableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSeekableByteChannel.java)\n\n\n* [WritableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestWritableByteChannel.java)\n\n\n### nio#channels#Classes\n\n* [AsynchronousChannelGroup](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannelGroup.java)\n\n\n* [AsynchronousFileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousFileChannel.java)\n\n\n* [AsynchronousServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousServerSocketChannel.java)\n\n\n* [AsynchronousSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousSocketChannel.java)\n\n\n* [Channels](java/src/test/io/robertsing/cookios/nio/channels/TestChannels.java)\n\n\n* [DatagramChannel](java/src/test/io/robertsing/cookios/nio/channels/TestDatagramChannel.java)\n\n\n* [FileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.java)\n\n\n* [FileChannel.MapMode](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.MapMode.java)\n\n\n* [FileLock](java/src/test/io/robertsing/cookios/nio/channels/TestFileLock.java)\n\n\n* [MembershipKey](java/src/test/io/robertsing/cookios/nio/channels/TestMembershipKey.java)\n\n\n* [Pipe](java/src/test/io/robertsing/cookios/nio/channels/TestPipe.java)\n\n\n* [SelectableChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSelectableChannel.java)\n\n\n* [SelectionKey](java/src/test/io/robertsing/cookios/nio/channels/TestSelectionKey.java)\n\n\n* [Selector](java/src/test/io/robertsing/cookios/nio/channels/TestSelector.java)\n\n\n* [ServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestServerSocketChannel.java)\n\n\n* [SocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSocketChannel.java)\n\n\n### nio#file#Interfaces\n\n* [CopyOption](java/src/test/io/robertsing/cookios/nio/file/TestCopyOption.java)\n\n\n* [DirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestDirectoryStream.java)\n\n\t遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n\n* [FileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestFileVisitor.java)\n\n\t@SimpleFileVisitor\n\n* [OpenOption](java/src/test/io/robertsing/cookios/nio/file/TestOpenOption.java)\n\n\n* [Path](java/src/test/io/robertsing/cookios/nio/file/TestPath.java)\n\n\n* [PathMatcher](java/src/test/io/robertsing/cookios/nio/file/TestPathMatcher.java)\n\n\n* [SecureDirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestSecureDirectoryStream.java)\n\n\n* [Watchable](java/src/test/io/robertsing/cookios/nio/file/TestWatchable.java)\n\n\n* [WatchEvent](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.java)\n\n\n* [WatchEvent.Kind](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Kind.java)\n\n\n* [WatchEvent.Modifier](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Modifier.java)\n\n\n* [WatchKey](java/src/test/io/robertsing/cookios/nio/file/TestWatchKey.java)\n\n\n* [WatchService](java/src/test/io/robertsing/cookios/niofile//TestWatchService.java)\n\n\n### nio#file#Classes\n\n* [Files]()\n\n\t1. copy\n\t2. createDirectories\n\t3. createDirectory\n\t4. createFile\n\t5. createLink\n\t6. createSymbolicLink\n\t7. createTempDirectory\n\t8. createTempFile\n\t9. delete\n\t10. deleteIfExists\n\t11. exists\n\t12. getAttribute\n\t13. getFileAttributeView\n\t14. getFileStore\n\t15. getLastModifiedTime\n\t16. getOwner\n\t17. getPosixFilePermissions\n\t18. isDirectory\n\t19. isExecutable\n\t20. isHidden\n\t21. isReadable\n\t22. isRegularFile\n\t23. isSameFile\n\t24. isSymbolicLink\n\t25. isWritable\n\t26. move\n\t27. newBufferedReader\n\t28. newBufferedWriter\n\t29. newByteChannel\n\t30. newDirectoryStream\n\t31. newInputStream\n\t32. newOutputStream\n\t33. notExists\n\t34. probeContentType\n\t35. readAllBytes\n\t36. readAllLines\n\t37. readAttributes\n\t38. readSymbolicLink\n\t39. setAttribute\n\t40. setLastModifiedTime\n\t41. setOwner\n\t42. setPosixFilePermissions\n\t43. walkFileTree\n\t44. write\n\n\n* [FileStore]()\n\n\t代表了真正的存储设备，提供了设备的详尽信息\n\n* [FileSystem](java/src/test/io/robertsing/cookios/nio/file/TestFileSystem.java)\n\n\n* [FileSystems](java/src/test/io/robertsing/cookios/nio/file/TestFileSystems.java)\n\n\n* [LinkPermission](java/src/test/io/robertsing/cookios/nio/file/TestLinkPermission.java)\n\n\n* [Paths](java/src/test/io/robertsing/cookios/nio/file/TestPaths.java)\n\n\n* [SimpleFileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestSimpleFileVisitor.java)\n\n\t与DirectoryStream 不同的是，这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n\n* [StandardWatchEventKinds](java/src/test/io/robertsing/cookios/nio/file/TestStandardWatchEventKinds.java)\n\n\n### nio#charset\n\n* [Charset](java/src/test/io/robertsing/cookios/nio/charset/TestCharset.java)\n\n\n* [CharsetDecoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetDecoder.java)\n\n\n* [CharsetEncoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetEncoder.java)\n\n\n* [CoderResult](java/src/test/io/robertsing/cookios/nio/charset/TestCoderResult.java)\n\n\n* [CodingErrorAction](java/src/test/io/robertsing/cookios/nio/charset/TestCodingErrorAction.java)\n\n\n* [StandardCharsets](java/src/test/io/robertsing/cookios/nio/charset/TestStandardCharsets.java)\n\n\n\n\n","slug":"io_models","published":1,"date":"2015-06-27T05:55:54.882Z","updated":"2015-06-27T05:53:05.468Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzu0003kwufhedajwzs"},{"title":"gitbook使用","_content":"# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n\n","source":"_posts/gitbook.md","raw":"title: gitbook使用\n---\n# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n\n","slug":"gitbook","published":1,"date":"2015-06-15T05:14:56.189Z","updated":"2015-06-15T04:48:10.862Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzv0004kwuf67d8gwpd"},{"title":"docker搭建日志分析","_content":"# 在docker中搭建elasticsearch + kibana + logstash,日志分析系统\n\n0. 下载安装docker,进入到docker里\n1. 下载安装centos,然后进入到centos里\n```\ndocker pull centos\ndocker run --net=host --name=log centos\ndocker attach log\n```\n2. 更改yum源\n```\ncd /etc/yum.repos.d/\nwget http://mirrors.163.com/.help/CentOS6-Base-163.repo\nyum makecache\nyum -y update\nyum install epel-release\n```\n3. 下载相关软件\n```\nyum -y install wget tar net-tools.x86_64 java-1.8.0-openjdk-devel.x86_64 redis nginx\n```\n4. 检查软件是否安装成功\n```\nyum list installed redis nginx\n```\n5. 下载elasticsearch + kibana + logstash\n```\nwget https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.5.2.tar.gz\nwget https://download.elastic.co/kibana/kibana/kibana-4.0.2-linux-x64.tar.gz\nwget https://download.elastic.co/logstash/logstash/logstash-1.4.2.tar.gz\n```\n6. 安装elasticsearch + kibana + logstash\n```\ntar -xvf elasticsearch-1.5.2.tar.gz\ntar -xvf kibana-4.0.2-linux-x64.tar.gz\ntar -xvf logstash-1.4.2.tar.gz \n```\n7. 运行elasticsearch + kibana + logstash\n```\nnohup ./elasticsearch-1.5.2/bin/elasticsearch &\nnohup ./kibana-4.0.2-linux-x64/bin/kibana &\n```\n\n###### Elasticsearch (LogStash的搜索引擎)\n1. 进入到该文件夹下的bin目录执行\n2. sudo ./plugin -i elasticsearch/marvel/latest\n3. 输入密码之后,程序就会自动下载marvel\n4. 随后我们启动命令./elasticsearch start\n5. 随后我们在浏览器里输入 http://192.168.1.104:9200/_plugin/marvel\n6. 我们就能看到Elasticsearch 的集群和数据管理界面 Marvel\n\n###### Kibana(用户友好的搜索界面)\n1. 将Kibana解压后拷贝进elasticsearch/plugins/目录下,最后去掉Kibana文件夹里的版本号\n2. 然后将Kibana文件夹里新建文件夹 _site,然后将其全部内容放进 _site里\n3. 执行./elasticsearch restart\n4. 随后我们在浏览器里输 http://192.168.1.104:9200/_plugin/kibana/\n\n###### Logstash\n1. 安装rvm ,分别运行下面三个命令\n```\ncurl -L get.rvm.io | bash -s stable, \nsource ~/.bashrc,  \nsource ~/.bash_profile\n```\n2. 修改 RVM 的 Ruby 安装源到国内的 淘宝镜像服务器,这样能提高安装速度(执行下面命令)\n``` \n sed -i -e 's/ftp\\.ruby-lang\\.org\\/pub\\/ruby/ruby\\.taobao\\.org\\/mirrors\\/ruby/g' ~/.rvm/config/db\n```\n3. 装JRUBY(执行下面俩个命令)\n```\n   rvm install jruby-1.7.11\n   rvm use jruby-1.7.11\n```\n4. 安装logstash ruby 依赖 : \n```\n./logstash deps\n```\n\n\n## Elasticsearch插件:\n### 插件安装:\n1. 我以安装elasticsearch-head为例, sudo ./plugin -install mobz/elasticsearch-head\n2. 然后我们重启一下elasticsearch, 在地址栏输入http://192.168.1.104:9200/_plugin/head/\n3. 我们就会看到head已经安装成功\n4. 需要说明的是,在启动elasticsearch时 我们会看到一条输出为 \n```\n[2015-01-25 11:39:11,936][INFO][plugins] [Lady Octopus] loaded [marvel], sites [marvel, head]\n```\n5. 这个是我们安装的全部的插件,当再安装完其他插件,如果有生成sites的话,我们只需要将地址拦中的head改成相应插件名即可\n\n### 插件内容摘自 http://www.searchtech.pro/elasticsearch-plugins\n##### 常用插件\n* `head:  elasticsearch的集群管理工具.\n* `bigdesk:   elasticsearch的一个集群监控工具,可以通过它来查看es集群的各种状态,如:cpu、内存使用情况,索引数据、搜索情况,http连接数等.\n\n分词插件\n* `Combo Analysis Plugin` :组合分词器,可以把多个分词器的结果组合在一起.\n* `Smart Chinese Analysis Plugin` :lucene默认的中文分词器\n* `ICU Analysis plugin` :lucene自带的ICU分词,ICU是一套稳定、成熟、功能强大、轻便易用和跨平台支持Unicode 的开发包.\n* `Stempel `(Polish) Analysis plugin` :法文分词器\n* `IK Analysis Plugin` :大名鼎鼎的ik分词,都懂的！\n* `Mmseg Analysis Plugin` :mmseg中文分词\n* `Hunspell Analysis Plugin` :lucene自带的Hunspell模块\n* `Japanese `(Kuromoji) Analysis plugin` :日文分词器\n* `Japanese Analysis plugin` :日文分词器\n* `Russian and English Morphological Analysis Plugin` :俄文英文分词器\n* `Pinyin Analysis Plugin `:拼音分词器\n* `String2Integer Analysis Plugin `:字符串转整型工具.主要用在facet这个功能上,如果facet的field的值是字符串的话,计算起来比较耗资源.可以把字符串映射成整型,对整型进行facet操作要比对字符串的快很多.\n\n#### 同步插件\n* `CouchDB River Plugin `:CouchDB和elasticsearch的同步插件\n* `Wikipedia River Plugin `:wikipedia文件读取插件.wikipedia是维基百科的一个离线库,不定期发布最新数据,是以xml形式发布的.这个river读取这个文件来建索引.\n* `Twitter River Plugin `:twitter的同步插件,可以同步你twitter上的微博.\n* `RabbitMQ River Plugin `:rabbitmq同步插件,读取rabbitmq上的队列信息并索引.\n* `RSS River Plugin `:定期索引指定一个或多个RSS源的数据.\n* `MongoDB River Plugin `:mongodb同步插件,mongodb必须搭成副本集的模式,因为这个插件的原理是通过定期读取mongodb中的oplog来同步数据.\n* `Open Archives Initiative `:可以索引oai数据提供者提供的数据.\n* `St9 River Plugin `:可以索引索引st9数据(st9是神马？囧！！！)\n* `Sofa River Plugin `:这个插件可以把多个CouchDB的数据库同步到同一个es索引中.\n* `JDBC River Plugin `:关系型数据库的同步插件\n* `FileSystem River Plugin `:本地文件系统文件同步插件,使用方法是指定一个本地目录路径,es会定期扫描索引该目录下的文件.\n* `LDAP River Plugin `:索引LDAP目录下的文件数据.\n* `Dropbox River Plugin `:索引dropbox网盘上的文件.通过oauth协议来调用dropbox上的api建索引.\n* `ActiveMQ River Plugin `:activemq队列的同步插件,和之前rabbitmq的类似\n* `Solr River Plugin `:solr同步插件,可以把solr里面的索引同步到es\n* `CSV River Plugin `:通过指定目录地址来索引csv文件.\n\n#### 数据传输插件\n* `Servlet transport `:Servlet rest插件,通过servlet来封装rest接口.\n* `Memcached transport plugin `:本插件可以通过memcached协议进行rest接口的调用.注意:这里不是使用memcache作为es的缓存.\n* `Thrift Transport `:使用thrift进行数据传输.\n* `ZeroMQ transport layer plugin `:使用zeromq进rest接口的调用.\n* `Jetty HTTP transport plugin `:使用jetty来提供http rest接口.默认是使用netty.这个插件的好处是可以对http接口进行一些权限的设置.\n\n#### 脚本插件\n* `Python language Plugin `:python脚本支持\n* `JavaScript language Plugin `:javascript脚本支持\n* `Groovy lang Plugin `:groovy脚本支持\n* `Clojure Language Plugin `:clojure脚本支持\n\n#### 站点插件(以网页形式展现)\n* `BigDesk Plugin `:监控es状态的插件,推荐！\n* `Elasticsearch Head Plugin `:很方便对es进行各种操作的客户端.\n* `Paramedic Plugin `:es监控插件\n* `SegmentSpy Plugin `:查看es索引segment状态的插件\n* `Inquisitor Plugin `:这个插件主要用来调试你的查询.\n\n#### 其它插件\n* `Mapper Attachments Type plugin `:附件类型插件,通过tika库把各种类型的文件格式解析成字符串.\n* `Hadoop Plugin `:hadoop和elasticsearch的集成插件,可以通过hadoop的mapreduce算法来并行建立索引,同时支持cascading,hive和pig等框架.\n* `AWS Cloud Plugin `:elasticsearch与amazon web services的集成.\n* `ElasticSearch Mock Solr Plugin `:elasticsearch的solr api接口.用了这个插件可以使用solr的api来调用es,直接用solrj就可以调用es.比较适用于从solr转es时暂时过度.\n* `Suggester Plugin `:es 搜索提示功能插件,不过es0.9版本后自带了这个功能,\n* `ElasticSearch PartialUpdate Plugin `:elasticsearch的部分更新插件.\n* `ZooKeeper Discovery Plugin `:通过zookeeper管理集群的插件.通过这个插件,es的分布式架构和solrcloud相似.\n* `ElasticSearch Changes Plugin `:elasticsearch索引操作记录插件.通过这个插件可以查看用户对索引的增删改操作.\n* `ElasticSearch View Plugin `:这个插件可以把es的文档以html,xml或text的方式显示出来,它也可以通过查询生成web页面.\n* `ElasticSearch New Relic Plugin `:elasticsearch和newrelic的集成插件.newrelica是一个性能监控工具.这个插件会把节点的状态数据传到newrelic的账号上.\n\n\n#### Logstash全部插件列表如下.\n\n\n* input插件列表:\namqp、drupal_dblog、eventlog、exec、file、ganglia、gelf、gemfire、 generator、heroku、irc、log4j、lumberjack、pipe、redis、relp、sqs、stdin、stomp、 syslog、tcp、twitter、udp、xmpp、zenoss、zeromq.\n\n* filter插件列表:\nalter、anonymize、checksum、csv、date、dns、environment、gelfify、 geoip、grep、grok、grokdiscovery、json、kv、metrics、multiline、mutate、noop、 split、syslog_pri、urldecode、xml、zeromq.\n\n* output插件列表:\namqp、boundary、circonus、cloudwatch、datadog、elasticsearch、 elasticsearch_http、elasticsearch_river、email、exec、file、ganglia、gelf、gemfire、graphite、 graphtastic、http、internal、irc、juggernaut、librato、loggly、lumberjack、metriccatcher、 mongodb、nagios、nagios_nsca、null、opentsdb、pagerduty、pipe、redis、riak、riemann、 sns、sqs、statsd、stdout、stomp、syslog、tcp、websocket、xmpp、zabbix、zeromq\n\n\nhttp://kibana.logstash.es/content/v3/10-minute-walk-through.html\n\nhttp://www.logstashbook.com/TheLogstashBook_sample.pdf\n\n","source":"_posts/docker搭建日志分析.md","raw":"title: docker搭建日志分析\n---\n# 在docker中搭建elasticsearch + kibana + logstash,日志分析系统\n\n0. 下载安装docker,进入到docker里\n1. 下载安装centos,然后进入到centos里\n```\ndocker pull centos\ndocker run --net=host --name=log centos\ndocker attach log\n```\n2. 更改yum源\n```\ncd /etc/yum.repos.d/\nwget http://mirrors.163.com/.help/CentOS6-Base-163.repo\nyum makecache\nyum -y update\nyum install epel-release\n```\n3. 下载相关软件\n```\nyum -y install wget tar net-tools.x86_64 java-1.8.0-openjdk-devel.x86_64 redis nginx\n```\n4. 检查软件是否安装成功\n```\nyum list installed redis nginx\n```\n5. 下载elasticsearch + kibana + logstash\n```\nwget https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.5.2.tar.gz\nwget https://download.elastic.co/kibana/kibana/kibana-4.0.2-linux-x64.tar.gz\nwget https://download.elastic.co/logstash/logstash/logstash-1.4.2.tar.gz\n```\n6. 安装elasticsearch + kibana + logstash\n```\ntar -xvf elasticsearch-1.5.2.tar.gz\ntar -xvf kibana-4.0.2-linux-x64.tar.gz\ntar -xvf logstash-1.4.2.tar.gz \n```\n7. 运行elasticsearch + kibana + logstash\n```\nnohup ./elasticsearch-1.5.2/bin/elasticsearch &\nnohup ./kibana-4.0.2-linux-x64/bin/kibana &\n```\n\n###### Elasticsearch (LogStash的搜索引擎)\n1. 进入到该文件夹下的bin目录执行\n2. sudo ./plugin -i elasticsearch/marvel/latest\n3. 输入密码之后,程序就会自动下载marvel\n4. 随后我们启动命令./elasticsearch start\n5. 随后我们在浏览器里输入 http://192.168.1.104:9200/_plugin/marvel\n6. 我们就能看到Elasticsearch 的集群和数据管理界面 Marvel\n\n###### Kibana(用户友好的搜索界面)\n1. 将Kibana解压后拷贝进elasticsearch/plugins/目录下,最后去掉Kibana文件夹里的版本号\n2. 然后将Kibana文件夹里新建文件夹 _site,然后将其全部内容放进 _site里\n3. 执行./elasticsearch restart\n4. 随后我们在浏览器里输 http://192.168.1.104:9200/_plugin/kibana/\n\n###### Logstash\n1. 安装rvm ,分别运行下面三个命令\n```\ncurl -L get.rvm.io | bash -s stable, \nsource ~/.bashrc,  \nsource ~/.bash_profile\n```\n2. 修改 RVM 的 Ruby 安装源到国内的 淘宝镜像服务器,这样能提高安装速度(执行下面命令)\n``` \n sed -i -e 's/ftp\\.ruby-lang\\.org\\/pub\\/ruby/ruby\\.taobao\\.org\\/mirrors\\/ruby/g' ~/.rvm/config/db\n```\n3. 装JRUBY(执行下面俩个命令)\n```\n   rvm install jruby-1.7.11\n   rvm use jruby-1.7.11\n```\n4. 安装logstash ruby 依赖 : \n```\n./logstash deps\n```\n\n\n## Elasticsearch插件:\n### 插件安装:\n1. 我以安装elasticsearch-head为例, sudo ./plugin -install mobz/elasticsearch-head\n2. 然后我们重启一下elasticsearch, 在地址栏输入http://192.168.1.104:9200/_plugin/head/\n3. 我们就会看到head已经安装成功\n4. 需要说明的是,在启动elasticsearch时 我们会看到一条输出为 \n```\n[2015-01-25 11:39:11,936][INFO][plugins] [Lady Octopus] loaded [marvel], sites [marvel, head]\n```\n5. 这个是我们安装的全部的插件,当再安装完其他插件,如果有生成sites的话,我们只需要将地址拦中的head改成相应插件名即可\n\n### 插件内容摘自 http://www.searchtech.pro/elasticsearch-plugins\n##### 常用插件\n* `head:  elasticsearch的集群管理工具.\n* `bigdesk:   elasticsearch的一个集群监控工具,可以通过它来查看es集群的各种状态,如:cpu、内存使用情况,索引数据、搜索情况,http连接数等.\n\n分词插件\n* `Combo Analysis Plugin` :组合分词器,可以把多个分词器的结果组合在一起.\n* `Smart Chinese Analysis Plugin` :lucene默认的中文分词器\n* `ICU Analysis plugin` :lucene自带的ICU分词,ICU是一套稳定、成熟、功能强大、轻便易用和跨平台支持Unicode 的开发包.\n* `Stempel `(Polish) Analysis plugin` :法文分词器\n* `IK Analysis Plugin` :大名鼎鼎的ik分词,都懂的！\n* `Mmseg Analysis Plugin` :mmseg中文分词\n* `Hunspell Analysis Plugin` :lucene自带的Hunspell模块\n* `Japanese `(Kuromoji) Analysis plugin` :日文分词器\n* `Japanese Analysis plugin` :日文分词器\n* `Russian and English Morphological Analysis Plugin` :俄文英文分词器\n* `Pinyin Analysis Plugin `:拼音分词器\n* `String2Integer Analysis Plugin `:字符串转整型工具.主要用在facet这个功能上,如果facet的field的值是字符串的话,计算起来比较耗资源.可以把字符串映射成整型,对整型进行facet操作要比对字符串的快很多.\n\n#### 同步插件\n* `CouchDB River Plugin `:CouchDB和elasticsearch的同步插件\n* `Wikipedia River Plugin `:wikipedia文件读取插件.wikipedia是维基百科的一个离线库,不定期发布最新数据,是以xml形式发布的.这个river读取这个文件来建索引.\n* `Twitter River Plugin `:twitter的同步插件,可以同步你twitter上的微博.\n* `RabbitMQ River Plugin `:rabbitmq同步插件,读取rabbitmq上的队列信息并索引.\n* `RSS River Plugin `:定期索引指定一个或多个RSS源的数据.\n* `MongoDB River Plugin `:mongodb同步插件,mongodb必须搭成副本集的模式,因为这个插件的原理是通过定期读取mongodb中的oplog来同步数据.\n* `Open Archives Initiative `:可以索引oai数据提供者提供的数据.\n* `St9 River Plugin `:可以索引索引st9数据(st9是神马？囧！！！)\n* `Sofa River Plugin `:这个插件可以把多个CouchDB的数据库同步到同一个es索引中.\n* `JDBC River Plugin `:关系型数据库的同步插件\n* `FileSystem River Plugin `:本地文件系统文件同步插件,使用方法是指定一个本地目录路径,es会定期扫描索引该目录下的文件.\n* `LDAP River Plugin `:索引LDAP目录下的文件数据.\n* `Dropbox River Plugin `:索引dropbox网盘上的文件.通过oauth协议来调用dropbox上的api建索引.\n* `ActiveMQ River Plugin `:activemq队列的同步插件,和之前rabbitmq的类似\n* `Solr River Plugin `:solr同步插件,可以把solr里面的索引同步到es\n* `CSV River Plugin `:通过指定目录地址来索引csv文件.\n\n#### 数据传输插件\n* `Servlet transport `:Servlet rest插件,通过servlet来封装rest接口.\n* `Memcached transport plugin `:本插件可以通过memcached协议进行rest接口的调用.注意:这里不是使用memcache作为es的缓存.\n* `Thrift Transport `:使用thrift进行数据传输.\n* `ZeroMQ transport layer plugin `:使用zeromq进rest接口的调用.\n* `Jetty HTTP transport plugin `:使用jetty来提供http rest接口.默认是使用netty.这个插件的好处是可以对http接口进行一些权限的设置.\n\n#### 脚本插件\n* `Python language Plugin `:python脚本支持\n* `JavaScript language Plugin `:javascript脚本支持\n* `Groovy lang Plugin `:groovy脚本支持\n* `Clojure Language Plugin `:clojure脚本支持\n\n#### 站点插件(以网页形式展现)\n* `BigDesk Plugin `:监控es状态的插件,推荐！\n* `Elasticsearch Head Plugin `:很方便对es进行各种操作的客户端.\n* `Paramedic Plugin `:es监控插件\n* `SegmentSpy Plugin `:查看es索引segment状态的插件\n* `Inquisitor Plugin `:这个插件主要用来调试你的查询.\n\n#### 其它插件\n* `Mapper Attachments Type plugin `:附件类型插件,通过tika库把各种类型的文件格式解析成字符串.\n* `Hadoop Plugin `:hadoop和elasticsearch的集成插件,可以通过hadoop的mapreduce算法来并行建立索引,同时支持cascading,hive和pig等框架.\n* `AWS Cloud Plugin `:elasticsearch与amazon web services的集成.\n* `ElasticSearch Mock Solr Plugin `:elasticsearch的solr api接口.用了这个插件可以使用solr的api来调用es,直接用solrj就可以调用es.比较适用于从solr转es时暂时过度.\n* `Suggester Plugin `:es 搜索提示功能插件,不过es0.9版本后自带了这个功能,\n* `ElasticSearch PartialUpdate Plugin `:elasticsearch的部分更新插件.\n* `ZooKeeper Discovery Plugin `:通过zookeeper管理集群的插件.通过这个插件,es的分布式架构和solrcloud相似.\n* `ElasticSearch Changes Plugin `:elasticsearch索引操作记录插件.通过这个插件可以查看用户对索引的增删改操作.\n* `ElasticSearch View Plugin `:这个插件可以把es的文档以html,xml或text的方式显示出来,它也可以通过查询生成web页面.\n* `ElasticSearch New Relic Plugin `:elasticsearch和newrelic的集成插件.newrelica是一个性能监控工具.这个插件会把节点的状态数据传到newrelic的账号上.\n\n\n#### Logstash全部插件列表如下.\n\n\n* input插件列表:\namqp、drupal_dblog、eventlog、exec、file、ganglia、gelf、gemfire、 generator、heroku、irc、log4j、lumberjack、pipe、redis、relp、sqs、stdin、stomp、 syslog、tcp、twitter、udp、xmpp、zenoss、zeromq.\n\n* filter插件列表:\nalter、anonymize、checksum、csv、date、dns、environment、gelfify、 geoip、grep、grok、grokdiscovery、json、kv、metrics、multiline、mutate、noop、 split、syslog_pri、urldecode、xml、zeromq.\n\n* output插件列表:\namqp、boundary、circonus、cloudwatch、datadog、elasticsearch、 elasticsearch_http、elasticsearch_river、email、exec、file、ganglia、gelf、gemfire、graphite、 graphtastic、http、internal、irc、juggernaut、librato、loggly、lumberjack、metriccatcher、 mongodb、nagios、nagios_nsca、null、opentsdb、pagerduty、pipe、redis、riak、riemann、 sns、sqs、statsd、stdout、stomp、syslog、tcp、websocket、xmpp、zabbix、zeromq\n\n\nhttp://kibana.logstash.es/content/v3/10-minute-walk-through.html\n\nhttp://www.logstashbook.com/TheLogstashBook_sample.pdf\n\n","slug":"docker搭建日志分析","published":1,"date":"2015-06-15T05:14:56.188Z","updated":"2015-06-15T04:46:15.389Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzx0005kwuf8v4fiev8"},{"title":"docker命令","_content":"## Docker命令\n#### `service docker start`  \n安装之后启动 Docker 服务.\n\n#### `docker pull` \n命令来从仓库获取所需要的镜像\n```\ndocker pull ubuntu12.04\n```\n\n#### `docker push` \n把自己创建的镜像上传到仓库中来共享\n```\ndocker push ouruser/sinatra\n```\n\n#### `docker images` \n显示本地已有的镜像.\n\n#### `docker commit` \n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n#### `docker build` \n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n#### `docker tag` \n命令来修改镜像的标签.\n```\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n#### `docker import` \n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n#### `docker save` \n导出镜像到本地文件\n```\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n#### `docker load` \n从导出的本地文件中再导入到本地镜像库 \n```\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n#### `docker rmi` \n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```\nsudo docker rmi training/sinatra\n```\n\n#### `docker run`  \n基于镜像新建一个容器并启动\n```\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n###### 映射所有接口地址\n使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n###### 此时默认会绑定本地所有接口上的所有地址。\n映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n##### 映射到指定地址的任意端口\n使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n#### `docker start` \n直接将一个已经终止的容器启动运行\n\n#### `docker stop` \n终止一个运行中的容器.\n\n#### `docker restart` \n将一个运行态的容器终止,然后再重新启动它.\n\n#### `docker attach` \n进入容器\n\n#### `docker export ` \n导出本地某个容器\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n#### `docker import` \n从容器快照文件中再导入为镜像\n```\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n#### `docker rm` \n移除容器.删除一个处于终止状态的容器\n```\ndocker rm  trusting_newton\n```\n\n#### `docker search` \n查找官方仓库中的镜像\n\n#### `docker ps` \n\n#### `docker logs` \n获取容器的输出信息\n```\ndocker logs insane_babbage\n```\n\n#### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile \n\nDockerfile中每一条指令都创建镜像的一层,例如\n```\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n##### 当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n##### `docker load` vs `docker import`\n用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n\n","source":"_posts/docker命令.md","raw":"title: docker命令\n---\n## Docker命令\n#### `service docker start`  \n安装之后启动 Docker 服务.\n\n#### `docker pull` \n命令来从仓库获取所需要的镜像\n```\ndocker pull ubuntu12.04\n```\n\n#### `docker push` \n把自己创建的镜像上传到仓库中来共享\n```\ndocker push ouruser/sinatra\n```\n\n#### `docker images` \n显示本地已有的镜像.\n\n#### `docker commit` \n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n#### `docker build` \n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n#### `docker tag` \n命令来修改镜像的标签.\n```\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n#### `docker import` \n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n#### `docker save` \n导出镜像到本地文件\n```\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n#### `docker load` \n从导出的本地文件中再导入到本地镜像库 \n```\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n#### `docker rmi` \n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```\nsudo docker rmi training/sinatra\n```\n\n#### `docker run`  \n基于镜像新建一个容器并启动\n```\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n###### 映射所有接口地址\n使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n###### 此时默认会绑定本地所有接口上的所有地址。\n映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n##### 映射到指定地址的任意端口\n使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n#### `docker start` \n直接将一个已经终止的容器启动运行\n\n#### `docker stop` \n终止一个运行中的容器.\n\n#### `docker restart` \n将一个运行态的容器终止,然后再重新启动它.\n\n#### `docker attach` \n进入容器\n\n#### `docker export ` \n导出本地某个容器\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n#### `docker import` \n从容器快照文件中再导入为镜像\n```\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n#### `docker rm` \n移除容器.删除一个处于终止状态的容器\n```\ndocker rm  trusting_newton\n```\n\n#### `docker search` \n查找官方仓库中的镜像\n\n#### `docker ps` \n\n#### `docker logs` \n获取容器的输出信息\n```\ndocker logs insane_babbage\n```\n\n#### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile \n\nDockerfile中每一条指令都创建镜像的一层,例如\n```\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n##### 当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n##### `docker load` vs `docker import`\n用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n\n","slug":"docker命令","published":1,"date":"2015-06-15T05:14:56.187Z","updated":"2015-06-15T04:46:29.100Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzy0006kwufyr4a7nc5"},{"title":"MemoryMXBean","_content":"## MemoryMXBean\n我们通过`MemoryMXBean mbeans = ManagementFactory.getMemoryMXBean();`获得JVM 内存系统的管理接口.\n下面是对`MemoryMXBean`的一个介绍：\n\n`MemoryUsage`对象是JVM内存使用情况的一个快照. 总的来说,`MemoryUsage`实例通常是由那些获得JVM的内存池或者JVM堆/非堆内存使用情况的方法创建的.\n\n`MemoryUsage`内部持有4个值：\n* `init` 表示的是当JVM实例启动时从操作系统内分配得到的内存初始值. 随着JVM的运行它可能会从操作系统中分配到更多的内存，也可能会将多余的内存还给操作系统. 这个值也可能是未定义的.\n* `used`  表示当前使用了多少JVM内存(单位`byte`).\n* `committed` 这个值表示当前虚拟机运行需要的内存大小. 这个值也是随着虚拟机运行而变化的. `committed`可能会小于`init`的值，但是却总是大于等于`used`的值。\n* `max`  represents the maximum amount of memory (in bytes) that can be used for memory management. Its value may be undefined. The maximum amount of memory may change over time if defined. The amount of used and committed memory will always be less than or equal to max if max is defined. A memory allocation may fail if it attempts to increase the used memory such that used > committed even if used <= max would still be true (for example, when the system is low on virtual memory).  \n该值表示的内存管理能使用的最大的内存值.该值也可能是未定义的. 当`max`被定义过之后,`used`和`committed`的值总是会小于`max`值的.\n\n下面的图展示了内存池的一个示例\n```\n+----------------------------------------------+\n+////////////////           |                  +\n+////////////////           |                  +\n+----------------------------------------------+\n\n|--------|\n   init\n|---------------|\n       used\n|---------------------------|\n          committed\n|----------------------------------------------|\n                    max\n```\n\nMXBean Mapping\nMemoryUsage is mapped to a CompositeData with attributes as specified in the from method.Since:1.5Author:Mandy Chung","source":"_posts/MemoryUsage.md","raw":"title: MemoryMXBean\n---\n## MemoryMXBean\n我们通过`MemoryMXBean mbeans = ManagementFactory.getMemoryMXBean();`获得JVM 内存系统的管理接口.\n下面是对`MemoryMXBean`的一个介绍：\n\n`MemoryUsage`对象是JVM内存使用情况的一个快照. 总的来说,`MemoryUsage`实例通常是由那些获得JVM的内存池或者JVM堆/非堆内存使用情况的方法创建的.\n\n`MemoryUsage`内部持有4个值：\n* `init` 表示的是当JVM实例启动时从操作系统内分配得到的内存初始值. 随着JVM的运行它可能会从操作系统中分配到更多的内存，也可能会将多余的内存还给操作系统. 这个值也可能是未定义的.\n* `used`  表示当前使用了多少JVM内存(单位`byte`).\n* `committed` 这个值表示当前虚拟机运行需要的内存大小. 这个值也是随着虚拟机运行而变化的. `committed`可能会小于`init`的值，但是却总是大于等于`used`的值。\n* `max`  represents the maximum amount of memory (in bytes) that can be used for memory management. Its value may be undefined. The maximum amount of memory may change over time if defined. The amount of used and committed memory will always be less than or equal to max if max is defined. A memory allocation may fail if it attempts to increase the used memory such that used > committed even if used <= max would still be true (for example, when the system is low on virtual memory).  \n该值表示的内存管理能使用的最大的内存值.该值也可能是未定义的. 当`max`被定义过之后,`used`和`committed`的值总是会小于`max`值的.\n\n下面的图展示了内存池的一个示例\n```\n+----------------------------------------------+\n+////////////////           |                  +\n+////////////////           |                  +\n+----------------------------------------------+\n\n|--------|\n   init\n|---------------|\n       used\n|---------------------------|\n          committed\n|----------------------------------------------|\n                    max\n```\n\nMXBean Mapping\nMemoryUsage is mapped to a CompositeData with attributes as specified in the from method.Since:1.5Author:Mandy Chung","slug":"MemoryUsage","published":1,"date":"2015-06-15T05:14:56.186Z","updated":"2015-06-15T03:23:40.100Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0lzz0007kwufc0fm3m5f"},{"title":"Flick Ticket Server","_content":"#### 为什么采用Ticket Server ####\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外FlickerMysql是基于主-主复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n#### 考虑GUID ####\n\nGUID是非常大的,他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会简历索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n#### 一致性哈希 ####\n像Amazon Dynamo等项目提出了在数据存储顶部采用一致性哈希环,来解决GUID/sharding问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然后MYSQL是针对快速随机读 优化的\n\n\n#### 集中自动增量 ####\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n#### 替换(重新插入) ####\n\n大概十多年前,mysql对ANSI SQL实现了一个非标准化的拓展-“REPLACE INTO”. 随后“INSERT ON DUPLICATE KEY UPDATE”做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是“REPLACE INTO” 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的PRIMARY KEY或者 UNIQUE index重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n#### 组装 ####\n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n\n* 下面展示了一下Ticket64 schema\n\n```\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n* 当我需要一个新的64位ID时,我执行面貌这个sql\n\n```\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n* SPOF(单点故障) \n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中\n大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n\n* 我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n#### More Sequences ##\n\n 在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n\n","source":"_posts/Flick Ticket Server.md","raw":"title: Flick Ticket Server\n---\n#### 为什么采用Ticket Server ####\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外FlickerMysql是基于主-主复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n#### 考虑GUID ####\n\nGUID是非常大的,他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会简历索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n#### 一致性哈希 ####\n像Amazon Dynamo等项目提出了在数据存储顶部采用一致性哈希环,来解决GUID/sharding问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然后MYSQL是针对快速随机读 优化的\n\n\n#### 集中自动增量 ####\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n#### 替换(重新插入) ####\n\n大概十多年前,mysql对ANSI SQL实现了一个非标准化的拓展-“REPLACE INTO”. 随后“INSERT ON DUPLICATE KEY UPDATE”做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是“REPLACE INTO” 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的PRIMARY KEY或者 UNIQUE index重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n#### 组装 ####\n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n\n* 下面展示了一下Ticket64 schema\n\n```\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n* 当我需要一个新的64位ID时,我执行面貌这个sql\n\n```\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n* SPOF(单点故障) \n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中\n大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n\n* 我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n#### More Sequences ##\n\n 在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n\n","slug":"Flick Ticket Server","published":1,"date":"2015-06-24T00:47:27.246Z","updated":"2015-06-24T00:47:27.245Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciben0m000008kwuf16jahz2m"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}