{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0},{"_id":"themes/jacman/source/js/totop.js","path":"js/totop.js","modified":0},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","path":"js/jquery.qrcode-0.12.0.min.js","modified":0},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":0},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":0},{"_id":"themes/jacman/source/js/gallery.js","path":"js/gallery.js","modified":0},{"_id":"themes/jacman/source/img/scrollup.png","path":"img/scrollup.png","modified":0},{"_id":"themes/jacman/source/img/logo.svg","path":"img/logo.svg","modified":0},{"_id":"themes/jacman/source/img/logo.png","path":"img/logo.png","modified":0},{"_id":"themes/jacman/source/img/jacman.jpg","path":"img/jacman.jpg","modified":0},{"_id":"themes/jacman/source/img/favicon.ico","path":"img/favicon.ico","modified":0},{"_id":"themes/jacman/source/img/cc-zero.svg","path":"img/cc-zero.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by.svg","path":"img/cc-by.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-sa.svg","path":"img/cc-by-sa.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nd.svg","path":"img/cc-by-nd.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc.svg","path":"img/cc-by-nc.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","path":"img/cc-by-nc-sa.svg","modified":0},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","path":"img/cc-by-nc-nd.svg","modified":0},{"_id":"themes/jacman/source/img/banner.jpg","path":"img/banner.jpg","modified":0},{"_id":"themes/jacman/source/img/author.jpg","path":"img/author.jpg","modified":0},{"_id":"themes/jacman/source/font/fontdiao.woff","path":"font/fontdiao.woff","modified":0},{"_id":"themes/jacman/source/font/fontdiao.ttf","path":"font/fontdiao.ttf","modified":0},{"_id":"themes/jacman/source/font/fontdiao.svg","path":"font/fontdiao.svg","modified":0},{"_id":"themes/jacman/source/font/fontdiao.eot","path":"font/fontdiao.eot","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","path":"font/fontawesome-webfont.woff","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","path":"font/fontawesome-webfont.ttf","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","path":"font/fontawesome-webfont.svg","modified":0},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","path":"font/fontawesome-webfont.eot","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","path":"font/coveredbyyourgrace-webfont.woff","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","path":"font/coveredbyyourgrace-webfont.ttf","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","path":"font/coveredbyyourgrace-webfont.svg","modified":0},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","path":"font/coveredbyyourgrace-webfont.eot","modified":0},{"_id":"themes/jacman/source/font/FontAwesome.otf","path":"font/FontAwesome.otf","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0},{"_id":"themes/jacman/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0},{"_id":"themes/jacman/source/css/style.styl","path":"css/style.styl","modified":0}],"Cache":[{"_id":"source/CNAME","shasum":"e8afbfc153d8646cc8ca9239cd55302520f821e1","modified":1434173657728},{"_id":"source/_posts/Archiva.md","shasum":"58e95bcc226c88ce398ac2278ecd8001b2f34061","modified":1442485321653},{"_id":"source/_posts/Flick Ticket Server.md","shasum":"ef32c5b6297a0216df3f96020031701672f851cc","modified":1442365471106},{"_id":"source/_posts/MongoDB.md","shasum":"875fa45381a06dad8b295ed7e8768f9b458b1ba5","modified":1442538415596},{"_id":"source/_posts/concurrency/collection/collection.md","shasum":"c38608a0f7782f1141db6cfbae50a35fd6e55858","modified":1442565564444},{"_id":"source/_posts/concurrency/collection/copyonwritearraylist.md","shasum":"2bd0d75934140688e2a78c42e4ae70e44fd49c9e","modified":1442567503217},{"_id":"source/_posts/concurrency/collection/linkedtransferqueue.md","shasum":"b207d5facc7bd621246f73ddd2a82044b083e90e","modified":1442565605134},{"_id":"source/_posts/concurrency/collection/skip_list.md","shasum":"34fa75e284225b648cce702f5e420d0f18909e52","modified":1442565600670},{"_id":"source/_posts/concurrency/collection/synchronize20.md","shasum":"e2a80dfa7fa7336f66846e335ed67b214af4311c","modified":1442565596204},{"_id":"source/_posts/concurrency/collection/synchronousqueue.md","shasum":"c6e6dbc2b202a940da57fca1a85a93e16e44a179","modified":1442565591973},{"_id":"source/_posts/concurrency/collection/使用带有延迟元素的线程安全列表.md","shasum":"ac8c197beec28c35adcdfeb168d9470dc067f9da","modified":1442565626309},{"_id":"source/_posts/concurrency/collection/使用按优先级排序的阻塞式线程安全列表.md","shasum":"1a16ddebea920f363a9825d8128105d934315152","modified":1442565579019},{"_id":"source/_posts/concurrency/collection/使用线程安全可遍历映射.md","shasum":"9c06dccaa6231d0fbd2aa30d6700721834e587c4","modified":1442565619292},{"_id":"source/_posts/concurrency/collection/使用阻塞式线程安全列表.md","shasum":"c95616908c3dd7b0c777af30c07f843b1dc19b6f","modified":1442565615588},{"_id":"source/_posts/concurrency/collection/使用非阻塞式线程安全列表.md","shasum":"3224b695624614dedb614342287db4477e881a0b","modified":1442565622887},{"_id":"source/_posts/concurrency/collection/生成并发随机数.md","shasum":"b5a0d28e04399e0dc31d57d443ed1d78572c365a","modified":1442565583380},{"_id":"source/_posts/concurrency/collection/简介.md","shasum":"20bd331a301562e20c86d549537125dff9f708b2","modified":1442565587211},{"_id":"source/_posts/docker命令.md","shasum":"d5c441b78722cd883ebcaf1160d730f234d07ae6","modified":1434343589100},{"_id":"source/_posts/dropwizard.md","shasum":"6b394ce237e7190b09b6d3830e5b6c1baeac4bdf","modified":1436270712217},{"_id":"source/_posts/gitbook.md","shasum":"d0df7c10982e70f3494b18b698abee6854cf02d7","modified":1434343690862},{"_id":"source/_posts/haskell.md","shasum":"36a5f386bb3c923a75a51b925167632009ae3273","modified":1442380453646},{"_id":"source/_posts/idea快捷键.md","shasum":"3ea10539101cd6a8720734125dd63ef4b75ca1a7","modified":1435717453156},{"_id":"source/_posts/io.md","shasum":"832953f4a976692c59f996fc0d0472dd7265df98","modified":1435384385468},{"_id":"source/_posts/java_hook.md","shasum":"224988be64f26af1d389bc8e600e73cf58c692f5","modified":1434343673735},{"_id":"source/_posts/java集合.md","shasum":"7c23c5271f676b7455d7cb2c2f7f6779f64b9630","modified":1435125058352},{"_id":"source/_posts/jvm7/JVM 参数.md","shasum":"3dc3cd7c19456675b0b25e87e7b320fa1201b3d4","modified":1442556715214},{"_id":"source/_posts/jvm7/class文件格式.md","shasum":"d599f003b9f105d37b14c64dc97ad231932dcdc5","modified":1442556666132},{"_id":"source/_posts/jvm7/gc_log.md","shasum":"7addee4e520aff60f4f6f4768fe5d318ca231673","modified":1442556728016},{"_id":"source/_posts/jvm7/java虚拟机结构.md","shasum":"b302d6e8a1710aef9c26144e932ed9591765837d","modified":1442556723655},{"_id":"source/_posts/jvm7/jstack_log.md","shasum":"115f9d1a1304fba2f6b192db4c6916344244a367","modified":1442556719647},{"_id":"source/_posts/jvm7/oql.md","shasum":"f84ae8d56cfbeca65b43ceab1678afbfc89395ef","modified":1442557087883},{"_id":"source/_posts/jvm7/内存分配.md","shasum":"ff784934dd17de9a64fb3f599a51e3e068dcd4f4","modified":1442557082755},{"_id":"source/_posts/jvm7/内存溢出.md","shasum":"7e75f4fadacf30fab041020c9f3d7281eb8fb1cb","modified":1442557080587},{"_id":"source/_posts/jvm7/垃圾收集.md","shasum":"11705ab7b245bc2fffa201f8d7a0d1017ada64a6","modified":1442557010617},{"_id":"source/_posts/jvm7/字节码指令.md","shasum":"7fa476777aa3ac938d37be4da31e43bd64ca9867","modified":1442557077011},{"_id":"source/_posts/jvm7/相关工具.md","shasum":"6a20a2eb4a2b87a16fc17f73536d9afb0e9beadd","modified":1442557078666},{"_id":"source/_posts/jvm7/类加载.md","shasum":"93185bedb20b06ccc858de22564f0d1edbca4f30","modified":1442557065667},{"_id":"source/_posts/logstash_config.md","shasum":"3e1ef0f6077c1520d8810fd70dc3e98fe54a3847","modified":1441702446580},{"_id":"source/_posts/python.md","shasum":"5e23a453ea1d6413faf7aea64ccc37af909ba38a","modified":1442389973224},{"_id":"source/_posts/security/Java加密.md","shasum":"23e95b7814b97c0be916c00092ff66622510313e","modified":1442560219406},{"_id":"source/_posts/security/README.md","shasum":"65ff33bb8006d9738c7c94acaf62d4265b5b777b","modified":1442559673628},{"_id":"source/_posts/security/java_security.md","shasum":"3d9f605e9195535dea296f538dc144d2d289686a","modified":1442560477045},{"_id":"source/_posts/security/java_security_cert.md","shasum":"75ad6f53e0cb979b133402ae5c0eccbe3b5ac261","modified":1442560488021},{"_id":"source/_posts/security/java_security_spec.md","shasum":"f642524197feac8b6e63b5d213b997f2cd8aee53","modified":1442560497518},{"_id":"source/_posts/security/javax_crypto.md","shasum":"99df69d6998624da4c0827fb743ff2d1f11238f2","modified":1442560505207},{"_id":"source/_posts/security/javax_net_ssl.md","shasum":"a80ba1bb042cae0b27ef234258dc0354b3127050","modified":1442560512670},{"_id":"source/_posts/security/加密算法.md","shasum":"7d03521951c857c71e7945dbfa4f69687e8a5abf","modified":1442560402401},{"_id":"source/_posts/security/密码学.md","shasum":"b92c34029ae6de1fc90a4395ff6f3580f19c5a98","modified":1442560415235},{"_id":"source/_posts/security/对称加密.md","shasum":"2f5a7bcbd4b3b15c17652fdce9f3aa32f2f6d891","modified":1442560373883},{"_id":"source/_posts/security/辅助工具.md","shasum":"67537237855cbde62b1599a1f3b536425f8e1646","modified":1442560410047},{"_id":"source/_posts/unity命令行使用.md","shasum":"0f1d4aec5a3f5dd201ccade5990d4ee5ab1647e4","modified":1435627294059},{"_id":"source/_posts/windows rust.md","shasum":"df3c044c0018b0896d63902bf2cb75d7c775844a","modified":1435395975723},{"_id":"source/_posts/计算java对象大小.md","shasum":"23a24979abc082c2c4220d9921a5ac68bdaeb9a3","modified":1442364574346},{"_id":"source/categories/concurrency/index.md","shasum":"3baed28fd70e0a53d0c5622c22694e1255ee5b96","modified":1442567620782},{"_id":"source/categories/jvm7/index.md","shasum":"620e1ad662eba214e55a56b1a48c3d74019dc446","modified":1442557444448},{"_id":"source/categories/security/index.md","shasum":"96b3503c9d89fcc632c720c60ca5687bbbc6aa20","modified":1442557491532},{"_id":"source/_posts/groovy.md","shasum":"3ca49de5d7eb44d561ebf9c94edd0f760620552d","modified":1442382944388},{"_id":"themes/jacman/LICENSE","shasum":"931516aa36c53eb7843c83d82662eb50cc3c4367","modified":1435808744000},{"_id":"themes/jacman/README.md","shasum":"38698c732ca2c0fa48de89cfee9859bc09e74fd4","modified":1435808744000},{"_id":"themes/jacman/README_zh.md","shasum":"ee9eeb2b72e5597a3550d59d231f443d990d3115","modified":1435808744000},{"_id":"themes/jacman/languages/default.yml","shasum":"ad0de3e82c7fc238cc067ffc37359b1420aef6b3","modified":1435808744000},{"_id":"themes/jacman/_config.yml","shasum":"1a994aa1d4ffda4176ec6ad56e24490d9d72ecc7","modified":1442559555035},{"_id":"themes/jacman/languages/zh-CN.yml","shasum":"5e4ac19d7b2bbf0d5b5aa55d33653380abda8b9a","modified":1435808744000},{"_id":"themes/jacman/languages/zh-TW.yml","shasum":"41c112162d79b4d3f97b417c7cd6ca6d70419ef2","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/after_footer.ejs","shasum":"806dc4349387eec9179000ad7c9fef4023a72aab","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/archive.ejs","shasum":"2c7395e7563fe016521712a645c28a13f952d52a","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/analytics.ejs","shasum":"fd004beb8d4500afd5fb3b3871a95afa2a375f16","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/article.ejs","shasum":"261ecacb8456f4cb972632b6a9103860fa63b9a3","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/article_row.ejs","shasum":"4cb855d91ece7f67b2ca0992fffa55472d0b9c93","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/categories.ejs","shasum":"8a52d0344d5bce1925cf586ed73c11192925209b","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/footer.ejs","shasum":"32db7e7c8171530d29c3878f387c4438d6057508","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/header.ejs","shasum":"18515612344ff048b9372b91b7eef6f3b143801f","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/head.ejs","shasum":"761941be4922cd3c177c8130296b909bf7db5c09","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/mathjax.ejs","shasum":"d42994ac696f52ba99c1cbac382cd76d5b04a3e8","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/pagination.ejs","shasum":"6146ac37dfb4f8613090bc52b3fc8cfa911a186a","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/article.ejs","shasum":"b09e3acea7076e1f01dfe0c2295e19951ea09437","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/catetags.ejs","shasum":"0e37bababc8f4659f5b59a552a946b46d89e4158","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/comment.ejs","shasum":"c88bc8f5805173920a5fdd7e9234a850e3d8e151","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/footer.ejs","shasum":"b12ec08a5845a3d8c01257614f1dfead879c87d2","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/gallery.ejs","shasum":"fafc2501d7e65983b0f5c2b58151ca12e57c0574","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/header.ejs","shasum":"36a705942b691abe0d643ea8afa339981b32f6f2","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/jiathis.ejs","shasum":"d7f5960039ac74924559ab6ba03c64457b8f0966","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/post/pagination.ejs","shasum":"7de9c07a4c968429a8088c31a28b7f3a993ded1b","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/search.ejs","shasum":"1083824a6c6c3df02767f2f3b727aee78ebb76ec","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/sidebar.ejs","shasum":"c4f527fff0070fbe65919053a16224412317f40d","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/tinysou_search.ejs","shasum":"06ecddc8a9d40b480fe2e958af1dab857a9d5441","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/tags.ejs","shasum":"b33b2b5d08f1d53a8de25a95f660f7f1cea7b3cb","modified":1435808744000},{"_id":"themes/jacman/layout/_partial/totop.ejs","shasum":"bea5bb7cb9350b8af7d97a8d223af63a5b30ab78","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/archive.ejs","shasum":"39ea6b7888406fbd1b4cf236ebd718e881493374","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/category.ejs","shasum":"c1fae96b5053da021bcc04ab2ce5c2c8d30de8a2","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/douban.ejs","shasum":"94ce1fb7a1143f34ac1365924b00cae64e1a111e","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/links.ejs","shasum":"e49868063439c2092cdf9a8ec82cc295b0e42f66","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/rss.ejs","shasum":"0a4b5f2a2e36a1d504fe2e7c6c8372cbb4628aab","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/tag.ejs","shasum":"7e82ad9c916b9ce871b2f65ce8f283c5ba47947b","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/tagcloud.ejs","shasum":"10a1001189d5c28ce6d42494563b9637c302b454","modified":1435808744000},{"_id":"themes/jacman/layout/_widget/weibo.ejs","shasum":"a31c2b223d0feb2a227e203cac9e5d13b7d328a8","modified":1435808744000},{"_id":"themes/jacman/layout/archive.ejs","shasum":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1435808744000},{"_id":"themes/jacman/layout/category.ejs","shasum":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1435808744000},{"_id":"themes/jacman/layout/index.ejs","shasum":"75cef2172c286994af412e11ab7f4f5a0daaf1f5","modified":1435808744000},{"_id":"themes/jacman/layout/layout.ejs","shasum":"5b4289a4526899809b9c2facea535367ff51ba2b","modified":1435808744000},{"_id":"themes/jacman/layout/page.ejs","shasum":"bd6bbf2ea8e183bd835867ff617dc6366b56748c","modified":1435808744000},{"_id":"themes/jacman/layout/post.ejs","shasum":"3114134775bdde5a83cf14feb019606fa2b2b2be","modified":1435808744000},{"_id":"themes/jacman/layout/tag.ejs","shasum":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1435808744000},{"_id":"themes/jacman/scripts/fancybox.js","shasum":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1435808744000},{"_id":"themes/jacman/source/css/_base/font.styl","shasum":"c8a0faf43b08e37ad07a5669db76d595da966159","modified":1435808744000},{"_id":"themes/jacman/source/css/_base/highlight/highlight.styl","shasum":"91b62bfc58390b0d5db782a75be6965ee3665eb3","modified":1435808744000},{"_id":"themes/jacman/source/css/_base/highlight/theme.styl","shasum":"e3a59bd427ba37a54ead9eeba9a5356b3f720a48","modified":1435808744000},{"_id":"themes/jacman/source/css/_base/public.styl","shasum":"a29e4a4fbc288323b7f3ca2e501a6609e5646e2f","modified":1435808744000},{"_id":"themes/jacman/source/css/_base/variable.styl","shasum":"cb652eb83c28a208743fabab92de896f8b7cbf7b","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/article.styl","shasum":"c69641b4a34a8c62986b335414413dbde26de25e","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/aside.styl","shasum":"6b0e46e2e3be200339197696f5aabd0871aa9952","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/duoshuo.styl","shasum":"e85f1192283f043115c272a9deb3cb6ced793990","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/footer.styl","shasum":"1911613a19b605a58f801c21b03b5d4c83b90f9c","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/gallery.styl","shasum":"7246809f4ce3166ec1b259bf475cae1a48e29aad","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/header.styl","shasum":"5121ceb712be3f2dde98b8b6e589b546e19eab8f","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/helper.styl","shasum":"1136600932b97534b88465bf05ef313630b2de3d","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/index.styl","shasum":"864fba1fcb3830a9055c366a99ce5c951c2e9fe9","modified":1435808744000},{"_id":"themes/jacman/source/css/_partial/totop.styl","shasum":"96363d7c5aaed5f649667fc0752a62620a67e872","modified":1435808744000},{"_id":"themes/jacman/source/css/style.styl","shasum":"a0a45af186a72ae68979bf26f2a5d0d2303189ca","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-buttons.js","shasum":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-media.js","shasum":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/helpers/jquery.fancybox-thumbs.js","shasum":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.css","shasum":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.js","shasum":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1435808744000},{"_id":"themes/jacman/source/fancybox/jquery.fancybox.pack.js","shasum":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1435808744000},{"_id":"themes/jacman/source/font/FontAwesome.otf","shasum":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1435808744000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.eot","shasum":"a17d0f10534303e40f210c506ebb8703fa23b7de","modified":1435808744000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.ttf","shasum":"194ccb4acf77a03dc25bcc174edb266143704fec","modified":1435808744000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.woff","shasum":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e","modified":1435808744000},{"_id":"themes/jacman/source/font/fontawesome-webfont.eot","shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1435808744000},{"_id":"themes/jacman/source/font/fontawesome-webfont.woff","shasum":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1435808744000},{"_id":"themes/jacman/source/font/fontdiao.eot","shasum":"9544a0d7ba208989302bc4da5a184faeb0e883c9","modified":1435808744000},{"_id":"themes/jacman/source/font/fontdiao.ttf","shasum":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab","modified":1435808744000},{"_id":"themes/jacman/source/font/fontdiao.woff","shasum":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1435808744000},{"_id":"themes/jacman/source/img/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1435808744000},{"_id":"themes/jacman/source/img/favicon.ico","shasum":"4a605a4cc4691ad8b07ea9bc7f1a8212f1ee57cb","modified":1442312340427},{"_id":"themes/jacman/source/img/logo.png","shasum":"cfe9ece003e30801e82fc31336412b48fd7fdaa2","modified":1442555098755},{"_id":"themes/jacman/source/img/logo.svg","shasum":"9ae38f7225c38624faeb7b74996efa9de7bf065b","modified":1435808744000},{"_id":"themes/jacman/source/img/scrollup.png","shasum":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3","modified":1435808744000},{"_id":"themes/jacman/source/js/gallery.js","shasum":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1435808744000},{"_id":"themes/jacman/source/js/jquery.imagesloaded.min.js","shasum":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1435808744000},{"_id":"themes/jacman/source/js/jquery.qrcode-0.12.0.min.js","shasum":"57c3987166a26415a71292162690e82c21e315ad","modified":1435808744000},{"_id":"themes/jacman/source/js/totop.js","shasum":"cad23c5ea7163d1e5c05a0fd3ef9233469da10cb","modified":1435808744000},{"_id":"themes/jacman/source/font/coveredbyyourgrace-webfont.svg","shasum":"eabdb262d8e246865dfb56031f01ff6e8d2f9d53","modified":1435808744000},{"_id":"themes/jacman/source/font/fontawesome-webfont.ttf","shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1435808744000},{"_id":"themes/jacman/source/font/fontdiao.svg","shasum":"334a94e6a66a8b089be7315d876bec93efe38d2b","modified":1435808744000},{"_id":"themes/jacman/source/js/jquery-2.0.3.min.js","shasum":"a0ae3697b0ab8c0e8bd3186c80db42abd6d97a8d","modified":1435808744000},{"_id":"themes/jacman/source/font/fontawesome-webfont.svg","shasum":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1435808744000},{"_id":"themes/jacman/source/img/banner.jpg","shasum":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74","modified":1435808744000},{"_id":"themes/jacman/source/img/author.jpg","shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c","modified":1442311242072},{"_id":"themes/jacman/source/img/jacman.jpg","shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c","modified":1442311242072},{"_id":"public/CNAME","modified":1442567662811,"shasum":"e8afbfc153d8646cc8ca9239cd55302520f821e1"},{"_id":"public/js/totop.js","modified":1442567662815,"shasum":"cad23c5ea7163d1e5c05a0fd3ef9233469da10cb"},{"_id":"public/js/jquery.qrcode-0.12.0.min.js","modified":1442567662818,"shasum":"57c3987166a26415a71292162690e82c21e315ad"},{"_id":"public/js/jquery.imagesloaded.min.js","modified":1442567662819,"shasum":"4109837b1f6477bacc6b095a863b1b95b1b3693f"},{"_id":"public/js/jquery-2.0.3.min.js","modified":1442567662821,"shasum":"a0ae3697b0ab8c0e8bd3186c80db42abd6d97a8d"},{"_id":"public/js/gallery.js","modified":1442567662822,"shasum":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed"},{"_id":"public/img/scrollup.png","modified":1442567662824,"shasum":"2137d4f1739aa8aa3fcb0348c3ddf1e41d62f2e3"},{"_id":"public/img/logo.svg","modified":1442567662826,"shasum":"9ae38f7225c38624faeb7b74996efa9de7bf065b"},{"_id":"public/img/logo.png","modified":1442567662827,"shasum":"cfe9ece003e30801e82fc31336412b48fd7fdaa2"},{"_id":"public/img/jacman.jpg","modified":1442567662837,"shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c"},{"_id":"public/img/favicon.ico","modified":1442567662839,"shasum":"4a605a4cc4691ad8b07ea9bc7f1a8212f1ee57cb"},{"_id":"public/img/cc-zero.svg","modified":1442567662840,"shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030"},{"_id":"public/img/cc-by.svg","modified":1442567662842,"shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e"},{"_id":"public/img/cc-by-sa.svg","modified":1442567662843,"shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e"},{"_id":"public/img/cc-by-nd.svg","modified":1442567662845,"shasum":"c563508ce9ced1e66948024ba1153400ac0e0621"},{"_id":"public/img/cc-by-nc.svg","modified":1442567662847,"shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7"},{"_id":"public/img/cc-by-nc-sa.svg","modified":1442567662849,"shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e"},{"_id":"public/img/cc-by-nc-nd.svg","modified":1442567662850,"shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564"},{"_id":"public/img/banner.jpg","modified":1442567662852,"shasum":"5104860c4f8b2e84ef734ba6c37fe7a288bf0d74"},{"_id":"public/img/author.jpg","modified":1442567662855,"shasum":"0273ab87d0f744a5d5922dc2663a2f4fd4184f4c"},{"_id":"public/font/fontdiao.woff","modified":1442567662857,"shasum":"71f54eb6e98aa28cafeb04aab71c0e5b349ea89f"},{"_id":"public/font/fontdiao.ttf","modified":1442567662859,"shasum":"ee9fd7be2493c9bf6d2841044e69a0830d9d3fab"},{"_id":"public/font/fontdiao.svg","modified":1442567662861,"shasum":"334a94e6a66a8b089be7315d876bec93efe38d2b"},{"_id":"public/font/fontdiao.eot","modified":1442567662863,"shasum":"9544a0d7ba208989302bc4da5a184faeb0e883c9"},{"_id":"public/font/fontawesome-webfont.woff","modified":1442567662864,"shasum":"04c3bf56d87a0828935bd6b4aee859995f321693"},{"_id":"public/font/fontawesome-webfont.ttf","modified":1442567662866,"shasum":"7f09c97f333917034ad08fa7295e916c9f72fd3f"},{"_id":"public/font/fontawesome-webfont.svg","modified":1442567662869,"shasum":"46fcc0194d75a0ddac0a038aee41b23456784814"},{"_id":"public/font/fontawesome-webfont.eot","modified":1442567662872,"shasum":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e"},{"_id":"public/font/coveredbyyourgrace-webfont.woff","modified":1442567662875,"shasum":"c6f8dc1a2f6ce914f120e80a876b8fd77b98888e"},{"_id":"public/font/coveredbyyourgrace-webfont.ttf","modified":1442567662876,"shasum":"194ccb4acf77a03dc25bcc174edb266143704fec"},{"_id":"public/font/coveredbyyourgrace-webfont.svg","modified":1442567662878,"shasum":"eabdb262d8e246865dfb56031f01ff6e8d2f9d53"},{"_id":"public/font/coveredbyyourgrace-webfont.eot","modified":1442567662880,"shasum":"a17d0f10534303e40f210c506ebb8703fa23b7de"},{"_id":"public/font/FontAwesome.otf","modified":1442567662883,"shasum":"b5b4f9be85f91f10799e87a083da1d050f842734"},{"_id":"public/fancybox/jquery.fancybox.pack.js","modified":1442567662884,"shasum":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e"},{"_id":"public/fancybox/jquery.fancybox.js","modified":1442567662886,"shasum":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed"},{"_id":"public/fancybox/jquery.fancybox.css","modified":1442567662888,"shasum":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6"},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","modified":1442567662889,"shasum":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c"},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","modified":1442567662891,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","modified":1442567662892,"shasum":"294420f9ff20f4e3584d212b0c262a00a96ecdb3"},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","modified":1442567662894,"shasum":"dc3645529a4bf72983a39fa34c1eb9146e082019"},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","modified":1442567662895,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/fancybox/helpers/fancybox_buttons.png","modified":1442567662896,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/fancybox/fancybox_sprite@2x.png","modified":1442567662898,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/fancybox/fancybox_sprite.png","modified":1442567662899,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/fancybox/fancybox_overlay.png","modified":1442567662901,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/fancybox/fancybox_loading@2x.gif","modified":1442567662903,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/fancybox/fancybox_loading.gif","modified":1442567662904,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/fancybox/blank.gif","modified":1442567662906,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/css/style.css","modified":1442567663606,"shasum":"26a67ba7cbebfbc2975af49420a43a019babef20"},{"_id":"public/categories/security/index.html","modified":1442567663879,"shasum":"a7eaf3f0a14d4e9e92db87638a03177b0738988f"},{"_id":"public/categories/jvm7/index.html","modified":1442567663893,"shasum":"2d4280549b5bf47ba2e5949a383ae3fd30ff6b32"},{"_id":"public/categories/concurrency/index.html","modified":1442567663907,"shasum":"06200c2be9c608ac04f857766bb53e0bbf9de47f"},{"_id":"public/2015/09/18/concurrency/collection/copyonwritearraylist/index.html","modified":1442567663929,"shasum":"d3d23b6f5149d9d8ae8b2c86a9b40cc86aa642fc"},{"_id":"public/2015/09/18/concurrency/collection/使用带有延迟元素的线程安全列表/index.html","modified":1442567663950,"shasum":"3f0427513579c388a0fee3c845cbcdab2ea1b31b"},{"_id":"public/2015/09/18/concurrency/collection/使用非阻塞式线程安全列表/index.html","modified":1442567663965,"shasum":"e731bec2b4e0175e8a352038be61fc1b0352901d"},{"_id":"public/2015/09/18/concurrency/collection/使用线程安全可遍历映射/index.html","modified":1442567663979,"shasum":"04246a006b256eca0a827843e649b8e8bd9f49b6"},{"_id":"public/2015/09/18/concurrency/collection/使用阻塞式线程安全列表/index.html","modified":1442567663991,"shasum":"24d3ea0ea83dd5da0506c7b1a9f6487198d476b3"},{"_id":"public/2015/09/18/concurrency/collection/linkedtransferqueue/index.html","modified":1442567664004,"shasum":"f11abbbc3d325bc9c4ec4890a32e02ba1774aeba"},{"_id":"public/2015/09/18/concurrency/collection/skip_list/index.html","modified":1442567664016,"shasum":"48ed61da01720f5be8b99e06f14868b0c89b89ba"},{"_id":"public/2015/09/18/concurrency/collection/synchronize20/index.html","modified":1442567664035,"shasum":"567a56c3c0ca2a26723fa43e6361032956adadf0"},{"_id":"public/2015/09/18/concurrency/collection/synchronousqueue/index.html","modified":1442567664048,"shasum":"119c2cddf11f98dd575eca5a13a9da06bbb1152b"},{"_id":"public/2015/09/18/concurrency/collection/简介/index.html","modified":1442567664063,"shasum":"e6cd238790497bb4a9af7ef5b0c7616a38eec8c7"},{"_id":"public/2015/09/18/concurrency/collection/生成并发随机数/index.html","modified":1442567664074,"shasum":"00b7c298c2607506c1d35a16a33cbea332a26f2b"},{"_id":"public/2015/09/18/concurrency/collection/使用按优先级排序的阻塞式线程安全列表/index.html","modified":1442567664087,"shasum":"e8d0017047a4e0802e6431bbb96dae80edee9946"},{"_id":"public/2015/09/18/concurrency/collection/collection/index.html","modified":1442567664101,"shasum":"e1573fcb8900ef3ad4ffe6b6ff9b28293a80baf4"},{"_id":"public/2015/09/18/security/辅助工具/index.html","modified":1442567664123,"shasum":"525d6c91ce11c3731315eff7d9e9a2e155e82df8"},{"_id":"public/2015/09/18/security/对称加密/index.html","modified":1442567664138,"shasum":"9670484876bd102365234edcf065febc1670c921"},{"_id":"public/2015/09/18/security/密码学/index.html","modified":1442567664157,"shasum":"9d303e584040b65ab1bf71e5a910ea98aefc98f8"},{"_id":"public/2015/09/18/security/加密算法/index.html","modified":1442567664175,"shasum":"6df118ac21dda5923f384a483608a04bf50930e8"},{"_id":"public/2015/09/18/security/javax_net_ssl/index.html","modified":1442567664208,"shasum":"d3beec61155a7a7ac8467dcb2e1a228350d7064d"},{"_id":"public/2015/09/18/security/javax_crypto/index.html","modified":1442567664245,"shasum":"c99b25aad0c168126700d456632c124f3ebc49a8"},{"_id":"public/2015/09/18/security/java_security_spec/index.html","modified":1442567664267,"shasum":"57ec9e206f8d67f3f64e962133d6ec606b803a91"},{"_id":"public/2015/09/18/security/java_security_cert/index.html","modified":1442567664287,"shasum":"6ae92eea90d27954cbec802dfa864be85fc7b9fa"},{"_id":"public/2015/09/18/security/java_security/index.html","modified":1442567664341,"shasum":"1d8966c4566691f76f7b0ea04eaf3a4f97f99f77"},{"_id":"public/2015/09/18/security/Java加密/index.html","modified":1442567664356,"shasum":"21b239e9e82f49630822d609dcfd450afa8b8fef"},{"_id":"public/2015/09/18/security/README/index.html","modified":1442567664398,"shasum":"187140ca9b01eb808f8b2d09d7a943ebc32a7806"},{"_id":"public/2015/09/18/jvm7/类加载/index.html","modified":1442567664435,"shasum":"16549f98b2b71610ad1adccfcff47d4e9a9a0f2e"},{"_id":"public/2015/09/18/jvm7/相关工具/index.html","modified":1442567664450,"shasum":"6e61039fe927d56911d6e2cf7dd1afcc7040c3b6"},{"_id":"public/2015/09/18/jvm7/字节码指令/index.html","modified":1442567664490,"shasum":"a7635903543eab4105c87aa37a3520172e67ec9e"},{"_id":"public/2015/09/18/jvm7/垃圾收集/index.html","modified":1442567664514,"shasum":"195ef87321428d4acb6b7a5a8b9c5ee996c5d9b9"},{"_id":"public/2015/09/18/jvm7/内存溢出/index.html","modified":1442567664547,"shasum":"bff1414b97f5008f0cf2ffb0e878a96e16b11e55"},{"_id":"public/2015/09/18/jvm7/内存分配/index.html","modified":1442567664569,"shasum":"c30576d4cfd64df785f0410bf517aa6071108b1a"},{"_id":"public/2015/09/18/jvm7/oql/index.html","modified":1442567664587,"shasum":"f3316e138c0ddc18198c83eb377bda25d980b64b"},{"_id":"public/2015/09/18/jvm7/jstack_log/index.html","modified":1442567664604,"shasum":"9d959bade1cc1f14f99224c044bdbfbfceb4273a"},{"_id":"public/2015/09/18/jvm7/java虚拟机结构/index.html","modified":1442567664631,"shasum":"3fd42b3089afc67ce8cbfa0da19fb5552b53ebb3"},{"_id":"public/2015/09/18/jvm7/gc_log/index.html","modified":1442567664645,"shasum":"10c47bcad5c98bd0348b9a7ee65eae376e197770"},{"_id":"public/2015/09/18/jvm7/class文件格式/index.html","modified":1442567664677,"shasum":"11eac63e3302cf2ff847f8cb7653aa6eda966ab0"},{"_id":"public/2015/09/18/jvm7/JVM 参数/index.html","modified":1442567664694,"shasum":"66c0b6444138762ecab25d6eeeb9a933294e4d9d"},{"_id":"public/2015/09/18/MongoDB/index.html","modified":1442567664751,"shasum":"52be49797e81669726a82d73166c60a8e469a55b"},{"_id":"public/2015/09/18/Archiva/index.html","modified":1442567664768,"shasum":"d5202dfd05103955a4791958cfa55a682b62057b"},{"_id":"public/2015/09/16/python/index.html","modified":1442567664810,"shasum":"e21b49d7f674e176145ab53d20faa59e6e52a520"},{"_id":"public/2015/09/16/groovy/index.html","modified":1442567664985,"shasum":"a6efabd4980715de7d99b6d7dd7bbd70060909eb"},{"_id":"public/2015/09/16/haskell/index.html","modified":1442567665033,"shasum":"c09200a39ef541dc4095d3e2f88988ef14e13344"},{"_id":"public/2015/09/16/io/index.html","modified":1442567665061,"shasum":"465abd52408515cf4237ac046347be78b24e5789"},{"_id":"public/2015/09/16/Flick Ticket Server/index.html","modified":1442567665077,"shasum":"eb227cc9809ef09c7bd01b49f95f117a56850973"},{"_id":"public/2015/09/16/java集合/index.html","modified":1442567665094,"shasum":"94be8aeef4944a9c510d8f5b0603184f423c308f"},{"_id":"public/2015/09/16/计算java对象大小/index.html","modified":1442567665106,"shasum":"c76ab03787cca71cafc40da3422dd51ee7abbd1d"},{"_id":"public/2015/09/08/logstash_config/index.html","modified":1442567665123,"shasum":"3884df3a8b95861e6f490b00484216286777afbd"},{"_id":"public/2015/07/07/dropwizard/index.html","modified":1442567665151,"shasum":"5795e1839fae6a68fa4a1c6710160102c4f98925"},{"_id":"public/2015/07/07/java_hook/index.html","modified":1442567665175,"shasum":"83a6cb16a5bdc8ef47390493ce6ff6d4606f35f2"},{"_id":"public/2015/07/01/unity命令行使用/index.html","modified":1442567665191,"shasum":"ebcf643a08bcdc6b81bffc1fec8210c3cd779eb7"},{"_id":"public/2015/07/01/idea快捷键/index.html","modified":1442567665202,"shasum":"18d51108fe80bc592e0cfbfbbd72ecc2db6dd055"},{"_id":"public/2015/06/27/windows rust/index.html","modified":1442567665213,"shasum":"ef1544ebf92d80c8213b968785cfab9b286f6b87"},{"_id":"public/2015/06/27/gitbook/index.html","modified":1442567665225,"shasum":"c40673ebe60c54da9bbcf67711a48ef5c6dc85eb"},{"_id":"public/2015/06/27/docker命令/index.html","modified":1442567665249,"shasum":"a61140d282e3dc0eb275a0cb496ab90a327ed498"},{"_id":"public/archives/index.html","modified":1442567665262,"shasum":"a312f7df8ce53da6b387c87a61436f66a8805a67"},{"_id":"public/archives/page/2/index.html","modified":1442567665272,"shasum":"1e5c127f1f1bbbee657b7e707024cfd626eaf8fb"},{"_id":"public/archives/page/3/index.html","modified":1442567665282,"shasum":"8cb80d81e0464036e92df34c5f5ed0cfdd80f535"},{"_id":"public/archives/page/4/index.html","modified":1442567665292,"shasum":"d783993a442fa50aa9b3a71e262a604b2d64b6ce"},{"_id":"public/archives/page/5/index.html","modified":1442567665301,"shasum":"b2c0841abe034f58621f392acecea7a10cace579"},{"_id":"public/archives/page/6/index.html","modified":1442567665308,"shasum":"1f4a82b37e08079f5641a5a60a72cab05e33d5bb"},{"_id":"public/archives/2015/index.html","modified":1442567665319,"shasum":"74126485fab76640236994520276766f13b58e3a"},{"_id":"public/archives/2015/page/2/index.html","modified":1442567665330,"shasum":"a87c57f428f5bc8ba8a5d1de33f07d7d0817e51e"},{"_id":"public/archives/2015/page/3/index.html","modified":1442567665342,"shasum":"30ece83c268efbffb464dd913a1ee6c529940410"},{"_id":"public/archives/2015/page/4/index.html","modified":1442567665351,"shasum":"95b1908269718d8a0c106bdee764c6506475f3a5"},{"_id":"public/archives/2015/page/5/index.html","modified":1442567665361,"shasum":"f22c1079d7363f434b3f42dcde1214d4e39ee5b3"},{"_id":"public/archives/2015/page/6/index.html","modified":1442567665367,"shasum":"add0470af0b163f521ce8f3b22e0f19f573b1169"},{"_id":"public/archives/2015/06/index.html","modified":1442567665374,"shasum":"ca466c4bbd7fdcff09e5cf6badf40d174e752a29"},{"_id":"public/archives/2015/07/index.html","modified":1442567665380,"shasum":"014d5ab68c823650e0359fcc8a78e2345b387296"},{"_id":"public/archives/2015/09/index.html","modified":1442567665389,"shasum":"3f2ed81837b83c489e551a4b455b9a6adef0d7e3"},{"_id":"public/archives/2015/09/page/2/index.html","modified":1442567665399,"shasum":"9a246798acda36e65d5882833d557347eac09dc3"},{"_id":"public/archives/2015/09/page/3/index.html","modified":1442567665408,"shasum":"8a2194c224f0190bbdfd242217d3675b9a6d422f"},{"_id":"public/archives/2015/09/page/4/index.html","modified":1442567665418,"shasum":"22c19d5a808b17549425796970c77aa940a8ba75"},{"_id":"public/archives/2015/09/page/5/index.html","modified":1442567665427,"shasum":"1c5fc455bd07218d1023709e8baeb3e6fef8e9e2"},{"_id":"public/categories/jvm7/page/2/index.html","modified":1442567665434,"shasum":"b29808296112ab1adf6e96d005ff511c0962d519"},{"_id":"public/categories/collection/index.html","modified":1442567665442,"shasum":"786b26912d794dfad94c9e2f268a508999ed1f2d"},{"_id":"public/categories/collection/page/2/index.html","modified":1442567665449,"shasum":"2a78e197090b31e9310b692ca0ccc0613bdbceaf"},{"_id":"public/categories/并发集合/index.html","modified":1442567665456,"shasum":"e241375cb74d86e6525304a830528d8c2076ed9b"},{"_id":"public/index.html","modified":1442567665477,"shasum":"09f0a73f62cc11dfdc5c7a349f70fdb49d3e7f2f"},{"_id":"public/page/2/index.html","modified":1442567665499,"shasum":"16a4861c67f2f4b05b4a4384f3305790f94ee61c"},{"_id":"public/page/3/index.html","modified":1442567665522,"shasum":"d756a377e38951c2f16067fe7c4911ebad84b816"},{"_id":"public/page/4/index.html","modified":1442567665548,"shasum":"8483162a0543a390016fb31380ae4b5fcbd3045e"},{"_id":"public/page/5/index.html","modified":1442567665573,"shasum":"fc90ac285f436536dd237bec7c9b834b51ed1452"},{"_id":"public/page/6/index.html","modified":1442567665587,"shasum":"e04f26c82f16b85517567f69328ca5d78b7d2cb9"}],"Category":[{"name":"security","_id":"ciepfje9a000774uf4uyrwljj"},{"name":"jvm7","_id":"ciepfjea2000v74ufcabnoi50"},{"name":"collection","_id":"ciepfjeb8001t74ufy0hfqhsr"},{"name":"并发集合","_id":"ciepfjebv002g74ufunvqzkfn"}],"Data":[],"Page":[{"layout":"categories","title":"加密解密","_content":"","source":"categories/security/index.md","raw":"layout: categories\ntitle: 加密解密\n---","date":"2015-09-18T07:04:24.857Z","updated":"2015-09-18T06:24:51.532Z","path":"categories/security/index.html","comments":1,"_id":"ciepfje8d000074ufq2xjbxw1"},{"layout":"categories","title":"jvm7","_content":"","source":"categories/jvm7/index.md","raw":"layout: categories\ntitle: jvm7\n---\n","date":"2015-09-18T07:04:24.856Z","updated":"2015-09-18T06:24:04.448Z","path":"categories/jvm7/index.html","comments":1,"_id":"ciepfje8x000174uf9wa7dsec"},{"layout":"categories","title":"java并发","_content":"layout: categories\ntitle: java并发\n---","source":"categories/concurrency/index.md","raw":"layout: categories\ntitle: java并发\n---\nlayout: categories\ntitle: java并发\n---","date":"2015-09-18T09:13:40.782Z","updated":"2015-09-18T09:13:40.782Z","path":"categories/concurrency/index.html","comments":1,"_id":"ciepfje8y000274ufu12zuki5"}],"Post":[{"_content":"\n## 对象\n要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.\n> 这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.\n\n另外一般内存的使用会被填充为8字节的倍数.\n\n","source":"_posts/计算java对象大小.md","raw":"\n## 对象\n要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.\n> 这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.\n\n另外一般内存的使用会被填充为8字节的倍数.\n\n","slug":"计算java对象大小","published":1,"date":"2015-09-16T00:49:34.346Z","updated":"2015-09-16T00:49:34.346Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje90000374ufs2uvlhgt"},{"title":"在windows上搭建rust开发环境","_content":"在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","source":"_posts/windows rust.md","raw":"title: 在windows上搭建rust开发环境\n---\n在windows上搭建rust开发环境\n\n1. 安装[msys2](http://sourceforge.net/projects/msys2/) (我的电脑是64位的,所以以下操作都是以64位为主)\n2. 在`msys2`中安装`openssl` -> `pacman -S mingw-w64-x86_64-openssl` (32位`pacman -S mingw-w64-i686-openssl`)\n3. 将`C:\\msys64\\mingw64\\bin`添加到环境变量`Path`中\n4. 将`C:\\msys64\\mingw64\\lib`下的`libcrypto.dll.a`复制一份,将新文件命名为`libeay32.a`\n5. 将`C:\\msys64\\mingw64\\lib`下的`libssl.dll.a`复制一份,将新文件命名为`libssl32.a`\n6. 下载安装[rust](http://www.rust-lang.org/)\n7. 将`Rust stable 1.0\\bin\\rustlib\\x86_64-pc-windows-gnu\\bin`这个`bin`改成其他的名字(随便什么名字,不让Path找到就好了)\n8. 现在rust程序就可以正常运行了","slug":"windows rust","published":1,"date":"2015-06-27T10:12:59.772Z","updated":"2015-06-27T09:06:15.723Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje95000474ufkqhm7j3p"},{"title":"unity命令行使用","_content":"# Command line arguments\n\n当从命令行启动`Unity`时,它可以在启动时接受一些参数和信息, 这种方式可以用于测试用例，自动构建和其他的任务。\n\n在`MacOS`系统下，你可以像下面这样启动\n```\n /Applications/Unity/Unity.app/Contents/MacOS/Unity\n```\n当在windows系统里，你就需要执行下面的命令了\n```\n \"C:\\Program Files (x86)\\Unity\\Editor\\Unity.exe\"\n```\n\n## Options\n\n正如上面提到的,`editor`也可以在启动时通过一些额外的命令来构建游戏, 下面就列举出了这些命令：\n\n* `-assetServerUpdate <IP[:port] projectName username password [r <revision>]>`\t从`IP:port`上的`Asset Server`强制更新项目. `port`是可选的,如果不指定的话,会默认选择`10733`这个端口. 这个命令可与`-projectPath`参数一起使用, 这样可确保你不会更新错项目.如果不指定项目名称的话,那么会默认的对`Unity`上次打开的项目进行更新. 如果`-projectPath`路径下不存在项目,那么会自动创建一个.\n* `-batchmode`  在`batch`模式下运行`Unity`.这个命令我们强烈建议你与其他命令一起使用, 它会确保不会弹出Edtior. 当由脚本代码抛出异常或者`Asset Server`更新失败或者其他操作引起的异常,`Unity`会直接返回错误码`1`并退出. 需要注意的是,在`batch`模式下,`Unity`会在控制台输出一些基础日志. 还有当在`batch`模式下打开一个项目,那么`Editor`就不能再开打这个相同的项目.\n* `-buildLinux32Player <pathname>`\t构建一个32位的linux版应用.(例如 `-buildLinux32Player path/to/your/build`).\n* `-buildLinux64Player <pathname>`\t构建一个64位的linux版应用.(例如 `-buildLinux64Player path/to/your/build`).\n* `-buildLinuxUniversalPlayer <pathname>`\t构建一个32位和64位的linux混合版应用.(例如 `-buildLinuxUniversalPlayer path/to/your/build`).\n* `-buildOSXPlayer <pathname>`\t构建一个32位的MacOS版应用.(例如 `-buildOSXPlayer path/to/your/build.app`).\n* `-buildOSX64Player <pathname>`\t构建一个64位的MacOS版应用.(例如 `-buildOSX64Player path/to/your/build.app`).\n* `-buildOSXUniversalPlayer <pathname>`\t构建一个32位和64位的MacOs混合版应用.(例如 `-buildOSXUniversalPlayer path/to/your/build.app`).\n* `-buildTarget <name>`\t当项目被加载之前允许用户选择的构建目标：`win32, win64, osx, linux, linux64, ios, android, web, webstreamed, webgl, xbox360, xboxone, ps3, ps4, psp2, wsa, wp8, bb10, tizen, samsungtv`.\n* `-buildWebPlayer <pathname>`\t构建一个在web上运行的应用.(例如`-buildWebPlayer path/to/your/build`).\n* `-buildWebPlayerStreamed <pathname>`\tBuild a streamed WebPlayer (`-buildWebPlayerStreamed path/to/your/build`).\n* `-buildWindowsPlayer <pathname>`\t构建一个32位的Windows版应用.(例如  `-buildWindowsPlayer path/to/your/build.exe`).\n* `-buildWindows64Player <pathname>`\t构建一个64位的Windows版应用.(例如  `-buildWindows64Player path/to/your/build.exe`).\n* `-createProject <pathname>`\t在指定路径下(`pathname`)创建一个空项目.\n* `-executeMethod <ClassName.MethodName>`\t只要Unity启动完成并且项目打开(可能还需要等待asset server更新完成)就执行该静态方法. 该功能可用于持续集成, 运行测试用例, 执行构建任务, 准备一些数据等等. 如果你想让程序在命令行中返回一个错误码,那么你可以直接在Unity中直接抛出一个异常,这时命令行返回的错误码是1，或者你可以调用`EditorApplication.Exit`,这时会返回一个非0的状态码. 如果你想要向该方法传递参数,那么你可以直接将这些参数添加到命令行上,然后在程序中使用`System.Environment.GetCommandLineArgs`获得这些参数.To use -executeMethod, you need to place the enclosing script in an Editor folder. The method to be executed must be defined as static.\n* `-exportPackage <exportAssetPath1 exportAssetPath2 ExportAssetPath3 exportFileName>`\t在指定的路径下导出`package`. `exportAssetPath`是一个从Unity项目导出到的文件夹(路径相对于Unity项目的根路径), `exportFileName`是package的名字. 一般这个选项可以一次性地导出整个文件夹.这个命令一般需要和`-projectPath`参数一起使用.\n* `-force-d3d9 (Windows only)`\t设置editor使用`Direct3D 9`进行渲染. 这个是默认选项,一般不需要你去设置这个值.\n* `-force-d3d11 (Windows only)`\t设置editor使用`Direct3D 11`进行渲染.\n* `-force-opengl (Windows only)`\t设置editor使用`OpenGL`进行渲染. 即使`Direct3D`可用我们也可以说使用`OpenGL`进行渲染. 一般我们是在` Direct3D 9.0c`不可用的情况下才选择使用`openGL`\n* `-force-free`\t让edtior在`Unity license`下运行, 即使我们安装了`Unity Pro license`\n* `-importPackage <pathname>`\t导入指定的`package`. 如果不进行导入的话,会出现一个对话框.\n* `-logFile <pathname>`\t指定Editor或者`Windows/Linux/OSX`版本应用的日志输出路径.\n* `-silent-crashes`\t不显示crashe对话框.\n* `-projectPath <pathname>`\t在指定的路径下打开项目.\n* `-quit`\t当其他命令都执行完之后退出Unity. 注意这个会将错误日志隐藏掉，但是可以在`Editor.log`中找到它.\n* `-serial <serial>`\tActivates Unity with the specified serial key. It is recommended to pass “-batchmode -quit” arguments as well, in order to quit Unity when done, if using this for automated activation of Unity. Please allow a few seconds before license file is created, as Unity needs to communicate with the license server. Make sure that License file folder exists, and has appropriate permissions before running Unity with this argument. In case activation fails, see the Editor.log for info. This option is new in Unity 5.0.\n\n#### Example usage\n```\n// C# example\nusing UnityEditor;\nclass MyEditorScript\n{\n     static void PerformBuild ()\n     {\n         string[] scenes = { \"Assets/MyScene.unity\" };\n         BuildPipeline.BuildPlayer(scenes, ...);\n     }\n}\n\n\n// JavaScript example\nstatic void PerformBuild ()\n{\n    string[] scenes = { \"Assets/MyScene.unity\" };\n    BuildPipeline.BuildPlayer(scenes, ...);\n}\n```\n下面的命令在`batch`模式下运行Unity, 同时执行`MyEditorScript.MyMethod`完成, 当该方法执行完之后退出.\n* `Windows`: `C:\\program files\\Unity\\Editor\\Unity.exe -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n* `Mac OS`: `/Applications/Unity/Unity.app/Contents/MacOS/Unity -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n\n下面的命令在`batch`执行Unity, 同时从`asset server`更新指定项目. 当全部的`asset`下载完之后, 指定的方法会被执行,当方法被完全执行之后,Unity会自动退出.\n```\n/Applications/Unity/Unity.app/Contents/MacOS/Unity -batchmode -projectPath ~/UnityProjects/AutobuildProject -assetServerUpdate 192.168.1.1 MyGame AutobuildUser l33tpa33 -executeMethod MyEditorScript.PerformBuild -quit\n```\n\n","source":"_posts/unity命令行使用.md","raw":"title: unity命令行使用\n---\n# Command line arguments\n\n当从命令行启动`Unity`时,它可以在启动时接受一些参数和信息, 这种方式可以用于测试用例，自动构建和其他的任务。\n\n在`MacOS`系统下，你可以像下面这样启动\n```\n /Applications/Unity/Unity.app/Contents/MacOS/Unity\n```\n当在windows系统里，你就需要执行下面的命令了\n```\n \"C:\\Program Files (x86)\\Unity\\Editor\\Unity.exe\"\n```\n\n## Options\n\n正如上面提到的,`editor`也可以在启动时通过一些额外的命令来构建游戏, 下面就列举出了这些命令：\n\n* `-assetServerUpdate <IP[:port] projectName username password [r <revision>]>`\t从`IP:port`上的`Asset Server`强制更新项目. `port`是可选的,如果不指定的话,会默认选择`10733`这个端口. 这个命令可与`-projectPath`参数一起使用, 这样可确保你不会更新错项目.如果不指定项目名称的话,那么会默认的对`Unity`上次打开的项目进行更新. 如果`-projectPath`路径下不存在项目,那么会自动创建一个.\n* `-batchmode`  在`batch`模式下运行`Unity`.这个命令我们强烈建议你与其他命令一起使用, 它会确保不会弹出Edtior. 当由脚本代码抛出异常或者`Asset Server`更新失败或者其他操作引起的异常,`Unity`会直接返回错误码`1`并退出. 需要注意的是,在`batch`模式下,`Unity`会在控制台输出一些基础日志. 还有当在`batch`模式下打开一个项目,那么`Editor`就不能再开打这个相同的项目.\n* `-buildLinux32Player <pathname>`\t构建一个32位的linux版应用.(例如 `-buildLinux32Player path/to/your/build`).\n* `-buildLinux64Player <pathname>`\t构建一个64位的linux版应用.(例如 `-buildLinux64Player path/to/your/build`).\n* `-buildLinuxUniversalPlayer <pathname>`\t构建一个32位和64位的linux混合版应用.(例如 `-buildLinuxUniversalPlayer path/to/your/build`).\n* `-buildOSXPlayer <pathname>`\t构建一个32位的MacOS版应用.(例如 `-buildOSXPlayer path/to/your/build.app`).\n* `-buildOSX64Player <pathname>`\t构建一个64位的MacOS版应用.(例如 `-buildOSX64Player path/to/your/build.app`).\n* `-buildOSXUniversalPlayer <pathname>`\t构建一个32位和64位的MacOs混合版应用.(例如 `-buildOSXUniversalPlayer path/to/your/build.app`).\n* `-buildTarget <name>`\t当项目被加载之前允许用户选择的构建目标：`win32, win64, osx, linux, linux64, ios, android, web, webstreamed, webgl, xbox360, xboxone, ps3, ps4, psp2, wsa, wp8, bb10, tizen, samsungtv`.\n* `-buildWebPlayer <pathname>`\t构建一个在web上运行的应用.(例如`-buildWebPlayer path/to/your/build`).\n* `-buildWebPlayerStreamed <pathname>`\tBuild a streamed WebPlayer (`-buildWebPlayerStreamed path/to/your/build`).\n* `-buildWindowsPlayer <pathname>`\t构建一个32位的Windows版应用.(例如  `-buildWindowsPlayer path/to/your/build.exe`).\n* `-buildWindows64Player <pathname>`\t构建一个64位的Windows版应用.(例如  `-buildWindows64Player path/to/your/build.exe`).\n* `-createProject <pathname>`\t在指定路径下(`pathname`)创建一个空项目.\n* `-executeMethod <ClassName.MethodName>`\t只要Unity启动完成并且项目打开(可能还需要等待asset server更新完成)就执行该静态方法. 该功能可用于持续集成, 运行测试用例, 执行构建任务, 准备一些数据等等. 如果你想让程序在命令行中返回一个错误码,那么你可以直接在Unity中直接抛出一个异常,这时命令行返回的错误码是1，或者你可以调用`EditorApplication.Exit`,这时会返回一个非0的状态码. 如果你想要向该方法传递参数,那么你可以直接将这些参数添加到命令行上,然后在程序中使用`System.Environment.GetCommandLineArgs`获得这些参数.To use -executeMethod, you need to place the enclosing script in an Editor folder. The method to be executed must be defined as static.\n* `-exportPackage <exportAssetPath1 exportAssetPath2 ExportAssetPath3 exportFileName>`\t在指定的路径下导出`package`. `exportAssetPath`是一个从Unity项目导出到的文件夹(路径相对于Unity项目的根路径), `exportFileName`是package的名字. 一般这个选项可以一次性地导出整个文件夹.这个命令一般需要和`-projectPath`参数一起使用.\n* `-force-d3d9 (Windows only)`\t设置editor使用`Direct3D 9`进行渲染. 这个是默认选项,一般不需要你去设置这个值.\n* `-force-d3d11 (Windows only)`\t设置editor使用`Direct3D 11`进行渲染.\n* `-force-opengl (Windows only)`\t设置editor使用`OpenGL`进行渲染. 即使`Direct3D`可用我们也可以说使用`OpenGL`进行渲染. 一般我们是在` Direct3D 9.0c`不可用的情况下才选择使用`openGL`\n* `-force-free`\t让edtior在`Unity license`下运行, 即使我们安装了`Unity Pro license`\n* `-importPackage <pathname>`\t导入指定的`package`. 如果不进行导入的话,会出现一个对话框.\n* `-logFile <pathname>`\t指定Editor或者`Windows/Linux/OSX`版本应用的日志输出路径.\n* `-silent-crashes`\t不显示crashe对话框.\n* `-projectPath <pathname>`\t在指定的路径下打开项目.\n* `-quit`\t当其他命令都执行完之后退出Unity. 注意这个会将错误日志隐藏掉，但是可以在`Editor.log`中找到它.\n* `-serial <serial>`\tActivates Unity with the specified serial key. It is recommended to pass “-batchmode -quit” arguments as well, in order to quit Unity when done, if using this for automated activation of Unity. Please allow a few seconds before license file is created, as Unity needs to communicate with the license server. Make sure that License file folder exists, and has appropriate permissions before running Unity with this argument. In case activation fails, see the Editor.log for info. This option is new in Unity 5.0.\n\n#### Example usage\n```\n// C# example\nusing UnityEditor;\nclass MyEditorScript\n{\n     static void PerformBuild ()\n     {\n         string[] scenes = { \"Assets/MyScene.unity\" };\n         BuildPipeline.BuildPlayer(scenes, ...);\n     }\n}\n\n\n// JavaScript example\nstatic void PerformBuild ()\n{\n    string[] scenes = { \"Assets/MyScene.unity\" };\n    BuildPipeline.BuildPlayer(scenes, ...);\n}\n```\n下面的命令在`batch`模式下运行Unity, 同时执行`MyEditorScript.MyMethod`完成, 当该方法执行完之后退出.\n* `Windows`: `C:\\program files\\Unity\\Editor\\Unity.exe -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n* `Mac OS`: `/Applications/Unity/Unity.app/Contents/MacOS/Unity -quit -batchmode -executeMethod MyEditorScript.MyMethod`\n\n下面的命令在`batch`执行Unity, 同时从`asset server`更新指定项目. 当全部的`asset`下载完之后, 指定的方法会被执行,当方法被完全执行之后,Unity会自动退出.\n```\n/Applications/Unity/Unity.app/Contents/MacOS/Unity -batchmode -projectPath ~/UnityProjects/AutobuildProject -assetServerUpdate 192.168.1.1 MyGame AutobuildUser l33tpa33 -executeMethod MyEditorScript.PerformBuild -quit\n```\n\n","slug":"unity命令行使用","published":1,"date":"2015-07-01T06:22:02.131Z","updated":"2015-06-30T01:21:34.059Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje97000574ufk1m3c9jz"},{"title":"辅助工具","_content":"#Bouncy Castle\n```\n在http://www.bouncycastle.org/latest_releases.html 下载 bcprov-jdk15on-151.jar 和 bcprov-ext-jdk15on-151.jar\n对于Bouncy Castle 提供的扩充算法支持,有俩种方案可选\n1. 配置方式,通过配置JRE环境,使其作为提供者提供相应的算法支持,在代码实现层面只需指定要扩展的算法名称\n\t1) 修改JDK\n\t修改java.security配置文件(jdk1.7.0_75\\jre\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jdk1.7.0_75\\jre\\lib\\ext\n\t2) 修改JRE\n\t修改java.security配置文件(jre7\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jre7\\lib\\ext\n\n2. 调用方式\n\t直接将bcprov-ext-jdk15on-151.jar 导入到项目工程文件\n\nBouncy Castle API\n1) JCE工具将其拓展包：仅包括org.bouncycastle.jce包. 这是对JCE框架的支持\n```\n\n##Base64\n\n###概念\n```\nBase64是一种基于64个字符的编码算法,根据RFC 2045的定义：Base64内容传送编码是一种以任意8位字节序列组合的描述形式, 这种\n形式不易被人直接识别.\n经过Base64编码后的数据会比原始数据略长,为原来的4/3,经Base64编码后的字符串的字符数是以4为单位的整数倍\n\nBase64算法有编码和解码操作可充当加密和解密操作,还有一张字符映射表充当了秘钥.\n由于字符映射表公开且Base64加密强度并不高,因此不能将其看作现代加密算法.\n但是如果将字符映射表调整,保密,改造后的Base64就具备了加密算法的意义\n\n而且Base64常作为密钥, 密文 和证书的一种通用存储编码格式\n```\n\n###实现原理\n```\n1) 将给定的字符串以字符为单位转换为对应的字符编码(如ASCII码)\n2) 将获得的字符编码转换为二进制码\n3) 对获得的二进制码做分组转换操作,每3个8位二进制码为1组,转换为每4个6位二进制码为1组(不足6位时低位补0)\n       这是一个分组变化的过程, 3个8位二进制码和4个6位二进制码的长度都是24位\n4) 对获得的4个6位二进制码补位,向6位二进制码添加2位 高位0,组成4个8位二进制码\n5) 将获得的4个8位二进制码转换为10进制码\n6) 将获得的十进制码转换为base64字符表中对应的字符\n```\n\n###举例\n```\n对A进行Base64编码\n字符\t\t\t\tA\nASCII码\t\t\t65\n二进制码\t\t\t01000001\n4-6二进制码\t\t010000\t\t010000\n4-8二进制码\t\t00010000\t00010000\n十进制\t\t\t16\t\t\t16\n字符表映射码\t\tQ\t\t\tQ\t\t\t=\t=\n\n字符A编码之后就变成了QQ==\n\nbase64 映射表\nV E\t\t\t  V E\t\t\tV E\t\t\t  V E\n0 A            17 R            34 i            51 z\n1 B            18 S            35 j            52 0\n2 C            19 T            36 k            53 1\n3 D            20 U            37 l            54 2\n4 E            21 V            38 m            55 3\n5 F            22 W            39 n            56 4\n6 G            23 X            40 o            57 5\n7 H            24 Y            41 p            58 6\n8 I            25 Z            42 q            59 7\n9 J            26 a            43 r            60 8\n10 K           27 b            44 s            61 9\n11 L           28 c            45 t            62 +\n12 M           29 d            46 u            63 /\n13 N           30 e            47 v\n14 O           31 f            48 w         (pad) =\n15 P           32 g            49 x\n16 Q           33 h            50 y\n```\n","source":"_posts/security/辅助工具.md","raw":"category: \n- security\ntitle: 辅助工具\n---\n#Bouncy Castle\n```\n在http://www.bouncycastle.org/latest_releases.html 下载 bcprov-jdk15on-151.jar 和 bcprov-ext-jdk15on-151.jar\n对于Bouncy Castle 提供的扩充算法支持,有俩种方案可选\n1. 配置方式,通过配置JRE环境,使其作为提供者提供相应的算法支持,在代码实现层面只需指定要扩展的算法名称\n\t1) 修改JDK\n\t修改java.security配置文件(jdk1.7.0_75\\jre\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jdk1.7.0_75\\jre\\lib\\ext\n\t2) 修改JRE\n\t修改java.security配置文件(jre7\\lib\\security)\n\t添加安全提供者 security.provider.11=org.bouncycastle.jce.provider.BouncyCastleProvider\n\t然后将bcprov-ext-jdk15on-151.jar 文件放入jre7\\lib\\ext\n\n2. 调用方式\n\t直接将bcprov-ext-jdk15on-151.jar 导入到项目工程文件\n\nBouncy Castle API\n1) JCE工具将其拓展包：仅包括org.bouncycastle.jce包. 这是对JCE框架的支持\n```\n\n##Base64\n\n###概念\n```\nBase64是一种基于64个字符的编码算法,根据RFC 2045的定义：Base64内容传送编码是一种以任意8位字节序列组合的描述形式, 这种\n形式不易被人直接识别.\n经过Base64编码后的数据会比原始数据略长,为原来的4/3,经Base64编码后的字符串的字符数是以4为单位的整数倍\n\nBase64算法有编码和解码操作可充当加密和解密操作,还有一张字符映射表充当了秘钥.\n由于字符映射表公开且Base64加密强度并不高,因此不能将其看作现代加密算法.\n但是如果将字符映射表调整,保密,改造后的Base64就具备了加密算法的意义\n\n而且Base64常作为密钥, 密文 和证书的一种通用存储编码格式\n```\n\n###实现原理\n```\n1) 将给定的字符串以字符为单位转换为对应的字符编码(如ASCII码)\n2) 将获得的字符编码转换为二进制码\n3) 对获得的二进制码做分组转换操作,每3个8位二进制码为1组,转换为每4个6位二进制码为1组(不足6位时低位补0)\n       这是一个分组变化的过程, 3个8位二进制码和4个6位二进制码的长度都是24位\n4) 对获得的4个6位二进制码补位,向6位二进制码添加2位 高位0,组成4个8位二进制码\n5) 将获得的4个8位二进制码转换为10进制码\n6) 将获得的十进制码转换为base64字符表中对应的字符\n```\n\n###举例\n```\n对A进行Base64编码\n字符\t\t\t\tA\nASCII码\t\t\t65\n二进制码\t\t\t01000001\n4-6二进制码\t\t010000\t\t010000\n4-8二进制码\t\t00010000\t00010000\n十进制\t\t\t16\t\t\t16\n字符表映射码\t\tQ\t\t\tQ\t\t\t=\t=\n\n字符A编码之后就变成了QQ==\n\nbase64 映射表\nV E\t\t\t  V E\t\t\tV E\t\t\t  V E\n0 A            17 R            34 i            51 z\n1 B            18 S            35 j            52 0\n2 C            19 T            36 k            53 1\n3 D            20 U            37 l            54 2\n4 E            21 V            38 m            55 3\n5 F            22 W            39 n            56 4\n6 G            23 X            40 o            57 5\n7 H            24 Y            41 p            58 6\n8 I            25 Z            42 q            59 7\n9 J            26 a            43 r            60 8\n10 K           27 b            44 s            61 9\n11 L           28 c            45 t            62 +\n12 M           29 d            46 u            63 /\n13 N           30 e            47 v\n14 O           31 f            48 w         (pad) =\n15 P           32 g            49 x\n16 Q           33 h            50 y\n```\n","slug":"security/辅助工具","published":1,"date":"2015-09-18T07:15:44.462Z","updated":"2015-09-18T07:13:30.047Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje99000674ufqfk4jhb4"},{"title":"对称加密","_content":"# 对称加密\n\n## 对称加密算法的由来\n\n  目前可知的可通过Java语言实现的对称加密算法大约20多种. java7仅提供部分算法实现,如DES,DESede,AES,Blowfish以及RC2和RC4算法.其他算法通过第三方加密软件包Bouncy Castle实现.\n  在对称加密算法中,DES最具有代表性,堪称典范; DESede是DES算法的变种; AES算法则作为DES算法的替代者;IDEA算法作为一种强加密算法,成为邮件加密软件PGP的核心算法之一.\n\n## 数据加密标准-DES\n  DES算法和DESede算法统称为DES系列算法. DESede算法是基于DES算法进行三重迭代,增加了算法的安全性.\n  1998年,实用化DES算法破译机的出现彻底宣告DES算法已不具备安全性. 1999年NIST版本新标准,规定\n\n","source":"_posts/security/对称加密.md","raw":"category: \n- security\ntitle: 对称加密\n---\n# 对称加密\n\n## 对称加密算法的由来\n\n  目前可知的可通过Java语言实现的对称加密算法大约20多种. java7仅提供部分算法实现,如DES,DESede,AES,Blowfish以及RC2和RC4算法.其他算法通过第三方加密软件包Bouncy Castle实现.\n  在对称加密算法中,DES最具有代表性,堪称典范; DESede是DES算法的变种; AES算法则作为DES算法的替代者;IDEA算法作为一种强加密算法,成为邮件加密软件PGP的核心算法之一.\n\n## 数据加密标准-DES\n  DES算法和DESede算法统称为DES系列算法. DESede算法是基于DES算法进行三重迭代,增加了算法的安全性.\n  1998年,实用化DES算法破译机的出现彻底宣告DES算法已不具备安全性. 1999年NIST版本新标准,规定\n\n","slug":"security/对称加密","published":1,"date":"2015-09-18T07:15:44.459Z","updated":"2015-09-18T07:12:53.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9d000974ufwdvc4wyv"},{"title":"密码学","_content":"# 加密\n## 对称加密\n### 分组密码\n#### 工作模式\n\n*. 电子密码本模式-ECB\n```\n\t优点：易于理解且简单易行;便于实现并行操作;没有误差产传递的问题\n\t缺点：不能隐藏明文模式,如果明文重复,则对于的密文也会重复,密文内容很容易被替换,重拍,删除,重放;\n\t\t对明文主动攻击的可能性较高\n\t用途：适用于加密密钥,随机数等短数据.例如安全地传递DES秘药,ECB是最合适的模式\n```\n*. 密文连接模式-CBC\n```\n\t优点：密文连接模式加密后的密文上下文关联,即使在明文中出现重复的信息也不会产生相同的密文;\n\t\t密文内容如果被替换,重拍,删除,重放或网络传输过程中发生错误,后续密文即被破坏,\n\t\t无法完成还原;对明文的主动攻击性较低\n\t缺点：不利于并行计算,目前没有已知的并行运算算法;误差传递,如果在加密过程中发生错误,则错误将被无限放大,\n\t\t导致加密失败;需要初始化向量\n\t用途：可加密任意长度的数据;适用于计算产生检测数据完整性的消息认证码Mac\n```\n*. 密文反馈模式-CFB\n```\n\t优点：隐藏了明文的模式,每一个分组的加密结果必受其前面所有分组内容的影响,即使出现许多次相同的明文,\n\t\t也均产生不同的密文;分组密码转化为流模式,可产生密钥流;可以及时加密传送小于分组的数据\n\t缺点：与CBC相似.不利于并行计算,目前没有已知的并行运算算法;存在误差传递,一个单元损坏影响多个单元;\n\t\t需要初始化向量.\n\t用途：因错误传播无界,可用于检查发现明文密文的篡改\n```\n*. 输出反馈模式-OFB\n```\n\t优点：隐藏了明文的模式;分组密码转化为流模式;无误差传递问题;可以及时加密传送小于分组的数据\n\t缺点：不利于并行计算;对明文的主动攻击是可能的,安全性较CFB差\n\t用途：适用于加密冗余性较大的数据,比如语音和图像数据\n```\n*. 计数器模式-CTR\n```\n\t优点：可并行计算;安全性至少与CBC模式一样好;加密与解密仅涉及密码算法的加密\n\t缺点：没有错误传播,因此不易确保数据完整性\n\t用途：适用于各种加密应用\n```\n### 流密码\n```\n\t同步流密码\n\t自同步流密码\n\t主要用于军事和外交\n\t常用算法 ： RC4,  SEAL\n```\n## 非对称密码\n\n非对称密码与对称密码体制相对,他们的主要区别在于：非对称密码体制的加密密钥和解密密钥不相同,分为俩个密钥,一个公开(公钥),一个保密(密钥).\n\n![非对称密码体制的保密通信模型]()\n\n在非对称密码体制中,公玥与私钥均可用于加密与解密操作,但它与对称密码体制有极大的不同. 公玥与私钥分属通信双方,一份消息的加密与解密需要公玥和私钥共同参与. 公玥加密需要私钥解密, 反之, 私钥加密需要公玥解密.\n\n![公玥加密-私钥解密的保密通信模型]()\n\n非对称密码的体制的主要优点是可以适应于开放性的使用环境, 秘钥管理相对简单, 可以方便安全地实现数字签名和验证. RSA是非对称密码体制的典范,它不仅仅可以完成一般的数据加密操作,同时也支持数字签名和验证. 除了数字签名非对称密码体制还支持数字信封等技术.\n\n非对称密码算法的安全性完全依赖于基于计算机复杂度上的难题,通常来自于数论.例如：\n* RSA来源于整数因子分解问题.\n* DSA-数字签名算法源于离散对数问题.\n* ECC-椭圆曲线加密算法源于离散对数问题.\n由于这些数学难题的实现多涉及底层模数乘法和指数运算,相比分组密码需要更多的计算机资源, 为了尼补这一缺陷, 非对称密码系统通常是复合式的:用高效率的对称密码算法进行加密解密处理; 用非对称密钥加密对称密码系统所使用的密钥, 通过这种复合方式增进效率.\n\n## 散列函数\n\n散列函数又称为哈希函数,消息摘要函数,单向函数或者杂凑函数. 与上述密码体制不同的是, 散列函数的主要作用不是完成数据加密解密操作, 它主要是用来验证数据的完整性. 散列值是一个短的随机字母和数字组成的字符串.\n\n![消息认证流程]()\n\n在上述认证流程中,信息收发双发在通信前已经商定了具体的散列算法,并且该算法是公开的.\n散列函数具有以下特性:\n* 消息的长度不受限制.\n* 对于给定的消息,其散列值的计算是很容易的.\n* 如果两个散列值不相同,则这两个散列值的原始输入消息也不相同,这个特性使得散列函数具有确定性的结果.\n* 散列函数的运算过程是不可逆的,这个特性称为函数的单向性.这也是单向函数命名的由来.\n* 对于一个已知的消息及其散列值,要找到另一个消息使其获得相同的散列值是不可能的,这个特性称为抗弱碰撞性.这被用来防止伪造.\n* 任意两个不同的消息的散列值一定不同,这个特性称为抗强碰撞性.\n\n\n## 数字签名\n\n通过散列函数可以确保数据内容的完整性,但这还远远不够. 此外,还需要确保数据来源的可认证性和数据发送行为的不可否任性. 完整性,可认证性和不可否认性是数字签名的主要特征. 数字签名针对以数字形式存储的消息进行处理, 产生一种带有操作者身份信息的编码.执行数字签名的实体称为签名者,签名过程中所使用的算法称为签名算法, 签名过程中生成的编码称为签名者对该消息的数字签名. 发送者通过网络连同数字签名一齐发送给接受者. 接受者在得到该消息及数字签名后,可以通过一个算法来验证签名的真伪以及识别相应的签名者. 这一过程称为验证过程, 其过程使用的算法称为验证算法. 数字签名离不开非对称密码体制, 签名算法受私钥控制,且由签名者保密. 验证算法受公玥控制,且对外公开.\nRSA算法既是最为常用的非对称加密算法,又是最为常用的签名算法.DSA算法是典型的数字签名算法,其本身属于非对称加密算法不具备数据加密与解密的功能.\n数字签名满足以下三个基本要求\n* 签名者任何时候都无法否认自己曾经签发的数字签名.\n* 信息接受者能够验证和确认收到的数字签名,但任何人无法伪造信息发送者的数字签名.\n* 当收发双发对数字签名的真伪产生争议时,可通过仲裁机构进行仲裁.\n\n![数字签名认证流程]()\n\n暂定甲方拥有私钥并且奖罚将公玥发布给乙方, 当甲方作为消息的发送方时, 甲方使用私钥对消息做签名处理,然后将加密的消息连同数字签名发送给乙方.乙方使用已获得的公玥对接收到的加密消息做解密处理,然后使用公玥及数字签名对原始消息做验证处理.\n```\n\t当然我们可以对消息先加密,然后对加密后的消息做签名处理,这样乙方获得消息后,先做验证处理,如果验证通过则对消息解密.\n\t反之,验证消息失败则抛弃消息.这样做显然可以提高系统的处理速度,但即便如此,仍建议大家先对消息做签名,再做加密处理.\n\t加密与签名都应该只针对原始消息做处理.加密是为了确保消息在传送过程中避免被破解,签名是为了确保消息的有效性.\n\t消息本身就可能是一个可执行文件,消息的接收方通过对消息的验证判断该文件是由有权执行,而这个文件本身是不需要加密的.\n```\n由于签名的不可伪造,甲方不能否认自己已经发送的消息,而乙方可验证消息的来源以及消息是否完整.数字签名可提供OSI参考模型5种安全服务中的3种：认证服务,抗否认性服务,数据完整性服务. 正因为如此,数字签名称为公玥基础设施以及许多网络安全机制的基础.\n```\n\t当乙方作为发送方,通过公玥将消息加密后发送给甲方时,由于算法,公玥公开,任何一个已获得公玥的窃密者都可以截获乙方\n\t发送的消息,替换成自己的消息发送给甲方,而甲方无法辨别消息来源是否是乙方.也就是说,上述的认证方式是单向的,属于\n\t单向认证. 如果拥有俩套公私玥,甲乙双方都对数据做签名及验证就可以避免这一问题. 没错这种认证方式是双向认证.以网银\n\t交易事宜的都是单向认证方式,无法验证使用者的身份. 而要求较高的网银交易都是双向认证方式,交易双方身份都可以得到验证.\n```\n\n## 公玥基础设施\n\n公钥基础设施（Public Key Infrastructure,PKI）是一个基于X.509的、用于创建、分配和撤回证书的模型.PKI能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系.换言之,PKI利用公钥密码技术构建基础设施,为网上电子商务、电子政务等应用提供安全服务.PKI技术是信息安全技术的核心,也是电子商务的关键和基础技术.如今大家所熟悉的网银交易系统就是PKI技术的具体体现.\n\nPKI由公钥密码技术、数字证书、证书认证中心和关于公钥的安全策略等基本成分共同组成,对密钥和证书进行管理.因此,PKI技术涉及对称加密算法、非对称加密算法、消息摘要算法和数字签名等密码学算法.\n\n我们目前所使用到的电子商务平台大部分都是基于PKI技术实现的.\n\n### 2.9.1 PKI的标准\n\nRSA公司定义了PKCS（Public Key Cryptography Standards,公钥加密标准）,并定义了许多PKI基础组件,如数字签名和证书请求格式；IETF（Internet Engineering Task Force,互联网工程任务组）和PKIWG（Public Key Infrastructure Working Group,PKI工作组）定义了一组具有可操作性的公钥基础设施协议PKIX（Public Key Infrastructure Using X.509,公钥基础设施X.509）.\n\n### PKCS共有15项标准:\n\n1. PKCS#1：RSA公钥算法加密和签名机制\n2. PKCS#3：DH密钥交换协议\n3. PKCS#5：PBE加密标准\n4. PKCS#6：公钥证书（X.509证书的扩展格式）标准语法\n5. PKCS#7：加密消息语法标准\n6. PKCS#8：私钥信息格式\n7. PKCS#9：选择属性格式\n8. PKCS#10：证书请求语法\n9. PKCS#11：密码装置标准接口\n10. PKCS#12：个人信息交换语法标准\n11. PKCS#13：椭圆曲线密码体制标准\n12. PKCS#14：伪随机数生成标准\n13. PKCS#15：密码令牌信息格式标准\n\n其中,PKCS#2和PKCS#4标准已被撤销,合并至PKCS#1中；较为常用的是PKCS#7、PKCS#10和PKCS#12.\n\n上述标准主要用于用户实体通过注册机构（RA）进行证书申请、用户证书更新等过程.当证书作废时,注册机构通过认证中心向目录服务器发布证书撤销列表.上述标准还用于扩展证书内容、数字签名、数字签名验证和定义数字信封格式等情况.在构建密钥填充方式时,考虑到不同的安全等级,也会选择不同PKCS标准.\n\nPKIX作为操作性标准涉及证书管理协议(Certificate Management Protocol,CMP)、安全多用途邮件扩展（S/MIME）和在线证书状态协议（Online Certificate Status Protocol,OCSP）等.\n\n##### PKI系统的组成\n\nPKI系统由认证中心（Certificate Authority,CA）、数字证书库（Certificate Repository,CR）、密钥备份及恢复系统、证书作废系统,以及应用程序接口（Application Programming Interface,API）五部分组成.其中,认证中心CA和数字证书库是PKI技术的核心.\n\n1. 认证中心\n\nCA是PKI的核心之一,是数字证书的申请及签发机构,且机构必须具有权威性,以确保公钥管理公开透明.\n\n### 认证中心的主要功能如下：\n* 证书发放\n* 证书更新\n* 证书撤销\n* 证书验证\n\n认证中心主要由注册服务器、注册机构（Registry Authority,RA）,和认证中心服务器三部分组成.\n\n2. 数字证书库\n\n数字证书库用于存储已签发的数字证书及公钥,包括LDAP（Light Direct Access Protocol,轻量级目录访问协议）目录服务器和普通数据库.用户可通过数字证书库进行证书查询,并可获得其他用户的证书及公钥.\n\n3. 密钥备份及恢复系统\n\n若用户丢失密钥则无法对数据解密,这将造成数据的丢失.为避免此类情况,PKI技术提供密钥备份及恢复功能.密钥的备份与恢复需要可信的权威机构来完成,这也是认证机构存在的必要条件.\n\n4. 证书作废系统\n\n为了确保证书的有效性,证书具有使用时效性,以确保证书所属环境的安全性.从另一个角度来讲,如果证书持有机构存在一定的安全性问题,即便证书未超过有效期,亦需要作废.PKI技术通过将证书列入作废证书列表（Certificate Revocation List,CRL）来完成证书作废操作.用户可以通过查询CRL来验证证书的有效性.\n\n5. 应用程序接口API\n\n为了便于用户能够方便地使用加密、签名验证等安全服务.PKI技术必须提供良好的应用程序接口,使得各式各样的应用,不同的系统架构都能以安全、一致、可信的方式与PKI进行交互,且能快速完成交互过程,以确保安全网络环境的完整性和易用性.\n\n### 数字证书\n\n数字证书是网络用户的身份标表,包含ID、公钥和颁发机构的数字签名等内容.其形式主要有X.509公钥证书、SPKI（Simple Public Key Infrastructure,简单PKI）证书、PGP（Pretty Good Privacy,译为“很好的私密”）证书和属性（Attribute）证书.其中,X.509证书最为常见.我们俗称的数字证书,通常指的是X.509公钥证书.\n\n目前,我们所使用的X.509证书通常由VeriSign、GeoTrust和Thawte三大国际权威认证机构签发.VeriSign由RSA控股,借助RSA成熟的安全技术提供了较为广泛的PKI产品,其产品活跃在电子商务平台中.当我们在淘宝或者亚马逊上购物时,总能看到熟悉的VeriSign字样,如图2-14所示.\n\n由于证书存在时效性,证书持有机构需要定期向认证机构申请证书签发.根据证书持有机构的证书使用范畴,认证机构会对不同的证书签发收取不同的费用.由此,证书持有机构需要每年向认证机构缴纳高额的年费.为了加强系统安全性,证书的密钥长度也会随着其费用递增.其中,价格最高的是商业网站的证书认证费用.上述的费用是认证机构得以生存的经济来源,同时也是电子商务平台等机构构建系统架构必须支付的安全成本之一.\n","source":"_posts/security/密码学.md","raw":"category: \n- security\ntitle: 密码学\n---\n# 加密\n## 对称加密\n### 分组密码\n#### 工作模式\n\n*. 电子密码本模式-ECB\n```\n\t优点：易于理解且简单易行;便于实现并行操作;没有误差产传递的问题\n\t缺点：不能隐藏明文模式,如果明文重复,则对于的密文也会重复,密文内容很容易被替换,重拍,删除,重放;\n\t\t对明文主动攻击的可能性较高\n\t用途：适用于加密密钥,随机数等短数据.例如安全地传递DES秘药,ECB是最合适的模式\n```\n*. 密文连接模式-CBC\n```\n\t优点：密文连接模式加密后的密文上下文关联,即使在明文中出现重复的信息也不会产生相同的密文;\n\t\t密文内容如果被替换,重拍,删除,重放或网络传输过程中发生错误,后续密文即被破坏,\n\t\t无法完成还原;对明文的主动攻击性较低\n\t缺点：不利于并行计算,目前没有已知的并行运算算法;误差传递,如果在加密过程中发生错误,则错误将被无限放大,\n\t\t导致加密失败;需要初始化向量\n\t用途：可加密任意长度的数据;适用于计算产生检测数据完整性的消息认证码Mac\n```\n*. 密文反馈模式-CFB\n```\n\t优点：隐藏了明文的模式,每一个分组的加密结果必受其前面所有分组内容的影响,即使出现许多次相同的明文,\n\t\t也均产生不同的密文;分组密码转化为流模式,可产生密钥流;可以及时加密传送小于分组的数据\n\t缺点：与CBC相似.不利于并行计算,目前没有已知的并行运算算法;存在误差传递,一个单元损坏影响多个单元;\n\t\t需要初始化向量.\n\t用途：因错误传播无界,可用于检查发现明文密文的篡改\n```\n*. 输出反馈模式-OFB\n```\n\t优点：隐藏了明文的模式;分组密码转化为流模式;无误差传递问题;可以及时加密传送小于分组的数据\n\t缺点：不利于并行计算;对明文的主动攻击是可能的,安全性较CFB差\n\t用途：适用于加密冗余性较大的数据,比如语音和图像数据\n```\n*. 计数器模式-CTR\n```\n\t优点：可并行计算;安全性至少与CBC模式一样好;加密与解密仅涉及密码算法的加密\n\t缺点：没有错误传播,因此不易确保数据完整性\n\t用途：适用于各种加密应用\n```\n### 流密码\n```\n\t同步流密码\n\t自同步流密码\n\t主要用于军事和外交\n\t常用算法 ： RC4,  SEAL\n```\n## 非对称密码\n\n非对称密码与对称密码体制相对,他们的主要区别在于：非对称密码体制的加密密钥和解密密钥不相同,分为俩个密钥,一个公开(公钥),一个保密(密钥).\n\n![非对称密码体制的保密通信模型]()\n\n在非对称密码体制中,公玥与私钥均可用于加密与解密操作,但它与对称密码体制有极大的不同. 公玥与私钥分属通信双方,一份消息的加密与解密需要公玥和私钥共同参与. 公玥加密需要私钥解密, 反之, 私钥加密需要公玥解密.\n\n![公玥加密-私钥解密的保密通信模型]()\n\n非对称密码的体制的主要优点是可以适应于开放性的使用环境, 秘钥管理相对简单, 可以方便安全地实现数字签名和验证. RSA是非对称密码体制的典范,它不仅仅可以完成一般的数据加密操作,同时也支持数字签名和验证. 除了数字签名非对称密码体制还支持数字信封等技术.\n\n非对称密码算法的安全性完全依赖于基于计算机复杂度上的难题,通常来自于数论.例如：\n* RSA来源于整数因子分解问题.\n* DSA-数字签名算法源于离散对数问题.\n* ECC-椭圆曲线加密算法源于离散对数问题.\n由于这些数学难题的实现多涉及底层模数乘法和指数运算,相比分组密码需要更多的计算机资源, 为了尼补这一缺陷, 非对称密码系统通常是复合式的:用高效率的对称密码算法进行加密解密处理; 用非对称密钥加密对称密码系统所使用的密钥, 通过这种复合方式增进效率.\n\n## 散列函数\n\n散列函数又称为哈希函数,消息摘要函数,单向函数或者杂凑函数. 与上述密码体制不同的是, 散列函数的主要作用不是完成数据加密解密操作, 它主要是用来验证数据的完整性. 散列值是一个短的随机字母和数字组成的字符串.\n\n![消息认证流程]()\n\n在上述认证流程中,信息收发双发在通信前已经商定了具体的散列算法,并且该算法是公开的.\n散列函数具有以下特性:\n* 消息的长度不受限制.\n* 对于给定的消息,其散列值的计算是很容易的.\n* 如果两个散列值不相同,则这两个散列值的原始输入消息也不相同,这个特性使得散列函数具有确定性的结果.\n* 散列函数的运算过程是不可逆的,这个特性称为函数的单向性.这也是单向函数命名的由来.\n* 对于一个已知的消息及其散列值,要找到另一个消息使其获得相同的散列值是不可能的,这个特性称为抗弱碰撞性.这被用来防止伪造.\n* 任意两个不同的消息的散列值一定不同,这个特性称为抗强碰撞性.\n\n\n## 数字签名\n\n通过散列函数可以确保数据内容的完整性,但这还远远不够. 此外,还需要确保数据来源的可认证性和数据发送行为的不可否任性. 完整性,可认证性和不可否认性是数字签名的主要特征. 数字签名针对以数字形式存储的消息进行处理, 产生一种带有操作者身份信息的编码.执行数字签名的实体称为签名者,签名过程中所使用的算法称为签名算法, 签名过程中生成的编码称为签名者对该消息的数字签名. 发送者通过网络连同数字签名一齐发送给接受者. 接受者在得到该消息及数字签名后,可以通过一个算法来验证签名的真伪以及识别相应的签名者. 这一过程称为验证过程, 其过程使用的算法称为验证算法. 数字签名离不开非对称密码体制, 签名算法受私钥控制,且由签名者保密. 验证算法受公玥控制,且对外公开.\nRSA算法既是最为常用的非对称加密算法,又是最为常用的签名算法.DSA算法是典型的数字签名算法,其本身属于非对称加密算法不具备数据加密与解密的功能.\n数字签名满足以下三个基本要求\n* 签名者任何时候都无法否认自己曾经签发的数字签名.\n* 信息接受者能够验证和确认收到的数字签名,但任何人无法伪造信息发送者的数字签名.\n* 当收发双发对数字签名的真伪产生争议时,可通过仲裁机构进行仲裁.\n\n![数字签名认证流程]()\n\n暂定甲方拥有私钥并且奖罚将公玥发布给乙方, 当甲方作为消息的发送方时, 甲方使用私钥对消息做签名处理,然后将加密的消息连同数字签名发送给乙方.乙方使用已获得的公玥对接收到的加密消息做解密处理,然后使用公玥及数字签名对原始消息做验证处理.\n```\n\t当然我们可以对消息先加密,然后对加密后的消息做签名处理,这样乙方获得消息后,先做验证处理,如果验证通过则对消息解密.\n\t反之,验证消息失败则抛弃消息.这样做显然可以提高系统的处理速度,但即便如此,仍建议大家先对消息做签名,再做加密处理.\n\t加密与签名都应该只针对原始消息做处理.加密是为了确保消息在传送过程中避免被破解,签名是为了确保消息的有效性.\n\t消息本身就可能是一个可执行文件,消息的接收方通过对消息的验证判断该文件是由有权执行,而这个文件本身是不需要加密的.\n```\n由于签名的不可伪造,甲方不能否认自己已经发送的消息,而乙方可验证消息的来源以及消息是否完整.数字签名可提供OSI参考模型5种安全服务中的3种：认证服务,抗否认性服务,数据完整性服务. 正因为如此,数字签名称为公玥基础设施以及许多网络安全机制的基础.\n```\n\t当乙方作为发送方,通过公玥将消息加密后发送给甲方时,由于算法,公玥公开,任何一个已获得公玥的窃密者都可以截获乙方\n\t发送的消息,替换成自己的消息发送给甲方,而甲方无法辨别消息来源是否是乙方.也就是说,上述的认证方式是单向的,属于\n\t单向认证. 如果拥有俩套公私玥,甲乙双方都对数据做签名及验证就可以避免这一问题. 没错这种认证方式是双向认证.以网银\n\t交易事宜的都是单向认证方式,无法验证使用者的身份. 而要求较高的网银交易都是双向认证方式,交易双方身份都可以得到验证.\n```\n\n## 公玥基础设施\n\n公钥基础设施（Public Key Infrastructure,PKI）是一个基于X.509的、用于创建、分配和撤回证书的模型.PKI能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系.换言之,PKI利用公钥密码技术构建基础设施,为网上电子商务、电子政务等应用提供安全服务.PKI技术是信息安全技术的核心,也是电子商务的关键和基础技术.如今大家所熟悉的网银交易系统就是PKI技术的具体体现.\n\nPKI由公钥密码技术、数字证书、证书认证中心和关于公钥的安全策略等基本成分共同组成,对密钥和证书进行管理.因此,PKI技术涉及对称加密算法、非对称加密算法、消息摘要算法和数字签名等密码学算法.\n\n我们目前所使用到的电子商务平台大部分都是基于PKI技术实现的.\n\n### 2.9.1 PKI的标准\n\nRSA公司定义了PKCS（Public Key Cryptography Standards,公钥加密标准）,并定义了许多PKI基础组件,如数字签名和证书请求格式；IETF（Internet Engineering Task Force,互联网工程任务组）和PKIWG（Public Key Infrastructure Working Group,PKI工作组）定义了一组具有可操作性的公钥基础设施协议PKIX（Public Key Infrastructure Using X.509,公钥基础设施X.509）.\n\n### PKCS共有15项标准:\n\n1. PKCS#1：RSA公钥算法加密和签名机制\n2. PKCS#3：DH密钥交换协议\n3. PKCS#5：PBE加密标准\n4. PKCS#6：公钥证书（X.509证书的扩展格式）标准语法\n5. PKCS#7：加密消息语法标准\n6. PKCS#8：私钥信息格式\n7. PKCS#9：选择属性格式\n8. PKCS#10：证书请求语法\n9. PKCS#11：密码装置标准接口\n10. PKCS#12：个人信息交换语法标准\n11. PKCS#13：椭圆曲线密码体制标准\n12. PKCS#14：伪随机数生成标准\n13. PKCS#15：密码令牌信息格式标准\n\n其中,PKCS#2和PKCS#4标准已被撤销,合并至PKCS#1中；较为常用的是PKCS#7、PKCS#10和PKCS#12.\n\n上述标准主要用于用户实体通过注册机构（RA）进行证书申请、用户证书更新等过程.当证书作废时,注册机构通过认证中心向目录服务器发布证书撤销列表.上述标准还用于扩展证书内容、数字签名、数字签名验证和定义数字信封格式等情况.在构建密钥填充方式时,考虑到不同的安全等级,也会选择不同PKCS标准.\n\nPKIX作为操作性标准涉及证书管理协议(Certificate Management Protocol,CMP)、安全多用途邮件扩展（S/MIME）和在线证书状态协议（Online Certificate Status Protocol,OCSP）等.\n\n##### PKI系统的组成\n\nPKI系统由认证中心（Certificate Authority,CA）、数字证书库（Certificate Repository,CR）、密钥备份及恢复系统、证书作废系统,以及应用程序接口（Application Programming Interface,API）五部分组成.其中,认证中心CA和数字证书库是PKI技术的核心.\n\n1. 认证中心\n\nCA是PKI的核心之一,是数字证书的申请及签发机构,且机构必须具有权威性,以确保公钥管理公开透明.\n\n### 认证中心的主要功能如下：\n* 证书发放\n* 证书更新\n* 证书撤销\n* 证书验证\n\n认证中心主要由注册服务器、注册机构（Registry Authority,RA）,和认证中心服务器三部分组成.\n\n2. 数字证书库\n\n数字证书库用于存储已签发的数字证书及公钥,包括LDAP（Light Direct Access Protocol,轻量级目录访问协议）目录服务器和普通数据库.用户可通过数字证书库进行证书查询,并可获得其他用户的证书及公钥.\n\n3. 密钥备份及恢复系统\n\n若用户丢失密钥则无法对数据解密,这将造成数据的丢失.为避免此类情况,PKI技术提供密钥备份及恢复功能.密钥的备份与恢复需要可信的权威机构来完成,这也是认证机构存在的必要条件.\n\n4. 证书作废系统\n\n为了确保证书的有效性,证书具有使用时效性,以确保证书所属环境的安全性.从另一个角度来讲,如果证书持有机构存在一定的安全性问题,即便证书未超过有效期,亦需要作废.PKI技术通过将证书列入作废证书列表（Certificate Revocation List,CRL）来完成证书作废操作.用户可以通过查询CRL来验证证书的有效性.\n\n5. 应用程序接口API\n\n为了便于用户能够方便地使用加密、签名验证等安全服务.PKI技术必须提供良好的应用程序接口,使得各式各样的应用,不同的系统架构都能以安全、一致、可信的方式与PKI进行交互,且能快速完成交互过程,以确保安全网络环境的完整性和易用性.\n\n### 数字证书\n\n数字证书是网络用户的身份标表,包含ID、公钥和颁发机构的数字签名等内容.其形式主要有X.509公钥证书、SPKI（Simple Public Key Infrastructure,简单PKI）证书、PGP（Pretty Good Privacy,译为“很好的私密”）证书和属性（Attribute）证书.其中,X.509证书最为常见.我们俗称的数字证书,通常指的是X.509公钥证书.\n\n目前,我们所使用的X.509证书通常由VeriSign、GeoTrust和Thawte三大国际权威认证机构签发.VeriSign由RSA控股,借助RSA成熟的安全技术提供了较为广泛的PKI产品,其产品活跃在电子商务平台中.当我们在淘宝或者亚马逊上购物时,总能看到熟悉的VeriSign字样,如图2-14所示.\n\n由于证书存在时效性,证书持有机构需要定期向认证机构申请证书签发.根据证书持有机构的证书使用范畴,认证机构会对不同的证书签发收取不同的费用.由此,证书持有机构需要每年向认证机构缴纳高额的年费.为了加强系统安全性,证书的密钥长度也会随着其费用递增.其中,价格最高的是商业网站的证书认证费用.上述的费用是认证机构得以生存的经济来源,同时也是电子商务平台等机构构建系统架构必须支付的安全成本之一.\n","slug":"security/密码学","published":1,"date":"2015-09-18T07:15:44.457Z","updated":"2015-09-18T07:13:35.235Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9f000b74ufkvfmuhnb"},{"title":"加密算法","_content":"#java7支持的算法\n## 消息摘要算法\n\n## MD系列\n* MD2             128位\n* MD5             128位\n\n## SHA系列\n* SHA-1           160位\n* SHA-256         256位\n* SHA-384         384位\n* SHA-512         512位\n\n## Hmac系列\n* HmacMD5        128位\n* HmacSHA1       160位\n* HmacSHA256     256位\n* HmacSHA384     384位\n* HmacSHA512     512位\n\n\n##  对称加密算法\n\n* DES\n```\n\t56(默认值)\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* DESede\n```\n\t112,168(默认值)\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* AES\n```\n\t128(默认值),192,256\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* Blowfish\n```\n\t32z至448(8的倍数,默认值128)\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* RC2\n```\n\t40至1024(8的倍数,默认值128)\n\tECB\n\tNoPadding\n```\n* RC4\n```\n\t40至1024(8的倍数,默认值128)\n\tECB\n\tNoPadding\n```\n## 对称加密算法-PBE\n* PBEWithMD5AndDES\n```\n\t56\n\tCBC\n\tPKCS5Padding\n```\n* PBEWithMD5AndTripleDES\n```\n\t112,168(默认值)\n\tCBC\n\tPKCS5Padding\n```\n* PBEWithSHA1AndRC2_40\n```\n\t112,168(默认值)\n\tCBC\n\tPKCS5Padding\n```\n* PBEWithSHA1AndDESede\n```\n\t40至1024(8的整数倍,默认值128)\n\tCBC\n\tPKCS5Padding\n```\n## 非对称加密算法\n* DH\n```\n\t512-1024(64的整数倍)\n```\n* RSA\n```\n\t512-65536(64的整数倍)\n\tECB\n```\n* ECDH\n```\n\t112-571\n```\n\n","source":"_posts/security/加密算法.md","raw":"category: \n- security\ntitle: 加密算法\n---\n#java7支持的算法\n## 消息摘要算法\n\n## MD系列\n* MD2             128位\n* MD5             128位\n\n## SHA系列\n* SHA-1           160位\n* SHA-256         256位\n* SHA-384         384位\n* SHA-512         512位\n\n## Hmac系列\n* HmacMD5        128位\n* HmacSHA1       160位\n* HmacSHA256     256位\n* HmacSHA384     384位\n* HmacSHA512     512位\n\n\n##  对称加密算法\n\n* DES\n```\n\t56(默认值)\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* DESede\n```\n\t112,168(默认值)\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* AES\n```\n\t128(默认值),192,256\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* Blowfish\n```\n\t32z至448(8的倍数,默认值128)\n\tECB,CBC,PCBC,CTR,CTS,CFB,CFB8至CFB128,OFB,OFB8至OFB128\n\tNoPadding,PKCS5Padding,ISO10126Padding\n```\n* RC2\n```\n\t40至1024(8的倍数,默认值128)\n\tECB\n\tNoPadding\n```\n* RC4\n```\n\t40至1024(8的倍数,默认值128)\n\tECB\n\tNoPadding\n```\n## 对称加密算法-PBE\n* PBEWithMD5AndDES\n```\n\t56\n\tCBC\n\tPKCS5Padding\n```\n* PBEWithMD5AndTripleDES\n```\n\t112,168(默认值)\n\tCBC\n\tPKCS5Padding\n```\n* PBEWithSHA1AndRC2_40\n```\n\t112,168(默认值)\n\tCBC\n\tPKCS5Padding\n```\n* PBEWithSHA1AndDESede\n```\n\t40至1024(8的整数倍,默认值128)\n\tCBC\n\tPKCS5Padding\n```\n## 非对称加密算法\n* DH\n```\n\t512-1024(64的整数倍)\n```\n* RSA\n```\n\t512-65536(64的整数倍)\n\tECB\n```\n* ECDH\n```\n\t112-571\n```\n\n","slug":"security/加密算法","published":1,"date":"2015-09-18T07:15:44.454Z","updated":"2015-09-18T07:13:22.401Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9h000d74uf2rwuniga"},{"title":"javax_net_ssl","_content":"## HttpsURLConnection\n```java\n\t\tURL url = new URL(\"www.baidu.com\");\n\t\t\tconn = (HttpsURLConnection) url.openConnection();\n\t\t\t// 打开输入模式\n\t\t\tconn.setDoInput(true);\n\t\t\t// 打开输出模式\n\t\t\tconn.setDoOutput(true);\t\t\t// 设置当此实例为安全Https URL连接创建套接字时使用的SSLSocketFactory\n\t\t\tconn.setSSLSocketFactory(get());\t\t\t// 获得握手期间的相关的证书链\n\t\t\t// 返回握手期间发送给服务器的证书\n\t\t\tconn.getLocalCertificates();\n\t\t\t// 返回服务器的证书链，它是作为定义会话的一部分而建立的\n\t\t\tconn.getServerCertificates();\t\t\t// 获取握手期间发送到服务器的主体\n\t\t\tconn.getLocalPrincipal();\n\t\t\t// 获取服务器的主体，它是作为定义会话一部分而建立的\n\t\t\tconn.getPeerPrincipal();\t\t\t// 获取在此链接之上的密码套件\n\t\t\tconn.getCipherSuite();\t\t\t// ...\n\t\t\n\t\t// 构建SSLSocketFactory\n\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t}\t\tKeyManagerFactory keyManagerFactory = null;\n\t\tTrustManagerFactory trustManagerFactory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tkeyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\");\n\t\t\ttrustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\t\tkeyManagerFactory.init(keyStore, \"password\".toCharArray());\n\t\t\ttrustManagerFactory.init(keyStore);\n\t\t}\t\tSSLContext ctx = null;\n\t\t\tctx = SSLContext.getInstance(\"SSL\");\n\t\t\t// 初始化上下文\n\t\t\tctx.init(keyManagerFactory.getKeyManagers(),\n\t\t\t\t\ttrustManagerFactory.getTrustManagers(), null);\n\t\t}\t\treturn ctx.getSocketFactory();\n\t}\n}\n```\nHttpsURLConnection 拓展了URLConnection, 支持各种特定于Https的功能\n## KeyManagerFactory\n```java\n\tpublic static void main(String[] args) {\n\t\tSystem.out.println(\"KeyManagerFactory 默认算法：\"\n\t\t\t\t+ KeyManagerFactory.getDefaultAlgorithm());\t\tKeyManagerFactory fatory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tfatory = KeyManagerFactory.getInstance(\"SunX509\");\t\t\tfor (KeyManager keyManager : fatory.getKeyManagers()) {\n\t\t\t\tSystem.out.println(keyManager.toString());\n\t\t\t}\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t\t// 使用秘钥内容源初始化此KeyManagerFactory 对象, 另外还可使用特定于提供者的秘钥内容源初始化此对象\n\t\t\tfatory.init(keyStore, \"password\".toCharArray());\t\t}\t\t// 另外一种设置秘钥库的方式\n\t\tSystem.setProperty(\"javax.net.ssl.keyStore\", \"D:\\\\server.keystore\");\n\t\tSystem.setProperty(\"javax.net.ssl.keyStorePassword\", \"123456\");\n\t}\n}\n```\n用来管理秘钥,设定秘钥库. 此类充当基于秘钥内容源的秘钥管理器的工厂.每个秘钥管理器管理特定类型的,由套接字所使用的秘钥内容\n## SSLContext\n```java\n\tpublic static void main(String[] args) {\n\t\t// 构建SSLSocketFactory\n\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t}\t\tKeyManagerFactory keyManagerFactory = null;\n\t\tTrustManagerFactory trustManagerFactory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tkeyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\");\n\t\t\ttrustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\t\tkeyManagerFactory.init(keyStore, \"password\".toCharArray());\n\t\t\ttrustManagerFactory.init(keyStore);\n\t\t}\t\t\tSSLContext ctx = SSLContext.getInstance(\"SSL\");\n\t\t\t// 初始化上下文\n\t\t\tctx.init(keyManagerFactory.getKeyManagers(),\n\t\t\t\t\ttrustManagerFactory.getTrustManagers(), null);\n\t\t\t// 返回此上下文的SSLSocketFactory 对象\n\t\t\tSSLSocketFactory socketFactory = ctx.getSocketFactory();\n\t\t\t// 返回此上下文的 ServerSocketFactory 对象\n\t\t\tSSLServerSocketFactory serverSocketFactory = ctx\n\t\t\t\t\t.getServerSocketFactory();\n\t\t\t// 返回服务器会话上下文，它表示可提供给服务器端SSL套接字握手阶段使用的SSL会话集\n\t\t\tctx.getServerSessionContext();\n\t\t\t// 返回客户端会话上下文，它表示可提供给客户端SSL套接字握手阶段使用的SSL会话集\n\t\t\tctx.getClientSessionContext();\n\t\t\t// 使用上下文创建新的SSLEngine(另一个create方法还可指定主机和端口)\n\t\t\tctx.createSSLEngine();\n\t\t}\n\t}\n}\n```\n表示安全套接字上下文,安全套接字协议的实现,它充当于安全套接字工厂或者SSLEngine的工厂\n用可选的一组秘钥和信任管理器及安全随机字节初始化此类\n## SSLServerSocket\n```java\n {@link SSLServerSocket} SSLServerSocket 是专用于服务器端的SSLSocket, 是ServerSocket的子类\n \n \n @author wangming\n\n/\n\tpublic static void main(String[] args) {\t\t// 构建SSLSocketFactory\n\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t}\t\tKeyManagerFactory keyManagerFactory = null;\n\t\tTrustManagerFactory trustManagerFactory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tkeyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\");\n\t\t\ttrustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\t\tkeyManagerFactory.init(keyStore, \"password\".toCharArray());\n\t\t\ttrustManagerFactory.init(keyStore);\n\t\t}\t\tSSLContext ctx = null;\n\t\t\tctx = SSLContext.getInstance(\"SSL\");\n\t\t\t// 初始化上下文\n\t\t\tctx.init(keyManagerFactory.getKeyManagers(),\n\t\t\t\t\ttrustManagerFactory.getTrustManagers(), null);\n\t\t}\t\tServerSocketFactory factory = ctx.getServerSocketFactory();\n\t\t\tSSLServerSocket serverSocket = (SSLServerSocket) factory\n\t\t\t\t\t.createServerSocket(8080);\n\t\t\tserverSocket.accept();\n\t\t} catch (IOException e) {\n\t\t}\n\t}\n}\n```\n   SSLServerSocket\n## SSLServerSocketFactory\n```java\n {@link SSLServerSocketFactory} 与SSLSocketFactory 操作几乎一致\n \n @author wangming\n\n/\n\tpublic static void main(String[] args) {\n\t\tSSLServerSocketFactory factory = (SSLServerSocketFactory) SSLServerSocketFactory\n\t\t\t\t.getDefault();\n\t\t\tfactory.createServerSocket(8080);\n\t\t} catch (IOException e) {\n\t\t}\n\t}\n}\n```\n   SSLServerSocketFactory\n## SSLSession.mdSSLSession 接口用于保持SSL协议网络交互会话状态. 用来描述俩个实体之间的会话关系\n在SSL的会话中,可以获得加密套件(CipherSuite),数字证书等\nCipherSuite 明确给出了加密参数, 具体包括：协议,秘钥交换算法,加密算法,工作模式和消息摘要算法\n如 TLS_RSA_TITH_AES_256_CBC_SHA 就是一个完成加密套件信息, 它表示：\n使用TLS协议,迷药交换算法为RSA,对称加密算法为AES(长度256),使用CBC模式,并使用SHA消息摘要算法\n## SSLSocket\n```java\n\tpublic Certificate[] get() {\n\t\t// 输出当前网络的debug日志\n\t\t// 将在控制台获得当前网络链接操作过程中使用到的数字证书信息和经过经过加密后的网络传输数据\n\t\tSystem.setProperty(\"javax.net.debug\", \"all\");\t\tSSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory\n\t\t\t\t.getDefault();\t\tSSLSession session = null;\n\t\t\tSSLSocket sslSocket = (SSLSocket) factory.createSocket(\"localhost\",\n\t\t\t\t\t8080);\t\t\t// 完成了加密套件和协议配置后，就可以开始握手协议，建立加密套接字进行加密通信了。\n\t\t\t// 在当前链接上建立SSL握手\n\t\t\tsslSocket.startHandshake();\t\t\t// 获得当前会话的SSLSession实例\n\t\t\tsession = sslSocket.getSession();\t\t\tsslSocket.close();\t\t\treturn session.getPeerCertificates();\n\t\t}\t\treturn null;\n\t}\n}\n```\nSSLSocket是基于SSL协议的Socket,用于设置加密套件,处理握手结束事件,并管理SSLSession\n目前Java环境中支持的协议有：SSLLv2Hello,SSLv3,TLSv1,TlSv1.1, TLSv1.2\n通常默认的是SSLv3和TLSv1.1\nsetEnabledProtocols(protocols);  通过该方法设置SSL链接可用协议\ngetSupportedCipherSuites()\t\t获得可支持的加密套件\nsetEnabledCipherSuites(suites)\t为当前SSL链接设置可用的加密套件\ngetEnabledCipherSuites()\t\t\t获得当前SSL链接可用的加密套件\n有时候需要与远程服务器建立基于SSLSocket的链接. 远程服务仅通过SSLSocket传递数字证书.\n这时候,就不能通过HttpsURLConnection来获得数字证书了,本方法就是通过SSLSocket来获得SSLSession\n并最终获得数字证书\n## SSLSocketFactory\n```java\n {@link SSLSocketFactory}\n 通过SSLSocketFactory 可创建SSLSocket, 并获得相应的加密套件\n \n @author wangming\n\n/\n\tpublic static void main(String[] args) {\n\t\tSSLSocketFactory sslFactory = (SSLSocketFactory)SSLSocketFactory.getDefault();\n\t\t\n\t\t\t// 创建SSLSocket实例\n\t\t\tSocket socket = sslFactory.createSocket(\"localhost\", 8080);\n\t\t\t\n\t\t\tSSLSocket sslSocket = (SSLSocket)socket;\n\t\t\t\n\t\t\t//获得默认加密套件\n\t\t\tsslFactory.getDefaultCipherSuites();\n\t\t\t\n\t\t\t// 获得当前SSL链接可支持的加密套件\n\t\t\tsslFactory.getSupportedCipherSuites();\n\t\t}\n\t}\n}\n```\n   SSLSocketFactory\n## TrustManagerFactory\n```java\n\tpublic static void main(String[] args) {\n\t\t\tTrustManagerFactory factory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t\t\n\t\t\t//  加载秘钥库文件\n\t\t\ttry(FileInputStream in = new FileInputStream(\"\")) {\n\t\t\t\tKeyStore ks = KeyStore.getInstance(\"JKS\");\n\t\t\t\tks.load(in, \"password\".toCharArray());\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t// 用证书授权源和相关的信任材料初始化此工厂\n\t\t\t\tfactory.init(ks);\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t// 另外一种设置信任库的方式\n\t\tSystem.setProperty(\"javax.net.ssl.trustStore\", \"D:\\\\server.keystore\");\n\t\tSystem.setProperty(\"javax.net.ssl.trustStorePassword\", \"123456\");\n\t}\n}\n```\n 管理信任材料的管理工厂,设定信任库\n 每个信任管理器管理特定类型的由安全套接字使用的信任材料\n","source":"_posts/security/javax_net_ssl.md","raw":"category: \n- security\ntitle: javax_net_ssl\n---\n## HttpsURLConnection\n```java\n\t\tURL url = new URL(\"www.baidu.com\");\n\t\t\tconn = (HttpsURLConnection) url.openConnection();\n\t\t\t// 打开输入模式\n\t\t\tconn.setDoInput(true);\n\t\t\t// 打开输出模式\n\t\t\tconn.setDoOutput(true);\t\t\t// 设置当此实例为安全Https URL连接创建套接字时使用的SSLSocketFactory\n\t\t\tconn.setSSLSocketFactory(get());\t\t\t// 获得握手期间的相关的证书链\n\t\t\t// 返回握手期间发送给服务器的证书\n\t\t\tconn.getLocalCertificates();\n\t\t\t// 返回服务器的证书链，它是作为定义会话的一部分而建立的\n\t\t\tconn.getServerCertificates();\t\t\t// 获取握手期间发送到服务器的主体\n\t\t\tconn.getLocalPrincipal();\n\t\t\t// 获取服务器的主体，它是作为定义会话一部分而建立的\n\t\t\tconn.getPeerPrincipal();\t\t\t// 获取在此链接之上的密码套件\n\t\t\tconn.getCipherSuite();\t\t\t// ...\n\t\t\n\t\t// 构建SSLSocketFactory\n\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t}\t\tKeyManagerFactory keyManagerFactory = null;\n\t\tTrustManagerFactory trustManagerFactory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tkeyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\");\n\t\t\ttrustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\t\tkeyManagerFactory.init(keyStore, \"password\".toCharArray());\n\t\t\ttrustManagerFactory.init(keyStore);\n\t\t}\t\tSSLContext ctx = null;\n\t\t\tctx = SSLContext.getInstance(\"SSL\");\n\t\t\t// 初始化上下文\n\t\t\tctx.init(keyManagerFactory.getKeyManagers(),\n\t\t\t\t\ttrustManagerFactory.getTrustManagers(), null);\n\t\t}\t\treturn ctx.getSocketFactory();\n\t}\n}\n```\nHttpsURLConnection 拓展了URLConnection, 支持各种特定于Https的功能\n## KeyManagerFactory\n```java\n\tpublic static void main(String[] args) {\n\t\tSystem.out.println(\"KeyManagerFactory 默认算法：\"\n\t\t\t\t+ KeyManagerFactory.getDefaultAlgorithm());\t\tKeyManagerFactory fatory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tfatory = KeyManagerFactory.getInstance(\"SunX509\");\t\t\tfor (KeyManager keyManager : fatory.getKeyManagers()) {\n\t\t\t\tSystem.out.println(keyManager.toString());\n\t\t\t}\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t\t// 使用秘钥内容源初始化此KeyManagerFactory 对象, 另外还可使用特定于提供者的秘钥内容源初始化此对象\n\t\t\tfatory.init(keyStore, \"password\".toCharArray());\t\t}\t\t// 另外一种设置秘钥库的方式\n\t\tSystem.setProperty(\"javax.net.ssl.keyStore\", \"D:\\\\server.keystore\");\n\t\tSystem.setProperty(\"javax.net.ssl.keyStorePassword\", \"123456\");\n\t}\n}\n```\n用来管理秘钥,设定秘钥库. 此类充当基于秘钥内容源的秘钥管理器的工厂.每个秘钥管理器管理特定类型的,由套接字所使用的秘钥内容\n## SSLContext\n```java\n\tpublic static void main(String[] args) {\n\t\t// 构建SSLSocketFactory\n\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t}\t\tKeyManagerFactory keyManagerFactory = null;\n\t\tTrustManagerFactory trustManagerFactory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tkeyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\");\n\t\t\ttrustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\t\tkeyManagerFactory.init(keyStore, \"password\".toCharArray());\n\t\t\ttrustManagerFactory.init(keyStore);\n\t\t}\t\t\tSSLContext ctx = SSLContext.getInstance(\"SSL\");\n\t\t\t// 初始化上下文\n\t\t\tctx.init(keyManagerFactory.getKeyManagers(),\n\t\t\t\t\ttrustManagerFactory.getTrustManagers(), null);\n\t\t\t// 返回此上下文的SSLSocketFactory 对象\n\t\t\tSSLSocketFactory socketFactory = ctx.getSocketFactory();\n\t\t\t// 返回此上下文的 ServerSocketFactory 对象\n\t\t\tSSLServerSocketFactory serverSocketFactory = ctx\n\t\t\t\t\t.getServerSocketFactory();\n\t\t\t// 返回服务器会话上下文，它表示可提供给服务器端SSL套接字握手阶段使用的SSL会话集\n\t\t\tctx.getServerSessionContext();\n\t\t\t// 返回客户端会话上下文，它表示可提供给客户端SSL套接字握手阶段使用的SSL会话集\n\t\t\tctx.getClientSessionContext();\n\t\t\t// 使用上下文创建新的SSLEngine(另一个create方法还可指定主机和端口)\n\t\t\tctx.createSSLEngine();\n\t\t}\n\t}\n}\n```\n表示安全套接字上下文,安全套接字协议的实现,它充当于安全套接字工厂或者SSLEngine的工厂\n用可选的一组秘钥和信任管理器及安全随机字节初始化此类\n## SSLServerSocket\n```java\n {@link SSLServerSocket} SSLServerSocket 是专用于服务器端的SSLSocket, 是ServerSocket的子类\n \n \n @author wangming\n\n/\n\tpublic static void main(String[] args) {\t\t// 构建SSLSocketFactory\n\t\tKeyStore keyStore = null;\n\t\t\tkeyStore = KeyStore.getInstance(\"JKS\");\n\t\t} catch (KeyStoreException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\t\t// 加载秘钥库文件\n\t\ttry (FileInputStream in = new FileInputStream(\"\")) {\n\t\t\tkeyStore.load(in, \"password\".toCharArray());\t\t}\t\tKeyManagerFactory keyManagerFactory = null;\n\t\tTrustManagerFactory trustManagerFactory = null;\n\t\t\t// 指定算法名获得实例化对象\n\t\t\tkeyManagerFactory = KeyManagerFactory.getInstance(\"SunX509\");\n\t\t\ttrustManagerFactory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t}\t\t\tkeyManagerFactory.init(keyStore, \"password\".toCharArray());\n\t\t\ttrustManagerFactory.init(keyStore);\n\t\t}\t\tSSLContext ctx = null;\n\t\t\tctx = SSLContext.getInstance(\"SSL\");\n\t\t\t// 初始化上下文\n\t\t\tctx.init(keyManagerFactory.getKeyManagers(),\n\t\t\t\t\ttrustManagerFactory.getTrustManagers(), null);\n\t\t}\t\tServerSocketFactory factory = ctx.getServerSocketFactory();\n\t\t\tSSLServerSocket serverSocket = (SSLServerSocket) factory\n\t\t\t\t\t.createServerSocket(8080);\n\t\t\tserverSocket.accept();\n\t\t} catch (IOException e) {\n\t\t}\n\t}\n}\n```\n   SSLServerSocket\n## SSLServerSocketFactory\n```java\n {@link SSLServerSocketFactory} 与SSLSocketFactory 操作几乎一致\n \n @author wangming\n\n/\n\tpublic static void main(String[] args) {\n\t\tSSLServerSocketFactory factory = (SSLServerSocketFactory) SSLServerSocketFactory\n\t\t\t\t.getDefault();\n\t\t\tfactory.createServerSocket(8080);\n\t\t} catch (IOException e) {\n\t\t}\n\t}\n}\n```\n   SSLServerSocketFactory\n## SSLSession.mdSSLSession 接口用于保持SSL协议网络交互会话状态. 用来描述俩个实体之间的会话关系\n在SSL的会话中,可以获得加密套件(CipherSuite),数字证书等\nCipherSuite 明确给出了加密参数, 具体包括：协议,秘钥交换算法,加密算法,工作模式和消息摘要算法\n如 TLS_RSA_TITH_AES_256_CBC_SHA 就是一个完成加密套件信息, 它表示：\n使用TLS协议,迷药交换算法为RSA,对称加密算法为AES(长度256),使用CBC模式,并使用SHA消息摘要算法\n## SSLSocket\n```java\n\tpublic Certificate[] get() {\n\t\t// 输出当前网络的debug日志\n\t\t// 将在控制台获得当前网络链接操作过程中使用到的数字证书信息和经过经过加密后的网络传输数据\n\t\tSystem.setProperty(\"javax.net.debug\", \"all\");\t\tSSLSocketFactory factory = (SSLSocketFactory) SSLSocketFactory\n\t\t\t\t.getDefault();\t\tSSLSession session = null;\n\t\t\tSSLSocket sslSocket = (SSLSocket) factory.createSocket(\"localhost\",\n\t\t\t\t\t8080);\t\t\t// 完成了加密套件和协议配置后，就可以开始握手协议，建立加密套接字进行加密通信了。\n\t\t\t// 在当前链接上建立SSL握手\n\t\t\tsslSocket.startHandshake();\t\t\t// 获得当前会话的SSLSession实例\n\t\t\tsession = sslSocket.getSession();\t\t\tsslSocket.close();\t\t\treturn session.getPeerCertificates();\n\t\t}\t\treturn null;\n\t}\n}\n```\nSSLSocket是基于SSL协议的Socket,用于设置加密套件,处理握手结束事件,并管理SSLSession\n目前Java环境中支持的协议有：SSLLv2Hello,SSLv3,TLSv1,TlSv1.1, TLSv1.2\n通常默认的是SSLv3和TLSv1.1\nsetEnabledProtocols(protocols);  通过该方法设置SSL链接可用协议\ngetSupportedCipherSuites()\t\t获得可支持的加密套件\nsetEnabledCipherSuites(suites)\t为当前SSL链接设置可用的加密套件\ngetEnabledCipherSuites()\t\t\t获得当前SSL链接可用的加密套件\n有时候需要与远程服务器建立基于SSLSocket的链接. 远程服务仅通过SSLSocket传递数字证书.\n这时候,就不能通过HttpsURLConnection来获得数字证书了,本方法就是通过SSLSocket来获得SSLSession\n并最终获得数字证书\n## SSLSocketFactory\n```java\n {@link SSLSocketFactory}\n 通过SSLSocketFactory 可创建SSLSocket, 并获得相应的加密套件\n \n @author wangming\n\n/\n\tpublic static void main(String[] args) {\n\t\tSSLSocketFactory sslFactory = (SSLSocketFactory)SSLSocketFactory.getDefault();\n\t\t\n\t\t\t// 创建SSLSocket实例\n\t\t\tSocket socket = sslFactory.createSocket(\"localhost\", 8080);\n\t\t\t\n\t\t\tSSLSocket sslSocket = (SSLSocket)socket;\n\t\t\t\n\t\t\t//获得默认加密套件\n\t\t\tsslFactory.getDefaultCipherSuites();\n\t\t\t\n\t\t\t// 获得当前SSL链接可支持的加密套件\n\t\t\tsslFactory.getSupportedCipherSuites();\n\t\t}\n\t}\n}\n```\n   SSLSocketFactory\n## TrustManagerFactory\n```java\n\tpublic static void main(String[] args) {\n\t\t\tTrustManagerFactory factory = TrustManagerFactory.getInstance(\"SunX509\");\n\t\t\t\n\t\t\t//  加载秘钥库文件\n\t\t\ttry(FileInputStream in = new FileInputStream(\"\")) {\n\t\t\t\tKeyStore ks = KeyStore.getInstance(\"JKS\");\n\t\t\t\tks.load(in, \"password\".toCharArray());\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t// 用证书授权源和相关的信任材料初始化此工厂\n\t\t\t\tfactory.init(ks);\n\t\t\t}\n\t\t\t\n\t\t}\n\t\t\n\t\t// 另外一种设置信任库的方式\n\t\tSystem.setProperty(\"javax.net.ssl.trustStore\", \"D:\\\\server.keystore\");\n\t\tSystem.setProperty(\"javax.net.ssl.trustStorePassword\", \"123456\");\n\t}\n}\n```\n 管理信任材料的管理工厂,设定信任库\n 每个信任管理器管理特定类型的由安全套接字使用的信任材料\n","slug":"security/javax_net_ssl","published":1,"date":"2015-09-18T07:15:44.452Z","updated":"2015-09-18T07:15:12.670Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9j000f74uf85iub86g"},{"title":"javax_crypto","_content":"## Cipher\n```java\nNoSuchPaddingException, InvalidKeyException,\n\tIllegalBlockSizeException, BadPaddingException {\n/*\n Cipher类是一个引擎类 它需要通过getlnstanceo工厂方法来实例化对象 我们可以通过指定转换模式的方式获得实例化对象\n 方法如下所示 getlnstance(string transformation) 返回指定转换的Cipher对象\n \n 也可以在制定转换模式的同时制定该转换模式的提供者 getlnstance(string transformation, Provider\n provider) getlnstance(stringtransformation, String provider)\n/// 完成密钥的包装和解包操作// 实例化KeyGenerator对象,并指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n/*\n 实例化Cipher对象 transformation 的格式是 算法/工作模式/填充模式\n/\nCipher c = Cipher.getInstance(\"DES/CBC/PKCS5Padding\");\n// 接下来执行包装操作\n// 初始化Cipher对象,用于包装\nc.init(Cipher.WRAP_MODE, sk);\n// 包装私密密钥\nbyte[] k = c.wrap(sk);// 得到字节数组k后,可以将其传递给需要解包的一方\n// 初始化Cipher对象,用于解包\nc.init(Cipher.UNWRAP_MODE, sk);\n// 解包私密密钥\nKey key = c.unwrap(k, \"DES\", Cipher.SECRET_KEY);// 加密 用密钥初始化加密模式\n// 初始化Cipher对象,用于加密操作\nc.init(Cipher.ENCRYPT_MODE, sk);\n// 加密\nbyte[] input = c.doFinal(\"DES DATA\".getBytes());// 解密操作与之相对于 用密钥初始化为解密模式\n// 初始化Cipher对象,用于解密操作\nc.init(Cipher.DECRYPT_MODE, sk);\n// 解密\nbyte[] output = c.doFinal(input);/*\n 加入SecureRandom参数来初始化 c.init(Cipher.DECRYPT_MODE, key, random);\n 通过以下方法可借助于证书，获得其公钥来完成加密和解密操作： 用取自给定证书的公钥初始化此Cipher对象 init（）\n 用取自给定证书的公钥和随机源初始化此Cipher对象 init（） 如果需要多次更新待加密（解密）的数据可使用如下方法。\n 最为常用的是通过输入给定位的字节数组完成更新： 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分\n update（） 或者通过偏移量的方式完成更新，方法如下所示：\n 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分 update（）\n 另外一种方式就是将更新结果输出至参数中，方法如下所示：\n 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分 update（）\n 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分 update（）\n \n 当然，我们也可以使用如下缓冲方式： 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分\n update（） 完成上述数据更新后，直接执行如下方法： 结束多部分加密和解密操作（具体取决于此Cipher对象的初始化方式）\n dofinal() 如果，加密（解密）操作不需要多次更新数据可以直接执行如下方法： 按单部分操作加密或解密数据，或者结束一个多部分操作\n dofinal()\n \n 或按以下偏移量的方式完成操作： 按单部分操作加密或解密数据，或者结束一个多部分操作 dofinal()\n 以下方式将操作后的结果存于给定的参数中，与上述方式大同小异： 结束多部分加密和解密操作（具体取决于此Cipher对象的初始化方式）\n dofinal() 与上述方法不同的是，以下方法可用于多部分操作，并操作结果存于给定参数中：\n 按单部分操作加密或解密数据，或者结束一个多部分操作 dofinal() 按单部分操作加密或解密数据，或者结束一个多部分操作\n dofinal() 以下方法提供了一种基于缓冲的处理方式： 按单部分操作加密或解密数据，或者结束一个多部分操作 dofinal()\n 除了完成数据的加密与解密，Cipher类还提供了对密钥的包装与解包。 我们先来了解一下与密钥包装有关的常量\n 用于将Cipher对象初始化为密钥包装模式的常量 init WAR_MODE\n \n 这一常量需要在进行Cipher对象初始化使用，给出如下示例代码： init（） 初始化 在此之后我们就可以执行包装操作，可使用如下方法：\n 包装密钥 wrap() 解包操作需要如下常量执行初始化 用于将Cipher初始化为密钥解包模式的常量 init WAR_MODE\n 这个常量同样需要在初始化中执行，给出如下示例代码： init（） 在此之后才能执行解包操作。 我们先看一下解包方法： 解包一个以前的密钥\n unwrap() 上述方法中的参数int wrappeKeyType需要使用如下常量： 用于表示要解包的密钥为“私钥”的常量 int\n PRIVATE_KEY 用于表示要解包的密钥为“公钥”的常量 PUBLIC_KEY 用于表示要解包的密钥为“私密密钥”的常量\n SECRET_KEY 在执行包装操作时使用的是私钥就使用私钥常量，依次对应。\n 如果读者对第2章中有关分组加密工作模式的内容还有印象，应该记得文中曾提到过初始化向量。我们可以通过如下方法获得：\n 返回新缓冲区中的初始化向量（IV） getIV() 通常，我们有必要通过如下方法来获悉当前转换模式所支持的密钥长度，方法如下所示：\n 根据所安装的JCB仲裁策略文件，返回指定转换的最大密钥长度 getMaxAllowedKeyLength()\n 分组加密中，每一组都有固定的长度，也称为块，以下方法可以获得相应的块大小： 返回块的大小（以字节为单位） getBlockSize()\n 以下方法获得输出缓冲区字节长度：\n 根据给定的输入长度inputLen(以字节单位)，返回保存下一个update或doFinal操作结果所需要的输出缓冲区长度（以字节为单位）\n getBlockSize() 我们也可以通过如下方法获得该Cipher对象的算法参数相关信息：\n 根据仲裁策略文件，返回包含最大Cipher参数值的AlgorithmParameterSpec对象\n getMaxAllowedKeyLength() 返回此Cipher使用的参数 getParameters() 此外，Cipher\n 类还提供以下方法： 返回此cipher使用的参数 getParameters() Cipher类作为一个引擎类，同样提供如下方法：\n 返回cipher对象的提供者 getProvider() 返回此Cipher对象的算法名称 getAlgorithm() /*\n/\n\t}}\n```\n为加密解密提供密码功能,它构成了Java Cryptographic Extension(JCE) 框架核心.\n在java.security包中 只完成了密钥的处理 并未完成加密与解密的操作. 这些核心 操作需要通过Cipher类来实现.\n## CipherInputStream\n```java\n {@link CipherInputStream}\n Ciper的拓展,称为密钥拓展流\n \n @author wangming\n\n/\n// 使用密钥输入流解密文件中数据// 实例化KeyGenerator对象,指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 实例化Cipher对象\nCipher c = Cipher.getInstance(\"DES\");// 接着从文件中读入数据,然后进行解密操作\nc.init(Cipher.DECRYPT_MODE, sk);\n// 实例化CipherInputStream\nCipherInputStream cis = new CipherInputStream(new FileInputStream(new File(\"secret\")), c);\n// 使用DataInputStream对象包装CipherInputStream对象\nDataInputStream dis = new DataInputStream(cis);\n// 读出解密后的数据\nString output = dis.readUTF();\ndis.close();\n\t}\n}\n```\nCiper的拓展,称为密钥拓展流\n## CipherOutputStream\n```java\n {@link CipherOutputStream}\n \n 密钥输出流\n \n @author wangming\n \n/\n\tNoSuchPaddingException, InvalidKeyException, IOException {\n// 密钥输出流加密操作// 实例化KeyGenerator对象,指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 实例化Cipher对象\nCipher c = Cipher.getInstance(\"DES\");// 初始化Cipher对象,用于加密操作\nc.init(Cipher.ENCRYPT_MODE, sk);\n// 待加密的原始数据\nString input = \"1234567890\";\n// 实例化CipherOutputStream对象\nCipherOutputStream cos = new CipherOutputStream(new FileOutputStream(new File(\"secret\")), c);\n// 使用DataOutputStream对象包装CipherOutputStream对象\nDataOutputStream dos = new DataOutputStream(cos);\n// 向输出流写待加密的数据\ndos.writeUTF(input);\n// 清空流\ndos.flush();\ndos.close();\n\t}\n}\n```\n密钥输出流\n## KeyAgreement\n```java\n\n {@link KeyAgreement}\n KeyAgreement类提供密钥协定协议的功能，它同样是一个引擎类。我们称它为密钥协定，将在DH算法实现中使用到它。 //此类提供密钥协定\n \n @author wangming\n\n/\t/*\n\t 与我们所熟悉的其他引擎类一样,KeyAgreement类需要通过getlnstce)工厂方法获得实例化对象：\n\t /返回实观指定密钥协定算法的KeyAgreement对象 public static KeyAgreement\n\t getlnstance(string algorithat) /返回实现指定密钥协定算法的KeyA9reement对象\n\t publicstaticKeyAgreementgetlnstance(String algorithat.Pravider provider)\n\t /返回实现指定密钥协定算法的KeyAgreement对象 public static KeyAgreement\n\t getlnstance(String algorittua.String provider\n\t 算法生成器共有两种初始化方式,与算法无关的方式或特定于算法的方式。 获得实例化对象后,需要执行以下初始化方法:\n\t init(Keykey,Algorithmparameterspec params) 或者，基于上述方式，再加入安全随机数参数，方法如下所示：\n\t key,Algorithmparameterspec params , SecureRanRandom random)\n\t 除上述方式外,我们也可以仅使用密钥和安全随机数两个参数完成初始化操作，方法如下所示： /用给定密钥和随机源初始化此KeyAgreement\n\t 用给定密钥执行此KeyAreement的下一个阶段,给定密钥是从此密钥协定所涉及的其他某个参与者那里接收的 public Key\n\t dophase(Key key, boolean lastphase) 最后，我们可以获得共享秘密密钥： /生成共亭秘密密钥并在新的缓冲区中返回它\n\t publicbytel1generategecreto /生成共享秘密密钥，并将其放入缓冲区 sharedsecret，从offer(包括）开始\n\t /创建共享秘密密钥并将其作为指定算法的SecretKey对象 public SecretKey generatesecret(String\n\t algorithm)\n\t \n\t 此外 KeyAgreement类还提供了以下常用方法： /返回此密钥协定对象的提供者 public Provider getprovider()\n\t /返回此密钥协定对象的算法名称 public String getALgorithm（）\n\t/\n// 实例化KeyPairGenerator对象,并指定DH算法\nKeyPairGenerator kpg = KeyPairGenerator.getInstance(\"DH\");\n// 生成KeyPair对象kp1\nKeyPair kp1 = kpg.generateKeyPair();\n// 生成KeyPair对象kp2\nKeyPair kp2 = kpg.generateKeyPair();\n// 实例化KeyAgreement对象\nKeyAgreement ka = KeyAgreement.getInstance(kpg.getAlgorithm());\n// 初始化KeyAgreement对象\nka.init(kp2.getPrivate());\n// 执行计划\nka.doPhase(kp1.getPublic(), true);\n// 生成SecretKey对象\nSecretKey sk = ka.generateSecret(\"DES\");\t}\n}\n```\nKeyAgreement类提供密钥协定协议的功能,它同样是一个引擎类.\n我们称它为密钥协定,将在DH算法实现中使用到它.\n## KeyGenerator\n```java\n/*\n\t 与KeypairGenerator类相似，KeyGenerator类通过如下方法获得实例化对象：\n\t 返回生成指定算法的秘密密钥的KeyGenerator对象public static final KeyGenerator\n\t getlnstance(String algorithm)另一种方式就是指定算法名称的同时指定该算法的提供者，方法如下所示：\n\t 返回生成指定算法的秘密密钥的KeyGenerator对象 public static final KeyGenerator\n\t getlnatance(String algorithm, Provider provider)\n\t 返回生成指定算法的秘密密钥的KeyGenerator对象public static final reyGenerator\n\t getlnstance(String algorithm, Provider provider)\n\t KeyGenerator对象可重复使用，也就是说，在生成密钥后，可以重复使用同一个KeyGenerator对象来生成更多的密钥。\n\t 生成密钥的方式有两种：与算法无关的方式和特定于算法的方式。这一点与KeypairGenemtor类生成密钥方式相类似。两者\n\t 之间的唯一不同是对象的初始化：\n\t \n\t 与算法无关的初始化。所有密钥生成器都具有密钥大小和随机源的概念。KeyGenerator类中有一个init（）方法，它带有\n\t 这两个通用共享类型的参数，还有一个只带有keysize参数的init（）方法，它使用具有最高优先级的已安装提供者的SecureRandom\n\t 实现作为随机源(如果已安装的提供者都不提供SecureRandom实现,则使用系统提供的随机源)。KeyGenerator类还提供一个只带随机\n\t 源参数的init()的方法。因为调用上述与算法无关的init（）方法时未指定其他参数，所以由提供者决定如何处理要与每个密钥关联的特\n\t 定于算法的参数(如果有)。\n\t 特定于算法的初始化。在已经存在特定于算法的参数集的情况下，有两个带Algorithmparameterspec参数的init（）方法。其中一个\n\t 方法还有一个SecureRandom参数，而另一个方法将具有高优先级的已安装提供者的SecureRandom实现作为随机源 (如果安装的提供者\n\t 都不提供SecureRandom实现，则使用系统提供的随机源)。如果客户端没有显式地初始化KeyGenerator (通过调用init（）方法)，\n\t 那么每个提供者都必须提供 (并记录) 默认初始化。与算法无关的初始化方法如下： 初始化此KeyGeneratorpublic final void\n\t init(secureRandom random) 初始化此KeyGenerator使其具有确定的密钥大小public final void\n\t init(int keysize) 使用用户提供的随机源初始化此KeyGenerator，使其具有确定的密钥大小public final void\n\t init(int keysize, SecureRandom random)\n\t \n\t 特定于算法的初始化方法如下： 用指定参敛集初始化此KeyGeneratorpublic final void\n\t init(Algorithmparameterspec params) 用指定参数集和用户提供的随机源初始化此KeyGeneratorpublic\n\t final void init(Algorithmparameterspec params, SecureRandom random)\n\t \n\t 完成初始化操作后 我们就可以通过以下方法获得秘密密钥： 生成一个SecretKey对象public final SecretKey\n\t generateKey() 与其他引擎类一样,KeyGenerator类提供如下两种方法: 返回此秘密密钥生成器对象的算法名称public\n\t final String getAlgorithm()返回此秘密密钥生成器对象的提供者public final String\n\t getAlgorithm()\n\t/// 实例化KeyGenerator对象,并指定HmacMD5算法\nKeyGenerator kg = KeyGenerator.getInstance(\"HmacMD5\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n\t}}\n```\nKeyGenerator类与KeypairGenerato类相似,\nKeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\nKeyGenerator类与KeypairGenerato类相似,KeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\nJava7版本中提供了Blowfish、AES、DES和DESede等多种对称加密算法实现,以及HmacMD5、\nHmacSHA1和HmacSHA256等多种安全消息摘要算法实现\n## Mac\n```java\n/*\n\t Mac与MessageDigest绝大多数方法相同，我们可以通过以下方法获得它的实例：\n\t返回实现指定摘要算法的Mac对象 \n\tgetInstance()\n\t或者，指定算法名称的同时指定该算法的提供者\n\t返回实现指定摘要算法的Mac对象\n\tgetInstance()\n\t返回实现指定摘要算法的Mac对象\n\tgetInstance()\n\t目前，Mac类支持HmacMD5 HmacSHA1 HmacSHA256 HmacSHA384 HmacSHA512 5种消息摘要算法。\n\t在获得Mac实现化对象后，需要通过给的密钥对Mac对象初始化，方法如下：\n\t用给定的密钥和算法参数初始化此Mac\n\tinit（）\n\t用给定的密钥和算法参数初始化此Mac\n\tinit（）\n\t这里的密钥Key指的是秘密密钥，请使用该密钥作为init（）方法的参数。\n\tMac类更新摘要方法与MessageDigest类相同，方法如下：\n\t使用指定的字节更新摘要。\n\tupdate（）\n\t使用指定的字节数组更新摘要。\n\tupdate（）\n\t上述方法传入参数不同，前一个传入的是字节，后一个传入的是字节数组。\n\t我们也可以通过输入偏移量的方式做更新操作，方法如下：\n\t使用指定的字节数组，从指定的偏移量开始更新摘要\n\tupdate()\n\t当然，我们还可以使用缓冲方式，方法如下：\n\t使用指定的字节缓冲更新摘要\n\tupdate()\n\t与MessageDigest类相同，更新摘要信息，其参数可以是更新一个字节、一个字节数组甚至是字节数组中的某一段偏移量，也可以是字节缓冲对象。\n\t这些方法的调用顺序不受限制，在向摘要中增加所需数据时可以多次调用。在完成摘要更新后，我们可以通过以下方法完成摘要操作：\n\t完成摘要操作\n\tdoFinal()\n\t使用指定的字节数组对摘要进行组后更新，然后完成摘要计算，返回消息摘要字节数组\n\tdoFinal()\n\t完成摘要操作，按指定的偏移量将摘要信息保存在字节数组中\n\tdoFinal()\n\t \n\t与MessageDigest类相同，Mac类也有重置方法：\n\t重置摘要以供再次使用\n\treset()\n\t执行该重置方法等同于创建一个新的Mac实例化对象。\n\t除了上述方法外，还常用到以下几个方法：\n\t返回以字节为单位的摘要长度，如果提供者不支持此操作并且实现是不可复制的，则返回0\n\t返回算法名称，如HmacMD5\n\tgetAlgorithm()\n\t返回此信息摘要对象的提供者\n\tgetprovider()\n\t/\n\t\n// 待做安全消息摘要的原始信息\nbyte[] input = \"MAC\".getBytes();\n// 初始化KeyGenerator对象,使用HmacMD5算法\nKeyGenerator kg = KeyGenerator.getInstance(\"HmacMD5\");\n// 构建SecretKey对象\nSecretKey sk = kg.generateKey();\n// 构建MAC对象\nMac mac = Mac.getInstance(sk.getAlgorithm());\n// 初始化Mac对象\nmac.init(sk);\n// 获得经过安全消息摘要后的信息\nbyte[] output = mac.doFinal(input);\n\t}\n}\n```\nMac属于消息摘要的一种,但它不同于一般消息摘要（如Message Digest提供的消息摘要实现）,\n仅通过输入数据无法活的吧消息摘要,必须有一个由发送方和接收方\n共享的秘密密钥才能生成最终的消息摘要——安全消息摘要.安全消息摘要又称消息认证（鉴别）码.\n## SealedObject\n```java\nIllegalBlockSizeException, IOException, ClassNotFoundException, BadPaddingException {\n// 待加密的字符串对象\nString input = \"SealedObject\";\n// 实例化KeyGenerator对象,并使用DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 创建秘密密钥\nSecretKey key = kg.generateKey();\n// 实例化用于加密的Cipher对象c1\nCipher c1 = Cipher.getInstance(key.getAlgorithm());\n// 初始化\nc1.init(Cipher.ENCRYPT_MODE, key);\n// 构建SealedObject对象\nSealedObject so = new SealedObject(input, c1);\n// 实例化用于解密的Cipher对象c2\nCipher c2 = Cipher.getInstance(key.getAlgorithm());\n// 初始化\nc2.init(Cipher.DECRYPT_MODE, key);\n// 获得解密后的字符串对象\nString output = (String)so.getObject(c2);\n\t}\n}\n```\nScaledObject使程序员能够用加密算法创建对象并保护其机密性\n在给定任何Serializable对象的情况下,程序员可以序列化格式(即深层复制)封装原始对象的SealedObject\n并使用类似于DES的加密算法密封(加密)其序列化的内容,保护其机密性\n加密的内容以后可以解密和烦序列话,生成原始对象\n已密封的原始对象可以使用以下俩种方式恢复\n1.使用采用Cipher对象的getObject)方法.\n此方法需要一个完全初始化的Cipher对象,用相同的用来蜜蜂对象的算法,密钥,填充方案等进行初始化.\n这样做的好处是解封密封 对象的一方不需要知道解密密钥. 例如一方用所需的解密密钥初始化Cipher对象之后,\n它就会将Cipher对象移交给以后要解封密封对象的另一方\n2.使用采用Key对象的getObject()方法.\n在此方法中getObject方法创建一个用于适当解密算法的Cipher对象\n并用给定的解密密钥和存储在密封对象中的算法参数 (如果有)对其进行初始化.\n这样做的好处是解封此对象的一方不需要跟踪用来密封该对象的参数 (如IV 、 初始化向量).\n## SecretKeyFactory\n```java\n\t/*\n\t既然SecretKeyFactory类也是一 个引擎类,同样需要通过getlnstance()工厂方法来实例化对象。\n\t我们可以通过制定算法名称的方式获得秘密密钥实例化对象，方法如下：\n\t返回转换指定算法的秘密密钥的SecretKeyFactory对象\n      public final static SecretXeyPactory getxnstance(String algorithm)\n      或者，指定算法名称的同时制定该算法的提供者，方法如下： \n      返回转换指定算法的秘迷密钥的SecretKeyFactory对象\n      public final static SecretReyfactory getlnstance(String algorlttmt, Provider provider)\n      返回转换指定算法的秘迷密钥的SecretKeyFactory对象\n      public final static SecretReyfactory getlnstance(String algorlttmt, sting provider)\n      算法生成器共有两种初始化方式：与算法无关的方式或特定于算法的方式。\n      得利SecretKeyFactory实例化对象后，我们就可以通过以下方法来生成秘密密钥：\n     /根据提供的密钥规范(密钥材料) 生成SecretKey对象\n      public final SecretKey generatesecret(Reyspec keyspec)\n      SecretKeyfactory类也是一个引擎类同样需要通过getlnstanceo工厂方法来实例化对象\n      与其他引擎类一 样，SecretKeyFactory类提供以下两种方法\n      返回此秘密密钥工厂对象的提供者\n      public final provider getprovider( )\n      返回此秘密密钥工厂对象的算法名称\n       public final String getAlgorithm()\n     /\n// 通过以下代码获得私密迷药的迷药编码字节数组\n// 实例化KeyGenerator对象,并指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey\nSecretKey sk = kg.generateKey();\n// 获得私密密钥的密钥编码字节数组\nbyte[] key = sk.getEncoded();// 得到上述密钥编码字节数组后,我们就可以还原其秘密密钥的对象\n// 由获得的密钥编码字节数组构建DESKeySpec对象\nDESKeySpec dks = new DESKeySpec(key);\n// 实例化SecreatKeyFactory对象\nSecretKeyFactory kf = SecretKeyFactory.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk1 = kf.generateSecret(dks);\n\t}}\n```\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,\n它用于产生秘密密钥,我们称之为秘密密钥工厂.\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,它用于产生秘密密钥,我们称之为秘密密钥工厂.\n  此类表示秘密密钥的工厂\n信任管理库及构建安全基于HTTPS的加密网络通信实现的知识\n","source":"_posts/security/javax_crypto.md","raw":"category: \n- security\ntitle: javax_crypto\n---\n## Cipher\n```java\nNoSuchPaddingException, InvalidKeyException,\n\tIllegalBlockSizeException, BadPaddingException {\n/*\n Cipher类是一个引擎类 它需要通过getlnstanceo工厂方法来实例化对象 我们可以通过指定转换模式的方式获得实例化对象\n 方法如下所示 getlnstance(string transformation) 返回指定转换的Cipher对象\n \n 也可以在制定转换模式的同时制定该转换模式的提供者 getlnstance(string transformation, Provider\n provider) getlnstance(stringtransformation, String provider)\n/// 完成密钥的包装和解包操作// 实例化KeyGenerator对象,并指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n/*\n 实例化Cipher对象 transformation 的格式是 算法/工作模式/填充模式\n/\nCipher c = Cipher.getInstance(\"DES/CBC/PKCS5Padding\");\n// 接下来执行包装操作\n// 初始化Cipher对象,用于包装\nc.init(Cipher.WRAP_MODE, sk);\n// 包装私密密钥\nbyte[] k = c.wrap(sk);// 得到字节数组k后,可以将其传递给需要解包的一方\n// 初始化Cipher对象,用于解包\nc.init(Cipher.UNWRAP_MODE, sk);\n// 解包私密密钥\nKey key = c.unwrap(k, \"DES\", Cipher.SECRET_KEY);// 加密 用密钥初始化加密模式\n// 初始化Cipher对象,用于加密操作\nc.init(Cipher.ENCRYPT_MODE, sk);\n// 加密\nbyte[] input = c.doFinal(\"DES DATA\".getBytes());// 解密操作与之相对于 用密钥初始化为解密模式\n// 初始化Cipher对象,用于解密操作\nc.init(Cipher.DECRYPT_MODE, sk);\n// 解密\nbyte[] output = c.doFinal(input);/*\n 加入SecureRandom参数来初始化 c.init(Cipher.DECRYPT_MODE, key, random);\n 通过以下方法可借助于证书，获得其公钥来完成加密和解密操作： 用取自给定证书的公钥初始化此Cipher对象 init（）\n 用取自给定证书的公钥和随机源初始化此Cipher对象 init（） 如果需要多次更新待加密（解密）的数据可使用如下方法。\n 最为常用的是通过输入给定位的字节数组完成更新： 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分\n update（） 或者通过偏移量的方式完成更新，方法如下所示：\n 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分 update（）\n 另外一种方式就是将更新结果输出至参数中，方法如下所示：\n 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分 update（）\n 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分 update（）\n \n 当然，我们也可以使用如下缓冲方式： 继续多部分加密或解密操作（具体取决于此Cipher对象的初始化方式），以处理其他数据部分\n update（） 完成上述数据更新后，直接执行如下方法： 结束多部分加密和解密操作（具体取决于此Cipher对象的初始化方式）\n dofinal() 如果，加密（解密）操作不需要多次更新数据可以直接执行如下方法： 按单部分操作加密或解密数据，或者结束一个多部分操作\n dofinal()\n \n 或按以下偏移量的方式完成操作： 按单部分操作加密或解密数据，或者结束一个多部分操作 dofinal()\n 以下方式将操作后的结果存于给定的参数中，与上述方式大同小异： 结束多部分加密和解密操作（具体取决于此Cipher对象的初始化方式）\n dofinal() 与上述方法不同的是，以下方法可用于多部分操作，并操作结果存于给定参数中：\n 按单部分操作加密或解密数据，或者结束一个多部分操作 dofinal() 按单部分操作加密或解密数据，或者结束一个多部分操作\n dofinal() 以下方法提供了一种基于缓冲的处理方式： 按单部分操作加密或解密数据，或者结束一个多部分操作 dofinal()\n 除了完成数据的加密与解密，Cipher类还提供了对密钥的包装与解包。 我们先来了解一下与密钥包装有关的常量\n 用于将Cipher对象初始化为密钥包装模式的常量 init WAR_MODE\n \n 这一常量需要在进行Cipher对象初始化使用，给出如下示例代码： init（） 初始化 在此之后我们就可以执行包装操作，可使用如下方法：\n 包装密钥 wrap() 解包操作需要如下常量执行初始化 用于将Cipher初始化为密钥解包模式的常量 init WAR_MODE\n 这个常量同样需要在初始化中执行，给出如下示例代码： init（） 在此之后才能执行解包操作。 我们先看一下解包方法： 解包一个以前的密钥\n unwrap() 上述方法中的参数int wrappeKeyType需要使用如下常量： 用于表示要解包的密钥为“私钥”的常量 int\n PRIVATE_KEY 用于表示要解包的密钥为“公钥”的常量 PUBLIC_KEY 用于表示要解包的密钥为“私密密钥”的常量\n SECRET_KEY 在执行包装操作时使用的是私钥就使用私钥常量，依次对应。\n 如果读者对第2章中有关分组加密工作模式的内容还有印象，应该记得文中曾提到过初始化向量。我们可以通过如下方法获得：\n 返回新缓冲区中的初始化向量（IV） getIV() 通常，我们有必要通过如下方法来获悉当前转换模式所支持的密钥长度，方法如下所示：\n 根据所安装的JCB仲裁策略文件，返回指定转换的最大密钥长度 getMaxAllowedKeyLength()\n 分组加密中，每一组都有固定的长度，也称为块，以下方法可以获得相应的块大小： 返回块的大小（以字节为单位） getBlockSize()\n 以下方法获得输出缓冲区字节长度：\n 根据给定的输入长度inputLen(以字节单位)，返回保存下一个update或doFinal操作结果所需要的输出缓冲区长度（以字节为单位）\n getBlockSize() 我们也可以通过如下方法获得该Cipher对象的算法参数相关信息：\n 根据仲裁策略文件，返回包含最大Cipher参数值的AlgorithmParameterSpec对象\n getMaxAllowedKeyLength() 返回此Cipher使用的参数 getParameters() 此外，Cipher\n 类还提供以下方法： 返回此cipher使用的参数 getParameters() Cipher类作为一个引擎类，同样提供如下方法：\n 返回cipher对象的提供者 getProvider() 返回此Cipher对象的算法名称 getAlgorithm() /*\n/\n\t}}\n```\n为加密解密提供密码功能,它构成了Java Cryptographic Extension(JCE) 框架核心.\n在java.security包中 只完成了密钥的处理 并未完成加密与解密的操作. 这些核心 操作需要通过Cipher类来实现.\n## CipherInputStream\n```java\n {@link CipherInputStream}\n Ciper的拓展,称为密钥拓展流\n \n @author wangming\n\n/\n// 使用密钥输入流解密文件中数据// 实例化KeyGenerator对象,指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 实例化Cipher对象\nCipher c = Cipher.getInstance(\"DES\");// 接着从文件中读入数据,然后进行解密操作\nc.init(Cipher.DECRYPT_MODE, sk);\n// 实例化CipherInputStream\nCipherInputStream cis = new CipherInputStream(new FileInputStream(new File(\"secret\")), c);\n// 使用DataInputStream对象包装CipherInputStream对象\nDataInputStream dis = new DataInputStream(cis);\n// 读出解密后的数据\nString output = dis.readUTF();\ndis.close();\n\t}\n}\n```\nCiper的拓展,称为密钥拓展流\n## CipherOutputStream\n```java\n {@link CipherOutputStream}\n \n 密钥输出流\n \n @author wangming\n \n/\n\tNoSuchPaddingException, InvalidKeyException, IOException {\n// 密钥输出流加密操作// 实例化KeyGenerator对象,指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 实例化Cipher对象\nCipher c = Cipher.getInstance(\"DES\");// 初始化Cipher对象,用于加密操作\nc.init(Cipher.ENCRYPT_MODE, sk);\n// 待加密的原始数据\nString input = \"1234567890\";\n// 实例化CipherOutputStream对象\nCipherOutputStream cos = new CipherOutputStream(new FileOutputStream(new File(\"secret\")), c);\n// 使用DataOutputStream对象包装CipherOutputStream对象\nDataOutputStream dos = new DataOutputStream(cos);\n// 向输出流写待加密的数据\ndos.writeUTF(input);\n// 清空流\ndos.flush();\ndos.close();\n\t}\n}\n```\n密钥输出流\n## KeyAgreement\n```java\n\n {@link KeyAgreement}\n KeyAgreement类提供密钥协定协议的功能，它同样是一个引擎类。我们称它为密钥协定，将在DH算法实现中使用到它。 //此类提供密钥协定\n \n @author wangming\n\n/\t/*\n\t 与我们所熟悉的其他引擎类一样,KeyAgreement类需要通过getlnstce)工厂方法获得实例化对象：\n\t /返回实观指定密钥协定算法的KeyAgreement对象 public static KeyAgreement\n\t getlnstance(string algorithat) /返回实现指定密钥协定算法的KeyA9reement对象\n\t publicstaticKeyAgreementgetlnstance(String algorithat.Pravider provider)\n\t /返回实现指定密钥协定算法的KeyAgreement对象 public static KeyAgreement\n\t getlnstance(String algorittua.String provider\n\t 算法生成器共有两种初始化方式,与算法无关的方式或特定于算法的方式。 获得实例化对象后,需要执行以下初始化方法:\n\t init(Keykey,Algorithmparameterspec params) 或者，基于上述方式，再加入安全随机数参数，方法如下所示：\n\t key,Algorithmparameterspec params , SecureRanRandom random)\n\t 除上述方式外,我们也可以仅使用密钥和安全随机数两个参数完成初始化操作，方法如下所示： /用给定密钥和随机源初始化此KeyAgreement\n\t 用给定密钥执行此KeyAreement的下一个阶段,给定密钥是从此密钥协定所涉及的其他某个参与者那里接收的 public Key\n\t dophase(Key key, boolean lastphase) 最后，我们可以获得共享秘密密钥： /生成共亭秘密密钥并在新的缓冲区中返回它\n\t publicbytel1generategecreto /生成共享秘密密钥，并将其放入缓冲区 sharedsecret，从offer(包括）开始\n\t /创建共享秘密密钥并将其作为指定算法的SecretKey对象 public SecretKey generatesecret(String\n\t algorithm)\n\t \n\t 此外 KeyAgreement类还提供了以下常用方法： /返回此密钥协定对象的提供者 public Provider getprovider()\n\t /返回此密钥协定对象的算法名称 public String getALgorithm（）\n\t/\n// 实例化KeyPairGenerator对象,并指定DH算法\nKeyPairGenerator kpg = KeyPairGenerator.getInstance(\"DH\");\n// 生成KeyPair对象kp1\nKeyPair kp1 = kpg.generateKeyPair();\n// 生成KeyPair对象kp2\nKeyPair kp2 = kpg.generateKeyPair();\n// 实例化KeyAgreement对象\nKeyAgreement ka = KeyAgreement.getInstance(kpg.getAlgorithm());\n// 初始化KeyAgreement对象\nka.init(kp2.getPrivate());\n// 执行计划\nka.doPhase(kp1.getPublic(), true);\n// 生成SecretKey对象\nSecretKey sk = ka.generateSecret(\"DES\");\t}\n}\n```\nKeyAgreement类提供密钥协定协议的功能,它同样是一个引擎类.\n我们称它为密钥协定,将在DH算法实现中使用到它.\n## KeyGenerator\n```java\n/*\n\t 与KeypairGenerator类相似，KeyGenerator类通过如下方法获得实例化对象：\n\t 返回生成指定算法的秘密密钥的KeyGenerator对象public static final KeyGenerator\n\t getlnstance(String algorithm)另一种方式就是指定算法名称的同时指定该算法的提供者，方法如下所示：\n\t 返回生成指定算法的秘密密钥的KeyGenerator对象 public static final KeyGenerator\n\t getlnatance(String algorithm, Provider provider)\n\t 返回生成指定算法的秘密密钥的KeyGenerator对象public static final reyGenerator\n\t getlnstance(String algorithm, Provider provider)\n\t KeyGenerator对象可重复使用，也就是说，在生成密钥后，可以重复使用同一个KeyGenerator对象来生成更多的密钥。\n\t 生成密钥的方式有两种：与算法无关的方式和特定于算法的方式。这一点与KeypairGenemtor类生成密钥方式相类似。两者\n\t 之间的唯一不同是对象的初始化：\n\t \n\t 与算法无关的初始化。所有密钥生成器都具有密钥大小和随机源的概念。KeyGenerator类中有一个init（）方法，它带有\n\t 这两个通用共享类型的参数，还有一个只带有keysize参数的init（）方法，它使用具有最高优先级的已安装提供者的SecureRandom\n\t 实现作为随机源(如果已安装的提供者都不提供SecureRandom实现,则使用系统提供的随机源)。KeyGenerator类还提供一个只带随机\n\t 源参数的init()的方法。因为调用上述与算法无关的init（）方法时未指定其他参数，所以由提供者决定如何处理要与每个密钥关联的特\n\t 定于算法的参数(如果有)。\n\t 特定于算法的初始化。在已经存在特定于算法的参数集的情况下，有两个带Algorithmparameterspec参数的init（）方法。其中一个\n\t 方法还有一个SecureRandom参数，而另一个方法将具有高优先级的已安装提供者的SecureRandom实现作为随机源 (如果安装的提供者\n\t 都不提供SecureRandom实现，则使用系统提供的随机源)。如果客户端没有显式地初始化KeyGenerator (通过调用init（）方法)，\n\t 那么每个提供者都必须提供 (并记录) 默认初始化。与算法无关的初始化方法如下： 初始化此KeyGeneratorpublic final void\n\t init(secureRandom random) 初始化此KeyGenerator使其具有确定的密钥大小public final void\n\t init(int keysize) 使用用户提供的随机源初始化此KeyGenerator，使其具有确定的密钥大小public final void\n\t init(int keysize, SecureRandom random)\n\t \n\t 特定于算法的初始化方法如下： 用指定参敛集初始化此KeyGeneratorpublic final void\n\t init(Algorithmparameterspec params) 用指定参数集和用户提供的随机源初始化此KeyGeneratorpublic\n\t final void init(Algorithmparameterspec params, SecureRandom random)\n\t \n\t 完成初始化操作后 我们就可以通过以下方法获得秘密密钥： 生成一个SecretKey对象public final SecretKey\n\t generateKey() 与其他引擎类一样,KeyGenerator类提供如下两种方法: 返回此秘密密钥生成器对象的算法名称public\n\t final String getAlgorithm()返回此秘密密钥生成器对象的提供者public final String\n\t getAlgorithm()\n\t/// 实例化KeyGenerator对象,并指定HmacMD5算法\nKeyGenerator kg = KeyGenerator.getInstance(\"HmacMD5\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n\t}}\n```\nKeyGenerator类与KeypairGenerato类相似,\nKeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\nKeyGenerator类与KeypairGenerato类相似,KeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\nJava7版本中提供了Blowfish、AES、DES和DESede等多种对称加密算法实现,以及HmacMD5、\nHmacSHA1和HmacSHA256等多种安全消息摘要算法实现\n## Mac\n```java\n/*\n\t Mac与MessageDigest绝大多数方法相同，我们可以通过以下方法获得它的实例：\n\t返回实现指定摘要算法的Mac对象 \n\tgetInstance()\n\t或者，指定算法名称的同时指定该算法的提供者\n\t返回实现指定摘要算法的Mac对象\n\tgetInstance()\n\t返回实现指定摘要算法的Mac对象\n\tgetInstance()\n\t目前，Mac类支持HmacMD5 HmacSHA1 HmacSHA256 HmacSHA384 HmacSHA512 5种消息摘要算法。\n\t在获得Mac实现化对象后，需要通过给的密钥对Mac对象初始化，方法如下：\n\t用给定的密钥和算法参数初始化此Mac\n\tinit（）\n\t用给定的密钥和算法参数初始化此Mac\n\tinit（）\n\t这里的密钥Key指的是秘密密钥，请使用该密钥作为init（）方法的参数。\n\tMac类更新摘要方法与MessageDigest类相同，方法如下：\n\t使用指定的字节更新摘要。\n\tupdate（）\n\t使用指定的字节数组更新摘要。\n\tupdate（）\n\t上述方法传入参数不同，前一个传入的是字节，后一个传入的是字节数组。\n\t我们也可以通过输入偏移量的方式做更新操作，方法如下：\n\t使用指定的字节数组，从指定的偏移量开始更新摘要\n\tupdate()\n\t当然，我们还可以使用缓冲方式，方法如下：\n\t使用指定的字节缓冲更新摘要\n\tupdate()\n\t与MessageDigest类相同，更新摘要信息，其参数可以是更新一个字节、一个字节数组甚至是字节数组中的某一段偏移量，也可以是字节缓冲对象。\n\t这些方法的调用顺序不受限制，在向摘要中增加所需数据时可以多次调用。在完成摘要更新后，我们可以通过以下方法完成摘要操作：\n\t完成摘要操作\n\tdoFinal()\n\t使用指定的字节数组对摘要进行组后更新，然后完成摘要计算，返回消息摘要字节数组\n\tdoFinal()\n\t完成摘要操作，按指定的偏移量将摘要信息保存在字节数组中\n\tdoFinal()\n\t \n\t与MessageDigest类相同，Mac类也有重置方法：\n\t重置摘要以供再次使用\n\treset()\n\t执行该重置方法等同于创建一个新的Mac实例化对象。\n\t除了上述方法外，还常用到以下几个方法：\n\t返回以字节为单位的摘要长度，如果提供者不支持此操作并且实现是不可复制的，则返回0\n\t返回算法名称，如HmacMD5\n\tgetAlgorithm()\n\t返回此信息摘要对象的提供者\n\tgetprovider()\n\t/\n\t\n// 待做安全消息摘要的原始信息\nbyte[] input = \"MAC\".getBytes();\n// 初始化KeyGenerator对象,使用HmacMD5算法\nKeyGenerator kg = KeyGenerator.getInstance(\"HmacMD5\");\n// 构建SecretKey对象\nSecretKey sk = kg.generateKey();\n// 构建MAC对象\nMac mac = Mac.getInstance(sk.getAlgorithm());\n// 初始化Mac对象\nmac.init(sk);\n// 获得经过安全消息摘要后的信息\nbyte[] output = mac.doFinal(input);\n\t}\n}\n```\nMac属于消息摘要的一种,但它不同于一般消息摘要（如Message Digest提供的消息摘要实现）,\n仅通过输入数据无法活的吧消息摘要,必须有一个由发送方和接收方\n共享的秘密密钥才能生成最终的消息摘要——安全消息摘要.安全消息摘要又称消息认证（鉴别）码.\n## SealedObject\n```java\nIllegalBlockSizeException, IOException, ClassNotFoundException, BadPaddingException {\n// 待加密的字符串对象\nString input = \"SealedObject\";\n// 实例化KeyGenerator对象,并使用DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 创建秘密密钥\nSecretKey key = kg.generateKey();\n// 实例化用于加密的Cipher对象c1\nCipher c1 = Cipher.getInstance(key.getAlgorithm());\n// 初始化\nc1.init(Cipher.ENCRYPT_MODE, key);\n// 构建SealedObject对象\nSealedObject so = new SealedObject(input, c1);\n// 实例化用于解密的Cipher对象c2\nCipher c2 = Cipher.getInstance(key.getAlgorithm());\n// 初始化\nc2.init(Cipher.DECRYPT_MODE, key);\n// 获得解密后的字符串对象\nString output = (String)so.getObject(c2);\n\t}\n}\n```\nScaledObject使程序员能够用加密算法创建对象并保护其机密性\n在给定任何Serializable对象的情况下,程序员可以序列化格式(即深层复制)封装原始对象的SealedObject\n并使用类似于DES的加密算法密封(加密)其序列化的内容,保护其机密性\n加密的内容以后可以解密和烦序列话,生成原始对象\n已密封的原始对象可以使用以下俩种方式恢复\n1.使用采用Cipher对象的getObject)方法.\n此方法需要一个完全初始化的Cipher对象,用相同的用来蜜蜂对象的算法,密钥,填充方案等进行初始化.\n这样做的好处是解封密封 对象的一方不需要知道解密密钥. 例如一方用所需的解密密钥初始化Cipher对象之后,\n它就会将Cipher对象移交给以后要解封密封对象的另一方\n2.使用采用Key对象的getObject()方法.\n在此方法中getObject方法创建一个用于适当解密算法的Cipher对象\n并用给定的解密密钥和存储在密封对象中的算法参数 (如果有)对其进行初始化.\n这样做的好处是解封此对象的一方不需要跟踪用来密封该对象的参数 (如IV 、 初始化向量).\n## SecretKeyFactory\n```java\n\t/*\n\t既然SecretKeyFactory类也是一 个引擎类,同样需要通过getlnstance()工厂方法来实例化对象。\n\t我们可以通过制定算法名称的方式获得秘密密钥实例化对象，方法如下：\n\t返回转换指定算法的秘密密钥的SecretKeyFactory对象\n      public final static SecretXeyPactory getxnstance(String algorithm)\n      或者，指定算法名称的同时制定该算法的提供者，方法如下： \n      返回转换指定算法的秘迷密钥的SecretKeyFactory对象\n      public final static SecretReyfactory getlnstance(String algorlttmt, Provider provider)\n      返回转换指定算法的秘迷密钥的SecretKeyFactory对象\n      public final static SecretReyfactory getlnstance(String algorlttmt, sting provider)\n      算法生成器共有两种初始化方式：与算法无关的方式或特定于算法的方式。\n      得利SecretKeyFactory实例化对象后，我们就可以通过以下方法来生成秘密密钥：\n     /根据提供的密钥规范(密钥材料) 生成SecretKey对象\n      public final SecretKey generatesecret(Reyspec keyspec)\n      SecretKeyfactory类也是一个引擎类同样需要通过getlnstanceo工厂方法来实例化对象\n      与其他引擎类一 样，SecretKeyFactory类提供以下两种方法\n      返回此秘密密钥工厂对象的提供者\n      public final provider getprovider( )\n      返回此秘密密钥工厂对象的算法名称\n       public final String getAlgorithm()\n     /\n// 通过以下代码获得私密迷药的迷药编码字节数组\n// 实例化KeyGenerator对象,并指定DES算法\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey\nSecretKey sk = kg.generateKey();\n// 获得私密密钥的密钥编码字节数组\nbyte[] key = sk.getEncoded();// 得到上述密钥编码字节数组后,我们就可以还原其秘密密钥的对象\n// 由获得的密钥编码字节数组构建DESKeySpec对象\nDESKeySpec dks = new DESKeySpec(key);\n// 实例化SecreatKeyFactory对象\nSecretKeyFactory kf = SecretKeyFactory.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk1 = kf.generateSecret(dks);\n\t}}\n```\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,\n它用于产生秘密密钥,我们称之为秘密密钥工厂.\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,它用于产生秘密密钥,我们称之为秘密密钥工厂.\n  此类表示秘密密钥的工厂\n信任管理库及构建安全基于HTTPS的加密网络通信实现的知识\n","slug":"security/javax_crypto","published":1,"date":"2015-09-18T07:15:44.450Z","updated":"2015-09-18T07:15:05.207Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9k000h74ufry2ezbgx"},{"title":"java_security_spec","_content":"## AlgorithmParameterSpec\n```java\n// 以DSAParameterSpec为例\nDSAParameterSpec dsa = new DSAParameterSpec(new BigInteger(\"1\"), new BigInteger(\"1\"), new BigInteger(\"1\"));\ndsa.getG(); // 返回基数G\ndsa.getP(); // 返回素数P\ndsa.getQ();\t// 返回子素数Q\n\t}\n}\n```\n此接口不包含任何方法或常亮.它仅用于将所有参数规范分组,并为其提供类型安全.所有参数规范否必须实现此接口\nAlgorithmParameterSpec接口有很多的子接口和实现类,用于特定算法的初始化.\n使用起来也很方便,只需要十一指定参数填充构造方法即可获得一个实例化对象\n## DESKeySpec\n```java// 实例化KeyGenerator对象,并指定DES对象\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 获得密钥编码字节数组\nbyte[] key = sk.getEncoded();// 在得到密钥编码字节数组后,我们将通过如下方法还原秘密密钥对象\n// 指定DES算法,还原SecretKey对象\nSecretKeySpec sk1 = new SecretKeySpec(key, \"DES\");// 实例化DESKeySpec对象,获得DES算法\nDESKeySpec dks = new DESKeySpec(key);\n// 实例化SecretKeyFactory对象,并指定DES算法\nSecretKeyFactory skf = SecretKeyFactory.getInstance(\"DESede\");\n// 获得SecretKey对象\nSecretKey kf = skf.generateSecret(dks);\n\t\n\t}\n\t\n// 如果是三重DES算法,除了将原来指明为DES算法的位置替换为DESede外\n// 还需要把DESKeySpec类换为DESedeKeySpec\n// 实例化，并指定DESede算法// 实例化KeyGenerator对象,并指定DESede对象\nKeyGenerator kg = KeyGenerator.getInstance(\"DESede\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 获得密钥编码字节数组\nbyte[] key = sk.getEncoded();// 在得到密钥编码字节数组后,我们将通过如下方法还原秘密密钥对象\n// 实例化DESedeKeySpec对象,获得DESede秘密密钥规范\nDESKeySpec dks = new DESKeySpec(key);\n// 实例化SecretKeyFactory对象,并指定DESede算法\nSecretKeyFactory skf = SecretKeyFactory.getInstance(\"DESede\");\n// 获得SecretKey对象\nSecretKey kf = skf.generateSecret(dks);\n\t}\n}\n```\nDESKeySpec和SecretKeySpec都是提供秘密密钥规范的实现类 DESKeySpec：指定类DES算法\nSecretKeySpec：兼容所有对称加密算法\nDESKeySpec有很多的同胞, DESedeKeySpec提供类三重DES加密算法的密钥规范 PBEKeySpec 提供了PBE算法的密钥规范\n## EncodedKeySpec\n```java\n 用编码格式来表示公钥和私钥,称之为编码密钥规范\n/\n\tInvalidKeySpecException {\n// 转换公钥编码密钥,以编码格式表示公钥\n// 指定DSA实例化KeyPairGenerator\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DSA\");\n// 初始化\nkg.initialize(1024);\n// 生成KeyPair对象\nKeyPair kp = kg.genKeyPair();/* ~~~~~~~~~~~~~~~~~~~~~~~/\n// 获得公钥的密钥字节数组\nbyte[] pkb = kp.getPublic().getEncoded();\n// 将公钥密钥字节数组再转换为公钥对象\n// 实例化X509EncodedKeySpec\nX509EncodedKeySpec xekp = new X509EncodedKeySpec(pkb);\n// 实例化KeyFactory\nKeyFactory kf = KeyFactory.getInstance(\"DSA\");\n// 获得PublicKey\nPublicKey pk = kf.generatePublic(xekp);/* ~~~~~~~~~~~~~~~~~~~~~~~/\n// 获得私钥的密钥字节数组\nbyte[] p1kb = kp.getPrivate().getEncoded();\n// 将私钥密钥字节数组再转换为私钥对象\n// 实例化X509EncodedKeySpec\nX509EncodedKeySpec x1ekp = new X509EncodedKeySpec(p1kb);\n// 实例化KeyFactory\nKeyFactory kf1 = KeyFactory.getInstance(\"DSA\");\n// 获得PublicKey\nPrivateKey p1k = kf.generatePrivate(x1ekp);\nx1ekp.getEncoded();\nx1ekp.getFormat();// X.509\n\t}// 转换私钥编码格式密钥,以编码格式表示私钥 (以PKCS#8标准作为密钥规范的编码格式)\n// 根据给定的编码密钥创建一个新的// 转换公钥编码密钥,以编码格式表示公钥\n// 指定DSA实例化KeyPairGenerator\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DSA\");\n// 初始化\nkg.initialize(1024);\n// 生成KeyPair对象\nKeyPair kp = kg.genKeyPair();// 根据获得的密钥对获得私钥密钥字节数组\nbyte[] ks = kp.getPrivate().getEncoded();\n// \nPKCS8EncodedKeySpec x1ekp = new PKCS8EncodedKeySpec(ks);\n// 指定DSA算法实例化KeyFactory\nKeyFactory kf = KeyFactory.getInstance(\"DSA\");\n// 获得PrivateKey\nPrivateKey pk = kf.generatePrivate(x1ekp);\nx1ekp.getEncoded();\nx1ekp.getFormat(); // PKCS#8\n\t}\n}\n```\n用编码格式来表示公钥和私钥,称之为编码密钥规范\n## KeySpec.md本接口不包含任何方法或常量,它仅用于将所有密钥规范分组,并为其提供类型安全.所有密钥规范都要继承该接口\nKeySpec的抽象实现类(EncodedKeySpec)构建了用于构建公钥规范和私钥规范的俩个实习\nX509EncodedKeySpec用于构建公钥\nPKCS8EncodedKeySpec用于构建私钥规范\nSecretKeySpec接口是KeySpec的实现类,用于构建私密密钥规范\n## ModifyPolicy\n```java\n\tpublic static void main(String[] args) {\n\tKeyGenerator kg = KeyGenerator.getInstance(\"AES\");\n\tkg.init(256);\n\tSecretKey skey = kg.generateKey();\n\tbyte[] key = skey.getEncoded();\n\t\n\t// 如果没有抛出java.security.InvalidKeyException 则证明修改成功\n} catch (NoSuchAlgorithmException e) {\n}\n\t}\n}\n## SecretKeySpec\n```java// 先获得RC2算法的密钥字节数组\n// 实例化KeyGenerator对象,并指定RC2对象\nKeyGenerator kg = KeyGenerator.getInstance(\"RC2\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 获得密钥编码字节数组\nbyte[] key = sk.getEncoded();// 在得到密钥编码字节数组后,我们将通过如下方法还原秘密密钥对象\n// 实例化SecretKey对象\nSecretKeySpec sk1 = new SecretKeySpec(key, \"RC2\");\n\t}\n}\n```\nSecretKeySpec类是KeySpec接口的实现类,用于构建秘密密钥规范\n此类仅能表示为一个字节数组并且没有任何与之相关联的密钥参数的原始密钥有用,如DES或Triple DES密钥\n","source":"_posts/security/java_security_spec.md","raw":"category: \n- security\ntitle: java_security_spec\n---\n## AlgorithmParameterSpec\n```java\n// 以DSAParameterSpec为例\nDSAParameterSpec dsa = new DSAParameterSpec(new BigInteger(\"1\"), new BigInteger(\"1\"), new BigInteger(\"1\"));\ndsa.getG(); // 返回基数G\ndsa.getP(); // 返回素数P\ndsa.getQ();\t// 返回子素数Q\n\t}\n}\n```\n此接口不包含任何方法或常亮.它仅用于将所有参数规范分组,并为其提供类型安全.所有参数规范否必须实现此接口\nAlgorithmParameterSpec接口有很多的子接口和实现类,用于特定算法的初始化.\n使用起来也很方便,只需要十一指定参数填充构造方法即可获得一个实例化对象\n## DESKeySpec\n```java// 实例化KeyGenerator对象,并指定DES对象\nKeyGenerator kg = KeyGenerator.getInstance(\"DES\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 获得密钥编码字节数组\nbyte[] key = sk.getEncoded();// 在得到密钥编码字节数组后,我们将通过如下方法还原秘密密钥对象\n// 指定DES算法,还原SecretKey对象\nSecretKeySpec sk1 = new SecretKeySpec(key, \"DES\");// 实例化DESKeySpec对象,获得DES算法\nDESKeySpec dks = new DESKeySpec(key);\n// 实例化SecretKeyFactory对象,并指定DES算法\nSecretKeyFactory skf = SecretKeyFactory.getInstance(\"DESede\");\n// 获得SecretKey对象\nSecretKey kf = skf.generateSecret(dks);\n\t\n\t}\n\t\n// 如果是三重DES算法,除了将原来指明为DES算法的位置替换为DESede外\n// 还需要把DESKeySpec类换为DESedeKeySpec\n// 实例化，并指定DESede算法// 实例化KeyGenerator对象,并指定DESede对象\nKeyGenerator kg = KeyGenerator.getInstance(\"DESede\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 获得密钥编码字节数组\nbyte[] key = sk.getEncoded();// 在得到密钥编码字节数组后,我们将通过如下方法还原秘密密钥对象\n// 实例化DESedeKeySpec对象,获得DESede秘密密钥规范\nDESKeySpec dks = new DESKeySpec(key);\n// 实例化SecretKeyFactory对象,并指定DESede算法\nSecretKeyFactory skf = SecretKeyFactory.getInstance(\"DESede\");\n// 获得SecretKey对象\nSecretKey kf = skf.generateSecret(dks);\n\t}\n}\n```\nDESKeySpec和SecretKeySpec都是提供秘密密钥规范的实现类 DESKeySpec：指定类DES算法\nSecretKeySpec：兼容所有对称加密算法\nDESKeySpec有很多的同胞, DESedeKeySpec提供类三重DES加密算法的密钥规范 PBEKeySpec 提供了PBE算法的密钥规范\n## EncodedKeySpec\n```java\n 用编码格式来表示公钥和私钥,称之为编码密钥规范\n/\n\tInvalidKeySpecException {\n// 转换公钥编码密钥,以编码格式表示公钥\n// 指定DSA实例化KeyPairGenerator\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DSA\");\n// 初始化\nkg.initialize(1024);\n// 生成KeyPair对象\nKeyPair kp = kg.genKeyPair();/* ~~~~~~~~~~~~~~~~~~~~~~~/\n// 获得公钥的密钥字节数组\nbyte[] pkb = kp.getPublic().getEncoded();\n// 将公钥密钥字节数组再转换为公钥对象\n// 实例化X509EncodedKeySpec\nX509EncodedKeySpec xekp = new X509EncodedKeySpec(pkb);\n// 实例化KeyFactory\nKeyFactory kf = KeyFactory.getInstance(\"DSA\");\n// 获得PublicKey\nPublicKey pk = kf.generatePublic(xekp);/* ~~~~~~~~~~~~~~~~~~~~~~~/\n// 获得私钥的密钥字节数组\nbyte[] p1kb = kp.getPrivate().getEncoded();\n// 将私钥密钥字节数组再转换为私钥对象\n// 实例化X509EncodedKeySpec\nX509EncodedKeySpec x1ekp = new X509EncodedKeySpec(p1kb);\n// 实例化KeyFactory\nKeyFactory kf1 = KeyFactory.getInstance(\"DSA\");\n// 获得PublicKey\nPrivateKey p1k = kf.generatePrivate(x1ekp);\nx1ekp.getEncoded();\nx1ekp.getFormat();// X.509\n\t}// 转换私钥编码格式密钥,以编码格式表示私钥 (以PKCS#8标准作为密钥规范的编码格式)\n// 根据给定的编码密钥创建一个新的// 转换公钥编码密钥,以编码格式表示公钥\n// 指定DSA实例化KeyPairGenerator\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DSA\");\n// 初始化\nkg.initialize(1024);\n// 生成KeyPair对象\nKeyPair kp = kg.genKeyPair();// 根据获得的密钥对获得私钥密钥字节数组\nbyte[] ks = kp.getPrivate().getEncoded();\n// \nPKCS8EncodedKeySpec x1ekp = new PKCS8EncodedKeySpec(ks);\n// 指定DSA算法实例化KeyFactory\nKeyFactory kf = KeyFactory.getInstance(\"DSA\");\n// 获得PrivateKey\nPrivateKey pk = kf.generatePrivate(x1ekp);\nx1ekp.getEncoded();\nx1ekp.getFormat(); // PKCS#8\n\t}\n}\n```\n用编码格式来表示公钥和私钥,称之为编码密钥规范\n## KeySpec.md本接口不包含任何方法或常量,它仅用于将所有密钥规范分组,并为其提供类型安全.所有密钥规范都要继承该接口\nKeySpec的抽象实现类(EncodedKeySpec)构建了用于构建公钥规范和私钥规范的俩个实习\nX509EncodedKeySpec用于构建公钥\nPKCS8EncodedKeySpec用于构建私钥规范\nSecretKeySpec接口是KeySpec的实现类,用于构建私密密钥规范\n## ModifyPolicy\n```java\n\tpublic static void main(String[] args) {\n\tKeyGenerator kg = KeyGenerator.getInstance(\"AES\");\n\tkg.init(256);\n\tSecretKey skey = kg.generateKey();\n\tbyte[] key = skey.getEncoded();\n\t\n\t// 如果没有抛出java.security.InvalidKeyException 则证明修改成功\n} catch (NoSuchAlgorithmException e) {\n}\n\t}\n}\n## SecretKeySpec\n```java// 先获得RC2算法的密钥字节数组\n// 实例化KeyGenerator对象,并指定RC2对象\nKeyGenerator kg = KeyGenerator.getInstance(\"RC2\");\n// 生成SecretKey对象\nSecretKey sk = kg.generateKey();\n// 获得密钥编码字节数组\nbyte[] key = sk.getEncoded();// 在得到密钥编码字节数组后,我们将通过如下方法还原秘密密钥对象\n// 实例化SecretKey对象\nSecretKeySpec sk1 = new SecretKeySpec(key, \"RC2\");\n\t}\n}\n```\nSecretKeySpec类是KeySpec接口的实现类,用于构建秘密密钥规范\n此类仅能表示为一个字节数组并且没有任何与之相关联的密钥参数的原始密钥有用,如DES或Triple DES密钥\n","slug":"security/java_security_spec","published":1,"date":"2015-09-18T07:15:44.448Z","updated":"2015-09-18T07:14:57.518Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9m000j74ufsk3bl1q5"},{"title":"java_security_cert","_content":"## Certificate.md用于管理证书的抽象类 证书有很多类型,如X.509证书,PGP证书和SDSI证书\n并且它们都以不同的方式存储并存储不同的信息,但却都可以通过继承Certificate类来实现\n## CertificateFactory\n```java\n// 实例化,并指明证书类型为 x.509\nCertificateFactory cf = CertificateFactory.getInstance(\"x.509\");\n// 获得证书输出流\nFileInputStream in = new FileInputStream(\"D:\\\\x.keystore\");\n// 生成一个证书对象,并使用从输出流in中读取的数据对它进行初始化\nCertificate c = cf.generateCertificate(in);\n// 返回从给定输入流in中读取的证书的集合视图\ncf.generateCertificates(in);// 生成一个CertPath,并使用从InputStream中读取的数据对它进行初始化\ncf.generateCertPath(in);\n// 还可使用List或者指定编码对其进行初始化// 生成一个证书撤销列表(CRL),并使用从输入流in中读取的数据对它进行初始化\ncf.generateCRL(in);// 返回CertificateFactory 支持的CertPath编码的迭代器,默认编码方式优先\ncf.getCertPathEncodings();// 返回CertificateFactory相关联的证书类型\ncf.getType();// 关闭流\nin.close();\n\t}\n}\n```\nCertificateFactory是一个引擎类,称之为证书工厂,可以通过它将证书导入程序中.\n## CertPath\n```java\n// 实例化,并指明证书类型为X.509\nCertificateFactory cf = CertificateFactory.getInstance(\"x.509\");\n// 获得证书输入流\nFileInputStream in = new FileInputStream(\"\");\n// 获得CertPath对象\nCertPath cp = cf.generateCertPath(in);in.close();// 获得证书路径中的证书列表\ncp.getCertificates();\n// 获得证书路径的编码形式,使用默认编码（还可指定编码） \ncp.getEncoded();// 获得证书路径中的Certificate类型 如x。509\ncp.getType();\t}\n}\n```\n定义了常用于所有CertPath的方法 其子类可处理不同类型的证书(x.509 PGP等)\n所有的CertPath对象都包含类型,Certificate列表及其支持的一种或多种编码\n## CRL\n```java\n// 实例化,并致命证书类型为 X509\nCertificateFactory cf = CertificateFactory.getInstance(\"X.509\");\n// 获得证书输入流\nFileInputStream in = new FileInputStream(\"\");\n// 获得证书撤销列表\nCRL crl = cf.generateCRL(in);\n// 关闭流\nin.close();\n// 获取CRL类型\ncrl.getType();\n// 检查给定的证书是否在此CRl中\n//\tcrl.isRevoked(cert)\n\t}\n}\n```\n证书可能会由于各种原因失效, 失效后证书将被制为无效,无效的结果就是产生CRL(证书撤销列表),\nCA负责发布CRL,CRL中列出了该CA已经撤销的证书\n验证证书时,首先需要查询此列表,然后再考虑接受证书的合法性\n## X509Certificate\n```java\n// 加载密钥库文件\nFileInputStream fin = new FileInputStream(new File(\"\"));\n// 实例化KeyStore对象\nKeyStore ks = KeyStore.getInstance(\"JKS\");\n// 加载密钥库\nks.load(fin, \"password\".toCharArray());\n// 关闭文件输入流\nfin.close();\n// 获得x.509类型证书\nX509Certificate xc = (X509Certificate)ks.getCertificate(\"alias\");\n// 通过证书标明的签名算法构建Signature对象\nSignature s = Signature.getInstance(xc.getSigAlgName());// 获取验证证书的有效期\nxc.getNotAfter(); \nxc.getNotBefore();// 检查给定的日期是否处于证书的有效期内\nxc.checkValidity(new Date());// 获取证书的相应属性\n// 获取证书的版本\nxc.getVersion();\n// 获取证书的SerialNumber\nxc.getSerialNumber();\n// 从关键BasicConstraints扩展(OID = 2.5.29.15)获取证书的限制路径长度\nxc.getBasicConstraints();// 获取一个表示KeyUsage扩展（OID＝2.5.29.15）的各个位的boolean数组\nxc.getKeyUsage();\n//获取一个不可修改的String列表，表示已扩展的密钥使用扩展（OID=2.5.29.37）中ExtKeyUsageSyntax字段的对象标识符（OBJECT IDENTIFIER）\nxc.getExtendedKeyUsage();// 获得证书的发布者的相关信息\n//从IssuerAltName扩展（OID＝2.5.29.18）中获取一个发布方替换名称的不可変集合\nxc.getIssuerAlternativeNames();\n//获取证书的issuerUniqueID值\nxc.getIssuerUniqueID();\n//以x500Principal的形式返回证书的发布方（发布方标识名）值\nxc.getIssuerX500Principal();// 以下方法可以获得证书主题的一些相关信息\n//从SubjectAltName扩展（OID=2.5.29.17）中获取一个主体替换名称的不可变集合\nxc.getSubjectAlternativeNames();\n// 获取证书的SubjectUniqueID\nxc.getSubjectUniqueID();\n// 以行X500Principal的形式返回证书的主体(主题标志名)值\nxc.getSubjectX500Principal();// 获得证书的DER编码的二进制信息\n// 从次证书中获取以DER编码的二进制信息\n// 从此证书中获取以DER编码的证书信息\nxc.getTBSCertificate();\n// 获取证书签名算法的签名算法名\nxc.getSigAlgName();\n// 获取证书的签名算法OID字符串\nxc.getSigAlgOID();\n// 从此证书的签名算法中获取DER编码形式的签名算法参数\nxc.getSigAlgParams();// 获取签名值\nxc.getSignature();\t}\n}\n```\nX509Certificate是Certificate的子类\nx.509证书的抽象类,此类提供类一种访问x.509证书的所有属性的标准方式\n## X509CRL\n```java\n// 实例化,并指明证书类型为X.509\nCertificateFactory cf = CertificateFactory.getInstance(\"x.509\");\n// 获得证书输入流\nFileInputStream in = new FileInputStream(\"\");\n// 获得证书\nX509Certificate c = (X509Certificate)cf.generateCertificate(in);\n// 获得证书撤销列表\nX509CRL xc = (X509CRL)cf.generateCRL(in);\n// 获得证书撤销列表实体\nX509CRLEntry xce = xc.getRevokedCertificate(c);\nin.close();\n// 获得版本号\nxc.getVersion();// 获得DER编码的二进制信息\n// 返回CRL的ASN.1 DER的编码形式\nxc.getEncoded();\n// 从CRL中获取以DER编码的CRL信息\nxc.getTBSCertList();// 获取crl的thisUpdate信息\nxc.getThisUpdate();\n// 获取crl的nextupdate信息\nxc.getNextUpdate();// 获取CRL签名算法的签名算法名\nxc.getSigAlgName();\n// 获取CRL签名算法的OID字符串\nxc.getSigAlgOID();// 获得数字签名值(原始签名位)\nxc.getSignature();// 获取具有给定证书serialNumber的CRL项\n//xc.getRevokedCertificate(serialNumber)// 验证是否已使用给定公钥相应的私钥签署了此CRL\n//xc.verify(key);// 以X500Principal的形式返回CRL的发布方\nxc.getIssuerX500Principal();\t}\n}\n```\n作为CRl的子类,已标明了类型为X.509的CRl, X.509证书撤销列表(CRL)的抽象类.\nCRL是标致已撤销证书的时间戳列表.\n它由证书颁发机构签署,并可在公共存储库中随意使用\n## X509CRLEntry.md已经撤销的证书类\n","source":"_posts/security/java_security_cert.md","raw":"category: \n- security\ntitle: java_security_cert\n---\n## Certificate.md用于管理证书的抽象类 证书有很多类型,如X.509证书,PGP证书和SDSI证书\n并且它们都以不同的方式存储并存储不同的信息,但却都可以通过继承Certificate类来实现\n## CertificateFactory\n```java\n// 实例化,并指明证书类型为 x.509\nCertificateFactory cf = CertificateFactory.getInstance(\"x.509\");\n// 获得证书输出流\nFileInputStream in = new FileInputStream(\"D:\\\\x.keystore\");\n// 生成一个证书对象,并使用从输出流in中读取的数据对它进行初始化\nCertificate c = cf.generateCertificate(in);\n// 返回从给定输入流in中读取的证书的集合视图\ncf.generateCertificates(in);// 生成一个CertPath,并使用从InputStream中读取的数据对它进行初始化\ncf.generateCertPath(in);\n// 还可使用List或者指定编码对其进行初始化// 生成一个证书撤销列表(CRL),并使用从输入流in中读取的数据对它进行初始化\ncf.generateCRL(in);// 返回CertificateFactory 支持的CertPath编码的迭代器,默认编码方式优先\ncf.getCertPathEncodings();// 返回CertificateFactory相关联的证书类型\ncf.getType();// 关闭流\nin.close();\n\t}\n}\n```\nCertificateFactory是一个引擎类,称之为证书工厂,可以通过它将证书导入程序中.\n## CertPath\n```java\n// 实例化,并指明证书类型为X.509\nCertificateFactory cf = CertificateFactory.getInstance(\"x.509\");\n// 获得证书输入流\nFileInputStream in = new FileInputStream(\"\");\n// 获得CertPath对象\nCertPath cp = cf.generateCertPath(in);in.close();// 获得证书路径中的证书列表\ncp.getCertificates();\n// 获得证书路径的编码形式,使用默认编码（还可指定编码） \ncp.getEncoded();// 获得证书路径中的Certificate类型 如x。509\ncp.getType();\t}\n}\n```\n定义了常用于所有CertPath的方法 其子类可处理不同类型的证书(x.509 PGP等)\n所有的CertPath对象都包含类型,Certificate列表及其支持的一种或多种编码\n## CRL\n```java\n// 实例化,并致命证书类型为 X509\nCertificateFactory cf = CertificateFactory.getInstance(\"X.509\");\n// 获得证书输入流\nFileInputStream in = new FileInputStream(\"\");\n// 获得证书撤销列表\nCRL crl = cf.generateCRL(in);\n// 关闭流\nin.close();\n// 获取CRL类型\ncrl.getType();\n// 检查给定的证书是否在此CRl中\n//\tcrl.isRevoked(cert)\n\t}\n}\n```\n证书可能会由于各种原因失效, 失效后证书将被制为无效,无效的结果就是产生CRL(证书撤销列表),\nCA负责发布CRL,CRL中列出了该CA已经撤销的证书\n验证证书时,首先需要查询此列表,然后再考虑接受证书的合法性\n## X509Certificate\n```java\n// 加载密钥库文件\nFileInputStream fin = new FileInputStream(new File(\"\"));\n// 实例化KeyStore对象\nKeyStore ks = KeyStore.getInstance(\"JKS\");\n// 加载密钥库\nks.load(fin, \"password\".toCharArray());\n// 关闭文件输入流\nfin.close();\n// 获得x.509类型证书\nX509Certificate xc = (X509Certificate)ks.getCertificate(\"alias\");\n// 通过证书标明的签名算法构建Signature对象\nSignature s = Signature.getInstance(xc.getSigAlgName());// 获取验证证书的有效期\nxc.getNotAfter(); \nxc.getNotBefore();// 检查给定的日期是否处于证书的有效期内\nxc.checkValidity(new Date());// 获取证书的相应属性\n// 获取证书的版本\nxc.getVersion();\n// 获取证书的SerialNumber\nxc.getSerialNumber();\n// 从关键BasicConstraints扩展(OID = 2.5.29.15)获取证书的限制路径长度\nxc.getBasicConstraints();// 获取一个表示KeyUsage扩展（OID＝2.5.29.15）的各个位的boolean数组\nxc.getKeyUsage();\n//获取一个不可修改的String列表，表示已扩展的密钥使用扩展（OID=2.5.29.37）中ExtKeyUsageSyntax字段的对象标识符（OBJECT IDENTIFIER）\nxc.getExtendedKeyUsage();// 获得证书的发布者的相关信息\n//从IssuerAltName扩展（OID＝2.5.29.18）中获取一个发布方替换名称的不可変集合\nxc.getIssuerAlternativeNames();\n//获取证书的issuerUniqueID值\nxc.getIssuerUniqueID();\n//以x500Principal的形式返回证书的发布方（发布方标识名）值\nxc.getIssuerX500Principal();// 以下方法可以获得证书主题的一些相关信息\n//从SubjectAltName扩展（OID=2.5.29.17）中获取一个主体替换名称的不可变集合\nxc.getSubjectAlternativeNames();\n// 获取证书的SubjectUniqueID\nxc.getSubjectUniqueID();\n// 以行X500Principal的形式返回证书的主体(主题标志名)值\nxc.getSubjectX500Principal();// 获得证书的DER编码的二进制信息\n// 从次证书中获取以DER编码的二进制信息\n// 从此证书中获取以DER编码的证书信息\nxc.getTBSCertificate();\n// 获取证书签名算法的签名算法名\nxc.getSigAlgName();\n// 获取证书的签名算法OID字符串\nxc.getSigAlgOID();\n// 从此证书的签名算法中获取DER编码形式的签名算法参数\nxc.getSigAlgParams();// 获取签名值\nxc.getSignature();\t}\n}\n```\nX509Certificate是Certificate的子类\nx.509证书的抽象类,此类提供类一种访问x.509证书的所有属性的标准方式\n## X509CRL\n```java\n// 实例化,并指明证书类型为X.509\nCertificateFactory cf = CertificateFactory.getInstance(\"x.509\");\n// 获得证书输入流\nFileInputStream in = new FileInputStream(\"\");\n// 获得证书\nX509Certificate c = (X509Certificate)cf.generateCertificate(in);\n// 获得证书撤销列表\nX509CRL xc = (X509CRL)cf.generateCRL(in);\n// 获得证书撤销列表实体\nX509CRLEntry xce = xc.getRevokedCertificate(c);\nin.close();\n// 获得版本号\nxc.getVersion();// 获得DER编码的二进制信息\n// 返回CRL的ASN.1 DER的编码形式\nxc.getEncoded();\n// 从CRL中获取以DER编码的CRL信息\nxc.getTBSCertList();// 获取crl的thisUpdate信息\nxc.getThisUpdate();\n// 获取crl的nextupdate信息\nxc.getNextUpdate();// 获取CRL签名算法的签名算法名\nxc.getSigAlgName();\n// 获取CRL签名算法的OID字符串\nxc.getSigAlgOID();// 获得数字签名值(原始签名位)\nxc.getSignature();// 获取具有给定证书serialNumber的CRL项\n//xc.getRevokedCertificate(serialNumber)// 验证是否已使用给定公钥相应的私钥签署了此CRL\n//xc.verify(key);// 以X500Principal的形式返回CRL的发布方\nxc.getIssuerX500Principal();\t}\n}\n```\n作为CRl的子类,已标明了类型为X.509的CRl, X.509证书撤销列表(CRL)的抽象类.\nCRL是标致已撤销证书的时间戳列表.\n它由证书颁发机构签署,并可在公共存储库中随意使用\n## X509CRLEntry.md已经撤销的证书类\n","slug":"security/java_security_cert","published":1,"date":"2015-09-18T07:15:44.446Z","updated":"2015-09-18T07:14:48.021Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9o000l74ufhc5wa25u"},{"title":"java_security","_content":"## AlgorithmParameterGenerator\n```java\nAlgorithmParameterGenerator apg = AlgorithmParameterGenerator.getInstance(Algorithm.DES.name());\n\n  与算法无关的初始化\n  所有参数生成器都共享大小概念和一个随机源\n  \n   特定于算法的参数生成值默认为某些标准值,除非他们可以从指定的大小派生\n   apg.init(size, random);\n/\napg.init(56);\n\n/*\n 实例化后就可以生成算法参数对象了\n/\nAlgorithmParameters ap = apg.generateParameters();\n\n// 获得字节数组\nbyte[] b = ap.getEncoded();\nSystem.out.println(new BigInteger(b).toString());\n\n\n  特定于算法的初始化\n  使用特定算法的语意初始化参数生成器对象,这些语意由特定于算法的参数生成值集合表示.\n  \n  apg.init(genParamSpec);\n  apg.init(genParamSpec, random);\n/\n\n```\n引擎类,用于生成某个特定算法中使用的参数集合.{@link AlgorithmParameters} 生成的参数\n## AlgorithmParameters.md\n```java\n// 实例化AlgorithmParameters 并指定DES算法\nAlgorithmParameters ap = AlgorithmParameters.getInstance(Algorithm.DES.name());\n// 使用BigInteger生成字节数组参数\nap.init(new BigInteger(\"19050619766489163472469\").toByteArray());\n// 获取参数字节数组\nbyte[] b = ap.getEncoded();\n// 打印经过BigInteger处理后的字符串,会得到与19050619766489163472469 相同的字符串\nSystem.out.println(\"BigInteger Encoded : \" + new BigInteger(b).toString());\n// 获取基本编码格式的参数\nSystem.out.println(\"Hex \t   Encoded : \" + Hex.toHexString(ap.getEncoded()));\n\n// 完成初始化后 获得参数对象的规范\n// ap.getParameterSpec(AlgorithmParameterSpec.class);\n// 使用 AlgorithmParameterSpec指定的参数初始化\n// ap.init(paramSpec);\n// 根据参数的基本解码格式导入指定的参数字节数组并对其解码\n// ap.init(new byte[]{});\n// 根据指定的解码方案从参数字节数组导入参数并对其解码\n// ap.init(params, format);\n\n// 注意的是 AlgorithmParameters对象只能被初始化一次,不能复用\n// ap.init(new byte[]{});\n\n// 获取此参数对象的算法的名称\nSystem.out.println(\"Algorithm : \" + ap.getAlgorithm());\n// 获取次参数对象的提供者\nSystem.out.println(\"Provider : \" + ap.getProvider());\n\n// 获取指定编码格式的参数\nap.getEncoded(\"\");\n\n```\n引擎类. 提供密码参数的不透明表示{@link AlgorithmParameters}AlgorithmParameters是一个引擎类,提供密码参数的不透明表示{@link AlgorithmParameterGenerator} 可以通过该引擎类生成不透明:不可以直接访问各参数域,只能得到与参数集相关联的算法名及该参数集的某类编码透明 :用户可以通过相应规范中定义的某个get方法来分别访问每个值\n## CodeSigner\n```java\n// 构建CertificateFactory对象,并指定证书类型为x.509\nCertificateFactory cf = CertificateFactory.getInstance(\"509\");\n// 生成Certificate对象\nCertPath cp = cf.generateCertPath(new FileInputStream(\"\"));\n// 实例化时间戳\nTimestamp t = new Timestamp(new Date(), cp);\n// 实例化CodeSinger对象\nCodeSigner cs = new CodeSigner(cp, t);\n// 对比\nboolean result = cs.equals(new CodeSigner(cp, t));\n```\n封装了代码签名者的信息,且他是不可变的,称之为代码签名 他和数字时间戳({@link Timestamp}) 紧密相连CodeSigner类是一个终态类,可以通过其构造方法完成实例化对象：\n* 构建CodeSigner对象 --> CodeSigner()\n完成实例化对象后,就可以通过以下方法获得其属性：\n* 返回签名者的CertPath对象 --> getSignerCertpath()\n* 返回签名时间戳  --> getTimestamp()注意,这里的Timestamp是java.security.Timestamp,是用做数字时间戳的Timestamp！\n获得CodeSigner对象后的最重要的操作就是执行比对,CodeSigner覆盖了equals()方法.\n测试指定对象与此CodeSigner对象是否相等 --> equals()\n如果,传入参数不是CodeSigner类的实现,则直接返回false.\n如果传入参数是CodeSigner类的实现,则比较其Timestamp和CerPath两个属性\n## DigestInputStream\n```java\n消息摘要输入流通过指定的读操作完成MessageDigest 的update()方法\n\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\ntry(FileInputStream in = new FileInputStream(new File(fileName));\nDigestInputStream dis = new DigestInputStream(in, md)) {\n\n\n 更新MessageDigest对象,将其与dis相关\n \n/\ndis.setMessageDigest(MessageDigest.getInstance(\"MD2\"));\n\n\n 读取字节 并更新摘要\n read会调用MessageDigest的update()方法完成摘要更新\n 之后通过nmd的digest完成摘要操作\n/\ndis.read();\n//  获取流中相关的MessageDigest\nMessageDigest nmd = dis.getMessageDigest();\nnmd.digest();\n\n//关闭DigestInputStream摘要功能,则该流就变成一般的流\ndis.on(false);\n\n// 待做消息摘要操作的原始信息\nbyte[] input = \"md5\".getBytes();\n// 使用MD5算法初始化MessageDigest对象\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\n\ntry(DigestInputStream dis = new DigestInputStream(\nnew ByteArrayInputStream(input), md)) {\n\t\n\tdis.read(input, 0, input.length);\n\tMessageDigest nmd = dis.getMessageDigest();\n\t// 获得摘要信息\n\tbyte[] output = nmd.digest();\n\tSystem.out.println(output);\n\n```\n消息摘要输入流通过指定的读操作完成MessageDigest 的update()方法\n\n## DigestOutputStream\n```java\n\n消息摘要输出流通过指定的写操作完成MessageDigest 的update()方法. 基本上和DigestInputStream类似\n\n\n// 待做消息摘要操作的原始信息\nbyte[] input = \"md5\".getBytes();\n// 使用MD5算法初始化MessageDigest对象\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\n\ntry (DigestOutputStream dis = new DigestOutputStream(\nnew ByteArrayOutputStream(), md)) {\n\t// 流输出\n\tdis.write(input, 0, input.length);\n\tMessageDigest nmd = dis.getMessageDigest();\n\t// 获得摘要信息\n\tbyte[] output = nmd.digest();\n\tSystem.out.println(output);\n\n\tdis.flush();\n```\n消息摘要输出流通过指定的写操作完成MessageDigest 的update()方法\n\n## Key\nKey接口是所有密钥接口的顶层接口,一切与加密有关的操作都离不开Key接口\n由于密钥必须在不同的实体间传输,因此所有的密钥都是可序列话的\n所有的密钥都具有三个形式\n算法:密钥算法, 如DES和DSA. getAlgorithm()\n编码形式:密钥的外部编码形式,密钥根据标准格式(RKC#8)编码,  getEncode()\n格式:已编码密钥的格式的名称,getFormat()\n对称密钥顶层接口\n{@link SecretKey}\n通常使用的是{@link SecretKeySpec}\nDES,AES 等多种对称密码算法均可通过该接口提供,PBE接口提供PBE算法定义并继承了该接口\nMAC算法实现过程中,通过SecretKey接口提供秘密秘钥\n非对称密钥顶层接口\n{@link PublicKey} 公钥接口\n{@link PrivateKey} 私钥接口\nDh,RSA,DSA,EC等多种非对称秘钥接口均继承了这俩个接口\n## KeyFactory\n```java\nKeyPairGenerator generator = KeyPairGenerator.getInstance(Algorithm.RSA.name());\ngenerator.initialize(1024);\nKeyPair kp = generator.genKeyPair();\n// 获得私钥密钥字节数组.使用过程中该密钥以此种形式保存传递给另一方\nbyte[] privateBytes = kp.getPrivate().getEncoded();\n// 由私钥密钥字节数组获得密钥规范\nPKCS8EncodedKeySpec pkcs = new PKCS8EncodedKeySpec(privateBytes);\n\n// 实例化密钥工厂,并指定RSA算法\nKeyFactory factory = KeyFactory.getInstance(Algorithm.RSA.name());\n// 根据提供的密钥规范生成publicKey和privateKey\nPrivateKey pk = factory.generatePrivate(pkcs);\nPublicKey k = factory.generatePublic(pkcs);\n\n// 将提供者可能未知或不受信任的密钥对象转换成次密钥工厂对应的密钥对象\nfactory.translateKey(pk);\n\n// 返回给定对象的规范\nfactory.getKeySpec(pk, PKCS8EncodedKeySpec.class);\n```\n同{@link KeyPairGenerator} 一样,它也是用来生成密钥(公钥和私钥)的引擎类,称之为密钥工厂\n按照指定的编码格式或密钥参数,提供一个用于输入和输出密钥的基础设施\n从另一方面来说KeyFactory 是通过密钥规范({@link KeySpec}) 还原密钥,\n与KeyFacory对应的是{@link SecretKeyFactory},用来生成秘密密钥\n\n## KeyPair.md对非对称密钥的拓展,是密钥对的载体,称之为密钥对一般是通过KeyPairGenerator#generateKeyPair()获得keyPair只能通过构造方法初始化内部的公钥和私钥,此外不提供设置公钥和私钥的方法\n\n## KeyPairGenerator\n```java\n// 生成指定算法的公钥私钥密钥对的KeyPairGenerator对象\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DH\");\n\n  与算法无关的初始化\n  所有密钥对生成器都共享大小概念和一个随机源\n  初始化给定密钥对大小的密钥对生成器,使用默认的参数集合,并使用以最高优先级安装的提供者的SecureRandom作为随机源\n  \n  keysize是用来控制密钥长度的,单位为位\n/\nkg.initialize(1024); // DH算法要求长度为64的倍数 长度为512-1024\n\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DH\");\n\n  特定算法的初始化\n  所有密钥对生成器都共享大小概念和一个随机源\n  初始化给定密钥对大小的密钥对生成器,使用默认的参数集合,并使用以最高优先级安装的提供者的SecureRandom作为随机源\n/\nkg.initialize(params);\n\n\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DH\");\nkg.initialize(1024); \n// generateKeyPair()由具体的密钥对生成器提供者实现\nKeyPair kp = kg.generateKeyPair();\n\n```\n引擎类. 负责生成公钥和私钥,称之为密钥对生成器,负责生成公钥和私钥,称之为密钥对生成器,同样是一个引擎类如果要生成私钥可以使用 {@link KeyGenerator}\n\n## KeyStore\n```java\nKeyStoreException, NoSuchAlgorithmException, CertificateException,\nUnrecoverableKeyException {\n// 加载密钥文件\ntry (FileInputStream in = new FileInputStream(\"\")) {\n// 实例化KeyStore对象\n// 根据Java安全属性文件中指定的默认密钥库类型, 如果不存在此类属性则返回字符串 jks\nKeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType());\n\n// 加载密钥库,使用密码\"password\"  (从给定输入流中加载和存储密钥库)\nks.load(in, \"password\".toCharArray());\n\n// 得到密钥对象后,可以获得其别名对应的私钥 ( 获得别名为\"alias\"所对应的私钥)\nPrivateKey pk = (PrivateKey) ks.getKey(\"alias\", \"password\".toCharArray());\n\n// 获得私钥项\n//PrivateKeyEntry pke = (KeyStore.PrivateKeyEntry) ks.getEntry( \"alias\", \"password\".toCharArray());\nPrivateKeyEntry pke = null;\n// 获得私钥\nPrivateKey privateKey = pke.getPrivateKey();\n\n// 返回此密钥库的类型\nks.getType();\n\n// 将此密钥存储到给定输出流,冰雨给定密码保护其完整性\n ks.store(new FileOutputStream(\"\"), \"password\".toCharArray());\n \n// 获取密钥库中的条目数\nks.size();\n\n// 在密钥库中,密钥和证书都是通过别名进行组织的\n// 通过以下方法获得密钥库的别名列表\nks.aliases();\n\n// 确定给定的别名是否在当前密钥库中\nks.containsAlias(\"\");\n\n// 返回与给定别名关联的密钥,并用给定密码来恢复他\n ks.getKey(\"alias\", \"password\".toCharArray());\n\n// 返回给定别名关联的证书\nCertificate cert = ks.getCertificate(\"alias\");\n\n// 返回给定别名关联的证书链\nCertificate[] chain = ks.getCertificateChain(\"alias\");\n\n// 返回证书给定证书匹配的第一个密钥库条目的别名\n ks.getCertificateAlias(cert);\n\n// 返回给定别名表示的条目的创建日期\nks.getCreationDate(\"alias\");\n\n// 删除次密钥库中给定别名标识的条目\nks.deleteEntry(\"\");\n\n// 将给定密钥(受保护的)分配给指定的别名\n ks.setKeyEntry(\"alias\", privateKey.getEncoded(), chain);\n\n// 将给定的密钥分配给给定的别名，并用给定密码保护他\n ks.setKeyEntry(\"alias\", privateKey, \"password\".toCharArray(), chain);\n\n// 将给定可信证书分配给给定别名\n ks.setCertificateEntry(\"alias\", cert);\n\n// 构造带私钥和相应证书链的私钥项\nPrivateKeyEntry pe = new KeyStore.PrivateKeyEntry(privateKey, null);\n\n// 从此死要内部的证书链数组首位中获取证书\npe.getCertificate();\n\n// 获取PrivateKey对象\npe.getPrivateKey();\nSecretKeyEntry ske = new KeyStore.SecretKeyEntry(\n(SecretKey) privateKey);\n\n// 秘密密钥项的主要作用是保护秘密密钥,通过如下方法获取秘密密钥\nske.getSecretKey();\n\n// 用可信证书构造信任证书项\nTrustedCertificateEntry tcf = new KeyStore.TrustedCertificateEntry(\n(Certificate) privateKey);\n\n// 从信任证书项获取可信证书\ntcf.getTrustedCertificate();\n}\n\t}\n}\n```\n称为密钥库,用于管理密钥和证书的存储\n密钥库类型：\n JKS,PKCS12,JCEKS 三种类型(名字不区分大小写)\n JCEKS 受美国出口限制\n PKCS12 这种类型的密钥库管理支持不是很完备,只能读取该类型的证书,却不能对其更改\nKeyStore.Entry接口是一个空借口,内部没有定义代码用于类型区分 KeyStore用于管理不同类型的条目,每种类型的条目都实现Entry接口\nEntry接口实现:\nPrivateKeyEntry:保存私钥和相应证书链的密钥库项\nSecretKeyEntry:保存私密密钥的密钥库项\nTrustedCertificateEntry:保存可信的证书的密钥库项\n## MessageDigest\n```java\n\n 通过指定算法获取MessageDigest 实例\n/\nMessageDigest.getInstance(\"MD5\");\n//MessageDigest.getInstance(\"MD5\", \"SunJCE\");// 使用SunJCE安全提供者提供的MD5 消息摘要\n//MessageDigest.getInstance(\"MD5\", new SunJCE());// 使用SunJCE安全提供者提供的MD5 消息摘要\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\n\nSystem.out.println(md.getAlgorithm());\nSystem.out.println(md.getProvider());\nSystem.out.println(md.getDigestLength());\n\n\n 使用指定字节更新摘要\n/\nmd.update((byte)1);\n\n\n 使用指定字节数组更新摘要\n \n md.update(new byte[]{(byte)1});\n/\n\n\n 使用指定字节数组和偏移量更新摘要\n \n md.update(new byte[]{(byte)1}, 1, 2);\n/\n\n\n 使用指定字节缓冲模式更新摘要\n \n md.update((byte)1);\n/\n\n\n 完成摘要更新后 完成摘要计算, 返回摘要数组\n/\nbyte[] digest = md.digest();\n\t\n\n 直接使用字节数组进行摘要更新同时完成摘要计算, 返回摘要数组\n \n md.digest(new byte[]{(byte)1});\n/\n\n\n\n 判断俩个摘要是否相等\n/\nbyte[] d1 = md.digest(new byte[]{(byte)1});\nbyte[] d2 = md.digest(new byte[]{(byte)2});\nboolean isEqual = MessageDigest.isEqual(d1, d2);\nAssert.assertEquals(false, isEqual);\n\nd1 = md.digest(new byte[]{(byte)1});\nd2 = md.digest(new byte[]{(byte)1});\nisEqual = MessageDigest.isEqual(d1, d2);\nAssert.assertEquals(true, isEqual);\n\n\n 重置摘要以供再次使用,执行该操作等同于创建一个新的MessageDigest实例\n/\nmd.reset();\n\nmd.clone(); // 如果实现是可复制的,则返回一个副本\n\t}\n\t\nbyte[] input = \"sha\".getBytes();\nMessageDigest sha = MessageDigest.getInstance(\"SHA\");\nsha.update(input);\nSystem.out.println(sha.digest());\n} catch (NoSuchAlgorithmException e) {\n}\n\t}\n}\n```\n实现了消息摘要算法\nJAVA7 支持 MD2 MD5 SHA-1 SHA-256 SHA-284 SHA-512 六种消息摘要算法\nMessageDigest DigestInputStream DigestOutputStream  Mac 均是消息认证的引擎类.\nMessageDigest : 提供核心的消息摘要实现\nDigestInputStream  DigestOutputStream  ： 为核心的消息摘要流实现\nMac ： 提供基于秘密密钥的安全消息摘要实现\nMac与MessageDigest没有任何依赖关系\n## Provider\n```java\n\n\n\n\nProvider provider = Security.getProvider(\"SUN\");\nSystem.out.println(\"Name : \" + provider.getName());\nSystem.out.println(\"Version : \" + provider.getVersion());\nSystem.out.println(\"Info : \" + provider.getInfo());\nSet<Entry<Object, Object>> keys = provider.entrySet();\nfor (Entry<Object, Object> entry : keys) {\nSystem.out.println(entry.getKey() + \" : \" + entry.getValue());\n}\n\n\t}\n}\n```\nProvider 可能实现的服务:DSA,RSA,MD5,SHA-1等算法,密钥的生成,转换和管理设置\n和 {@link Security} 一起构成了安全提供者\nJCA和JCE是Java平台用于安全和加密服务的俩组API,它们并不执行任何算法,它们只是链接应用和实际算法实现程序的一组接口\n软件开发商可以根据JCE接口将各种算法实现后打包成一个安全提供者.\n要实现一个完整的安全结构就需要一个或者多个第三方提供的JCE产品(安全提供者们)\n安全提供者抽象了俩个概念：\n引擎：可以理解为操作,如加密,解密\n算法：可以理解为如何加密,如何解密\nProvider 可能实现的服务:\n  DSA,RSA,MD5,SHA-1等算法\n  密钥的生成,转换和管理设置\nSUN\nSunRsaSign\nSunEC\nSunJSSE\nSunJCE\nSunJGSS\nSunSASL\nXMLDSig\nSunPCSC\nSunMSCAPI\n## SecureRandom.md```java\n\n\n\n\n {@link SecureRandom}\n \n \t安全随机数生成器   TODO\n SHA1PRNG是其默认算法\n \n\n/\n\n\nSecureRandom.getInstance(\"MD5\");\n\t}\n\t\nSecureRandom sr = SecureRandom.getInstance(\"MD5\");\n\n 可使用如下方法多次生成种子\n 返回给定种子字节数量,该数量可是要此类来将自身设置为种子的种子生成算法来计算\n/\nbyte[] seeds = sr.generateSeed(256);\n\t}\n\t\nSecureRandom sr = SecureRandom.getInstance(\"MD5\");\n// SecureRandom覆盖了Random几个方法.\n// 生成用户指定的随机字节数,其结果填充到byte[]数组中\nbyte[] bytes = new byte[1024];\nsr.nextBytes(bytes);\n\n\t}\n\t\n// TODO\n\t}\n}\n```\n安全随机数生成器 ,SHA1PRNG是其默认算法\n\n## Security\n```java\n\n\t\n\t 在提供者数组尾部增加新的提供者\n\t/\n\t}\n\t\n\t\n\t 在提供者数组某个位置增加新的提供者\n\t/\n//Security.insertProviderAt(provider, position)\n\t}\n\t\n\t\n\t 将带有指定名称的提供者从提供者数组中移除,其后提供者位置可能上移\n\t/\nSecurity.removeProvider(\"\");\n\t}\n\t\n\t\n\t 获取带有指定名称的提供者\n\t/\nSecurity.getProvider(\"\");\n\t}\n\t\n\t\n\t \n\t/\nSecurity.getProviders();\n\t}\n\t\n\t\n\t 返回包含制定的选择标准的所有已安装的提供者的数组(拷贝),如果尚未安装此类提供者,则返回null\n\t/\n//Security.getProviders(filter)\n\t}\n\t\n\t\n\t 返回包含制定的选择标准的所有已安装的提供者的数组(拷贝),如果尚未安装此类提供者,则返回null\n\t/\nSecurity.getProviders(\"\");\n\t}\n\t\n\t\n\t 获取安全属性值\n\t/\nSecurity.getProperty(\"\");\n\t}\n\t\n\t\n\t 设置安全属性值\n\t/\nSecurity.setProperty(\"\", \"\");\n\t}\n\t\n\t\n\t 通过指定加密服务所对应的可用算法活类型的名称\n\t \n\t/\nSecurity.getAlgorithms(\"\"); // TODO\n\t}\n\t\n\t\n}\n```\n管理java程序中所用到的提供者\nSecurity类是一个终态类,除了私有的构造方法外,其余均匀静态方法\n## Signature\n```java\n// 实例化对象\nSignature s = Signature.getInstance(\"NONEwithDSA\");\n// 使用指定的参数集初始化签名引擎\n//s.setParameter(params);\n// 获取与次签名对象一起使用的参数\ns.getParameters();\n// 根据私密密钥初始化要进行签名操作的签名对象\n//s.initSign(privateKey);\n// 根据公共密钥初始化要进行验证操作的签名对象 (验证一般数字签名)\n//s.initVerify(publicKey);\n// 根据公共密钥初始化要进行验证操作的签名对象 (验证签名证书)\n//s.initVerify(certificate);\n\n// 完成初始化操作便可更新Signature对象中的数据了\ns.update((byte)1);\n\n// 完成更新后便个做签名操作了,完成签名后返回了存储在缓冲区中的呃签名字节长度\nbyte[] signed = s.sign();\n\n// 开始验证\nboolean vResult = s.verify(signed);\n\n\t\n// 代做签名的原始信息\nbyte[] bytes = \"Data signture\".getBytes();\n// 实例化KeyPairGenerator对象\nKeyPairGenerator kpg = KeyPairGenerator.getInstance(\"DSA\");\nkpg.initialize(1024);\nKeyPair kp = kpg.genKeyPair();\n// 实例化Signature对象\nSignature s = Signature.getInstance(kpg.getAlgorithm());\n// 初始化用来签名操作的Signature对象\ns.initSign(kp.getPrivate());\n// 更新\ns.update(bytes);\n// 获得签名\nbyte[] sign = s.sign();\n/* 完成签名/\n\n\n// 用公钥完成验证\ns.initVerify(kp.getPublic());\n// 更新\ns.update(bytes);\n// 获得验证结果\nboolean status = s.verify(sign);\n\t}\n}\n```\n引擎类. 用来生成和验证数字签名.\n用来生成和验证数字签名.同样是引擎类\n使用Sinature对象签名数据或验证签名包括下面三个阶段\n1.初始化\n初始化验证签名的公钥\n初始化签署签名的私钥\n2.更新\n根绝初始化的类型,可更新要签名活验证的字节\n3.签署或验证所有更新字节的签名\n支持的算法\n\t基于:DSA\nNONEwithDSA,SHAwithDSA\n\t基于:RSA\nMD2whitRSA,MD5whitRSA,SHA1whitRSA,SHA256whitRSA,SHA256whitRSA,SHA384whitRSA,SHA512whitRSA\n## SignedObject\n\n签名对象通过以下构造方法完成实例化对象：\n通过任何可序列化对象构造Signedobject对象\npublic Signedobject(Serializable object,privateKey,Signature signingEngine)\n在完成上述实例化操作后，可通过以下方法获得封装后边的对象和签名：\n获取已封装的对象 --> getobject() \n\n在已签名对象上按字节数组的形式获取签名  -->\t getobject()\n接着，可以通过公钥和Signature进行验证操作：\n使用指派的验证引擎，通过给定的验证密钥验证Sibnedobject中的签名是否为内部存储对象的有效签名  verify()\n\n此外，SignedObject还提供了以下方法：\n获取签名算法的名称 getAlgorithm()\n\n\n```java\n// 代做签名的原始信息\nbyte[] bytes = \"Data signture\".getBytes();\n// 实例化KeyPairGenerator对象\nKeyPairGenerator kpg = KeyPairGenerator.getInstance(\"DSA\");\nkpg.initialize(1024);\nKeyPair kp = kpg.genKeyPair();\n// 实例化Signature对象\nSignature s = Signature.getInstance(kpg.getAlgorithm());\nSignedObject so = new SignedObject(bytes, kp.getPrivate(), s);\n// 获得签名\nbyte[] sign = so.getSignature();\n/* 完成签名/\n\n// 用公钥完成验证\n// 获得验证结果\nboolean status = so.verify(kp.getPublic(), s);\n\t}\n}\n```\n用来创建实际运行时的对象.在检测不到这些对象的情况下,其完整性不会遭受损害\nSignedObject包含另一个Serializable对象,即签名的对象及其签名.\n签名对象是对原始对象的深层复制(以序列化形式),一旦生成了副本对原始对的进一步操作就不再影响该副本\n\n## Timestamp\n用来封装有关签署时间戳的信息.它包括时间戳的日期和时间,以及有关生成时间戳的Timestamping Authority信息\n构建一个数字时间戳需要提供时间和签名证书路径（CertPath）两个参数，方法如下：\n构建一个Timestamp对象 --> Timestamp（）\n\n获得数字时间戳后的主要目的在于校验给定对象是否与此数字时间戳一致，方法如下：\n比较指定的对象和Timestamp对象是否相同 --> equals（）\n\n当然，我们可以通过数字时间戳获得相应的签名证书路径和生成数字时间戳的日期和时间，方法如下：\n返回Timestamping Authority的证书路径  --> getSignerCertPath()\n\n返回生成数字数字时间戳时的日期和时间  --> getTimestamp()\n\n此外，数字时间戳覆盖了以下两种方法：\n返回描述此数字时间戳的字符串tostring()\n```java\n// 构造一个数字时间戳\n// 构建CertificateFactory对象,并指定证书类型为x.509\nCertificateFactory cf = CertificateFactory.getInstance(\"509\");\n// 生成Certificate对象\nCertPath cp = cf.generateCertPath(new FileInputStream(\"\"));\n// 实例化时间戳\nTimestamp t = new Timestamp(new Date(), cp);\n\t}\n}\n```\n用来封装有关签署时间戳的信息.\n","source":"_posts/security/java_security.md","raw":"category: \n- security\ntitle: java_security\n---\n## AlgorithmParameterGenerator\n```java\nAlgorithmParameterGenerator apg = AlgorithmParameterGenerator.getInstance(Algorithm.DES.name());\n\n  与算法无关的初始化\n  所有参数生成器都共享大小概念和一个随机源\n  \n   特定于算法的参数生成值默认为某些标准值,除非他们可以从指定的大小派生\n   apg.init(size, random);\n/\napg.init(56);\n\n/*\n 实例化后就可以生成算法参数对象了\n/\nAlgorithmParameters ap = apg.generateParameters();\n\n// 获得字节数组\nbyte[] b = ap.getEncoded();\nSystem.out.println(new BigInteger(b).toString());\n\n\n  特定于算法的初始化\n  使用特定算法的语意初始化参数生成器对象,这些语意由特定于算法的参数生成值集合表示.\n  \n  apg.init(genParamSpec);\n  apg.init(genParamSpec, random);\n/\n\n```\n引擎类,用于生成某个特定算法中使用的参数集合.{@link AlgorithmParameters} 生成的参数\n## AlgorithmParameters.md\n```java\n// 实例化AlgorithmParameters 并指定DES算法\nAlgorithmParameters ap = AlgorithmParameters.getInstance(Algorithm.DES.name());\n// 使用BigInteger生成字节数组参数\nap.init(new BigInteger(\"19050619766489163472469\").toByteArray());\n// 获取参数字节数组\nbyte[] b = ap.getEncoded();\n// 打印经过BigInteger处理后的字符串,会得到与19050619766489163472469 相同的字符串\nSystem.out.println(\"BigInteger Encoded : \" + new BigInteger(b).toString());\n// 获取基本编码格式的参数\nSystem.out.println(\"Hex \t   Encoded : \" + Hex.toHexString(ap.getEncoded()));\n\n// 完成初始化后 获得参数对象的规范\n// ap.getParameterSpec(AlgorithmParameterSpec.class);\n// 使用 AlgorithmParameterSpec指定的参数初始化\n// ap.init(paramSpec);\n// 根据参数的基本解码格式导入指定的参数字节数组并对其解码\n// ap.init(new byte[]{});\n// 根据指定的解码方案从参数字节数组导入参数并对其解码\n// ap.init(params, format);\n\n// 注意的是 AlgorithmParameters对象只能被初始化一次,不能复用\n// ap.init(new byte[]{});\n\n// 获取此参数对象的算法的名称\nSystem.out.println(\"Algorithm : \" + ap.getAlgorithm());\n// 获取次参数对象的提供者\nSystem.out.println(\"Provider : \" + ap.getProvider());\n\n// 获取指定编码格式的参数\nap.getEncoded(\"\");\n\n```\n引擎类. 提供密码参数的不透明表示{@link AlgorithmParameters}AlgorithmParameters是一个引擎类,提供密码参数的不透明表示{@link AlgorithmParameterGenerator} 可以通过该引擎类生成不透明:不可以直接访问各参数域,只能得到与参数集相关联的算法名及该参数集的某类编码透明 :用户可以通过相应规范中定义的某个get方法来分别访问每个值\n## CodeSigner\n```java\n// 构建CertificateFactory对象,并指定证书类型为x.509\nCertificateFactory cf = CertificateFactory.getInstance(\"509\");\n// 生成Certificate对象\nCertPath cp = cf.generateCertPath(new FileInputStream(\"\"));\n// 实例化时间戳\nTimestamp t = new Timestamp(new Date(), cp);\n// 实例化CodeSinger对象\nCodeSigner cs = new CodeSigner(cp, t);\n// 对比\nboolean result = cs.equals(new CodeSigner(cp, t));\n```\n封装了代码签名者的信息,且他是不可变的,称之为代码签名 他和数字时间戳({@link Timestamp}) 紧密相连CodeSigner类是一个终态类,可以通过其构造方法完成实例化对象：\n* 构建CodeSigner对象 --> CodeSigner()\n完成实例化对象后,就可以通过以下方法获得其属性：\n* 返回签名者的CertPath对象 --> getSignerCertpath()\n* 返回签名时间戳  --> getTimestamp()注意,这里的Timestamp是java.security.Timestamp,是用做数字时间戳的Timestamp！\n获得CodeSigner对象后的最重要的操作就是执行比对,CodeSigner覆盖了equals()方法.\n测试指定对象与此CodeSigner对象是否相等 --> equals()\n如果,传入参数不是CodeSigner类的实现,则直接返回false.\n如果传入参数是CodeSigner类的实现,则比较其Timestamp和CerPath两个属性\n## DigestInputStream\n```java\n消息摘要输入流通过指定的读操作完成MessageDigest 的update()方法\n\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\ntry(FileInputStream in = new FileInputStream(new File(fileName));\nDigestInputStream dis = new DigestInputStream(in, md)) {\n\n\n 更新MessageDigest对象,将其与dis相关\n \n/\ndis.setMessageDigest(MessageDigest.getInstance(\"MD2\"));\n\n\n 读取字节 并更新摘要\n read会调用MessageDigest的update()方法完成摘要更新\n 之后通过nmd的digest完成摘要操作\n/\ndis.read();\n//  获取流中相关的MessageDigest\nMessageDigest nmd = dis.getMessageDigest();\nnmd.digest();\n\n//关闭DigestInputStream摘要功能,则该流就变成一般的流\ndis.on(false);\n\n// 待做消息摘要操作的原始信息\nbyte[] input = \"md5\".getBytes();\n// 使用MD5算法初始化MessageDigest对象\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\n\ntry(DigestInputStream dis = new DigestInputStream(\nnew ByteArrayInputStream(input), md)) {\n\t\n\tdis.read(input, 0, input.length);\n\tMessageDigest nmd = dis.getMessageDigest();\n\t// 获得摘要信息\n\tbyte[] output = nmd.digest();\n\tSystem.out.println(output);\n\n```\n消息摘要输入流通过指定的读操作完成MessageDigest 的update()方法\n\n## DigestOutputStream\n```java\n\n消息摘要输出流通过指定的写操作完成MessageDigest 的update()方法. 基本上和DigestInputStream类似\n\n\n// 待做消息摘要操作的原始信息\nbyte[] input = \"md5\".getBytes();\n// 使用MD5算法初始化MessageDigest对象\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\n\ntry (DigestOutputStream dis = new DigestOutputStream(\nnew ByteArrayOutputStream(), md)) {\n\t// 流输出\n\tdis.write(input, 0, input.length);\n\tMessageDigest nmd = dis.getMessageDigest();\n\t// 获得摘要信息\n\tbyte[] output = nmd.digest();\n\tSystem.out.println(output);\n\n\tdis.flush();\n```\n消息摘要输出流通过指定的写操作完成MessageDigest 的update()方法\n\n## Key\nKey接口是所有密钥接口的顶层接口,一切与加密有关的操作都离不开Key接口\n由于密钥必须在不同的实体间传输,因此所有的密钥都是可序列话的\n所有的密钥都具有三个形式\n算法:密钥算法, 如DES和DSA. getAlgorithm()\n编码形式:密钥的外部编码形式,密钥根据标准格式(RKC#8)编码,  getEncode()\n格式:已编码密钥的格式的名称,getFormat()\n对称密钥顶层接口\n{@link SecretKey}\n通常使用的是{@link SecretKeySpec}\nDES,AES 等多种对称密码算法均可通过该接口提供,PBE接口提供PBE算法定义并继承了该接口\nMAC算法实现过程中,通过SecretKey接口提供秘密秘钥\n非对称密钥顶层接口\n{@link PublicKey} 公钥接口\n{@link PrivateKey} 私钥接口\nDh,RSA,DSA,EC等多种非对称秘钥接口均继承了这俩个接口\n## KeyFactory\n```java\nKeyPairGenerator generator = KeyPairGenerator.getInstance(Algorithm.RSA.name());\ngenerator.initialize(1024);\nKeyPair kp = generator.genKeyPair();\n// 获得私钥密钥字节数组.使用过程中该密钥以此种形式保存传递给另一方\nbyte[] privateBytes = kp.getPrivate().getEncoded();\n// 由私钥密钥字节数组获得密钥规范\nPKCS8EncodedKeySpec pkcs = new PKCS8EncodedKeySpec(privateBytes);\n\n// 实例化密钥工厂,并指定RSA算法\nKeyFactory factory = KeyFactory.getInstance(Algorithm.RSA.name());\n// 根据提供的密钥规范生成publicKey和privateKey\nPrivateKey pk = factory.generatePrivate(pkcs);\nPublicKey k = factory.generatePublic(pkcs);\n\n// 将提供者可能未知或不受信任的密钥对象转换成次密钥工厂对应的密钥对象\nfactory.translateKey(pk);\n\n// 返回给定对象的规范\nfactory.getKeySpec(pk, PKCS8EncodedKeySpec.class);\n```\n同{@link KeyPairGenerator} 一样,它也是用来生成密钥(公钥和私钥)的引擎类,称之为密钥工厂\n按照指定的编码格式或密钥参数,提供一个用于输入和输出密钥的基础设施\n从另一方面来说KeyFactory 是通过密钥规范({@link KeySpec}) 还原密钥,\n与KeyFacory对应的是{@link SecretKeyFactory},用来生成秘密密钥\n\n## KeyPair.md对非对称密钥的拓展,是密钥对的载体,称之为密钥对一般是通过KeyPairGenerator#generateKeyPair()获得keyPair只能通过构造方法初始化内部的公钥和私钥,此外不提供设置公钥和私钥的方法\n\n## KeyPairGenerator\n```java\n// 生成指定算法的公钥私钥密钥对的KeyPairGenerator对象\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DH\");\n\n  与算法无关的初始化\n  所有密钥对生成器都共享大小概念和一个随机源\n  初始化给定密钥对大小的密钥对生成器,使用默认的参数集合,并使用以最高优先级安装的提供者的SecureRandom作为随机源\n  \n  keysize是用来控制密钥长度的,单位为位\n/\nkg.initialize(1024); // DH算法要求长度为64的倍数 长度为512-1024\n\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DH\");\n\n  特定算法的初始化\n  所有密钥对生成器都共享大小概念和一个随机源\n  初始化给定密钥对大小的密钥对生成器,使用默认的参数集合,并使用以最高优先级安装的提供者的SecureRandom作为随机源\n/\nkg.initialize(params);\n\n\nKeyPairGenerator kg = KeyPairGenerator.getInstance(\"DH\");\nkg.initialize(1024); \n// generateKeyPair()由具体的密钥对生成器提供者实现\nKeyPair kp = kg.generateKeyPair();\n\n```\n引擎类. 负责生成公钥和私钥,称之为密钥对生成器,负责生成公钥和私钥,称之为密钥对生成器,同样是一个引擎类如果要生成私钥可以使用 {@link KeyGenerator}\n\n## KeyStore\n```java\nKeyStoreException, NoSuchAlgorithmException, CertificateException,\nUnrecoverableKeyException {\n// 加载密钥文件\ntry (FileInputStream in = new FileInputStream(\"\")) {\n// 实例化KeyStore对象\n// 根据Java安全属性文件中指定的默认密钥库类型, 如果不存在此类属性则返回字符串 jks\nKeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType());\n\n// 加载密钥库,使用密码\"password\"  (从给定输入流中加载和存储密钥库)\nks.load(in, \"password\".toCharArray());\n\n// 得到密钥对象后,可以获得其别名对应的私钥 ( 获得别名为\"alias\"所对应的私钥)\nPrivateKey pk = (PrivateKey) ks.getKey(\"alias\", \"password\".toCharArray());\n\n// 获得私钥项\n//PrivateKeyEntry pke = (KeyStore.PrivateKeyEntry) ks.getEntry( \"alias\", \"password\".toCharArray());\nPrivateKeyEntry pke = null;\n// 获得私钥\nPrivateKey privateKey = pke.getPrivateKey();\n\n// 返回此密钥库的类型\nks.getType();\n\n// 将此密钥存储到给定输出流,冰雨给定密码保护其完整性\n ks.store(new FileOutputStream(\"\"), \"password\".toCharArray());\n \n// 获取密钥库中的条目数\nks.size();\n\n// 在密钥库中,密钥和证书都是通过别名进行组织的\n// 通过以下方法获得密钥库的别名列表\nks.aliases();\n\n// 确定给定的别名是否在当前密钥库中\nks.containsAlias(\"\");\n\n// 返回与给定别名关联的密钥,并用给定密码来恢复他\n ks.getKey(\"alias\", \"password\".toCharArray());\n\n// 返回给定别名关联的证书\nCertificate cert = ks.getCertificate(\"alias\");\n\n// 返回给定别名关联的证书链\nCertificate[] chain = ks.getCertificateChain(\"alias\");\n\n// 返回证书给定证书匹配的第一个密钥库条目的别名\n ks.getCertificateAlias(cert);\n\n// 返回给定别名表示的条目的创建日期\nks.getCreationDate(\"alias\");\n\n// 删除次密钥库中给定别名标识的条目\nks.deleteEntry(\"\");\n\n// 将给定密钥(受保护的)分配给指定的别名\n ks.setKeyEntry(\"alias\", privateKey.getEncoded(), chain);\n\n// 将给定的密钥分配给给定的别名，并用给定密码保护他\n ks.setKeyEntry(\"alias\", privateKey, \"password\".toCharArray(), chain);\n\n// 将给定可信证书分配给给定别名\n ks.setCertificateEntry(\"alias\", cert);\n\n// 构造带私钥和相应证书链的私钥项\nPrivateKeyEntry pe = new KeyStore.PrivateKeyEntry(privateKey, null);\n\n// 从此死要内部的证书链数组首位中获取证书\npe.getCertificate();\n\n// 获取PrivateKey对象\npe.getPrivateKey();\nSecretKeyEntry ske = new KeyStore.SecretKeyEntry(\n(SecretKey) privateKey);\n\n// 秘密密钥项的主要作用是保护秘密密钥,通过如下方法获取秘密密钥\nske.getSecretKey();\n\n// 用可信证书构造信任证书项\nTrustedCertificateEntry tcf = new KeyStore.TrustedCertificateEntry(\n(Certificate) privateKey);\n\n// 从信任证书项获取可信证书\ntcf.getTrustedCertificate();\n}\n\t}\n}\n```\n称为密钥库,用于管理密钥和证书的存储\n密钥库类型：\n JKS,PKCS12,JCEKS 三种类型(名字不区分大小写)\n JCEKS 受美国出口限制\n PKCS12 这种类型的密钥库管理支持不是很完备,只能读取该类型的证书,却不能对其更改\nKeyStore.Entry接口是一个空借口,内部没有定义代码用于类型区分 KeyStore用于管理不同类型的条目,每种类型的条目都实现Entry接口\nEntry接口实现:\nPrivateKeyEntry:保存私钥和相应证书链的密钥库项\nSecretKeyEntry:保存私密密钥的密钥库项\nTrustedCertificateEntry:保存可信的证书的密钥库项\n## MessageDigest\n```java\n\n 通过指定算法获取MessageDigest 实例\n/\nMessageDigest.getInstance(\"MD5\");\n//MessageDigest.getInstance(\"MD5\", \"SunJCE\");// 使用SunJCE安全提供者提供的MD5 消息摘要\n//MessageDigest.getInstance(\"MD5\", new SunJCE());// 使用SunJCE安全提供者提供的MD5 消息摘要\nMessageDigest md = MessageDigest.getInstance(\"MD5\");\n\nSystem.out.println(md.getAlgorithm());\nSystem.out.println(md.getProvider());\nSystem.out.println(md.getDigestLength());\n\n\n 使用指定字节更新摘要\n/\nmd.update((byte)1);\n\n\n 使用指定字节数组更新摘要\n \n md.update(new byte[]{(byte)1});\n/\n\n\n 使用指定字节数组和偏移量更新摘要\n \n md.update(new byte[]{(byte)1}, 1, 2);\n/\n\n\n 使用指定字节缓冲模式更新摘要\n \n md.update((byte)1);\n/\n\n\n 完成摘要更新后 完成摘要计算, 返回摘要数组\n/\nbyte[] digest = md.digest();\n\t\n\n 直接使用字节数组进行摘要更新同时完成摘要计算, 返回摘要数组\n \n md.digest(new byte[]{(byte)1});\n/\n\n\n\n 判断俩个摘要是否相等\n/\nbyte[] d1 = md.digest(new byte[]{(byte)1});\nbyte[] d2 = md.digest(new byte[]{(byte)2});\nboolean isEqual = MessageDigest.isEqual(d1, d2);\nAssert.assertEquals(false, isEqual);\n\nd1 = md.digest(new byte[]{(byte)1});\nd2 = md.digest(new byte[]{(byte)1});\nisEqual = MessageDigest.isEqual(d1, d2);\nAssert.assertEquals(true, isEqual);\n\n\n 重置摘要以供再次使用,执行该操作等同于创建一个新的MessageDigest实例\n/\nmd.reset();\n\nmd.clone(); // 如果实现是可复制的,则返回一个副本\n\t}\n\t\nbyte[] input = \"sha\".getBytes();\nMessageDigest sha = MessageDigest.getInstance(\"SHA\");\nsha.update(input);\nSystem.out.println(sha.digest());\n} catch (NoSuchAlgorithmException e) {\n}\n\t}\n}\n```\n实现了消息摘要算法\nJAVA7 支持 MD2 MD5 SHA-1 SHA-256 SHA-284 SHA-512 六种消息摘要算法\nMessageDigest DigestInputStream DigestOutputStream  Mac 均是消息认证的引擎类.\nMessageDigest : 提供核心的消息摘要实现\nDigestInputStream  DigestOutputStream  ： 为核心的消息摘要流实现\nMac ： 提供基于秘密密钥的安全消息摘要实现\nMac与MessageDigest没有任何依赖关系\n## Provider\n```java\n\n\n\n\nProvider provider = Security.getProvider(\"SUN\");\nSystem.out.println(\"Name : \" + provider.getName());\nSystem.out.println(\"Version : \" + provider.getVersion());\nSystem.out.println(\"Info : \" + provider.getInfo());\nSet<Entry<Object, Object>> keys = provider.entrySet();\nfor (Entry<Object, Object> entry : keys) {\nSystem.out.println(entry.getKey() + \" : \" + entry.getValue());\n}\n\n\t}\n}\n```\nProvider 可能实现的服务:DSA,RSA,MD5,SHA-1等算法,密钥的生成,转换和管理设置\n和 {@link Security} 一起构成了安全提供者\nJCA和JCE是Java平台用于安全和加密服务的俩组API,它们并不执行任何算法,它们只是链接应用和实际算法实现程序的一组接口\n软件开发商可以根据JCE接口将各种算法实现后打包成一个安全提供者.\n要实现一个完整的安全结构就需要一个或者多个第三方提供的JCE产品(安全提供者们)\n安全提供者抽象了俩个概念：\n引擎：可以理解为操作,如加密,解密\n算法：可以理解为如何加密,如何解密\nProvider 可能实现的服务:\n  DSA,RSA,MD5,SHA-1等算法\n  密钥的生成,转换和管理设置\nSUN\nSunRsaSign\nSunEC\nSunJSSE\nSunJCE\nSunJGSS\nSunSASL\nXMLDSig\nSunPCSC\nSunMSCAPI\n## SecureRandom.md```java\n\n\n\n\n {@link SecureRandom}\n \n \t安全随机数生成器   TODO\n SHA1PRNG是其默认算法\n \n\n/\n\n\nSecureRandom.getInstance(\"MD5\");\n\t}\n\t\nSecureRandom sr = SecureRandom.getInstance(\"MD5\");\n\n 可使用如下方法多次生成种子\n 返回给定种子字节数量,该数量可是要此类来将自身设置为种子的种子生成算法来计算\n/\nbyte[] seeds = sr.generateSeed(256);\n\t}\n\t\nSecureRandom sr = SecureRandom.getInstance(\"MD5\");\n// SecureRandom覆盖了Random几个方法.\n// 生成用户指定的随机字节数,其结果填充到byte[]数组中\nbyte[] bytes = new byte[1024];\nsr.nextBytes(bytes);\n\n\t}\n\t\n// TODO\n\t}\n}\n```\n安全随机数生成器 ,SHA1PRNG是其默认算法\n\n## Security\n```java\n\n\t\n\t 在提供者数组尾部增加新的提供者\n\t/\n\t}\n\t\n\t\n\t 在提供者数组某个位置增加新的提供者\n\t/\n//Security.insertProviderAt(provider, position)\n\t}\n\t\n\t\n\t 将带有指定名称的提供者从提供者数组中移除,其后提供者位置可能上移\n\t/\nSecurity.removeProvider(\"\");\n\t}\n\t\n\t\n\t 获取带有指定名称的提供者\n\t/\nSecurity.getProvider(\"\");\n\t}\n\t\n\t\n\t \n\t/\nSecurity.getProviders();\n\t}\n\t\n\t\n\t 返回包含制定的选择标准的所有已安装的提供者的数组(拷贝),如果尚未安装此类提供者,则返回null\n\t/\n//Security.getProviders(filter)\n\t}\n\t\n\t\n\t 返回包含制定的选择标准的所有已安装的提供者的数组(拷贝),如果尚未安装此类提供者,则返回null\n\t/\nSecurity.getProviders(\"\");\n\t}\n\t\n\t\n\t 获取安全属性值\n\t/\nSecurity.getProperty(\"\");\n\t}\n\t\n\t\n\t 设置安全属性值\n\t/\nSecurity.setProperty(\"\", \"\");\n\t}\n\t\n\t\n\t 通过指定加密服务所对应的可用算法活类型的名称\n\t \n\t/\nSecurity.getAlgorithms(\"\"); // TODO\n\t}\n\t\n\t\n}\n```\n管理java程序中所用到的提供者\nSecurity类是一个终态类,除了私有的构造方法外,其余均匀静态方法\n## Signature\n```java\n// 实例化对象\nSignature s = Signature.getInstance(\"NONEwithDSA\");\n// 使用指定的参数集初始化签名引擎\n//s.setParameter(params);\n// 获取与次签名对象一起使用的参数\ns.getParameters();\n// 根据私密密钥初始化要进行签名操作的签名对象\n//s.initSign(privateKey);\n// 根据公共密钥初始化要进行验证操作的签名对象 (验证一般数字签名)\n//s.initVerify(publicKey);\n// 根据公共密钥初始化要进行验证操作的签名对象 (验证签名证书)\n//s.initVerify(certificate);\n\n// 完成初始化操作便可更新Signature对象中的数据了\ns.update((byte)1);\n\n// 完成更新后便个做签名操作了,完成签名后返回了存储在缓冲区中的呃签名字节长度\nbyte[] signed = s.sign();\n\n// 开始验证\nboolean vResult = s.verify(signed);\n\n\t\n// 代做签名的原始信息\nbyte[] bytes = \"Data signture\".getBytes();\n// 实例化KeyPairGenerator对象\nKeyPairGenerator kpg = KeyPairGenerator.getInstance(\"DSA\");\nkpg.initialize(1024);\nKeyPair kp = kpg.genKeyPair();\n// 实例化Signature对象\nSignature s = Signature.getInstance(kpg.getAlgorithm());\n// 初始化用来签名操作的Signature对象\ns.initSign(kp.getPrivate());\n// 更新\ns.update(bytes);\n// 获得签名\nbyte[] sign = s.sign();\n/* 完成签名/\n\n\n// 用公钥完成验证\ns.initVerify(kp.getPublic());\n// 更新\ns.update(bytes);\n// 获得验证结果\nboolean status = s.verify(sign);\n\t}\n}\n```\n引擎类. 用来生成和验证数字签名.\n用来生成和验证数字签名.同样是引擎类\n使用Sinature对象签名数据或验证签名包括下面三个阶段\n1.初始化\n初始化验证签名的公钥\n初始化签署签名的私钥\n2.更新\n根绝初始化的类型,可更新要签名活验证的字节\n3.签署或验证所有更新字节的签名\n支持的算法\n\t基于:DSA\nNONEwithDSA,SHAwithDSA\n\t基于:RSA\nMD2whitRSA,MD5whitRSA,SHA1whitRSA,SHA256whitRSA,SHA256whitRSA,SHA384whitRSA,SHA512whitRSA\n## SignedObject\n\n签名对象通过以下构造方法完成实例化对象：\n通过任何可序列化对象构造Signedobject对象\npublic Signedobject(Serializable object,privateKey,Signature signingEngine)\n在完成上述实例化操作后，可通过以下方法获得封装后边的对象和签名：\n获取已封装的对象 --> getobject() \n\n在已签名对象上按字节数组的形式获取签名  -->\t getobject()\n接着，可以通过公钥和Signature进行验证操作：\n使用指派的验证引擎，通过给定的验证密钥验证Sibnedobject中的签名是否为内部存储对象的有效签名  verify()\n\n此外，SignedObject还提供了以下方法：\n获取签名算法的名称 getAlgorithm()\n\n\n```java\n// 代做签名的原始信息\nbyte[] bytes = \"Data signture\".getBytes();\n// 实例化KeyPairGenerator对象\nKeyPairGenerator kpg = KeyPairGenerator.getInstance(\"DSA\");\nkpg.initialize(1024);\nKeyPair kp = kpg.genKeyPair();\n// 实例化Signature对象\nSignature s = Signature.getInstance(kpg.getAlgorithm());\nSignedObject so = new SignedObject(bytes, kp.getPrivate(), s);\n// 获得签名\nbyte[] sign = so.getSignature();\n/* 完成签名/\n\n// 用公钥完成验证\n// 获得验证结果\nboolean status = so.verify(kp.getPublic(), s);\n\t}\n}\n```\n用来创建实际运行时的对象.在检测不到这些对象的情况下,其完整性不会遭受损害\nSignedObject包含另一个Serializable对象,即签名的对象及其签名.\n签名对象是对原始对象的深层复制(以序列化形式),一旦生成了副本对原始对的进一步操作就不再影响该副本\n\n## Timestamp\n用来封装有关签署时间戳的信息.它包括时间戳的日期和时间,以及有关生成时间戳的Timestamping Authority信息\n构建一个数字时间戳需要提供时间和签名证书路径（CertPath）两个参数，方法如下：\n构建一个Timestamp对象 --> Timestamp（）\n\n获得数字时间戳后的主要目的在于校验给定对象是否与此数字时间戳一致，方法如下：\n比较指定的对象和Timestamp对象是否相同 --> equals（）\n\n当然，我们可以通过数字时间戳获得相应的签名证书路径和生成数字时间戳的日期和时间，方法如下：\n返回Timestamping Authority的证书路径  --> getSignerCertPath()\n\n返回生成数字数字时间戳时的日期和时间  --> getTimestamp()\n\n此外，数字时间戳覆盖了以下两种方法：\n返回描述此数字时间戳的字符串tostring()\n```java\n// 构造一个数字时间戳\n// 构建CertificateFactory对象,并指定证书类型为x.509\nCertificateFactory cf = CertificateFactory.getInstance(\"509\");\n// 生成Certificate对象\nCertPath cp = cf.generateCertPath(new FileInputStream(\"\"));\n// 实例化时间戳\nTimestamp t = new Timestamp(new Date(), cp);\n\t}\n}\n```\n用来封装有关签署时间戳的信息.\n","slug":"security/java_security","published":1,"date":"2015-09-18T07:15:44.443Z","updated":"2015-09-18T07:14:37.045Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9r000n74uf73v7gwd5"},{"_content":"category: \n- security\ntitle: README\ncategory: \n- 加密\ntitle: README\n# JDK加密\n## java.security包详解\n\n#### javax_crypto\n###### Cipher\n* [Cipher](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestCipher.java)\n```\n为加密解密提供密码功能,它构成了Java Cryptographic Extension(JCE) 框架核心.\n在java.security包中 只完成了密钥的处理 并未完成加密与解密的操作. 这些核心 操作需要通过Cipher类来实现.\n```\n* [CipherInputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestCipherInputStream.java)\n```\nCiper的拓展,称为密钥拓展流\n```\n\n* [CipherOutputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestCipherOutputStream.java)\n\n```\n密钥输出流\n```\n\n* [SealedObject](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestSealedObject.java)\n\n```\nScaledObject使程序员能够用加密算法创建对象并保护其机密性\n在给定任何Serializable对象的情况下,程序员可以序列化格式(即深层复制)封装原始对象的SealedObject\n并使用类似于DES的加密算法密封(加密)其序列化的内容,保护其机密性\n\n加密的内容以后可以解密和烦序列话,生成原始对象\n\n已密封的原始对象可以使用以下俩种方式恢复\n1.使用采用Cipher对象的getObject)方法.\n\t\t此方法需要一个完全初始化的Cipher对象,用相同的用来蜜蜂对象的算法,密钥,填充方案等进行初始化.\n\t\t这样做的好处是解封密封 对象的一方不需要知道解密密钥. 例如一方用所需的解密密钥初始化Cipher对象之后,\n\t\t它就会将Cipher对象移交给以后要解封密封对象的另一方\n2.使用采用Key对象的getObject()方法.\n\t\t在此方法中getObject方法创建一个用于适当解密算法的Cipher对象\n\t\t并用给定的解密密钥和存储在密封对象中的算法参数 (如果有)对其进行初始化.\n\t\t这样做的好处是解封此对象的一方不需要跟踪用来密封该对象的参数 (如IV 、 初始化向量).\n```\n\n###### MacMessageDigest\n\n* [KeyAgreement](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestKeyAgreement.java)\n\n```\nKeyAgreement类提供密钥协定协议的功能,它同样是一个引擎类.\n我们称它为密钥协定,将在DH算法实现中使用到它.\n```\n\n* [KeyGenerator](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestKeyGenerator.java)\n\n```\nKeyGenerator类与KeypairGenerato类相似,\nKeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\nKeyGenerator类与KeypairGenerato类相似,KeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\n生成用于对称加密算法的秘密密钥,并提供相关信息 public class KeyGenerator extends Object\n\nJava7版本中提供了Blowfish、AES、DES和DESede等多种对称加密算法实现,以及HmacMD5、\nHmacSHA1和HmacSHA256等多种安全消息摘要算法实现\n```\n\n* [Mac](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestMac.java)\n\n```\nMac属于消息摘要的一种,但它不同于一般消息摘要（如Message Digest提供的消息摘要实现）,\n仅通过输入数据无法活的吧消息摘要,必须有一个由发送方和接收方\n共享的秘密密钥才能生成最终的消息摘要——安全消息摘要.安全消息摘要又称消息认证（鉴别）码.\n```\n\n* [SecretKeyFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestSecretKeyFactory.java)\n\n```\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,\n它用于产生秘密密钥,我们称之为秘密密钥工厂.\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,它用于产生秘密密钥,我们称之为秘密密钥工厂.\n  此类表示秘密密钥的工厂\n```\n\n###### javax_net_ssl 包用于提供安全套接字包的类,该包对构建秘钥库,\n信任管理库及构建安全基于HTTPS的加密网络通信实现的知识\n\n* [HttpsURLConnection](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestHttpsURLConnection.java)\n\n```\nHttpsURLConnection 拓展了URLConnection, 支持各种特定于Https的功能\n```\n\n* [KeyManagerFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestKeyManagerFactory.java)\n\n```\n用来管理秘钥,设定秘钥库. 此类充当基于秘钥内容源的秘钥管理器的工厂.每个秘钥管理器管理特定类型的,由套接字所使用的秘钥内容\n```\n\n* [SSLContext](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLContext.java)\n\n```\n表示安全套接字上下文,安全套接字协议的实现,它充当于安全套接字工厂或者SSLEngine的工厂\n用可选的一组秘钥和信任管理器及安全随机字节初始化此类\n```\n\n* [SSLServerSocket](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLServerSocket.java)\n\n```\n   SSLServerSocket\n```\n\n* [SSLServerSocketFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLServerSocketFactory.java)\n\n```\n   SSLServerSocketFactory\n```\n\n* [SSLSession](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLSession.java)\n\n```\nSSLSession 接口用于保持SSL协议网络交互会话状态. 用来描述俩个实体之间的会话关系\n在SSL的会话中,可以获得加密套件(CipherSuite),数字证书等\n\nCipherSuite 明确给出了加密参数, 具体包括：协议,秘钥交换算法,加密算法,工作模式和消息摘要算法\n如 TLS_RSA_TITH_AES_256_CBC_SHA 就是一个完成加密套件信息, 它表示：\n使用TLS协议,迷药交换算法为RSA,对称加密算法为AES(长度256),使用CBC模式,并使用SHA消息摘要算法\n```\n\n* [SSLSocket](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLSocket.java)\n\n```\nSSLSocket是基于SSL协议的Socket,用于设置加密套件,处理握手结束事件,并管理SSLSession\n\n目前Java环境中支持的协议有：SSLLv2Hello,SSLv3,TLSv1,TlSv1.1, TLSv1.2\n通常默认的是SSLv3和TLSv1.1\nsetEnabledProtocols(protocols);  通过该方法设置SSL链接可用协议\n\n\ngetSupportedCipherSuites()\t\t获得可支持的加密套件\nsetEnabledCipherSuites(suites)\t为当前SSL链接设置可用的加密套件\ngetEnabledCipherSuites()\t\t\t获得当前SSL链接可用的加密套件\n\n有时候需要与远程服务器建立基于SSLSocket的链接. 远程服务仅通过SSLSocket传递数字证书.\n这时候,就不能通过HttpsURLConnection来获得数字证书了,本方法就是通过SSLSocket来获得SSLSession\n并最终获得数字证书\n```\n\n* [SSLSocketFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLSocketFactory.java)\n\n```\n   SSLSocketFactory\n```\n\n* [TrustManagerFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestTrustManagerFactory.java)\n\n```\n 管理信任材料的管理工厂,设定信任库\n\n 每个信任管理器管理特定类型的由安全套接字使用的信任材料\n```\n\n###### java_security  为安全框架提供类和接口, 该包只能完成消息摘要算法的实现,同时提供数字签名和秘钥接口的定义\n\n* [AlgorithmParameterGenerator](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestAlgorithmParameterGenerator.java)\n\n```\n引擎类,用于生成某个特定算法中使用的参数集合.\n\n{@link AlgorithmParameters} 生成的参数\n```\n\n* [AlgorithmParameters](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestAlgorithmParameters.java)\n\n```\n引擎类. 提供密码参数的不透明表示\n{@link AlgorithmParameters}\nAlgorithmParameters是一个引擎类,提供密码参数的不透明表示\n\n{@link AlgorithmParameterGenerator} 可以通过该引擎类生成\n\n不透明:不可以直接访问各参数域,只能得到与参数集相关联的算法名及该参数集的某类编码\n透明 :用户可以通过相应规范中定义的某个get方法来分别访问每个值\n```\n\n###### Key\n\n* [Key](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKey.java)\n\n```\nKey接口是所有密钥接口的顶层接口,一切与加密有关的操作都离不开Key接口\nKey接口是所有密钥接口的顶层接口,一切与加密有关的操作都离不开Key接口\n由于密钥必须在不同的实体间传输,因此所有的密钥都是可序列话的\n\n所有的密钥都具有三个形式\n算法:密钥算法, 如DES和DSA. getAlgorithm()\n编码形式:密钥的外部编码形式,密钥根据标准格式(RKC#8)编码,  getEncode()\n格式:已编码密钥的格式的名称,getFormat()\n\n对称密钥顶层接口\n{@link SecretKey}\n\t\t通常使用的是{@link SecretKeySpec}\nDES,AES 等多种对称密码算法均可通过该接口提供,PBE接口提供PBE算法定义并继承了该接口\nMAC算法实现过程中,通过SecretKey接口提供秘密秘钥\n\n非对称密钥顶层接口\n{@link PublicKey} 公钥接口\n{@link PrivateKey} 私钥接口\nDh,RSA,DSA,EC等多种非对称秘钥接口均继承了这俩个接口\n```\n\n* [KeyFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyFactory.java)\n\n```java\n同{@link KeyPairGenerator} 一样,它也是用来生成密钥(公钥和私钥)的引擎类,称之为密钥工厂\n按照指定的编码格式或密钥参数,提供一个用于输入和输出密钥的基础设施\n\n从另一方面来说KeyFactory 是通过密钥规范({@link KeySpec}) 还原密钥,\n与KeyFacory对应的是{@link SecretKeyFactory},用来生成秘密密钥\n```\n\n* [KeyPair](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyPair.java)\n\n```java\n对非对称密钥的拓展,是密钥对的载体,称之为密钥对\n\n一般是通过KeyPairGenerator#generateKeyPair()获得\n\nkeyPair只能通过构造方法初始化内部的公钥和私钥,此外不提供设置公钥和私钥的方法\n```\n\n* [KeyPairGenerator](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyPairGenerator.java)\n\n```\n引擎类. 负责生成公钥和私钥,称之为密钥对生成器,\n负责生成公钥和私钥,称之为密钥对生成器,同样是一个引擎类\n如果要生成私钥可以使用 {@link KeyGenerator}\n```\n\n* [KeyStore](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyStore.java)\n\n```java\n称为密钥库,用于管理密钥和证书的存储\n\n密钥库类型：\n JKS,PKCS12,JCEKS 三种类型(名字不区分大小写)\n JCEKS 受美国出口限制\n PKCS12 这种类型的密钥库管理支持不是很完备,只能读取该类型的证书,却不能对其更改\n\nKeyStore.Entry接口是一个空借口,内部没有定义代码用于类型区分 KeyStore用于管理不同类型的条目,每种类型的条目都实现Entry接口\n\nEntry接口实现:\nPrivateKeyEntry:保存私钥和相应证书链的密钥库项\nSecretKeyEntry:保存私密密钥的密钥库项\nTrustedCertificateEntry:保存可信的证书的密钥库项\n```\n\n###### MessageDigest\n\n* [DigestInputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testMessageDigest/TestDigestInputStream.java)\n\n```\n消息摘要输入流通过指定的读操作完成MessageDigest 的update()方法\n```\n\n* [DigestOutputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testMessageDigest/TestDigestOutputStream.java)\n\n```\n消息摘要输出流通过指定的写操作完成MessageDigest 的update()方法\n```\n\n* [MessageDigest](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testMessageDigest/TestMessageDigest.java)\n\n```\n实现了消息摘要算法\nJAVA7 支持 MD2 MD5 SHA-1 SHA-256 SHA-284 SHA-512 六种消息摘要算法\n\nMessageDigest DigestInputStream DigestOutputStream  Mac 均是消息认证的引擎类.\nMessageDigest : 提供核心的消息摘要实现\nDigestInputStream  DigestOutputStream  ： 为核心的消息摘要流实现\nMac ： 提供基于秘密密钥的安全消息摘要实现\n\nMac与MessageDigest没有任何依赖关系\n```\n\n* [Provider](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestProvider.java)\n\n```\nProvider 可能实现的服务:DSA,RSA,MD5,SHA-1等算法,密钥的生成,转换和管理设置\n\n和 {@link Security} 一起构成了安全提供者\n\nJCA和JCE是Java平台用于安全和加密服务的俩组API,它们并不执行任何算法,它们只是链接应用和实际算法实现程序的一组接口\n软件开发商可以根据JCE接口将各种算法实现后打包成一个安全提供者.\n要实现一个完整的安全结构就需要一个或者多个第三方提供的JCE产品(安全提供者们)\n\n安全提供者抽象了俩个概念：\n引擎：可以理解为操作,如加密,解密\n算法：可以理解为如何加密,如何解密\n\nProvider 可能实现的服务:\n  DSA,RSA,MD5,SHA-1等算法\n  密钥的生成,转换和管理设置\n\nSUN\nSunRsaSign\nSunEC\nSunJSSE\nSunJCE\nSunJGSS\nSunSASL\nXMLDSig\nSunPCSC\nSunMSCAPI\n```\n\n* [SecureRandom](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestSecureRandom.java)\n\n```\n安全随机数生成器 ,SHA1PRNG是其默认算法\n```\n\n* [Security](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestSecurity.java)\n\n```\n管理java程序中所用到的提供者\nSecurity类是一个终态类,除了私有的构造方法外,其余均匀静态方法\n```\n\n###### Sign\n\n* [CodeSigner](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestCodeSigner.java)\n\n```\n封装了代码签名者的信息,且他是不可变的,称之为代码签名 他和数字时间戳({@link Timestamp}) 紧密相连\n\nCodeSigner类是一个终态类,可以通过其构造方法完成实例化对象：\n构建CodeSigner对象 --> CodeSigner()\n完成实例化对象后,就可以通过以下方法获得其属性：\n返回签名者的CertPath对象 --> getSignerCertpath()\n返回签名时间戳  --> getTimestamp()\n\n注意,这里的Timestamp是java.security.Timestamp,是用做数字时间戳的Timestamp！\n获得CodeSigner对象后的最重要的操作就是执行比对,CodeSigner覆盖了equals()方法.\n\n测试指定对象与此CodeSigner对象是否相等 --> equals()\n如果,传入参数不是CodeSigner类的实现,则直接返回false.\n如果传入参数是CodeSigner类的实现,则比较其Timestamp和CerPath两个属性\n```\n\n* [Signature](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestSignature.java)\n\n```\n引擎类. 用来生成和验证数字签名.\n用来生成和验证数字签名.同样是引擎类\n\n使用Sinature对象签名数据或验证签名包括下面三个阶段\n1.初始化\n\t\t初始化验证签名的公钥\n\t\t初始化签署签名的私钥\n2.更新\n\t\t根绝初始化的类型,可更新要签名活验证的字节\n3.签署或验证所有更新字节的签名\n\n支持的算法\n\t基于:DSA\n\t\tNONEwithDSA,SHAwithDSA\n\t基于:RSA\n\t\tMD2whitRSA,MD5whitRSA,SHA1whitRSA,SHA256whitRSA,SHA256whitRSA,SHA384whitRSA,SHA512whitRSA\n```\n\n* [SignedObject](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestSignedObject.java)\n\n```\n用来创建实际运行时的对象.在检测不到这些对象的情况下,其完整性不会遭受损害\n\nSignedObject包含另一个Serializable对象,即签名的对象及其签名.\n签名对象是对原始对象的深层复制(以序列化形式),一旦生成了副本对原始对的进一步操作就不再影响该副本\n```\n\n* [Timestamp](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestTimestamp.java)\n\n```\n用来封装有关签署时间戳的信息.\n```\n\n###### java_security_cert\n\n* [Certificate](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCertificate.java)\n\n```\n用于管理证书的抽象类 证书有很多类型,如X.509证书,PGP证书和SDSI证书\n并且它们都以不同的方式存储并存储不同的信息,但却都可以通过继承Certificate类来实现\n```\n\n* [CertificateFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCertificateFactory.java)\n\n```\nCertificateFactory是一个引擎类,称之为证书工厂,可以通过它将证书导入程序中.\n```\n\n* [CertPath](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCertPath.java)\n\n```\n定义了常用于所有CertPath的方法 其子类可处理不同类型的证书(x.509 PGP等)\n所有的CertPath对象都包含类型,Certificate列表及其支持的一种或多种编码\n```\n\n* [CRL](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCRL.java)\n\n```\n证书可能会由于各种原因失效, 失效后证书将被制为无效,无效的结果就是产生CRL(证书撤销列表),\nCA负责发布CRL,CRL中列出了该CA已经撤销的证书\n验证证书时,首先需要查询此列表,然后再考虑接受证书的合法性\n```\n\n* [X509Certificate](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestX509Certificate.java)\n\n```\nX509Certificate是Certificate的子类\nx.509证书的抽象类,此类提供类一种访问x.509证书的所有属性的标准方式\n```\n\n* [X509CRL](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestX509CRL.java)\n\n```\n作为CRl的子类,已标明了类型为X.509的CRl, X.509证书撤销列表(CRL)的抽象类.\nCRL是标致已撤销证书的时间戳列表.\n它由证书颁发机构签署,并可在公共存储库中随意使用\n```\n\n* [X509CRLEntry](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestX509CRLEntry.java)\n\n```\n已经撤销的证书类\n```\n\n###### java_security_spec\n\n* [AlgorithmParameterSpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestAlgorithmParameterSpec.java)\n\n```\n此接口不包含任何方法或常亮.它仅用于将所有参数规范分组,并为其提供类型安全.所有参数规范否必须实现此接口\nAlgorithmParameterSpec接口有很多的子接口和实现类,用于特定算法的初始化.\n使用起来也很方便,只需要十一指定参数填充构造方法即可获得一个实例化对象\n```\n\n* [DESKeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestDESKeySpec.java)\n\n```\nDESKeySpec和SecretKeySpec都是提供秘密密钥规范的实现类 DESKeySpec：指定类DES算法\nSecretKeySpec：兼容所有对称加密算法\n\nDESKeySpec有很多的同胞, DESedeKeySpec提供类三重DES加密算法的密钥规范 PBEKeySpec 提供了PBE算法的密钥规范\n```\n\n* [EncodedKeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestEncodedKeySpec.java)\n\n```\n用编码格式来表示公钥和私钥,称之为编码密钥规范\n```\n\n* [KeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestKeySpec.java)\n\n```\n本接口不包含任何方法或常量,它仅用于将所有密钥规范分组,并为其提供类型安全.所有密钥规范都要继承该接口\nKeySpec的抽象实现类(EncodedKeySpec)构建了用于构建公钥规范和私钥规范的俩个实习\nX509EncodedKeySpec用于构建公钥\nPKCS8EncodedKeySpec用于构建私钥规范\n\nSecretKeySpec接口是KeySpec的实现类,用于构建私密密钥规范\n```\n\n* [SecretKeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestSecretKeySpec.java)\n\n```\nSecretKeySpec类是KeySpec接口的实现类,用于构建秘密密钥规范\n此类仅能表示为一个字节数组并且没有任何与之相关联的密钥参数的原始密钥有用,如DES或Triple DES密钥\n```\n\n* [ModifyPolicy](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/TestModifyPolicy.java)\n\n```\n\n```\n","source":"_posts/security/README.md","raw":"category: \n- security\ntitle: README\ncategory: \n- 加密\ntitle: README\n# JDK加密\n## java.security包详解\n\n#### javax_crypto\n###### Cipher\n* [Cipher](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestCipher.java)\n```\n为加密解密提供密码功能,它构成了Java Cryptographic Extension(JCE) 框架核心.\n在java.security包中 只完成了密钥的处理 并未完成加密与解密的操作. 这些核心 操作需要通过Cipher类来实现.\n```\n* [CipherInputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestCipherInputStream.java)\n```\nCiper的拓展,称为密钥拓展流\n```\n\n* [CipherOutputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestCipherOutputStream.java)\n\n```\n密钥输出流\n```\n\n* [SealedObject](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testCipher/TestSealedObject.java)\n\n```\nScaledObject使程序员能够用加密算法创建对象并保护其机密性\n在给定任何Serializable对象的情况下,程序员可以序列化格式(即深层复制)封装原始对象的SealedObject\n并使用类似于DES的加密算法密封(加密)其序列化的内容,保护其机密性\n\n加密的内容以后可以解密和烦序列话,生成原始对象\n\n已密封的原始对象可以使用以下俩种方式恢复\n1.使用采用Cipher对象的getObject)方法.\n\t\t此方法需要一个完全初始化的Cipher对象,用相同的用来蜜蜂对象的算法,密钥,填充方案等进行初始化.\n\t\t这样做的好处是解封密封 对象的一方不需要知道解密密钥. 例如一方用所需的解密密钥初始化Cipher对象之后,\n\t\t它就会将Cipher对象移交给以后要解封密封对象的另一方\n2.使用采用Key对象的getObject()方法.\n\t\t在此方法中getObject方法创建一个用于适当解密算法的Cipher对象\n\t\t并用给定的解密密钥和存储在密封对象中的算法参数 (如果有)对其进行初始化.\n\t\t这样做的好处是解封此对象的一方不需要跟踪用来密封该对象的参数 (如IV 、 初始化向量).\n```\n\n###### MacMessageDigest\n\n* [KeyAgreement](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestKeyAgreement.java)\n\n```\nKeyAgreement类提供密钥协定协议的功能,它同样是一个引擎类.\n我们称它为密钥协定,将在DH算法实现中使用到它.\n```\n\n* [KeyGenerator](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestKeyGenerator.java)\n\n```\nKeyGenerator类与KeypairGenerato类相似,\nKeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\nKeyGenerator类与KeypairGenerato类相似,KeyGenerato类用来生成私密密钥,我们称之为私密密钥生成器.\n生成用于对称加密算法的秘密密钥,并提供相关信息 public class KeyGenerator extends Object\n\nJava7版本中提供了Blowfish、AES、DES和DESede等多种对称加密算法实现,以及HmacMD5、\nHmacSHA1和HmacSHA256等多种安全消息摘要算法实现\n```\n\n* [Mac](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestMac.java)\n\n```\nMac属于消息摘要的一种,但它不同于一般消息摘要（如Message Digest提供的消息摘要实现）,\n仅通过输入数据无法活的吧消息摘要,必须有一个由发送方和接收方\n共享的秘密密钥才能生成最终的消息摘要——安全消息摘要.安全消息摘要又称消息认证（鉴别）码.\n```\n\n* [SecretKeyFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_crypto/testMacMessageDigest/TestSecretKeyFactory.java)\n\n```\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,\n它用于产生秘密密钥,我们称之为秘密密钥工厂.\nSecretKe factor类同样属于引擎类,与Kefactory类相对应,它用于产生秘密密钥,我们称之为秘密密钥工厂.\n  此类表示秘密密钥的工厂\n```\n\n###### javax_net_ssl 包用于提供安全套接字包的类,该包对构建秘钥库,\n信任管理库及构建安全基于HTTPS的加密网络通信实现的知识\n\n* [HttpsURLConnection](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestHttpsURLConnection.java)\n\n```\nHttpsURLConnection 拓展了URLConnection, 支持各种特定于Https的功能\n```\n\n* [KeyManagerFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestKeyManagerFactory.java)\n\n```\n用来管理秘钥,设定秘钥库. 此类充当基于秘钥内容源的秘钥管理器的工厂.每个秘钥管理器管理特定类型的,由套接字所使用的秘钥内容\n```\n\n* [SSLContext](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLContext.java)\n\n```\n表示安全套接字上下文,安全套接字协议的实现,它充当于安全套接字工厂或者SSLEngine的工厂\n用可选的一组秘钥和信任管理器及安全随机字节初始化此类\n```\n\n* [SSLServerSocket](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLServerSocket.java)\n\n```\n   SSLServerSocket\n```\n\n* [SSLServerSocketFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLServerSocketFactory.java)\n\n```\n   SSLServerSocketFactory\n```\n\n* [SSLSession](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLSession.java)\n\n```\nSSLSession 接口用于保持SSL协议网络交互会话状态. 用来描述俩个实体之间的会话关系\n在SSL的会话中,可以获得加密套件(CipherSuite),数字证书等\n\nCipherSuite 明确给出了加密参数, 具体包括：协议,秘钥交换算法,加密算法,工作模式和消息摘要算法\n如 TLS_RSA_TITH_AES_256_CBC_SHA 就是一个完成加密套件信息, 它表示：\n使用TLS协议,迷药交换算法为RSA,对称加密算法为AES(长度256),使用CBC模式,并使用SHA消息摘要算法\n```\n\n* [SSLSocket](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLSocket.java)\n\n```\nSSLSocket是基于SSL协议的Socket,用于设置加密套件,处理握手结束事件,并管理SSLSession\n\n目前Java环境中支持的协议有：SSLLv2Hello,SSLv3,TLSv1,TlSv1.1, TLSv1.2\n通常默认的是SSLv3和TLSv1.1\nsetEnabledProtocols(protocols);  通过该方法设置SSL链接可用协议\n\n\ngetSupportedCipherSuites()\t\t获得可支持的加密套件\nsetEnabledCipherSuites(suites)\t为当前SSL链接设置可用的加密套件\ngetEnabledCipherSuites()\t\t\t获得当前SSL链接可用的加密套件\n\n有时候需要与远程服务器建立基于SSLSocket的链接. 远程服务仅通过SSLSocket传递数字证书.\n这时候,就不能通过HttpsURLConnection来获得数字证书了,本方法就是通过SSLSocket来获得SSLSession\n并最终获得数字证书\n```\n\n* [SSLSocketFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestSSLSocketFactory.java)\n\n```\n   SSLSocketFactory\n```\n\n* [TrustManagerFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/javax_net_ssl/TestTrustManagerFactory.java)\n\n```\n 管理信任材料的管理工厂,设定信任库\n\n 每个信任管理器管理特定类型的由安全套接字使用的信任材料\n```\n\n###### java_security  为安全框架提供类和接口, 该包只能完成消息摘要算法的实现,同时提供数字签名和秘钥接口的定义\n\n* [AlgorithmParameterGenerator](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestAlgorithmParameterGenerator.java)\n\n```\n引擎类,用于生成某个特定算法中使用的参数集合.\n\n{@link AlgorithmParameters} 生成的参数\n```\n\n* [AlgorithmParameters](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestAlgorithmParameters.java)\n\n```\n引擎类. 提供密码参数的不透明表示\n{@link AlgorithmParameters}\nAlgorithmParameters是一个引擎类,提供密码参数的不透明表示\n\n{@link AlgorithmParameterGenerator} 可以通过该引擎类生成\n\n不透明:不可以直接访问各参数域,只能得到与参数集相关联的算法名及该参数集的某类编码\n透明 :用户可以通过相应规范中定义的某个get方法来分别访问每个值\n```\n\n###### Key\n\n* [Key](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKey.java)\n\n```\nKey接口是所有密钥接口的顶层接口,一切与加密有关的操作都离不开Key接口\nKey接口是所有密钥接口的顶层接口,一切与加密有关的操作都离不开Key接口\n由于密钥必须在不同的实体间传输,因此所有的密钥都是可序列话的\n\n所有的密钥都具有三个形式\n算法:密钥算法, 如DES和DSA. getAlgorithm()\n编码形式:密钥的外部编码形式,密钥根据标准格式(RKC#8)编码,  getEncode()\n格式:已编码密钥的格式的名称,getFormat()\n\n对称密钥顶层接口\n{@link SecretKey}\n\t\t通常使用的是{@link SecretKeySpec}\nDES,AES 等多种对称密码算法均可通过该接口提供,PBE接口提供PBE算法定义并继承了该接口\nMAC算法实现过程中,通过SecretKey接口提供秘密秘钥\n\n非对称密钥顶层接口\n{@link PublicKey} 公钥接口\n{@link PrivateKey} 私钥接口\nDh,RSA,DSA,EC等多种非对称秘钥接口均继承了这俩个接口\n```\n\n* [KeyFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyFactory.java)\n\n```java\n同{@link KeyPairGenerator} 一样,它也是用来生成密钥(公钥和私钥)的引擎类,称之为密钥工厂\n按照指定的编码格式或密钥参数,提供一个用于输入和输出密钥的基础设施\n\n从另一方面来说KeyFactory 是通过密钥规范({@link KeySpec}) 还原密钥,\n与KeyFacory对应的是{@link SecretKeyFactory},用来生成秘密密钥\n```\n\n* [KeyPair](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyPair.java)\n\n```java\n对非对称密钥的拓展,是密钥对的载体,称之为密钥对\n\n一般是通过KeyPairGenerator#generateKeyPair()获得\n\nkeyPair只能通过构造方法初始化内部的公钥和私钥,此外不提供设置公钥和私钥的方法\n```\n\n* [KeyPairGenerator](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyPairGenerator.java)\n\n```\n引擎类. 负责生成公钥和私钥,称之为密钥对生成器,\n负责生成公钥和私钥,称之为密钥对生成器,同样是一个引擎类\n如果要生成私钥可以使用 {@link KeyGenerator}\n```\n\n* [KeyStore](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testKey/TestKeyStore.java)\n\n```java\n称为密钥库,用于管理密钥和证书的存储\n\n密钥库类型：\n JKS,PKCS12,JCEKS 三种类型(名字不区分大小写)\n JCEKS 受美国出口限制\n PKCS12 这种类型的密钥库管理支持不是很完备,只能读取该类型的证书,却不能对其更改\n\nKeyStore.Entry接口是一个空借口,内部没有定义代码用于类型区分 KeyStore用于管理不同类型的条目,每种类型的条目都实现Entry接口\n\nEntry接口实现:\nPrivateKeyEntry:保存私钥和相应证书链的密钥库项\nSecretKeyEntry:保存私密密钥的密钥库项\nTrustedCertificateEntry:保存可信的证书的密钥库项\n```\n\n###### MessageDigest\n\n* [DigestInputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testMessageDigest/TestDigestInputStream.java)\n\n```\n消息摘要输入流通过指定的读操作完成MessageDigest 的update()方法\n```\n\n* [DigestOutputStream](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testMessageDigest/TestDigestOutputStream.java)\n\n```\n消息摘要输出流通过指定的写操作完成MessageDigest 的update()方法\n```\n\n* [MessageDigest](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testMessageDigest/TestMessageDigest.java)\n\n```\n实现了消息摘要算法\nJAVA7 支持 MD2 MD5 SHA-1 SHA-256 SHA-284 SHA-512 六种消息摘要算法\n\nMessageDigest DigestInputStream DigestOutputStream  Mac 均是消息认证的引擎类.\nMessageDigest : 提供核心的消息摘要实现\nDigestInputStream  DigestOutputStream  ： 为核心的消息摘要流实现\nMac ： 提供基于秘密密钥的安全消息摘要实现\n\nMac与MessageDigest没有任何依赖关系\n```\n\n* [Provider](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestProvider.java)\n\n```\nProvider 可能实现的服务:DSA,RSA,MD5,SHA-1等算法,密钥的生成,转换和管理设置\n\n和 {@link Security} 一起构成了安全提供者\n\nJCA和JCE是Java平台用于安全和加密服务的俩组API,它们并不执行任何算法,它们只是链接应用和实际算法实现程序的一组接口\n软件开发商可以根据JCE接口将各种算法实现后打包成一个安全提供者.\n要实现一个完整的安全结构就需要一个或者多个第三方提供的JCE产品(安全提供者们)\n\n安全提供者抽象了俩个概念：\n引擎：可以理解为操作,如加密,解密\n算法：可以理解为如何加密,如何解密\n\nProvider 可能实现的服务:\n  DSA,RSA,MD5,SHA-1等算法\n  密钥的生成,转换和管理设置\n\nSUN\nSunRsaSign\nSunEC\nSunJSSE\nSunJCE\nSunJGSS\nSunSASL\nXMLDSig\nSunPCSC\nSunMSCAPI\n```\n\n* [SecureRandom](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestSecureRandom.java)\n\n```\n安全随机数生成器 ,SHA1PRNG是其默认算法\n```\n\n* [Security](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/TestSecurity.java)\n\n```\n管理java程序中所用到的提供者\nSecurity类是一个终态类,除了私有的构造方法外,其余均匀静态方法\n```\n\n###### Sign\n\n* [CodeSigner](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestCodeSigner.java)\n\n```\n封装了代码签名者的信息,且他是不可变的,称之为代码签名 他和数字时间戳({@link Timestamp}) 紧密相连\n\nCodeSigner类是一个终态类,可以通过其构造方法完成实例化对象：\n构建CodeSigner对象 --> CodeSigner()\n完成实例化对象后,就可以通过以下方法获得其属性：\n返回签名者的CertPath对象 --> getSignerCertpath()\n返回签名时间戳  --> getTimestamp()\n\n注意,这里的Timestamp是java.security.Timestamp,是用做数字时间戳的Timestamp！\n获得CodeSigner对象后的最重要的操作就是执行比对,CodeSigner覆盖了equals()方法.\n\n测试指定对象与此CodeSigner对象是否相等 --> equals()\n如果,传入参数不是CodeSigner类的实现,则直接返回false.\n如果传入参数是CodeSigner类的实现,则比较其Timestamp和CerPath两个属性\n```\n\n* [Signature](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestSignature.java)\n\n```\n引擎类. 用来生成和验证数字签名.\n用来生成和验证数字签名.同样是引擎类\n\n使用Sinature对象签名数据或验证签名包括下面三个阶段\n1.初始化\n\t\t初始化验证签名的公钥\n\t\t初始化签署签名的私钥\n2.更新\n\t\t根绝初始化的类型,可更新要签名活验证的字节\n3.签署或验证所有更新字节的签名\n\n支持的算法\n\t基于:DSA\n\t\tNONEwithDSA,SHAwithDSA\n\t基于:RSA\n\t\tMD2whitRSA,MD5whitRSA,SHA1whitRSA,SHA256whitRSA,SHA256whitRSA,SHA384whitRSA,SHA512whitRSA\n```\n\n* [SignedObject](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestSignedObject.java)\n\n```\n用来创建实际运行时的对象.在检测不到这些对象的情况下,其完整性不会遭受损害\n\nSignedObject包含另一个Serializable对象,即签名的对象及其签名.\n签名对象是对原始对象的深层复制(以序列化形式),一旦生成了副本对原始对的进一步操作就不再影响该副本\n```\n\n* [Timestamp](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security/testSign/TestTimestamp.java)\n\n```\n用来封装有关签署时间戳的信息.\n```\n\n###### java_security_cert\n\n* [Certificate](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCertificate.java)\n\n```\n用于管理证书的抽象类 证书有很多类型,如X.509证书,PGP证书和SDSI证书\n并且它们都以不同的方式存储并存储不同的信息,但却都可以通过继承Certificate类来实现\n```\n\n* [CertificateFactory](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCertificateFactory.java)\n\n```\nCertificateFactory是一个引擎类,称之为证书工厂,可以通过它将证书导入程序中.\n```\n\n* [CertPath](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCertPath.java)\n\n```\n定义了常用于所有CertPath的方法 其子类可处理不同类型的证书(x.509 PGP等)\n所有的CertPath对象都包含类型,Certificate列表及其支持的一种或多种编码\n```\n\n* [CRL](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestCRL.java)\n\n```\n证书可能会由于各种原因失效, 失效后证书将被制为无效,无效的结果就是产生CRL(证书撤销列表),\nCA负责发布CRL,CRL中列出了该CA已经撤销的证书\n验证证书时,首先需要查询此列表,然后再考虑接受证书的合法性\n```\n\n* [X509Certificate](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestX509Certificate.java)\n\n```\nX509Certificate是Certificate的子类\nx.509证书的抽象类,此类提供类一种访问x.509证书的所有属性的标准方式\n```\n\n* [X509CRL](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestX509CRL.java)\n\n```\n作为CRl的子类,已标明了类型为X.509的CRl, X.509证书撤销列表(CRL)的抽象类.\nCRL是标致已撤销证书的时间戳列表.\n它由证书颁发机构签署,并可在公共存储库中随意使用\n```\n\n* [X509CRLEntry](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_cert/TestX509CRLEntry.java)\n\n```\n已经撤销的证书类\n```\n\n###### java_security_spec\n\n* [AlgorithmParameterSpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestAlgorithmParameterSpec.java)\n\n```\n此接口不包含任何方法或常亮.它仅用于将所有参数规范分组,并为其提供类型安全.所有参数规范否必须实现此接口\nAlgorithmParameterSpec接口有很多的子接口和实现类,用于特定算法的初始化.\n使用起来也很方便,只需要十一指定参数填充构造方法即可获得一个实例化对象\n```\n\n* [DESKeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestDESKeySpec.java)\n\n```\nDESKeySpec和SecretKeySpec都是提供秘密密钥规范的实现类 DESKeySpec：指定类DES算法\nSecretKeySpec：兼容所有对称加密算法\n\nDESKeySpec有很多的同胞, DESedeKeySpec提供类三重DES加密算法的密钥规范 PBEKeySpec 提供了PBE算法的密钥规范\n```\n\n* [EncodedKeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestEncodedKeySpec.java)\n\n```\n用编码格式来表示公钥和私钥,称之为编码密钥规范\n```\n\n* [KeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestKeySpec.java)\n\n```\n本接口不包含任何方法或常量,它仅用于将所有密钥规范分组,并为其提供类型安全.所有密钥规范都要继承该接口\nKeySpec的抽象实现类(EncodedKeySpec)构建了用于构建公钥规范和私钥规范的俩个实习\nX509EncodedKeySpec用于构建公钥\nPKCS8EncodedKeySpec用于构建私钥规范\n\nSecretKeySpec接口是KeySpec的实现类,用于构建私密密钥规范\n```\n\n* [SecretKeySpec](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/java_security_spec/TestSecretKeySpec.java)\n\n```\nSecretKeySpec类是KeySpec接口的实现类,用于构建秘密密钥规范\n此类仅能表示为一个字节数组并且没有任何与之相关联的密钥参数的原始密钥有用,如DES或Triple DES密钥\n```\n\n* [ModifyPolicy](https://github.com/wanggnim/GnimSecurity/blob/master/java/src/test/wang/gnim/jdk/TestModifyPolicy.java)\n\n```\n\n```\n","slug":"security/README","published":1,"date":"2015-09-18T07:03:21.960Z","updated":"2015-09-18T07:01:13.628Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9t000p74ufb0w1qp62"},{"title":"Java加密","_content":"# Java加密\n\n## Java与密码学\n\n#### Java安全领域组成部分\n\nJava安全领域总共分为4个部分:\n* `JCA`(`Java Cryptography Architecture`,Java加密体系结构)\n```\n\tJCA提供基本的加密框架,如证书、数字签名、消息摘要和密钥对产生器.\n```\n* `JCE`(`Java Cryptography Extension`,Java加密扩展包)\n```\n\tJCE在JCA的基础上作了扩展,提供了各种加密算法、消息摘要算法和密钥管理等功能.\n\t我们已经有所了解的DES算法、AES算法、RSA算法、DSA算法等就是通过JCE来提供的.\n\t有关JCE的实现主要在javax.crypto包(及其子包)中.\n```\n* `JSSE`(`Java Secure Sockets Extension`,Java安全套接字扩展包)\n```\n\tJSSE提供了基于SSL(Secure Sockets Layer,安全套接字层)的加密功能.\n\t在网络的传输过程中,信息会经过多个主机(很有可能其中一台就被窃听),最终传送给接收者,\n\t这是不安全的.这种确保网络通信安全的服务就是由JSSE来提供的.\n```\n* `JAAS`(`Java Authentication and Authentication Service`,Java鉴别与安全服务).\n```\n\tJAAS提供了在Java平台上进行用户身份鉴别的功能.如何提供一个符合标准安全机制的登录模块,\n\t通过可配置的方式集成至各个系统中呢？这是由JAAS来提供的.\n```\n\nJCA和JCE是Java平台提供的用于安全和加密服务的两组API.它们并不执行任何算法,它们只是连接应用和实际算法实现程序的一组接口.软件开发商可以根据JCE接口(又称安全提供者接口)将各种算法实现后,打包成一个Provider(安全提供者),动态地加载到Java运行环境中.\n\n根据美国出口限制规定,JCA可出口(JCA和Sun的一些默认实现包含在Java发行版中),但JCE对部分国家是限制出口的.因此,要实现一个完整的安全结构,就需要一个或多个第三方厂商提供的JCE产品,称为安全提供者.BouncyCastle JCE就是其中的一个安全提供者.\n\n安全提供者是承担特定安全机制实现的第三方.有些提供者是完全免费的,而另一些提供者则需要付费.提供安全提供者的公司有Sun、Bouncy Castle等,Sun提供了如何开发安全提供者的细节.Bouncy Castle提供了可以在J2ME/J2EE/J2SE平台得到支持的API,而且Bouncy Castle的API是免费的.\n\nJDK 1.4版本及其后续版本中包含了上述扩展包,无须进行配置.在此之前,安装JDK后需要对上述扩展包进行相应配置.\n\n####  安全提供者体系结构\n\nJava安全体系结构通过扩展的方式,加入了更多的算法实现及相应的安全机制.我们把这些提供者称为安全提供者(以下简称“提供者”).\n\n###### 以下内容是JDK 1.7所提供的安全提供者的配置信息.\n* security.provider.1=sun.security.provider.Sun\n* security.provider.2=sun.security.rsa.SunRsaSign\n* security.provider.3=sun.security.ec.SunEC\n* security.provider.4=com.sun.net.ssl.internal.ssl.Provider\n* security.provider.5=com.sun.crypto.provider.SunJCE\n* security.provider.6=sun.security.jgss.SunProvider\n* security.provider.7=com.sun.security.sasl.Provider\n* security.provider.8=org.jcp.xml.dsig.internal.dom.XMLDSigRI\n* security.provider.9=sun.security.smartcardio.SunPCSC\n* security.provider.10=sun.security.mscapi.SunMSCAPI\n\n> 上述这些提供者均是`Provider`类(`java.security.Provider`)的子类.其中`sun.security.provider.Sun`是基本安全提供者,`sun.security.rsa.SunRsaSign`是实现RSA算法的提供者.\n>\n> 与上一版本对比,Java 7新增了EC算法安全提供者—`sun.security.ec.SunEC`,暗示在该版本中可能支持相应的算法实现.\n>\n> Java安全体系不仅支持来自Sun官方提供的安全提供者,同时也可配置第三方安全提供者以扩展相应的算法实现等.\n\n###### 安全提供者实现了两个概念的抽象:\n* 引擎\n```\n\t引擎可以理解为操作,如加密、解密等.\n```\n* 算法.\n```\n\t算法则定义了操作如何执行,如一个算法可以理解为一个引擎的具体实现.当然,一个算法可以有多种实现方式,\n\t这就意味着同一个算法可能与多个引擎的具体实现相对应.\n```\n\n> 安全提供者接口的目的就是提供一个简单的机制,从而可以很方便地改变或替换算法及其实现.在实际开发中,程序员只需要用引擎类实现特定的操作,而不需要关心实际进行运算的类是哪一个.\n>\n> `Provider`类和`Security`类(`java.security.Security`)共同构成了安全提供者的概念.\n\n#### 本文全貌\n\n* 主要详解了`java.security`包与`javax.crypto包`,这两个包中包含了Java加密与解密的核心部分.\n* 在`java.security.interfaces`包和`javax.crypto.interfaces`包中包含了密钥相关的接口.\n* 在`java.security.spec`包和`javax.crypto.spec`包中包含了密钥规范和算法参数规范的类和接口.\n\n","source":"_posts/security/Java加密.md","raw":"category: \n- security\ntitle: Java加密\n---\n# Java加密\n\n## Java与密码学\n\n#### Java安全领域组成部分\n\nJava安全领域总共分为4个部分:\n* `JCA`(`Java Cryptography Architecture`,Java加密体系结构)\n```\n\tJCA提供基本的加密框架,如证书、数字签名、消息摘要和密钥对产生器.\n```\n* `JCE`(`Java Cryptography Extension`,Java加密扩展包)\n```\n\tJCE在JCA的基础上作了扩展,提供了各种加密算法、消息摘要算法和密钥管理等功能.\n\t我们已经有所了解的DES算法、AES算法、RSA算法、DSA算法等就是通过JCE来提供的.\n\t有关JCE的实现主要在javax.crypto包(及其子包)中.\n```\n* `JSSE`(`Java Secure Sockets Extension`,Java安全套接字扩展包)\n```\n\tJSSE提供了基于SSL(Secure Sockets Layer,安全套接字层)的加密功能.\n\t在网络的传输过程中,信息会经过多个主机(很有可能其中一台就被窃听),最终传送给接收者,\n\t这是不安全的.这种确保网络通信安全的服务就是由JSSE来提供的.\n```\n* `JAAS`(`Java Authentication and Authentication Service`,Java鉴别与安全服务).\n```\n\tJAAS提供了在Java平台上进行用户身份鉴别的功能.如何提供一个符合标准安全机制的登录模块,\n\t通过可配置的方式集成至各个系统中呢？这是由JAAS来提供的.\n```\n\nJCA和JCE是Java平台提供的用于安全和加密服务的两组API.它们并不执行任何算法,它们只是连接应用和实际算法实现程序的一组接口.软件开发商可以根据JCE接口(又称安全提供者接口)将各种算法实现后,打包成一个Provider(安全提供者),动态地加载到Java运行环境中.\n\n根据美国出口限制规定,JCA可出口(JCA和Sun的一些默认实现包含在Java发行版中),但JCE对部分国家是限制出口的.因此,要实现一个完整的安全结构,就需要一个或多个第三方厂商提供的JCE产品,称为安全提供者.BouncyCastle JCE就是其中的一个安全提供者.\n\n安全提供者是承担特定安全机制实现的第三方.有些提供者是完全免费的,而另一些提供者则需要付费.提供安全提供者的公司有Sun、Bouncy Castle等,Sun提供了如何开发安全提供者的细节.Bouncy Castle提供了可以在J2ME/J2EE/J2SE平台得到支持的API,而且Bouncy Castle的API是免费的.\n\nJDK 1.4版本及其后续版本中包含了上述扩展包,无须进行配置.在此之前,安装JDK后需要对上述扩展包进行相应配置.\n\n####  安全提供者体系结构\n\nJava安全体系结构通过扩展的方式,加入了更多的算法实现及相应的安全机制.我们把这些提供者称为安全提供者(以下简称“提供者”).\n\n###### 以下内容是JDK 1.7所提供的安全提供者的配置信息.\n* security.provider.1=sun.security.provider.Sun\n* security.provider.2=sun.security.rsa.SunRsaSign\n* security.provider.3=sun.security.ec.SunEC\n* security.provider.4=com.sun.net.ssl.internal.ssl.Provider\n* security.provider.5=com.sun.crypto.provider.SunJCE\n* security.provider.6=sun.security.jgss.SunProvider\n* security.provider.7=com.sun.security.sasl.Provider\n* security.provider.8=org.jcp.xml.dsig.internal.dom.XMLDSigRI\n* security.provider.9=sun.security.smartcardio.SunPCSC\n* security.provider.10=sun.security.mscapi.SunMSCAPI\n\n> 上述这些提供者均是`Provider`类(`java.security.Provider`)的子类.其中`sun.security.provider.Sun`是基本安全提供者,`sun.security.rsa.SunRsaSign`是实现RSA算法的提供者.\n>\n> 与上一版本对比,Java 7新增了EC算法安全提供者—`sun.security.ec.SunEC`,暗示在该版本中可能支持相应的算法实现.\n>\n> Java安全体系不仅支持来自Sun官方提供的安全提供者,同时也可配置第三方安全提供者以扩展相应的算法实现等.\n\n###### 安全提供者实现了两个概念的抽象:\n* 引擎\n```\n\t引擎可以理解为操作,如加密、解密等.\n```\n* 算法.\n```\n\t算法则定义了操作如何执行,如一个算法可以理解为一个引擎的具体实现.当然,一个算法可以有多种实现方式,\n\t这就意味着同一个算法可能与多个引擎的具体实现相对应.\n```\n\n> 安全提供者接口的目的就是提供一个简单的机制,从而可以很方便地改变或替换算法及其实现.在实际开发中,程序员只需要用引擎类实现特定的操作,而不需要关心实际进行运算的类是哪一个.\n>\n> `Provider`类和`Security`类(`java.security.Security`)共同构成了安全提供者的概念.\n\n#### 本文全貌\n\n* 主要详解了`java.security`包与`javax.crypto包`,这两个包中包含了Java加密与解密的核心部分.\n* 在`java.security.interfaces`包和`javax.crypto.interfaces`包中包含了密钥相关的接口.\n* 在`java.security.spec`包和`javax.crypto.spec`包中包含了密钥规范和算法参数规范的类和接口.\n\n","slug":"security/Java加密","published":1,"date":"2015-09-18T07:15:44.440Z","updated":"2015-09-18T07:10:19.406Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9u000q74uf1fpxbx6y"},{"title":"PYTHON2","_content":"\n# 字符串\n* `capitalize(...)` : `S.capitalize() -> str`\n\n    Return a capitalized version of S, i.e. make the first character\n    have upper case and the rest lower case.\n\n* `casefold(...)` : `S.casefold() -> str`\n\n    Return a version of S suitable for caseless comparisons.\n\n* `center(...)` : `S.center(width[, fillchar]) -> str`\n\n    Return S centered in a string of length width. Padding is\n    done using the specified fill character (default is a space)\n\n* `count(...)` : `S.count(sub[, start[, end]]) -> int`\n\n    Return the number of non-overlapping occurrences of substring sub in\n    string S[start:end].  Optional arguments start and end are\n    interpreted as in slice notation.\n\n* `encode(...)` : `S.encode(encoding='utf-8', errors='strict') -> bytes`\n\n    Encode S using the codec registered for encoding. Default encoding\n    is 'utf-8'. errors may be given to set a different error\n    handling scheme. Default is 'strict' meaning that encoding errors raise\n    a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n    'xmlcharrefreplace' as well as any other name registered with\n    codecs.register_error that can handle UnicodeEncodeErrors.\n\n* `endswith(...)` : `S.endswith(suffix[, start[, end]]) -> bool`\n\n    Return True if S ends with the specified suffix, False otherwise.\n    With optional start, test S beginning at that position.\n    With optional end, stop comparing S at that position.\n    suffix can also be a tuple of strings to try.\n\n* `expandtabs(...)` : `S.expandtabs(tabsize=8) -> str`\n\n    Return a copy of S where all tab characters are expanded using spaces.\n    If tabsize is not given, a tab size of 8 characters is assumed.\n\n* `find(...)` : `S.find(sub[, start[, end]]) -> int`\n\n    Return the lowest index in S where substring sub is found,\n    such that sub is contained within S[start:end].  Optional\n    arguments start and end are interpreted as in slice notation.\n\n    Return -1 on failure.\n\n* `format(...)` : `S.format(*args, **kwargs) -> str`\n\n    Return a formatted version of S, using substitutions from args and kwargs.\n    The substitutions are identified by braces ('{' and '}').\n\n* `format_map(...)` : `S.format_map(mapping) -> str`\n\n    Return a formatted version of S, using substitutions from mapping.\n    The substitutions are identified by braces ('{' and '}').\n\n* `index(...)` : `S.index(sub[, start[, end]]) -> int`\n\n    Like S.find() but raise ValueError when the substring is not found.\n\n* `isalnum(...)` : `S.isalnum() -> bool`\n\n    Return True if all characters in S are alphanumeric\n    and there is at least one character in S, False otherwise.\n\n* `isalpha(...)` : `S.isalpha() -> bool`\n\n    Return True if all characters in S are alphabetic\n    and there is at least one character in S, False otherwise.\n\n* `isdecimal(...)` : `S.isdecimal() -> bool`\n\n    Return True if there are only decimal characters in S,\n    False otherwise.\n\n* `isdigit(...)` : `S.isdigit() -> bool`\n\n    Return True if all characters in S are digits\n    and there is at least one character in S, False otherwise.\n\n* `isidentifier(...)` : `S.isidentifier() -> bool`\n\n    Return True if S is a valid identifier according\n    to the language definition.\n\n    Use keyword.iskeyword() to test for reserved identifiers\n    such as \"def\" and \"class\".\n\n* `islower(...)` : `S.islower() -> bool`\n\n    Return True if all cased characters in S are lowercase and there is\n    at least one cased character in S, False otherwise.\n\n* `isnumeric(...)` : `S.isnumeric() -> bool`\n\n    Return True if there are only numeric characters in S,\n    False otherwise.\n\n* `isprintable(...)` : `S.isprintable() -> bool`\n\n    Return True if all characters in S are considered\n    printable in repr() or S is empty, False otherwise.\n\n* `isspace(...)` : `S.isspace() -> bool`\n\n    Return True if all characters in S are whitespace\n    and there is at least one character in S, False otherwise.\n\n* `istitle(...)` : `S.istitle() -> bool`\n\n    Return True if S is a titlecased string and there is at least one\n    character in S, i.e. upper- and titlecase characters may only\n    follow uncased characters and lowercase characters only cased ones.\n    Return False otherwise.\n\n* `isupper(...)` : `S.isupper() -> bool`\n\n    Return True if all cased characters in S are uppercase and there is\n    at least one cased character in S, False otherwise.\n\n* `join(...)` : `S.join(iterable) -> str`\n\n    Return a string which is the concatenation of the strings in the\n    iterable.  The separator between elements is S.\n\n* `ljust(...)` : `S.ljust(width[, fillchar]) -> str`\n\n    Return S left-justified in a Unicode string of length width. Padding is\n    done using the specified fill character (default is a space).\n\n* `lower(...)` : `S.lower() -> str`\n\n    Return a copy of the string S converted to lowercase.\n\n* `lstrip(...)` : `S.lstrip([chars]) -> str`\n\n    Return a copy of the string S with leading whitespace removed.\n    If chars is given and not None, remove characters in chars instead.\n\n* `partition(...)` : `S.partition(sep) -> (head, sep, tail)`\n\n    Search for the separator sep in S, and return the part before it,\n    the separator itself, and the part after it.  If the separator is not\n    found, return S and two empty strings.\n\n* `replace(...)` : `S.replace(old, new[, count]) -> str`\n\n    Return a copy of S with all occurrences of substring\n    old replaced by new.  If the optional argument count is\n    given, only the first count occurrences are replaced.\n\n* `rfind(...)` : `S.rfind(sub[, start[, end]]) -> int`\n\n    Return the highest index in S where substring sub is found,\n    such that sub is contained within S[start:end].  Optional\n    arguments start and end are interpreted as in slice notation.\n\n    Return -1 on failure.\n\n* `rindex(...)` : `S.rindex(sub[, start[, end]]) -> int`\n\n    Like S.rfind() but raise ValueError when the substring is not found.\n\n* `rjust(...)` : `S.rjust(width[, fillchar]) -> str`\n\n    Return S right-justified in a string of length width. Padding is\n    done using the specified fill character (default is a space).\n\n* `rpartition(...)` : `S.rpartition(sep) -> (head, sep, tail)`\n\n    Search for the separator sep in S, starting at the end of S, and return\n    the part before it, the separator itself, and the part after it.  If the\n    separator is not found, return two empty strings and S.\n\n* `rsplit(...)` : `S.rsplit(sep=None, maxsplit=-1) -> list of strings`\n\n    Return a list of the words in S, using sep as the\n    delimiter string, starting at the end of the string and\n    working to the front.  If maxsplit is given, at most maxsplit\n    splits are done. If sep is not specified, any whitespace string\n    is a separator.\n\n* `rstrip(...)` : `S.rstrip([chars]) -> str`\n\n    Return a copy of the string S with trailing whitespace removed.\n    If chars is given and not None, remove characters in chars instead.\n\n* `split(...)` : `S.split(sep=None, maxsplit=-1) -> list of strings`\n\n    Return a list of the words in S, using sep as the\n    delimiter string.  If maxsplit is given, at most maxsplit\n    splits are done. If sep is not specified or is None, any\n    whitespace string is a separator and empty strings are\n    removed from the result.\n\n* `splitlines(...)` : `S.splitlines([keepends]) -> list of strings`\n\n    Return a list of the lines in S, breaking at line boundaries.\n    Line breaks are not included in the resulting list unless keepends\n    is given and true.\n\n* `startswith(...)` : `S.startswith(prefix[, start[, end]]) -> bool`\n\n    Return True if S starts with the specified prefix, False otherwise.\n    With optional start, test S beginning at that position.\n    With optional end, stop comparing S at that position.\n    prefix can also be a tuple of strings to try.\n\n* `strip(...)` : `S.strip([chars]) -> str`\n\n    Return a copy of the string S with leading and trailing\n    whitespace removed.\n    If chars is given and not None, remove characters in chars instead.\n\n* `swapcase(...)` : `S.swapcase() -> str`\n\n    Return a copy of S with uppercase characters converted to lowercase\n    and vice versa.\n\n* `title(...)` : `S.title() -> str`\n\n    Return a titlecased version of S, i.e. words start with title case\n    characters, all remaining cased characters have lower case.\n\n* `translate(...)` : `S.translate(table) -> str`\n\n    Return a copy of the string S, where all characters have been mapped\n    through the given translation table, which must be a mapping of\n    Unicode ordinals to Unicode ordinals, strings, or None.\n    Unmapped characters are left untouched. Characters mapped to None\n    are deleted.\n\n* `upper(...)` : `S.upper() -> str`\n\n    Return a copy of S converted to uppercase.\n\n* `zfill(...)` : `S.zfill(width) -> str`\n\n    Pad a numeric string S with zeros on the left, to fill a field\n    of the specified width. The string S is never truncated.\n\n# 内置数据结构\n## 列表\n* 声明一个列表 `list = [123, \"ad\"]`\n* 索引第一个元素 `list[0]`\n* 在尾部添加一个元素 `list.append(2.56)`\n* 对第一个元素重新赋值 `list[0] = \"0\"`\n* 获取列表长度 `len(list)`\n* 删除第一个元素 `del list[0]`\n\n\n\n## 元组\n元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组\n```python\ntumple = (123, \"adf\")\nprint(tumple[0])\nprint(len(tumple))\n```\n\n## 字典\n```python\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nprint(map)\nprint(len(map))\nprint(map[\"key1\"])\ndel map[\"key1\"]\nprint(map)\n\nfor key in map:\n    print(key + \"   \" + map[key])\nif \"key2\" in map:\n    print(\"map contains key2\")\n\nhelp(dict)\n```\n\n## 序列\n序列的两个主要特点是索引操作符和切片操作符\n```python\nshoplist = ['apple', 'mango', 'carrot', 'banana']\n\nprint('Item 0 is', shoplist[0])\nprint('Item -1 is', shoplist[-1])\n\n# Slicing on a list\nprint('Item 1 to 3 is', shoplist[1:3])\nprint('Item 2 to end is', shoplist[2:])\nprint('Item 1 to -1 is', shoplist[1:-1])\nprint('Item start to end is', shoplist[:])\n\n# Slicing on a string\nname = 'swaroop'\nprint('characters 1 to 3 is', name[1:3])\nprint('characters 2 to end is', name[2:])\nprint('characters 1 to -1 is', name[1:-1])\nprint('characters start to end is', name[:])\n```\n\n\n# 文件\n\n\n# 控制流\n## if\n```python\ntmp = 0\nif tmp > 0 :\n    print(\">\")\nelif tmp < 0 :\n    print(\"<\")\nelse :\n    print(\"=\")\n```\n\n## while\n```python\ntmp = 0\nwhile tmp < 3 :\n    print(tmp)\n    tmp +=1\nelse :\n    print(\"over\")\n```\n\n## for\n```python\nfor i in [0,1,2,3,4]:\n    print(i)\n\n    if i > 2 :\n        break\n    else :\n        continue\n\nelse:\n    print('loop over')\n```\n\n# 函数\n\n## 定义一个不带参数的函数\n```python\n# 定义一个不带参数的函数\ndef printHelloworld():\n    print(\"hello world\")\n\n# 调用函数\nprintHelloworld()\n```\n\n## 定义一个带参数的函数\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n## 函数中的局部变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    value = saywhat\n    print(value)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n当在函数内部修改了局部变量之后,并不会影响脚本中的变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nstr = \"hello world\"\nprintHelloworld(str)\nprint(str)\n```\n\n## 使用global语句\n```python\n# 定义一个带参数的函数\ndef printHelloworld():\n    global saywhat # 此处不可进行初始化\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nprintHelloworld()\nprint(saywhat)\n```\n\n## 默认参数值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str + \" \" + str1 + \" \" + str2)\n\n# 调用函数\nprintHelloworld(\"123\", str2=\"789\")\n```\n\n## return返回值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str)\n    if str1==\"str1 value\" :\n        return \"nil value\"\n    print(str1)\n    print(str2)\n\n# 调用函数\nresult = printHelloworld(\"123\", str2=\"789\")\nprint(result)\n\nresult = printHelloworld(\"123\", str1=\"789\")\nprint(result)\n```\n\n# 模块\n模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。\n\n## 使用`sys`模块\n```python\nimport sys\n\nfor argv in sys.argv :\n    print(argv)\n```\n\n使用`from..import..`, `import`可以使用`*`\n```python\nfrom sys import argv\n\nfor argvtmp in argv :\n    print(argvtmp)\n```\n\n模块的name,下面的语法输出当前模块的name\n```python\nprint(__name__)\n```\n\n## 自定义模块\n* 建立`mymodule.py`文件\n```python\n# Filename: mymodule.py\n\ndef printModuleName():\n    print(__name__)\n```\n* 建立`test_mymodule.py`文件\n```python\nimport mymodule\n\nmymodule.printModuleName()\n```\n1. 需要注意的是`mymodule.py`文件的`Filename`必须和文件名相同\n2. 如果`module`的name是`__main__`说明这个module是由用户启动的\n\n# 面向对象\n\n## self\n类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称`self`\n```python\n\n```\n\n## 创建一个类\n```python\nclass Person:\n    pass\n\np = Person()\nprint p\n```\n\n## 对象的方法\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n\np = Person()\np.run()\n```\n\n### __init__方法\n`__init__`方法在类的一个对象被建立时，马上运行\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"init\")\n\np = Person()\np.run()\n```\n\n### __del__方法\n```python\nclass Person:\n    def __init__(self):\n        print(\"init\")\n    def __del__(self):\n        print(\"__destory__\")\n\np = Person()\n```\n\n#### 类与对象的方法\n* 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。\n\n* 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。\n\n```python\nclass Father:\n    age = 0\n\nfather = Father()\nfather.age = 10\nFather.age = 20\nprint(father.age)\nprint(Father.age)\n```\n\n## 继承\n```python\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n\nclass Son(Father):\n    pass\n\nson = Son()\nprint(son.name)\nson.run()\n\n```\n\n### `__init__`, `__del__`在继承中的使用\nPython不会自动调用父类的constructor\n```python\nclass Mother:\n    pass\n\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"Father init\")\n    def __del__(self):\n        print(\"Father del\")\n\nclass Son(Father, Mother):\n    def __init__(self):\n        print(\"Son init\")\n    def __del__(self):\n        print(\"Son del\")\n\nson = Son()\nprint(son.name)\nson.run()\n\n\n```","source":"_posts/python.md","raw":"title: PYTHON2\n---\n\n# 字符串\n* `capitalize(...)` : `S.capitalize() -> str`\n\n    Return a capitalized version of S, i.e. make the first character\n    have upper case and the rest lower case.\n\n* `casefold(...)` : `S.casefold() -> str`\n\n    Return a version of S suitable for caseless comparisons.\n\n* `center(...)` : `S.center(width[, fillchar]) -> str`\n\n    Return S centered in a string of length width. Padding is\n    done using the specified fill character (default is a space)\n\n* `count(...)` : `S.count(sub[, start[, end]]) -> int`\n\n    Return the number of non-overlapping occurrences of substring sub in\n    string S[start:end].  Optional arguments start and end are\n    interpreted as in slice notation.\n\n* `encode(...)` : `S.encode(encoding='utf-8', errors='strict') -> bytes`\n\n    Encode S using the codec registered for encoding. Default encoding\n    is 'utf-8'. errors may be given to set a different error\n    handling scheme. Default is 'strict' meaning that encoding errors raise\n    a UnicodeEncodeError. Other possible values are 'ignore', 'replace' and\n    'xmlcharrefreplace' as well as any other name registered with\n    codecs.register_error that can handle UnicodeEncodeErrors.\n\n* `endswith(...)` : `S.endswith(suffix[, start[, end]]) -> bool`\n\n    Return True if S ends with the specified suffix, False otherwise.\n    With optional start, test S beginning at that position.\n    With optional end, stop comparing S at that position.\n    suffix can also be a tuple of strings to try.\n\n* `expandtabs(...)` : `S.expandtabs(tabsize=8) -> str`\n\n    Return a copy of S where all tab characters are expanded using spaces.\n    If tabsize is not given, a tab size of 8 characters is assumed.\n\n* `find(...)` : `S.find(sub[, start[, end]]) -> int`\n\n    Return the lowest index in S where substring sub is found,\n    such that sub is contained within S[start:end].  Optional\n    arguments start and end are interpreted as in slice notation.\n\n    Return -1 on failure.\n\n* `format(...)` : `S.format(*args, **kwargs) -> str`\n\n    Return a formatted version of S, using substitutions from args and kwargs.\n    The substitutions are identified by braces ('{' and '}').\n\n* `format_map(...)` : `S.format_map(mapping) -> str`\n\n    Return a formatted version of S, using substitutions from mapping.\n    The substitutions are identified by braces ('{' and '}').\n\n* `index(...)` : `S.index(sub[, start[, end]]) -> int`\n\n    Like S.find() but raise ValueError when the substring is not found.\n\n* `isalnum(...)` : `S.isalnum() -> bool`\n\n    Return True if all characters in S are alphanumeric\n    and there is at least one character in S, False otherwise.\n\n* `isalpha(...)` : `S.isalpha() -> bool`\n\n    Return True if all characters in S are alphabetic\n    and there is at least one character in S, False otherwise.\n\n* `isdecimal(...)` : `S.isdecimal() -> bool`\n\n    Return True if there are only decimal characters in S,\n    False otherwise.\n\n* `isdigit(...)` : `S.isdigit() -> bool`\n\n    Return True if all characters in S are digits\n    and there is at least one character in S, False otherwise.\n\n* `isidentifier(...)` : `S.isidentifier() -> bool`\n\n    Return True if S is a valid identifier according\n    to the language definition.\n\n    Use keyword.iskeyword() to test for reserved identifiers\n    such as \"def\" and \"class\".\n\n* `islower(...)` : `S.islower() -> bool`\n\n    Return True if all cased characters in S are lowercase and there is\n    at least one cased character in S, False otherwise.\n\n* `isnumeric(...)` : `S.isnumeric() -> bool`\n\n    Return True if there are only numeric characters in S,\n    False otherwise.\n\n* `isprintable(...)` : `S.isprintable() -> bool`\n\n    Return True if all characters in S are considered\n    printable in repr() or S is empty, False otherwise.\n\n* `isspace(...)` : `S.isspace() -> bool`\n\n    Return True if all characters in S are whitespace\n    and there is at least one character in S, False otherwise.\n\n* `istitle(...)` : `S.istitle() -> bool`\n\n    Return True if S is a titlecased string and there is at least one\n    character in S, i.e. upper- and titlecase characters may only\n    follow uncased characters and lowercase characters only cased ones.\n    Return False otherwise.\n\n* `isupper(...)` : `S.isupper() -> bool`\n\n    Return True if all cased characters in S are uppercase and there is\n    at least one cased character in S, False otherwise.\n\n* `join(...)` : `S.join(iterable) -> str`\n\n    Return a string which is the concatenation of the strings in the\n    iterable.  The separator between elements is S.\n\n* `ljust(...)` : `S.ljust(width[, fillchar]) -> str`\n\n    Return S left-justified in a Unicode string of length width. Padding is\n    done using the specified fill character (default is a space).\n\n* `lower(...)` : `S.lower() -> str`\n\n    Return a copy of the string S converted to lowercase.\n\n* `lstrip(...)` : `S.lstrip([chars]) -> str`\n\n    Return a copy of the string S with leading whitespace removed.\n    If chars is given and not None, remove characters in chars instead.\n\n* `partition(...)` : `S.partition(sep) -> (head, sep, tail)`\n\n    Search for the separator sep in S, and return the part before it,\n    the separator itself, and the part after it.  If the separator is not\n    found, return S and two empty strings.\n\n* `replace(...)` : `S.replace(old, new[, count]) -> str`\n\n    Return a copy of S with all occurrences of substring\n    old replaced by new.  If the optional argument count is\n    given, only the first count occurrences are replaced.\n\n* `rfind(...)` : `S.rfind(sub[, start[, end]]) -> int`\n\n    Return the highest index in S where substring sub is found,\n    such that sub is contained within S[start:end].  Optional\n    arguments start and end are interpreted as in slice notation.\n\n    Return -1 on failure.\n\n* `rindex(...)` : `S.rindex(sub[, start[, end]]) -> int`\n\n    Like S.rfind() but raise ValueError when the substring is not found.\n\n* `rjust(...)` : `S.rjust(width[, fillchar]) -> str`\n\n    Return S right-justified in a string of length width. Padding is\n    done using the specified fill character (default is a space).\n\n* `rpartition(...)` : `S.rpartition(sep) -> (head, sep, tail)`\n\n    Search for the separator sep in S, starting at the end of S, and return\n    the part before it, the separator itself, and the part after it.  If the\n    separator is not found, return two empty strings and S.\n\n* `rsplit(...)` : `S.rsplit(sep=None, maxsplit=-1) -> list of strings`\n\n    Return a list of the words in S, using sep as the\n    delimiter string, starting at the end of the string and\n    working to the front.  If maxsplit is given, at most maxsplit\n    splits are done. If sep is not specified, any whitespace string\n    is a separator.\n\n* `rstrip(...)` : `S.rstrip([chars]) -> str`\n\n    Return a copy of the string S with trailing whitespace removed.\n    If chars is given and not None, remove characters in chars instead.\n\n* `split(...)` : `S.split(sep=None, maxsplit=-1) -> list of strings`\n\n    Return a list of the words in S, using sep as the\n    delimiter string.  If maxsplit is given, at most maxsplit\n    splits are done. If sep is not specified or is None, any\n    whitespace string is a separator and empty strings are\n    removed from the result.\n\n* `splitlines(...)` : `S.splitlines([keepends]) -> list of strings`\n\n    Return a list of the lines in S, breaking at line boundaries.\n    Line breaks are not included in the resulting list unless keepends\n    is given and true.\n\n* `startswith(...)` : `S.startswith(prefix[, start[, end]]) -> bool`\n\n    Return True if S starts with the specified prefix, False otherwise.\n    With optional start, test S beginning at that position.\n    With optional end, stop comparing S at that position.\n    prefix can also be a tuple of strings to try.\n\n* `strip(...)` : `S.strip([chars]) -> str`\n\n    Return a copy of the string S with leading and trailing\n    whitespace removed.\n    If chars is given and not None, remove characters in chars instead.\n\n* `swapcase(...)` : `S.swapcase() -> str`\n\n    Return a copy of S with uppercase characters converted to lowercase\n    and vice versa.\n\n* `title(...)` : `S.title() -> str`\n\n    Return a titlecased version of S, i.e. words start with title case\n    characters, all remaining cased characters have lower case.\n\n* `translate(...)` : `S.translate(table) -> str`\n\n    Return a copy of the string S, where all characters have been mapped\n    through the given translation table, which must be a mapping of\n    Unicode ordinals to Unicode ordinals, strings, or None.\n    Unmapped characters are left untouched. Characters mapped to None\n    are deleted.\n\n* `upper(...)` : `S.upper() -> str`\n\n    Return a copy of S converted to uppercase.\n\n* `zfill(...)` : `S.zfill(width) -> str`\n\n    Pad a numeric string S with zeros on the left, to fill a field\n    of the specified width. The string S is never truncated.\n\n# 内置数据结构\n## 列表\n* 声明一个列表 `list = [123, \"ad\"]`\n* 索引第一个元素 `list[0]`\n* 在尾部添加一个元素 `list.append(2.56)`\n* 对第一个元素重新赋值 `list[0] = \"0\"`\n* 获取列表长度 `len(list)`\n* 删除第一个元素 `del list[0]`\n\n\n\n## 元组\n元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组\n```python\ntumple = (123, \"adf\")\nprint(tumple[0])\nprint(len(tumple))\n```\n\n## 字典\n```python\nmap = {\n       \"key1\":\"value1\",\n       \"key2\":\"value2\",\n       \"key3\":\"value3\",\n       }\nprint(map)\nprint(len(map))\nprint(map[\"key1\"])\ndel map[\"key1\"]\nprint(map)\n\nfor key in map:\n    print(key + \"   \" + map[key])\nif \"key2\" in map:\n    print(\"map contains key2\")\n\nhelp(dict)\n```\n\n## 序列\n序列的两个主要特点是索引操作符和切片操作符\n```python\nshoplist = ['apple', 'mango', 'carrot', 'banana']\n\nprint('Item 0 is', shoplist[0])\nprint('Item -1 is', shoplist[-1])\n\n# Slicing on a list\nprint('Item 1 to 3 is', shoplist[1:3])\nprint('Item 2 to end is', shoplist[2:])\nprint('Item 1 to -1 is', shoplist[1:-1])\nprint('Item start to end is', shoplist[:])\n\n# Slicing on a string\nname = 'swaroop'\nprint('characters 1 to 3 is', name[1:3])\nprint('characters 2 to end is', name[2:])\nprint('characters 1 to -1 is', name[1:-1])\nprint('characters start to end is', name[:])\n```\n\n\n# 文件\n\n\n# 控制流\n## if\n```python\ntmp = 0\nif tmp > 0 :\n    print(\">\")\nelif tmp < 0 :\n    print(\"<\")\nelse :\n    print(\"=\")\n```\n\n## while\n```python\ntmp = 0\nwhile tmp < 3 :\n    print(tmp)\n    tmp +=1\nelse :\n    print(\"over\")\n```\n\n## for\n```python\nfor i in [0,1,2,3,4]:\n    print(i)\n\n    if i > 2 :\n        break\n    else :\n        continue\n\nelse:\n    print('loop over')\n```\n\n# 函数\n\n## 定义一个不带参数的函数\n```python\n# 定义一个不带参数的函数\ndef printHelloworld():\n    print(\"hello world\")\n\n# 调用函数\nprintHelloworld()\n```\n\n## 定义一个带参数的函数\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n## 函数中的局部变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    value = saywhat\n    print(value)\n\n# 调用函数\nprintHelloworld(\"hello world\")\n```\n\n当在函数内部修改了局部变量之后,并不会影响脚本中的变量\n```python\n# 定义一个带参数的函数\ndef printHelloworld(saywhat):\n    print(saywhat)\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nstr = \"hello world\"\nprintHelloworld(str)\nprint(str)\n```\n\n## 使用global语句\n```python\n# 定义一个带参数的函数\ndef printHelloworld():\n    global saywhat # 此处不可进行初始化\n    saywhat = \"new value\"\n    print(saywhat)\n\n# 调用函数\nprintHelloworld()\nprint(saywhat)\n```\n\n## 默认参数值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str + \" \" + str1 + \" \" + str2)\n\n# 调用函数\nprintHelloworld(\"123\", str2=\"789\")\n```\n\n## return返回值\n```python\ndef printHelloworld(str, str1=\"str1 value\", str2=\"str2 value\"):\n    print(str)\n    if str1==\"str1 value\" :\n        return \"nil value\"\n    print(str1)\n    print(str2)\n\n# 调用函数\nresult = printHelloworld(\"123\", str2=\"789\")\nprint(result)\n\nresult = printHelloworld(\"123\", str1=\"789\")\nprint(result)\n```\n\n# 模块\n模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。\n\n## 使用`sys`模块\n```python\nimport sys\n\nfor argv in sys.argv :\n    print(argv)\n```\n\n使用`from..import..`, `import`可以使用`*`\n```python\nfrom sys import argv\n\nfor argvtmp in argv :\n    print(argvtmp)\n```\n\n模块的name,下面的语法输出当前模块的name\n```python\nprint(__name__)\n```\n\n## 自定义模块\n* 建立`mymodule.py`文件\n```python\n# Filename: mymodule.py\n\ndef printModuleName():\n    print(__name__)\n```\n* 建立`test_mymodule.py`文件\n```python\nimport mymodule\n\nmymodule.printModuleName()\n```\n1. 需要注意的是`mymodule.py`文件的`Filename`必须和文件名相同\n2. 如果`module`的name是`__main__`说明这个module是由用户启动的\n\n# 面向对象\n\n## self\n类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称`self`\n```python\n\n```\n\n## 创建一个类\n```python\nclass Person:\n    pass\n\np = Person()\nprint p\n```\n\n## 对象的方法\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n\np = Person()\np.run()\n```\n\n### __init__方法\n`__init__`方法在类的一个对象被建立时，马上运行\n```python\nclass Person:\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"init\")\n\np = Person()\np.run()\n```\n\n### __del__方法\n```python\nclass Person:\n    def __init__(self):\n        print(\"init\")\n    def __del__(self):\n        print(\"__destory__\")\n\np = Person()\n```\n\n#### 类与对象的方法\n* 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。\n\n* 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。\n\n```python\nclass Father:\n    age = 0\n\nfather = Father()\nfather.age = 10\nFather.age = 20\nprint(father.age)\nprint(Father.age)\n```\n\n## 继承\n```python\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n\nclass Son(Father):\n    pass\n\nson = Son()\nprint(son.name)\nson.run()\n\n```\n\n### `__init__`, `__del__`在继承中的使用\nPython不会自动调用父类的constructor\n```python\nclass Mother:\n    pass\n\nclass Father:\n    name = \"Tom\"\n    def run(self):\n        print(\"run\")\n    def __init__(self):\n        print(\"Father init\")\n    def __del__(self):\n        print(\"Father del\")\n\nclass Son(Father, Mother):\n    def __init__(self):\n        print(\"Son init\")\n    def __del__(self):\n        print(\"Son del\")\n\nson = Son()\nprint(son.name)\nson.run()\n\n\n```","slug":"python","published":1,"date":"2015-09-16T07:53:08.718Z","updated":"2015-09-16T07:52:53.224Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9x000s74ufildr0l3y"},{"title":"logstash配置文件","_content":"### input插件\n```json\ninput {\n    # 用来收集系统性能和提供各种存储方式来存储不同值的机制\n\tcollectd {\t\n\t\tport => 25826 ## 端口号与发送端对应\n\t\ttype => collectd\n\t}\n\t# collectd的替换配置\n\tudp {\n\t\tport \t\t=> 25826\n\t\tbuffer_size => 1452\n\t\tworkers \t=> 3       # Default is 2\n\t\tqueue_size \t=> 30000   # Default is 2000\n\t\tcodec \t\t=> collectd { }\n\t\ttype \t\t=> \"collectd\"\n\t}\n\t# 只支持文件的绝对路径，而且会不自动递归目录. /path/to/**/*.log，用 ** 来缩写表示递归全部子目录。\n\tfile {\n        path \t\t\t\t=> [\"D:/logs/*.log\"]\n        type \t\t\t\t=> \"system\"\n        start_position \t\t=> \"beginning\"\n\t\tdiscover_interval \t=> # logstash 每隔多久去检查一次被监听的 path 下是否有新文件。默认值是 15 秒。\n\t\texclude \t\t\t=> # 不想被监听的文件可以排除出去，这里跟 path 一样支持 glob 展开。\n\t\tstat_interval  \t\t=> # logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒。\n\t\tstart_position   \t=> # logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行\n\t\t\n\t\t# codec配置\n\t\tcodec \t\t\t\t=> \"json\"\n    }\n\tstdin {\n        add_field => {\"key\" => \"value\"}\n        codec => \"plain\"\n        tags => [\"add\"]\n        type => \"std\"\n\t\t\n\t\tcodec => multiline {\n            pattern => \"^\\[\"\n            negate => true\n            what => \"previous\"\n        }\n    }\n\tsyslog {\n\t\tport => \"514\"\n\t}\n\tinput {\n\t\ttcp {\n\t\t\tport => 8888\n\t\t\tmode => \"server\"\n\t\t\tssl_enable => false\n\t\t}\n\t}\n}\n```\n\n### filter插件\n```json\nfilter {\n\t#命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它\t\n    grok {\n        match => [\"message\",  \"%{COMBINEDAPACHELOG}\"]\n    }\n\tdate {\n        match => [\"logdate\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\n    }\n\tjson {\n        source => \"message\"\n        target => \"jsoncontent\"\n    }\n\tmutate {\n\t\t#类型转换\n        convert => [\"request_time\", \"float\"]\n\t\t#字符串处理\n\t\tgsub \t=> [\"urlparams\", \"[\\\\?#]\", \"_\"]\n\t\tsplit \t=> [\"message\", \"|\"]\n\t\tjoin \t=> [\"message\", \",\"]\n\t\tmerge \t=> [\"message\", \"message\"]\n\t\t#字段处理\n\t\trename => [\"syslog_host\", \"host\"]\n\t\tupdate => [\"syslog_host\", \"host\"]\n\t\treplace => [\"syslog_host\", \"host\"]\n    }\n\truby {\n        \n    }\n\tsplit {\n        field => \"message\"\n        terminator => \"#\"\n    }\n\t\n}\n```\n\n### output插件\n```json\noutput {\n    file {\n        path => \"D:\\logs\\a.log\"\n        message_format => \"%{message}\"\n        gzip => false\n    }\n\telasticsearch {\n        host => \"192.168.0.2\"\n        protocol => \"http\"\n        index => \"logstash-%{type}-%{+YYYY.MM.dd}\"\n        index_type => \"%{type}\"\n        workers => 5\n        template_overwrite => true\n    }\n}\n```","source":"_posts/logstash_config.md","raw":"title: logstash配置文件\n---\n### input插件\n```json\ninput {\n    # 用来收集系统性能和提供各种存储方式来存储不同值的机制\n\tcollectd {\t\n\t\tport => 25826 ## 端口号与发送端对应\n\t\ttype => collectd\n\t}\n\t# collectd的替换配置\n\tudp {\n\t\tport \t\t=> 25826\n\t\tbuffer_size => 1452\n\t\tworkers \t=> 3       # Default is 2\n\t\tqueue_size \t=> 30000   # Default is 2000\n\t\tcodec \t\t=> collectd { }\n\t\ttype \t\t=> \"collectd\"\n\t}\n\t# 只支持文件的绝对路径，而且会不自动递归目录. /path/to/**/*.log，用 ** 来缩写表示递归全部子目录。\n\tfile {\n        path \t\t\t\t=> [\"D:/logs/*.log\"]\n        type \t\t\t\t=> \"system\"\n        start_position \t\t=> \"beginning\"\n\t\tdiscover_interval \t=> # logstash 每隔多久去检查一次被监听的 path 下是否有新文件。默认值是 15 秒。\n\t\texclude \t\t\t=> # 不想被监听的文件可以排除出去，这里跟 path 一样支持 glob 展开。\n\t\tstat_interval  \t\t=> # logstash 每隔多久检查一次被监听文件状态（是否有更新），默认是 1 秒。\n\t\tstart_position   \t=> # logstash 从什么位置开始读取文件数据，默认是结束位置，也就是说 logstash 进程会以类似 tail -F 的形式运行\n\t\t\n\t\t# codec配置\n\t\tcodec \t\t\t\t=> \"json\"\n    }\n\tstdin {\n        add_field => {\"key\" => \"value\"}\n        codec => \"plain\"\n        tags => [\"add\"]\n        type => \"std\"\n\t\t\n\t\tcodec => multiline {\n            pattern => \"^\\[\"\n            negate => true\n            what => \"previous\"\n        }\n    }\n\tsyslog {\n\t\tport => \"514\"\n\t}\n\tinput {\n\t\ttcp {\n\t\t\tport => 8888\n\t\t\tmode => \"server\"\n\t\t\tssl_enable => false\n\t\t}\n\t}\n}\n```\n\n### filter插件\n```json\nfilter {\n\t#命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它\t\n    grok {\n        match => [\"message\",  \"%{COMBINEDAPACHELOG}\"]\n    }\n\tdate {\n        match => [\"logdate\", \"dd/MMM/yyyy:HH:mm:ss Z\"]\n    }\n\tjson {\n        source => \"message\"\n        target => \"jsoncontent\"\n    }\n\tmutate {\n\t\t#类型转换\n        convert => [\"request_time\", \"float\"]\n\t\t#字符串处理\n\t\tgsub \t=> [\"urlparams\", \"[\\\\?#]\", \"_\"]\n\t\tsplit \t=> [\"message\", \"|\"]\n\t\tjoin \t=> [\"message\", \",\"]\n\t\tmerge \t=> [\"message\", \"message\"]\n\t\t#字段处理\n\t\trename => [\"syslog_host\", \"host\"]\n\t\tupdate => [\"syslog_host\", \"host\"]\n\t\treplace => [\"syslog_host\", \"host\"]\n    }\n\truby {\n        \n    }\n\tsplit {\n        field => \"message\"\n        terminator => \"#\"\n    }\n\t\n}\n```\n\n### output插件\n```json\noutput {\n    file {\n        path => \"D:\\logs\\a.log\"\n        message_format => \"%{message}\"\n        gzip => false\n    }\n\telasticsearch {\n        host => \"192.168.0.2\"\n        protocol => \"http\"\n        index => \"logstash-%{type}-%{+YYYY.MM.dd}\"\n        index_type => \"%{type}\"\n        workers => 5\n        template_overwrite => true\n    }\n}\n```","slug":"logstash_config","published":1,"date":"2015-09-08T08:54:53.249Z","updated":"2015-09-08T08:54:06.580Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfje9z000t74ufnd7bc1u5"},{"title":"类加载机制","_content":"# 类加载机制\n\n## 类从被加载进虚拟机内存开始到卸载出内存的生命周期:\n```java\n  1. 加载\n  2. 验证\n  3. 准备\n  4. 解析\n  5. 初始化\n  6. 使用\n  7. 卸载\n```\n\n###### 特殊说明\n```java\n2.验证, 3.准备, 4.解析 又称为连接阶段\n1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载\n```\n\n### 1. 加载:\n##### 虚拟机通过下面三个阶段完成一个类的加载过程\n\n1. 通过一个类的全限定名来获取此类的二进制流.\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构\n3. 在java对中生成一个代表这个类的java.class.Class对象,作为方法区这些数据的入口,外部程序通过Class对象来访问存储在方法区里的类型数据.\n\n##### 加载阶段的特殊说明\n\n加载阶段是开发阶段可控性最强的,因为我们可以使用系统提供的类加载器来完成类的加载,我们也可以自己实现类加载虽然虚拟机规定了需要上面三个过程加载一个类,但是并没有具体说明. 例如\"通过一个类的全限定名来获取此类的二进制流\",它并没有说明从哪里获取以及如何获取,这就给虚拟机加载的具体实现留下了很大的空间\n\n相对与其他类加载阶段,加载阶段(准确的说是加载阶段中获取类的二进制流的动作)是开发期可控性最强的阶段,因为加载阶段既可以使用系统提供的类加载器完成,也可以通过用户自定义的类加载器去完成.\n\n###### 加载阶段完成后的动作\n\n加载阶段完成后,虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中,方法区中的数据格式由虚拟机自行定义.然后在java堆中实例化一个java.lang.Class类的对象,这个对象将作为程序访问方法区中的这些类型数据的外部接口.加载阶段与连接阶段开始时间顺序是一定的,但是加载阶段可能还没完成,连接阶段就已经开始了,但这些夹在加载阶段的动作,仍然属于连接阶段的内容.\n\n### 2. 验证:\n\n验证阶段是为了确保Class文件的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全.java语言本身是相对安全的语言,使用纯粹的java代码无法做到诸如访问数组边界以外的数据,将一个对象转型为它并未实现的类型,跳转到不存在的代码之类的事情,如果这样做了,编译器将拒绝编译. 在字节码层面上, 上述java代码无法做到的事情是可以实现的,至少语义上是可以表达的. 虚拟机如果不检查输入的字节流,对其完全信任的话,很可能会输入有害的字节流而导致系统崩溃.\n\n\n#### 校验过程\n##### class文件格式验证 (保证输入的字节流能正确地解析并存储于方法区之内.)\n确保符合Class文件规范,且能被当前版本的虚拟机处理.\n\n1. 是否以魔术0xCAFEBABY 开头\n2. 主次版本号是否在当前虚拟机处理范围内.\n3. 常量池中是否有不被支持的常量类型(检查常量tag标志)\n4. ... 还有很多其他校验\n\n##### 元数据验证  (基于方法区的数据结构)\n进行语义分析验证,以便符合java语言规范. 基本上就是在检验数据类型\n\n1. 这个类是否是父类.\n2. 这个类是否继承了不允许继承的类(被final修饰的类)\n3. 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法\n4. ... 还有很多其他校验\n\n##### 字节码验证  (基于方法区的数据结构)\n\n基本上是在对方法体进行验证.这个校验是整个验证过程中最复杂的一个阶段,主要是针对数据流和控制流进行分析. 在对元数据信息的数据类型做完校验后,这阶段对类的方法体进行校验.\n\n1. 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表.\n2. 保证跳转指令不会跳转到方法体以外的字节码指令上\n3. ...  还有很多其他校验\n\n在JDK1.6之后javac编译器进行了一项优化, 给方法体的Code属性的属性表中增加了一项\"StackMapTable\"属性,这项属性描述了方法体中所有的基本块(Basic Block,按照控制流拆分的代码块) 开始时本地变量表和操作数栈应有的状态, 这可以将字节码验证的类型推导转变为类型检查从而节省一些时间.\n\n##### 符号引用验证\n\n最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验\n\n1. 符号引用通过字符串描述的全限定名是否能找到对应的类\n2. 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段\n3. ... 还有很多其他的校验\n\n符号引用的校验是确保解析动作能正常执行.\n\n\n### 3. 准备\n\n准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些内存都将在方法区中进行分配. 这个阶段中有俩个容易产生混淆的概念需要强调一下,首先是这时候进行内存分配的仅包括类变量,而不包括实例变量,实例变量将会在对象实例化时随着对象\n一起分配在java堆中. 其中是这里所说的初始值\"通常情况\"下是数据类型为0.例如:\n```java\npublic static int value = 123;\n```\n\n变量value在准备阶段初始值为0而不是123,因为这时候尚未开始执行任何java方法,而把value赋值为123的putstatic指令是程序编译后,存放于类构造器<clinit>()方法之中,所以value赋值123的动作将在初始化阶段才会被执行.但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值.\n\n\n### 4. 解析\n\n解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量)\n\n1. 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中.\n2. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在.\n\n#### 解析时间\n\n虚拟机并没有规定解析阶段发生的具体时间,只要求在`anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic`这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析.所以虚拟机会根据需要来判断,到底是在类被加载器加载时对常量池的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它.\n\n#### 多次解析\n\n对同一个符号引用进行多次解析请求是很常见的,虚拟机实现可能会对第一次解析的结果进行缓存(在运行时常量池中记录直接引用,并发常量标志为已解析状态)从而避免重复解析动作.无论是否真正执行了多次解析动作,虚拟机需要保证的都是在同一个实体中,如果一个符号引用之前已经被成功解析过,那么后续的引用解析请求就应当一直成功,同样,如果第一次解析失败,其他指令对这个符号的解析请求也应当收到相同的异常.下面将讲解四种引用的解析过程\n\n#### 解析过程\n##### 类或接口解析(CONSTANT_Class_info)\n\n假设当前代码所处的类为D,如果把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,虚拟机完成整个解析需要以下步骤\n\n1. 如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C.在加载过程中,由于元数据验证,字节码验证的需要,又将可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将宣告失败.\n\n2. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似\"[Ljava.lang.Integer\"的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是\"java.lang.Integer\",接着由虚拟机生成一个代表此数组维度和元素的数组对象\n\n3. 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出\"java.lang.IllegalAccessError\"异常\n\n##### 字段解析(CONSTANT_Fieldref_info)\n\n要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用. 如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示.\n\n1. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束\n\n2. 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n3. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n4. 否则,查找失败,抛出java.lang.NoSuchFieldError异常\n\n如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出\"java.lang.IllegalAccessError\"异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译~.\n\n##### 类方法解析(CONSTANT_Methodref_info)\n\n类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类.\n\n1. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError.\n\n2. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束.\n\n3. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束\n\n4. 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常\n\n5. 否则,宣告查找失败,抛出java.lang.NoSuchMethodError.\n\n最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError\n\n##### 接口方法解析(CONSTANT_InterfaceMethodref_info)\n\n接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口:\n\n1. 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常.\n\n2. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n3. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n4. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常\n\n由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出\"java.lang.IllegalAccessError\"异常\n\n### 5. 类的初始化\n\n类初始化阶段是类加载过程中最后一步,前面的类加载过程中,除了加载阶段用户应用程序可以通过自定义类加载参与之外,其余动作全部由虚拟机主导和控制.到了初始化阶段才真正开始执行类中定义的java字节码.\n\n在准备阶段,变量已经赋值过一次系统要求的初始值,而在初始阶段,则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源,或者可以从另一个角度来表达: 初始化阶段执行类构造器<clinit>方法的过程.\n\n#### <clinit>方法执行过程可能会影响程序运行行为的一些特点和细节\n\n1. <clinit>方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问.\n\n2. <clinit>()方法和实例的构造函数(<init>)不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的<clinit>()方法执行之前,父类的<clinit>方法已经执行完毕,因此虚拟机中第一个被执行的<clinit>()方法的类肯定是java.lang.Object\n\n3. 由于父类的<clinit>()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作\n\n4. <clinit>()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<clinit>()方法.\n\n5. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成<clinit>()方法.但接口与类不同的是,执行接口<clinit>方法不需要先执行父接口<clinit>()方法.只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的<clinit>()方法.\n\n6. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的<clinit>()方法,其他线程都需要阻塞等待,直到活动线程执行<clinit>()方法完毕. 如果,在一个类的<clinit>()方法中有耗时很长的操作,那就很可能造成多个进程阻塞.\n\n###### <clinit>方法执行顺序\n```java\n    public class NewClass {\n\n    static class Parent {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent {\n        public static int B = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n\n```\n###### 字段解析\n```java\n    public class DeadLoopClass {\n\n    static {\n        if(true) {\n            System.out.println(Thread.currentThread() + \" init DeadLoopClass \");\n            while(true){}\n        }\n    }\n\n    public static void main(String[] args) {\n        Runnable script = new Runnable() {\n\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread() + \" start\");\n                DeadLoopClass dlc = new DeadLoopClass();\n                System.out.println(Thread.currentThread() + \" run over\");\n            }\n\n        };\n\n        Thread t1 = new Thread(script);\n        Thread t2 = new Thread(script);\n        t1.start();\n        t2.start();\n    }\n}\n\n```\n#### 对类进行初始化的四种情况\n\n1. 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化\n\n2. 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化\n\n3. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化.\n\n4. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类.\n\n#### 被动引用的例子1\n```java\n/**\n *\n * 通过子类引用父类的静态字段,不会导致子类的类初始化\n */\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n\n\n}\n\nclass SubClass extends SuperClass {\n    static {\n        System.out.println(\"SubClass init\");\n    }\n}\n\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(SubClass.value);\n    }\n}\n```\n###### 被动引用的例子2\n```java\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n}\n\n/**\n *\n * 通过数组定义来引用类,不会触发此类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        SuperClass[] sca = new SuperClass[10];\n    }\n}\n```\n###### 被动引用的例子3\n```java\nclass ConstClass {\n    static {\n        System.out.println(\"ConstClass init\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n}\n/**\n *\n * 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,\n * 因此不会触发定义常量的类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n```\n\n# 类加载器\n\n## 类和类加载器\n\n#### 类加载器的意义\n\n类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等.\n\n#### 类加载器相等判断\n\n判断俩个类相等可以通过下面方法: Class对象的equals()方法, isAssignbleFrom()方法, isInstance()方法的返回结果, 也包括使用instanceof关键字做对象所属关系判断等.\n\n#### 不同的类加载器对instanceof关键字运算结果的影响\n```java\npublic class ClassLoaderTest {\n\n\tpublic static void main(String args) throws Exception {\n\n\t\tClassLoader myLoader = new ClassLoader() {\n\n\t\t\t@Override\n\t\t\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\t\t\ttry{\n\t\t\t\t\tint index = name.lastIndexOf(\".\") + 1;\n\t\t\t\t\tString fileName = name.substring(index) + \".class\";\n\t\t\t\t\tInputStream in = getClass().getResourceAsStream(fileName);\n\t\t\t\t\tif(in == null) {\n\t\t\t\t\t\treturn super.loadClass(name);\n\t\t\t\t\t}\n\n\t\t\t\t\tbyte[] b = new byte[in.available()];\n\t\t\t\t\tin.read(b);\n\t\t\t\t\treturn defineClass(name, b, 0, b.length);\n\t\t\t\t} catch(IOException e) {\n\t\t\t\t\tthrow new ClassNotFoundException(name);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tObject obj = myLoader.loadClass(ClassLoaderTest.class.getCanonicalName())\n\t\t\t\t.newInstance();\n\t\tSystem.out.println(obj.getClass());\n\t\tSystem.out.println(obj instanceof ClassLoaderTest);\n\t}\n}\n```\n\n## 双亲委派模型\n![ClassLoader的体系架构](/images/ClassLoader的体系架构.png)\n\n站在java虚拟机的角都讲, 只存在俩种不同的类加载器:一种是启动类加载器,这个类加载器使用C++语言实践,是虚拟机自身的一部分. 另一种就是其他的类加载器,这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:`java.lang.ClassLoader`\n\n### 系统提供的类加载器\n##### 启动类加载器\n\n这个类加载器负责将<JAVA_HOME>\\lib目录中的,或者-Xbootclasspath参数所指定的路径中的,并且是虚拟机识别的(仅按照\n文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法\n被java程序直接使用.\n\n##### 扩展类加载器\n\n这个类加载器由sun.misc.Launcher$ExtClassLoader 实现,负责加载<JAVA_HOME>\\lib\\ext 目录中的,或者被java.ext.dirs\n系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器.\n\n##### 应用程序加载器\n\n这个类加载器由sun.misc.Launcher$AppClassLoader来实现. 由于类加载器是ClassLoader中getSystemClassLoader()方法\n的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个\n类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器.\n\n##### 双亲委派模型定义\n\n类加载器之间的这种层次关系, 就称为类加载器的双亲委派模型. 双亲委派模型除了顶层的启动类加载器外,其余的类加载都应当有自己的类加载. 这里的类加载器之间的父子关系一般不会以继承的关系来实现,而都是使用组合关系来复用类加载器\n\n###### 双亲委派模型的工作工程\n\n如果一个类加载器收到了类加载的请求,它首先不会自己去尝试加载这个类,而是把这个请求委派给父类加载器去完成,每一个\n层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个\n加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载.\n\n######\n\n使用双亲委派模型来组织类加载之间的关系,有一个显而易见的好处就是java类随着它的类加载一起具备了一种带有优先级的\n层次关系.例如类 java.lang.Object,它存放在rt.jar之中,无论哪一个类加载要加载这个类,最终都是委派给启动类加载器\n进行加载,因此Object类在程序的各种类加载器环境中都是同一个类.\n\n相反,如果没有使用双亲委派模型,由各个类加载器自行去加载的话,如果用户自己写了一个名为java.lang.Object的类,并\n放在程序ClassPath中,那系统中将会出现多个不同的Object类,java类型体系中最基础的行为也就无从保证,应用程序也将会\n变得一片混乱. (可以自己试试写一个与rt.jar类库中已有类重名的java类,将会发现可以正常编译,但永远无法被加载运行).\n\n### 破坏双亲委派模型\n* 为了向前兼容,JDK1.2之后的java.lang.ClassLoader添加了一个新的protected方法findClass(),在此之前,用户去继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法,因此虚拟机在进行类加载的时候会调用加载器的私有方法loadClassInternal(),而这个类的唯一逻辑就是去调用自己的loadClass().\n\nJDK1.2之后已不提倡用户再去覆盖loadClass()方法,而应当把自己的类加载逻辑写到findClass()方法中,在loadClass()方法的逻辑里如果父类加载失败,则会调用自己的findClass()方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的\n\n* 为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在\n应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.\n\n有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则.\n\n* 由于用户对程序动态性的追求而导致的\n\n在JSR-297,JSR-277 规范从纸上标准变成真正可运行的程序之前,OSGI是当前业界JAVA模块化标准.\n在OSGI每一个程序模块都有一个自己的类加载器,当需要更换一个Bundle,就把Bundle连同类加载一起换掉以实现代码的热替换.\n在OSGI环境下,类加载器不再是双亲委派模型中的树状结构,而是进一步发展为网状结构,当收到类加载请求时,osgi将按照下面\n的顺序进行类搜索:\n\n1. 将以java.*开头的类,委派给类加载器加载\n\n2. 否则,将委派列表名单内的类,委派给父类加载器加载.\n\n3. 否则,将Import列表中的类,委派给Export这个类的Bundle的类加载器加载.\n\n4. 否则,查找当前Bundle的ClassPath,使用自己的类加载器加载.\n\n5. 否则,查找类是否在自己的Fragment Bundle中,如果在,则委派给Fragment Bundle的类加载器加载\n\n6. 否则,查找Dynamic Import列表的Bundle,如果在,则委派给对应Bundle的类加载器加载.\n\n7. 否则,类查找失败.\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/jvm7/类加载.md","raw":"categories:\n- jvm7\ntitle: 类加载机制\n---\n# 类加载机制\n\n## 类从被加载进虚拟机内存开始到卸载出内存的生命周期:\n```java\n  1. 加载\n  2. 验证\n  3. 准备\n  4. 解析\n  5. 初始化\n  6. 使用\n  7. 卸载\n```\n\n###### 特殊说明\n```java\n2.验证, 3.准备, 4.解析 又称为连接阶段\n1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载\n```\n\n### 1. 加载:\n##### 虚拟机通过下面三个阶段完成一个类的加载过程\n\n1. 通过一个类的全限定名来获取此类的二进制流.\n2. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构\n3. 在java对中生成一个代表这个类的java.class.Class对象,作为方法区这些数据的入口,外部程序通过Class对象来访问存储在方法区里的类型数据.\n\n##### 加载阶段的特殊说明\n\n加载阶段是开发阶段可控性最强的,因为我们可以使用系统提供的类加载器来完成类的加载,我们也可以自己实现类加载虽然虚拟机规定了需要上面三个过程加载一个类,但是并没有具体说明. 例如\"通过一个类的全限定名来获取此类的二进制流\",它并没有说明从哪里获取以及如何获取,这就给虚拟机加载的具体实现留下了很大的空间\n\n相对与其他类加载阶段,加载阶段(准确的说是加载阶段中获取类的二进制流的动作)是开发期可控性最强的阶段,因为加载阶段既可以使用系统提供的类加载器完成,也可以通过用户自定义的类加载器去完成.\n\n###### 加载阶段完成后的动作\n\n加载阶段完成后,虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中,方法区中的数据格式由虚拟机自行定义.然后在java堆中实例化一个java.lang.Class类的对象,这个对象将作为程序访问方法区中的这些类型数据的外部接口.加载阶段与连接阶段开始时间顺序是一定的,但是加载阶段可能还没完成,连接阶段就已经开始了,但这些夹在加载阶段的动作,仍然属于连接阶段的内容.\n\n### 2. 验证:\n\n验证阶段是为了确保Class文件的信息符合当前虚拟机的要求,并且不会危害虚拟机自身的安全.java语言本身是相对安全的语言,使用纯粹的java代码无法做到诸如访问数组边界以外的数据,将一个对象转型为它并未实现的类型,跳转到不存在的代码之类的事情,如果这样做了,编译器将拒绝编译. 在字节码层面上, 上述java代码无法做到的事情是可以实现的,至少语义上是可以表达的. 虚拟机如果不检查输入的字节流,对其完全信任的话,很可能会输入有害的字节流而导致系统崩溃.\n\n\n#### 校验过程\n##### class文件格式验证 (保证输入的字节流能正确地解析并存储于方法区之内.)\n确保符合Class文件规范,且能被当前版本的虚拟机处理.\n\n1. 是否以魔术0xCAFEBABY 开头\n2. 主次版本号是否在当前虚拟机处理范围内.\n3. 常量池中是否有不被支持的常量类型(检查常量tag标志)\n4. ... 还有很多其他校验\n\n##### 元数据验证  (基于方法区的数据结构)\n进行语义分析验证,以便符合java语言规范. 基本上就是在检验数据类型\n\n1. 这个类是否是父类.\n2. 这个类是否继承了不允许继承的类(被final修饰的类)\n3. 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法\n4. ... 还有很多其他校验\n\n##### 字节码验证  (基于方法区的数据结构)\n\n基本上是在对方法体进行验证.这个校验是整个验证过程中最复杂的一个阶段,主要是针对数据流和控制流进行分析. 在对元数据信息的数据类型做完校验后,这阶段对类的方法体进行校验.\n\n1. 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表.\n2. 保证跳转指令不会跳转到方法体以外的字节码指令上\n3. ...  还有很多其他校验\n\n在JDK1.6之后javac编译器进行了一项优化, 给方法体的Code属性的属性表中增加了一项\"StackMapTable\"属性,这项属性描述了方法体中所有的基本块(Basic Block,按照控制流拆分的代码块) 开始时本地变量表和操作数栈应有的状态, 这可以将字节码验证的类型推导转变为类型检查从而节省一些时间.\n\n##### 符号引用验证\n\n最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验\n\n1. 符号引用通过字符串描述的全限定名是否能找到对应的类\n2. 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段\n3. ... 还有很多其他的校验\n\n符号引用的校验是确保解析动作能正常执行.\n\n\n### 3. 准备\n\n准备阶段是正式为类变量分配内存并设置类变量初始值的阶段,这些内存都将在方法区中进行分配. 这个阶段中有俩个容易产生混淆的概念需要强调一下,首先是这时候进行内存分配的仅包括类变量,而不包括实例变量,实例变量将会在对象实例化时随着对象\n一起分配在java堆中. 其中是这里所说的初始值\"通常情况\"下是数据类型为0.例如:\n```java\npublic static int value = 123;\n```\n\n变量value在准备阶段初始值为0而不是123,因为这时候尚未开始执行任何java方法,而把value赋值为123的putstatic指令是程序编译后,存放于类构造器<clinit>()方法之中,所以value赋值123的动作将在初始化阶段才会被执行.但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值.\n\n\n### 4. 解析\n\n解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量)\n\n1. 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中.\n2. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在.\n\n#### 解析时间\n\n虚拟机并没有规定解析阶段发生的具体时间,只要求在`anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic`这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析.所以虚拟机会根据需要来判断,到底是在类被加载器加载时对常量池的符号引用进行解析,还是等到一个符号引用将要被使用前才去解析它.\n\n#### 多次解析\n\n对同一个符号引用进行多次解析请求是很常见的,虚拟机实现可能会对第一次解析的结果进行缓存(在运行时常量池中记录直接引用,并发常量标志为已解析状态)从而避免重复解析动作.无论是否真正执行了多次解析动作,虚拟机需要保证的都是在同一个实体中,如果一个符号引用之前已经被成功解析过,那么后续的引用解析请求就应当一直成功,同样,如果第一次解析失败,其他指令对这个符号的解析请求也应当收到相同的异常.下面将讲解四种引用的解析过程\n\n#### 解析过程\n##### 类或接口解析(CONSTANT_Class_info)\n\n假设当前代码所处的类为D,如果把一个从未解析过的符号引用N解析为一个类或接口C的直接引用,虚拟机完成整个解析需要以下步骤\n\n1. 如果C不是一个数组类型,那虚拟机将会把代表N的全限定名传递给D的类加载器去加载这个类C.在加载过程中,由于元数据验证,字节码验证的需要,又将可能触发其他相关类的加载动作,例如加载这个类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将宣告失败.\n\n2. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似\"[Ljava.lang.Integer\"的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是\"java.lang.Integer\",接着由虚拟机生成一个代表此数组维度和元素的数组对象\n\n3. 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出\"java.lang.IllegalAccessError\"异常\n\n##### 字段解析(CONSTANT_Fieldref_info)\n\n要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用. 如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示.\n\n1. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束\n\n2. 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n3. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束.\n\n4. 否则,查找失败,抛出java.lang.NoSuchFieldError异常\n\n如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出\"java.lang.IllegalAccessError\"异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译~.\n\n##### 类方法解析(CONSTANT_Methodref_info)\n\n类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类.\n\n1. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError.\n\n2. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束.\n\n3. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束\n\n4. 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常\n\n5. 否则,宣告查找失败,抛出java.lang.NoSuchMethodError.\n\n最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError\n\n##### 接口方法解析(CONSTANT_InterfaceMethodref_info)\n\n接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口:\n\n1. 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常.\n\n2. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n3. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束.\n\n4. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常\n\n由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出\"java.lang.IllegalAccessError\"异常\n\n### 5. 类的初始化\n\n类初始化阶段是类加载过程中最后一步,前面的类加载过程中,除了加载阶段用户应用程序可以通过自定义类加载参与之外,其余动作全部由虚拟机主导和控制.到了初始化阶段才真正开始执行类中定义的java字节码.\n\n在准备阶段,变量已经赋值过一次系统要求的初始值,而在初始阶段,则是根据程序员通过程序制定的主观计划去初始化类变量和其他资源,或者可以从另一个角度来表达: 初始化阶段执行类构造器<clinit>方法的过程.\n\n#### <clinit>方法执行过程可能会影响程序运行行为的一些特点和细节\n\n1. <clinit>方法是由编译器自动收集类中的所有变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问.\n\n2. <clinit>()方法和实例的构造函数(<init>)不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的<clinit>()方法执行之前,父类的<clinit>方法已经执行完毕,因此虚拟机中第一个被执行的<clinit>()方法的类肯定是java.lang.Object\n\n3. 由于父类的<clinit>()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作\n\n4. <clinit>()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成<clinit>()方法.\n\n5. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成<clinit>()方法.但接口与类不同的是,执行接口<clinit>方法不需要先执行父接口<clinit>()方法.只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的<clinit>()方法.\n\n6. 虚拟机会保证一个类的<clinit>()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的<clinit>()方法,其他线程都需要阻塞等待,直到活动线程执行<clinit>()方法完毕. 如果,在一个类的<clinit>()方法中有耗时很长的操作,那就很可能造成多个进程阻塞.\n\n###### <clinit>方法执行顺序\n```java\n    public class NewClass {\n\n    static class Parent {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Sub extends Parent {\n        public static int B = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Sub.B);\n    }\n}\n\n```\n###### 字段解析\n```java\n    public class DeadLoopClass {\n\n    static {\n        if(true) {\n            System.out.println(Thread.currentThread() + \" init DeadLoopClass \");\n            while(true){}\n        }\n    }\n\n    public static void main(String[] args) {\n        Runnable script = new Runnable() {\n\n            @Override\n            public void run() {\n                System.out.println(Thread.currentThread() + \" start\");\n                DeadLoopClass dlc = new DeadLoopClass();\n                System.out.println(Thread.currentThread() + \" run over\");\n            }\n\n        };\n\n        Thread t1 = new Thread(script);\n        Thread t2 = new Thread(script);\n        t1.start();\n        t2.start();\n    }\n}\n\n```\n#### 对类进行初始化的四种情况\n\n1. 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化\n\n2. 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化\n\n3. 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化.\n\n4. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类.\n\n#### 被动引用的例子1\n```java\n/**\n *\n * 通过子类引用父类的静态字段,不会导致子类的类初始化\n */\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n\n\n}\n\nclass SubClass extends SuperClass {\n    static {\n        System.out.println(\"SubClass init\");\n    }\n}\n\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(SubClass.value);\n    }\n}\n```\n###### 被动引用的例子2\n```java\nclass SuperClass {\n\n    static {\n        System.out.println(\"SuperClass init\");\n    }\n\n    public static int value = 123;\n}\n\n/**\n *\n * 通过数组定义来引用类,不会触发此类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        SuperClass[] sca = new SuperClass[10];\n    }\n}\n```\n###### 被动引用的例子3\n```java\nclass ConstClass {\n    static {\n        System.out.println(\"ConstClass init\");\n    }\n    public static final String HELLOWORLD = \"hello world\";\n}\n/**\n *\n * 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,\n * 因此不会触发定义常量的类的初始化\n */\npublic class NotInitialization {\n    public static void main(String[] args) {\n        System.out.println(ConstClass.HELLOWORLD);\n    }\n}\n```\n\n# 类加载器\n\n## 类和类加载器\n\n#### 类加载器的意义\n\n类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等.\n\n#### 类加载器相等判断\n\n判断俩个类相等可以通过下面方法: Class对象的equals()方法, isAssignbleFrom()方法, isInstance()方法的返回结果, 也包括使用instanceof关键字做对象所属关系判断等.\n\n#### 不同的类加载器对instanceof关键字运算结果的影响\n```java\npublic class ClassLoaderTest {\n\n\tpublic static void main(String args) throws Exception {\n\n\t\tClassLoader myLoader = new ClassLoader() {\n\n\t\t\t@Override\n\t\t\tpublic Class<?> loadClass(String name) throws ClassNotFoundException {\n\t\t\t\ttry{\n\t\t\t\t\tint index = name.lastIndexOf(\".\") + 1;\n\t\t\t\t\tString fileName = name.substring(index) + \".class\";\n\t\t\t\t\tInputStream in = getClass().getResourceAsStream(fileName);\n\t\t\t\t\tif(in == null) {\n\t\t\t\t\t\treturn super.loadClass(name);\n\t\t\t\t\t}\n\n\t\t\t\t\tbyte[] b = new byte[in.available()];\n\t\t\t\t\tin.read(b);\n\t\t\t\t\treturn defineClass(name, b, 0, b.length);\n\t\t\t\t} catch(IOException e) {\n\t\t\t\t\tthrow new ClassNotFoundException(name);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\n\t\tObject obj = myLoader.loadClass(ClassLoaderTest.class.getCanonicalName())\n\t\t\t\t.newInstance();\n\t\tSystem.out.println(obj.getClass());\n\t\tSystem.out.println(obj instanceof ClassLoaderTest);\n\t}\n}\n```\n\n## 双亲委派模型\n![ClassLoader的体系架构](/images/ClassLoader的体系架构.png)\n\n站在java虚拟机的角都讲, 只存在俩种不同的类加载器:一种是启动类加载器,这个类加载器使用C++语言实践,是虚拟机自身的一部分. 另一种就是其他的类加载器,这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:`java.lang.ClassLoader`\n\n### 系统提供的类加载器\n##### 启动类加载器\n\n这个类加载器负责将<JAVA_HOME>\\lib目录中的,或者-Xbootclasspath参数所指定的路径中的,并且是虚拟机识别的(仅按照\n文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法\n被java程序直接使用.\n\n##### 扩展类加载器\n\n这个类加载器由sun.misc.Launcher$ExtClassLoader 实现,负责加载<JAVA_HOME>\\lib\\ext 目录中的,或者被java.ext.dirs\n系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器.\n\n##### 应用程序加载器\n\n这个类加载器由sun.misc.Launcher$AppClassLoader来实现. 由于类加载器是ClassLoader中getSystemClassLoader()方法\n的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个\n类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器.\n\n##### 双亲委派模型定义\n\n类加载器之间的这种层次关系, 就称为类加载器的双亲委派模型. 双亲委派模型除了顶层的启动类加载器外,其余的类加载都应当有自己的类加载. 这里的类加载器之间的父子关系一般不会以继承的关系来实现,而都是使用组合关系来复用类加载器\n\n###### 双亲委派模型的工作工程\n\n如果一个类加载器收到了类加载的请求,它首先不会自己去尝试加载这个类,而是把这个请求委派给父类加载器去完成,每一个\n层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个\n加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载.\n\n######\n\n使用双亲委派模型来组织类加载之间的关系,有一个显而易见的好处就是java类随着它的类加载一起具备了一种带有优先级的\n层次关系.例如类 java.lang.Object,它存放在rt.jar之中,无论哪一个类加载要加载这个类,最终都是委派给启动类加载器\n进行加载,因此Object类在程序的各种类加载器环境中都是同一个类.\n\n相反,如果没有使用双亲委派模型,由各个类加载器自行去加载的话,如果用户自己写了一个名为java.lang.Object的类,并\n放在程序ClassPath中,那系统中将会出现多个不同的Object类,java类型体系中最基础的行为也就无从保证,应用程序也将会\n变得一片混乱. (可以自己试试写一个与rt.jar类库中已有类重名的java类,将会发现可以正常编译,但永远无法被加载运行).\n\n### 破坏双亲委派模型\n* 为了向前兼容,JDK1.2之后的java.lang.ClassLoader添加了一个新的protected方法findClass(),在此之前,用户去继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法,因此虚拟机在进行类加载的时候会调用加载器的私有方法loadClassInternal(),而这个类的唯一逻辑就是去调用自己的loadClass().\n\nJDK1.2之后已不提倡用户再去覆盖loadClass()方法,而应当把自己的类加载逻辑写到findClass()方法中,在loadClass()方法的逻辑里如果父类加载失败,则会调用自己的findClass()方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的\n\n* 为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在\n应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.\n\n有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则.\n\n* 由于用户对程序动态性的追求而导致的\n\n在JSR-297,JSR-277 规范从纸上标准变成真正可运行的程序之前,OSGI是当前业界JAVA模块化标准.\n在OSGI每一个程序模块都有一个自己的类加载器,当需要更换一个Bundle,就把Bundle连同类加载一起换掉以实现代码的热替换.\n在OSGI环境下,类加载器不再是双亲委派模型中的树状结构,而是进一步发展为网状结构,当收到类加载请求时,osgi将按照下面\n的顺序进行类搜索:\n\n1. 将以java.*开头的类,委派给类加载器加载\n\n2. 否则,将委派列表名单内的类,委派给父类加载器加载.\n\n3. 否则,将Import列表中的类,委派给Export这个类的Bundle的类加载器加载.\n\n4. 否则,查找当前Bundle的ClassPath,使用自己的类加载器加载.\n\n5. 否则,查找类是否在自己的Fragment Bundle中,如果在,则委派给Fragment Bundle的类加载器加载\n\n6. 否则,查找Dynamic Import列表的Bundle,如果在,则委派给对应Bundle的类加载器加载.\n\n7. 否则,类查找失败.\n\n\n\n\n\n\n\n\n\n\n","slug":"jvm7/类加载","published":1,"date":"2015-09-18T06:28:21.292Z","updated":"2015-09-18T06:17:45.667Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjea0000u74uf0o5ytdnn"},{"title":"JVM 相关工具","_content":"# JVM 相关工具\n\n## JPS:虚拟机进程状况工具\n列出正在运行的虚拟机进程,并显示虚拟机执行主类的名称,以及这些进程的本地虚拟机的唯一ID(LVMID). 对于\n本地虚拟机进程来说,LVMID与操作系统的进程ID是一致的,使用windwos的任务管理器或者Unix的ps命令也可以\n查询到虚拟机进程的LVMID,但如果同时启动了多个虚拟机进程,无法根据进程名称定位时,那就只能依赖jps命令\n显示主类的功能才能区分.\n######命令格式:\n```\njps [ options ] [hostid]\n```\njps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,hostid为RMI注册表中注册的主机名\n######jps工具主要选项\n* -q: 只输出LVMID,省略主类的名称\n* -m: 输出虚拟机进程启动时传递给主类main()函数的参数\n* -l: 输出主类的全名,如果进程执行的jar包,输出jar路径\n* -v: 输出虚拟机进程启动时JVM参数.\n\n##jstat:虚拟机统计信息监视工具\n用于监视虚拟机各种运行状态信息的命令行工具.它可以显示本地或远程虚拟机进程中的类装载,内存,\n垃圾收集,JIT编译等运行数据.\n######jstat命令格式\n```\njstat [ option vmid [interval [s|ms] [count]]]\n```\n对于命令格式中的VMID与LVMID需要特别说明一下:如果是本地虚拟机进程,VMID和LVMID是一致的,如果是远程\n虚拟机进程,那么VMID的格式应该是:\n```\n[protocol:] [//]lvmid[@hostname [:port] /servername]\n```\n选项option代表着用户希望查询的虚拟机信息,主要分为三类:类装载,垃圾收集,运行期编译状况.\n######jstat工具主要选项\n* -class: 监视类装载,卸载数量,总空间及类装载所耗费的时间\n* -gc: 监视java堆状况,包括Eden区,2个survivor区,老年代,永久代等的容量,已用空间,GC时间合计等信息.\n* -gccapacity: 监视内容与-gc基本相同,但输出主要关注java堆各个区域使用到最大和最小空间.\n* -gcutil: 监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比.\n* -gccause: 与-gcutil功能一样,但是会额外输出导致上一次GC产生的原因.\n* -gcnew:监视新生代GC的状况.\n* -gcnewcapacity: 监视内容与-gcnew基本相同输出主要关注使用到的最大和最小空间\n* -gcold: 监视老年代GC的状况.\n* -gcoldcapacity: 监视内容与-gcold基本相同,但输出主要关注使用到的最大和最小空间\n* -gcpermcapacity: 输出永久代使用到呃最大和最小空间\n* -compiler: 输出JIT编译器编译过的方法,耗时等信息\n* -printcompilation: 输出已经被JIT编译的方法.\n\n> E -> Eden. S0 -> Survivor0. S1 -> Survivor1. O -> Old. P -> Permanent. YGC -> YoungGC,Minor GC.\n> FGC  -> Full GC. FGCT -> Full GC Time.\n\n## Jinfo:Java配置\njinfo的作用是实时查看和调整虚拟机的各项参数.\n###### jinfo命令格式\n```\njinfo [ option ] pid\n```\n\n## Jmap:java内存映射工具\n用于生成堆转储快照.如果不使用jmap命令,想要获取java堆转储快照还有一些比较暴力的手段:\n`-XX:+HeapDumpOnOutOfMemoryError`,可以让虚拟机在OOM异常自动生成dump文件,通过\n`-XX:+HeapDumpOnCtrlBreak`参数则可以使用`[CTRL] + [Break]` 键让虚拟机生成dump文件,又或者在Linux系统\n下通过`kill -3`命令发送进程退出信号,也能拿到dump文件.\n\njmap的作用并不仅仅是为了获取dump文件,它还可以查询`finalize`执行队列,java堆和永久代的详细信息,如\n空间使用率,当前使用的是哪种收集器.\n\n和jinfo命令一样,jmap有不少功能是在windows平台下受限的,除了生成dump文件`-dump`选项和用于查看每个类的\n实例,空间占用统计的`-histo`选项所有系统操作系统都提供之外,其余选项只能在Linux/Solaris下使用.\n\n###### jmap命令格式\n```\njmap [ option ] vmid\n```\n\n###### jmap工具主要选项\n* `-dump`: 生成java堆转储快照.格式为:`-dump:[live,]format=b,file=<filename>`.live表示只dump存活对象\n* `-finalizerinfo`: 显示在`F-Queue`中等待`Finalizer`线程执行`finalize`方法的对象.\n* `-heap`: 显示java堆的详细信息,使用哪种回收器,参数配置,分代状况.\n* `-histo`: 显示堆中对象统计信息,包括类,实例数量和合计容量\n* `-permstat`: 以`ClassLoader`为统计口径显示永久代内存状态.\n* `-F`: 当虚拟机进程对`-dump`选项没有响应时,可使用这个选项强制生成dump快照\n\n## jstack: java堆栈跟踪工具\n`jstack`命令用于生成虚拟机当前时刻的线程快照.线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的\n集合,生成线程快照的主要目的是定位线程出现长时间停顿的原因,如[线程间死锁](),[死循环](),请求外部资源\n导致长时间等待.\n\n######jstack命令格式\n```\njstack [ option ] vmid\n```\n\n###### jstack工具主要选项\n* `-F`: 当正常输出的请求不被响应时,强制说出线程堆栈\n* `-l`: 除堆栈外,显示关于锁的附加信息\n* `-m`: 如果调用本地方法的话,可以显示c/c++的堆栈\n\n","source":"_posts/jvm7/相关工具.md","raw":"categories:\n- jvm7\ntitle: JVM 相关工具\n---\n# JVM 相关工具\n\n## JPS:虚拟机进程状况工具\n列出正在运行的虚拟机进程,并显示虚拟机执行主类的名称,以及这些进程的本地虚拟机的唯一ID(LVMID). 对于\n本地虚拟机进程来说,LVMID与操作系统的进程ID是一致的,使用windwos的任务管理器或者Unix的ps命令也可以\n查询到虚拟机进程的LVMID,但如果同时启动了多个虚拟机进程,无法根据进程名称定位时,那就只能依赖jps命令\n显示主类的功能才能区分.\n######命令格式:\n```\njps [ options ] [hostid]\n```\njps可以通过RMI协议查询开启了RMI服务的远程虚拟机进程状态,hostid为RMI注册表中注册的主机名\n######jps工具主要选项\n* -q: 只输出LVMID,省略主类的名称\n* -m: 输出虚拟机进程启动时传递给主类main()函数的参数\n* -l: 输出主类的全名,如果进程执行的jar包,输出jar路径\n* -v: 输出虚拟机进程启动时JVM参数.\n\n##jstat:虚拟机统计信息监视工具\n用于监视虚拟机各种运行状态信息的命令行工具.它可以显示本地或远程虚拟机进程中的类装载,内存,\n垃圾收集,JIT编译等运行数据.\n######jstat命令格式\n```\njstat [ option vmid [interval [s|ms] [count]]]\n```\n对于命令格式中的VMID与LVMID需要特别说明一下:如果是本地虚拟机进程,VMID和LVMID是一致的,如果是远程\n虚拟机进程,那么VMID的格式应该是:\n```\n[protocol:] [//]lvmid[@hostname [:port] /servername]\n```\n选项option代表着用户希望查询的虚拟机信息,主要分为三类:类装载,垃圾收集,运行期编译状况.\n######jstat工具主要选项\n* -class: 监视类装载,卸载数量,总空间及类装载所耗费的时间\n* -gc: 监视java堆状况,包括Eden区,2个survivor区,老年代,永久代等的容量,已用空间,GC时间合计等信息.\n* -gccapacity: 监视内容与-gc基本相同,但输出主要关注java堆各个区域使用到最大和最小空间.\n* -gcutil: 监视内容与-gc基本相同,但输出主要关注已使用空间占总空间的百分比.\n* -gccause: 与-gcutil功能一样,但是会额外输出导致上一次GC产生的原因.\n* -gcnew:监视新生代GC的状况.\n* -gcnewcapacity: 监视内容与-gcnew基本相同输出主要关注使用到的最大和最小空间\n* -gcold: 监视老年代GC的状况.\n* -gcoldcapacity: 监视内容与-gcold基本相同,但输出主要关注使用到的最大和最小空间\n* -gcpermcapacity: 输出永久代使用到呃最大和最小空间\n* -compiler: 输出JIT编译器编译过的方法,耗时等信息\n* -printcompilation: 输出已经被JIT编译的方法.\n\n> E -> Eden. S0 -> Survivor0. S1 -> Survivor1. O -> Old. P -> Permanent. YGC -> YoungGC,Minor GC.\n> FGC  -> Full GC. FGCT -> Full GC Time.\n\n## Jinfo:Java配置\njinfo的作用是实时查看和调整虚拟机的各项参数.\n###### jinfo命令格式\n```\njinfo [ option ] pid\n```\n\n## Jmap:java内存映射工具\n用于生成堆转储快照.如果不使用jmap命令,想要获取java堆转储快照还有一些比较暴力的手段:\n`-XX:+HeapDumpOnOutOfMemoryError`,可以让虚拟机在OOM异常自动生成dump文件,通过\n`-XX:+HeapDumpOnCtrlBreak`参数则可以使用`[CTRL] + [Break]` 键让虚拟机生成dump文件,又或者在Linux系统\n下通过`kill -3`命令发送进程退出信号,也能拿到dump文件.\n\njmap的作用并不仅仅是为了获取dump文件,它还可以查询`finalize`执行队列,java堆和永久代的详细信息,如\n空间使用率,当前使用的是哪种收集器.\n\n和jinfo命令一样,jmap有不少功能是在windows平台下受限的,除了生成dump文件`-dump`选项和用于查看每个类的\n实例,空间占用统计的`-histo`选项所有系统操作系统都提供之外,其余选项只能在Linux/Solaris下使用.\n\n###### jmap命令格式\n```\njmap [ option ] vmid\n```\n\n###### jmap工具主要选项\n* `-dump`: 生成java堆转储快照.格式为:`-dump:[live,]format=b,file=<filename>`.live表示只dump存活对象\n* `-finalizerinfo`: 显示在`F-Queue`中等待`Finalizer`线程执行`finalize`方法的对象.\n* `-heap`: 显示java堆的详细信息,使用哪种回收器,参数配置,分代状况.\n* `-histo`: 显示堆中对象统计信息,包括类,实例数量和合计容量\n* `-permstat`: 以`ClassLoader`为统计口径显示永久代内存状态.\n* `-F`: 当虚拟机进程对`-dump`选项没有响应时,可使用这个选项强制生成dump快照\n\n## jstack: java堆栈跟踪工具\n`jstack`命令用于生成虚拟机当前时刻的线程快照.线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的\n集合,生成线程快照的主要目的是定位线程出现长时间停顿的原因,如[线程间死锁](),[死循环](),请求外部资源\n导致长时间等待.\n\n######jstack命令格式\n```\njstack [ option ] vmid\n```\n\n###### jstack工具主要选项\n* `-F`: 当正常输出的请求不被响应时,强制说出线程堆栈\n* `-l`: 除堆栈外,显示关于锁的附加信息\n* `-m`: 如果调用本地方法的话,可以显示c/c++的堆栈\n\n","slug":"jvm7/相关工具","published":1,"date":"2015-09-18T06:28:21.291Z","updated":"2015-09-18T06:17:58.666Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjea3000x74ufomgeso8c"},{"title":"字节码指令","_content":"## 字节码指令\n### 虚拟机指令集所支持的数据类型\n\n|操作码    |byte   |short  |int     |long   |float  |double |char   |refernce |\n|---------|------:|------:|-------:|------:|------:|------:|------:|--------:|\n|Tipush   |bipush |sipush |        |       |       |       |       |         |\n|Tconst   |       |       |iconst  |lconst |fconst |dconst |       |aconst   |\n|Tload    |       |       |iload   |lload  |fload  |dload  |       |aload    |\n|Tstore   |       |       |store   |lstore |fstore |dstore |cstore |astore   |\n|Tinc     |       |       |iinc    |       |       |       |       |         |\n|Taload   |baload |saload |iaload  |laload |faload |daload |caload |aaload   |\n|Tastore  |bastore|sastore|iastore |lastore|fastore|dastore|castore|aastore  |\n|Tadd     |       |       |iadd    |ladd   |fadd   |dadd   |       |         |\n|Tsub     |       |       |isub    |lsub   |fsub   |dsub   |       |         |\n|Tmul     |       |       |imul    |lmul   |fmul   |dmul   |       |         |\n|Tdiv     |       |       |idiv    |ldiv   |fdiv   |ddiv   |       |         |\n|Trem     |       |       |irem    |lrem   |frem   |drem   |       |         |\n|Tneg     |       |       |ineg    |lneg   |fneg   |dneg   |       |         |\n|Tshl     |       |       |ishl    |lshl   |       |       |       |         |\n|Tshr     |       |       |ishr    |lshr   |       |       |       |         |\n|Tushr    |       |       |iushr   |lushr  |       |       |       |         |\n|Tand     |       |       |iand    |land   |       |       |       |         |\n|Tor      |       |       |ior     |lor    |       |       |       |         |\n|Txor     |       |       |ixor    |lxor   |       |       |       |         |\n|i2T      |i2b    |i2s    |        |i2l    |i2f    |i2d    |       |         |\n|l2T      |       |       |l2i     |       |l2f    |l2d    |       |         |\n|f2T      |       |       |f2i     |f2l    |       |f2d    |       |         |\n|d2T      |       |       |d2i     |d2l    |d2f    |       |       |         |\n|Tcmp     |       |       |        |lcmp   |       |       |       |         |\n|Tcmpl    |       |       |        |       |fcmpl  |dcmpl  |       |         |\n|if_TcmpOP|       |       |if_icmOP|       |       |       |       |if_acmpOP|\n|Treturn  |       |       |ireturn |lreturn|freturn|dreturn|       |areturn  |\n\n\n### 加载和存储指令\n* 加载和存储指令用于将数据从栈帧的本地变量表和操作数栈之间来回传递\n* 将一个本地变量加载到操作数栈的指令有:\n```\n  1. iload,\n  2. iload_<n>,\n  3. lload,\n  4. lload_<n>,\n  5. fload,\n  6. fload_<n>,\n  7. dload,\n  8. dload_<n>,\n  9. aload       从局部变量表加载一个reference类型值到操作数栈\n  10. aload_<n>  从局部变量表加载一个reference类型值到操作数栈\n  11. caload     从数组中加载一个char类型数据到操作数栈\n```\n* 将一个数值从操作数栈存储到局部变量表的指令有:\n```\n  1. istore\n  2. istore_<n>\n  3. lstore\n  4. lstore_<n>\n  5. fstore\n  6. fstore_<n>\n  7. dstore\n  8. dstore_<n>\n  9. astore       将一个reference类型数据保存到本地变量表\n  10. astore_<n>  将一个reference类型数据保存到本地变量表\n```\n* 将一个常量加载到操作数栈的指令有:\n```\n  1. bipush       将一个byte类型数据入栈\n  2. sipush\n  3. ldc\n  4. ldc_w\n  5. ldc2_w\n  6. aconst_null   将一个null值入栈到操作数栈中.\n  7. iconst_m1\n  8. iconst_<i>\n  9. locnst_<l>\n  10. fconst_<f>\n  11. dconst_<d>\n```\n* 以上指令中有部分是以尖括号为结尾的,这种代表了一组指令, 例如iload_1, iload_2, 等等. 他们表面上没有操作数, 不需要进行取操作数的动作,但操作数都包含在指令中\n\n### 算数指令\n* 算数指令是对俩个操作数栈上的值进行某种特定运算,然后把结构重新压入操作数栈.\n* 加法指令\n```\n  1.  iadd\n  2.  ladd\n  3.  fadd\n  4.  dadd\n```\n* 减法指令\n```\n  1.  isub\n  2.  lsub\n  3.  fsub\n  4.  dsub\n```\n* 乘法指令\n```\n  1.  imul\n  2.  lmul\n  3.  fmul\n  4.  dmul\n```\n* 除法指令\n```\n  1.  idiv\n  2.  ldiv\n  3.  fdiv\n  4.  ddiv\n```\n* 求余指令\n```\n  1.  irem\n  2.  lrem\n  3.  frem\n  4.  drem\n```\n* 取反指令\n```\n  1.  ineg\n  2.  lneg\n  3.  dneg\n  4.  dneg\n```\n* 位移指令\n```\n  1.  ishl\n  2.  ishr\n  3.  iushr\n  4.  lshl\n  5.  lshr\n  6.  lushr\n```\n* 按位或指令\n```\n  1.  ior\n  2.  lor\n```\n* 按位与指令\n```\n  1.  iand\n  2.  land\n```\n* 按位异或指令\n```\n  1.  ixor\n  2.  lxor\n```\n* 局部变量自增指令\n```\n  1.  iinc\n```\n* 比较之类\n```\n  1.  dcmpg\n  2.  dcmpl\n  3.  fcmpg\n  4.  fcmpl\n  5.  lcmp\n```\n\n### 类型转换指令\n* 可以将俩种java虚拟机数值类型进行相互转换\n* 这些转换指令一般用于实现用户代码的显示类型转换或用来处理虚拟机字节码指令集中指令的非完全独立的问题\n* 宽化类型转换:\n```\n  1. 从int类型到long, float, double类型. i2l和i2d 指令都不会丢失精确度,但是i2f可能会发生精度丢失\n  2. 从long类型到float, double类型. l2f,l2d都可能会发生精度丢失\n  3. 从float到double类型. 在FP-strict模式下可以确保,精度不会丢失\n```\n* 窄化类型转换\n```\n  1. 从int到byte, short, char 类型\n  2. 从long到int类型\n  3. 从float到int 或者 long类型\n  4. 从double 到int, long, float.\n```\n### 对象创建与操作\n* 创建类实例的指令\n```\n  1.  new\n```\n* 创建数组的指令\n```\n  1.  newarray\n  2.  anewarray       创建一个类型为reference类型的数组\n  3.  multianewarray\n```\n* 访问类字段和类实例字段\n```\n  1.  getstatic\n  2.  putstatic\n  3.  getfield\n  4.  putfield\n```\n* 把一个数组元素加载到操作数栈的指令\n```\n  1.  baload  从数组中读取byte或者boolean类型的数据\n  2.  aload   从局部变量表加载一个reference类型值到操作数栈\n  3.  saload\n  4.  iaload\n  5.  laload\n  6.  faload\n  7.  daload\n  8.  aaload  从数组中加一个reference类型数据到操作数栈.\n```\n* 将一个操作数栈元素存储到数组元素中\n```\n  1.  bastore  从操作数栈读取一个byte或者boolean类型数据并存储数组中\n  2.  castore  从操作数栈读取一个char类型并存储数组\n  3.  sastore\n  4.  iastore\n  5.  fastore\n  6.  dastore\n  7.  aastore  从操作数栈读取一个reference类型数据存入到数组中.\n```\n* 取数组长度的指令\n```\n  1.  arraylength  取数组长度\n```\n* 检查类实例类型的指令\n```\n  1.  instanceof\n  2.  instancecast\n```\n\n### 操作数栈管理指令\n* 直接用于操作操作数栈的指令:\n```\n  1. pop\n  2. pop2\n  3. dup\n  4. dup2\n  5. dip_x1\n  6. dup2_x1\n  7. dup_x2\n  8. dup2_x2\n  9. swap\n```\n### 控制转移指令\n*   控制转移指令可以让虚拟机有条件或者无条件地从指定指令而不是控制转移指令的下一条指令继续执行程序\n*   条件分支指令\n```\n  1. ifeq\n  2. iflt\n  3. ifle\n  4. ifgt\n  5. ifnull\n  6. ifnonnull\n  7. if_icmpeq\n  8. if_icmpne\n  9. if_icmplt\n  10. if_icmmpgt\n  11. if_cfimmple\n  12. if_acmpeq\n  13. if_acmpne\n```\n* 复合条件分支\n```\n  1. tableswitch\n  2. lookupswitch\n```\n* 无条件分支\n```\n  1. goto\n  2. goto_w\n  3. jsr\n  4. jsr_w\n  5. ret\n```\n* boolean, byte, char, short 类型作为条件分支比较操作, 都使用int 类型的比较指令完成\n* long, float, double 类型的条件分支, 则先会执行相应类型的比较运算指令, 运算指令会返回一个整型值到操作数栈中,然后再执行int类型的条件分支比较操作来完成整个分支的跳转.\n* 所有int类型的条件分支转移指令进行的都是有符号的比较操作\n\n### 方法调用和返回指令\n* 方法调用\n```\n 1. invokevirtual: 用于调用对象的实例方法, 根据对象的实际类型进行分派(虚方法分派).\n 2. invokeinterface: 用于调用接口方法. 它会在运行时搜索一个实现了这个接口方法的对象, 并找出合适的方法进行调用\n 3. invokespecial: 指令用于一些需要特殊处理的实例方法, 包括实例初始化方法, 私有方法和父类方法\n 4. invokestatic:  指令用于调用命名类中的类方法\n 5. invokedynamic: 指令用于绑定了invokedynamic指令的调用点对象作为目标的方法. 调用点对象是一个特殊的语法结构,\n                   当一条invokedynamic首次被java虚拟机执行前, java虚拟机会执行一个引导方法并以这个方法的运行结果\n                   作为调用点对象.因此每条invokedynamic指令都有一个独一无二的链接期状态.\n```\n* 返回指令\n```\n  1. ireturn  用以返回boolean, byte, char, short, int 类型使用\n  2. lreturn\n  3. freturn\n  4. dreturn\n  5. areturn  从方法中返回一个reference类型数据\n  6. 有一条特殊的return指令供声明为void的方法, 实例初始化方法, 类和接口的类初始化方法使用\n```\n\n### 抛出异常\n* 程序中显式的异常由athrow指令抛出, 其他的异常会在其他指令检测到异常时由虚拟机自动抛出\n```\n   1. athrow  抛出一个异常\n```\n\n### 同步\njava虚拟机支持方法级的同步以及方法内部一段指令序列的同步.这俩种同步机制都使用同步锁来支持的.方法级的同步是隐式的,无需通过字节码指令来控制,它实现在方法调用和返回操作之中.\n\n虚拟机从方法常量池中的方法表结构中的`ACC_SYNCHRONIZED`访问标志来区分一个方法是否是同步方法.当调用同步方法时,调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否设置了,如果设置了,执行线程会先持有同步锁,然后执行方法.最后在方法结束时,释放掉同步锁. 在方法执行期间,执行线程有了同步锁,其他线程都无法再获得同一个同步锁.\n\n同步一段指令集序列, 通常是由java中`synchronized`块表示的. java虚拟机中有`monitorenter`和`monitorexit`俩个指令来支持`synchronized`语义.\n\n结构化锁定指的是在方法调用期间每一个同步锁退出斗鱼前面的同步锁进入相匹配的情形. 因为无法保证所有提交给java虚拟机执行的代码都满足结构化锁定,所以java虚拟机允许通过以下俩条规则来保证结构化锁定成立. (T代表一个线程, M代表一个同步锁)\n\n1. T在方法执行时持有的同步锁M的次数必须与T在此方法完成时释放同步锁M的次数想等\n2. 在方法调用过程中,任何时刻都不会出现线程T释放同步锁M的次数比T持有同步锁M次数多的情况\n","source":"_posts/jvm7/字节码指令.md","raw":"categories:\n- jvm7\ntitle: 字节码指令\n---\n## 字节码指令\n### 虚拟机指令集所支持的数据类型\n\n|操作码    |byte   |short  |int     |long   |float  |double |char   |refernce |\n|---------|------:|------:|-------:|------:|------:|------:|------:|--------:|\n|Tipush   |bipush |sipush |        |       |       |       |       |         |\n|Tconst   |       |       |iconst  |lconst |fconst |dconst |       |aconst   |\n|Tload    |       |       |iload   |lload  |fload  |dload  |       |aload    |\n|Tstore   |       |       |store   |lstore |fstore |dstore |cstore |astore   |\n|Tinc     |       |       |iinc    |       |       |       |       |         |\n|Taload   |baload |saload |iaload  |laload |faload |daload |caload |aaload   |\n|Tastore  |bastore|sastore|iastore |lastore|fastore|dastore|castore|aastore  |\n|Tadd     |       |       |iadd    |ladd   |fadd   |dadd   |       |         |\n|Tsub     |       |       |isub    |lsub   |fsub   |dsub   |       |         |\n|Tmul     |       |       |imul    |lmul   |fmul   |dmul   |       |         |\n|Tdiv     |       |       |idiv    |ldiv   |fdiv   |ddiv   |       |         |\n|Trem     |       |       |irem    |lrem   |frem   |drem   |       |         |\n|Tneg     |       |       |ineg    |lneg   |fneg   |dneg   |       |         |\n|Tshl     |       |       |ishl    |lshl   |       |       |       |         |\n|Tshr     |       |       |ishr    |lshr   |       |       |       |         |\n|Tushr    |       |       |iushr   |lushr  |       |       |       |         |\n|Tand     |       |       |iand    |land   |       |       |       |         |\n|Tor      |       |       |ior     |lor    |       |       |       |         |\n|Txor     |       |       |ixor    |lxor   |       |       |       |         |\n|i2T      |i2b    |i2s    |        |i2l    |i2f    |i2d    |       |         |\n|l2T      |       |       |l2i     |       |l2f    |l2d    |       |         |\n|f2T      |       |       |f2i     |f2l    |       |f2d    |       |         |\n|d2T      |       |       |d2i     |d2l    |d2f    |       |       |         |\n|Tcmp     |       |       |        |lcmp   |       |       |       |         |\n|Tcmpl    |       |       |        |       |fcmpl  |dcmpl  |       |         |\n|if_TcmpOP|       |       |if_icmOP|       |       |       |       |if_acmpOP|\n|Treturn  |       |       |ireturn |lreturn|freturn|dreturn|       |areturn  |\n\n\n### 加载和存储指令\n* 加载和存储指令用于将数据从栈帧的本地变量表和操作数栈之间来回传递\n* 将一个本地变量加载到操作数栈的指令有:\n```\n  1. iload,\n  2. iload_<n>,\n  3. lload,\n  4. lload_<n>,\n  5. fload,\n  6. fload_<n>,\n  7. dload,\n  8. dload_<n>,\n  9. aload       从局部变量表加载一个reference类型值到操作数栈\n  10. aload_<n>  从局部变量表加载一个reference类型值到操作数栈\n  11. caload     从数组中加载一个char类型数据到操作数栈\n```\n* 将一个数值从操作数栈存储到局部变量表的指令有:\n```\n  1. istore\n  2. istore_<n>\n  3. lstore\n  4. lstore_<n>\n  5. fstore\n  6. fstore_<n>\n  7. dstore\n  8. dstore_<n>\n  9. astore       将一个reference类型数据保存到本地变量表\n  10. astore_<n>  将一个reference类型数据保存到本地变量表\n```\n* 将一个常量加载到操作数栈的指令有:\n```\n  1. bipush       将一个byte类型数据入栈\n  2. sipush\n  3. ldc\n  4. ldc_w\n  5. ldc2_w\n  6. aconst_null   将一个null值入栈到操作数栈中.\n  7. iconst_m1\n  8. iconst_<i>\n  9. locnst_<l>\n  10. fconst_<f>\n  11. dconst_<d>\n```\n* 以上指令中有部分是以尖括号为结尾的,这种代表了一组指令, 例如iload_1, iload_2, 等等. 他们表面上没有操作数, 不需要进行取操作数的动作,但操作数都包含在指令中\n\n### 算数指令\n* 算数指令是对俩个操作数栈上的值进行某种特定运算,然后把结构重新压入操作数栈.\n* 加法指令\n```\n  1.  iadd\n  2.  ladd\n  3.  fadd\n  4.  dadd\n```\n* 减法指令\n```\n  1.  isub\n  2.  lsub\n  3.  fsub\n  4.  dsub\n```\n* 乘法指令\n```\n  1.  imul\n  2.  lmul\n  3.  fmul\n  4.  dmul\n```\n* 除法指令\n```\n  1.  idiv\n  2.  ldiv\n  3.  fdiv\n  4.  ddiv\n```\n* 求余指令\n```\n  1.  irem\n  2.  lrem\n  3.  frem\n  4.  drem\n```\n* 取反指令\n```\n  1.  ineg\n  2.  lneg\n  3.  dneg\n  4.  dneg\n```\n* 位移指令\n```\n  1.  ishl\n  2.  ishr\n  3.  iushr\n  4.  lshl\n  5.  lshr\n  6.  lushr\n```\n* 按位或指令\n```\n  1.  ior\n  2.  lor\n```\n* 按位与指令\n```\n  1.  iand\n  2.  land\n```\n* 按位异或指令\n```\n  1.  ixor\n  2.  lxor\n```\n* 局部变量自增指令\n```\n  1.  iinc\n```\n* 比较之类\n```\n  1.  dcmpg\n  2.  dcmpl\n  3.  fcmpg\n  4.  fcmpl\n  5.  lcmp\n```\n\n### 类型转换指令\n* 可以将俩种java虚拟机数值类型进行相互转换\n* 这些转换指令一般用于实现用户代码的显示类型转换或用来处理虚拟机字节码指令集中指令的非完全独立的问题\n* 宽化类型转换:\n```\n  1. 从int类型到long, float, double类型. i2l和i2d 指令都不会丢失精确度,但是i2f可能会发生精度丢失\n  2. 从long类型到float, double类型. l2f,l2d都可能会发生精度丢失\n  3. 从float到double类型. 在FP-strict模式下可以确保,精度不会丢失\n```\n* 窄化类型转换\n```\n  1. 从int到byte, short, char 类型\n  2. 从long到int类型\n  3. 从float到int 或者 long类型\n  4. 从double 到int, long, float.\n```\n### 对象创建与操作\n* 创建类实例的指令\n```\n  1.  new\n```\n* 创建数组的指令\n```\n  1.  newarray\n  2.  anewarray       创建一个类型为reference类型的数组\n  3.  multianewarray\n```\n* 访问类字段和类实例字段\n```\n  1.  getstatic\n  2.  putstatic\n  3.  getfield\n  4.  putfield\n```\n* 把一个数组元素加载到操作数栈的指令\n```\n  1.  baload  从数组中读取byte或者boolean类型的数据\n  2.  aload   从局部变量表加载一个reference类型值到操作数栈\n  3.  saload\n  4.  iaload\n  5.  laload\n  6.  faload\n  7.  daload\n  8.  aaload  从数组中加一个reference类型数据到操作数栈.\n```\n* 将一个操作数栈元素存储到数组元素中\n```\n  1.  bastore  从操作数栈读取一个byte或者boolean类型数据并存储数组中\n  2.  castore  从操作数栈读取一个char类型并存储数组\n  3.  sastore\n  4.  iastore\n  5.  fastore\n  6.  dastore\n  7.  aastore  从操作数栈读取一个reference类型数据存入到数组中.\n```\n* 取数组长度的指令\n```\n  1.  arraylength  取数组长度\n```\n* 检查类实例类型的指令\n```\n  1.  instanceof\n  2.  instancecast\n```\n\n### 操作数栈管理指令\n* 直接用于操作操作数栈的指令:\n```\n  1. pop\n  2. pop2\n  3. dup\n  4. dup2\n  5. dip_x1\n  6. dup2_x1\n  7. dup_x2\n  8. dup2_x2\n  9. swap\n```\n### 控制转移指令\n*   控制转移指令可以让虚拟机有条件或者无条件地从指定指令而不是控制转移指令的下一条指令继续执行程序\n*   条件分支指令\n```\n  1. ifeq\n  2. iflt\n  3. ifle\n  4. ifgt\n  5. ifnull\n  6. ifnonnull\n  7. if_icmpeq\n  8. if_icmpne\n  9. if_icmplt\n  10. if_icmmpgt\n  11. if_cfimmple\n  12. if_acmpeq\n  13. if_acmpne\n```\n* 复合条件分支\n```\n  1. tableswitch\n  2. lookupswitch\n```\n* 无条件分支\n```\n  1. goto\n  2. goto_w\n  3. jsr\n  4. jsr_w\n  5. ret\n```\n* boolean, byte, char, short 类型作为条件分支比较操作, 都使用int 类型的比较指令完成\n* long, float, double 类型的条件分支, 则先会执行相应类型的比较运算指令, 运算指令会返回一个整型值到操作数栈中,然后再执行int类型的条件分支比较操作来完成整个分支的跳转.\n* 所有int类型的条件分支转移指令进行的都是有符号的比较操作\n\n### 方法调用和返回指令\n* 方法调用\n```\n 1. invokevirtual: 用于调用对象的实例方法, 根据对象的实际类型进行分派(虚方法分派).\n 2. invokeinterface: 用于调用接口方法. 它会在运行时搜索一个实现了这个接口方法的对象, 并找出合适的方法进行调用\n 3. invokespecial: 指令用于一些需要特殊处理的实例方法, 包括实例初始化方法, 私有方法和父类方法\n 4. invokestatic:  指令用于调用命名类中的类方法\n 5. invokedynamic: 指令用于绑定了invokedynamic指令的调用点对象作为目标的方法. 调用点对象是一个特殊的语法结构,\n                   当一条invokedynamic首次被java虚拟机执行前, java虚拟机会执行一个引导方法并以这个方法的运行结果\n                   作为调用点对象.因此每条invokedynamic指令都有一个独一无二的链接期状态.\n```\n* 返回指令\n```\n  1. ireturn  用以返回boolean, byte, char, short, int 类型使用\n  2. lreturn\n  3. freturn\n  4. dreturn\n  5. areturn  从方法中返回一个reference类型数据\n  6. 有一条特殊的return指令供声明为void的方法, 实例初始化方法, 类和接口的类初始化方法使用\n```\n\n### 抛出异常\n* 程序中显式的异常由athrow指令抛出, 其他的异常会在其他指令检测到异常时由虚拟机自动抛出\n```\n   1. athrow  抛出一个异常\n```\n\n### 同步\njava虚拟机支持方法级的同步以及方法内部一段指令序列的同步.这俩种同步机制都使用同步锁来支持的.方法级的同步是隐式的,无需通过字节码指令来控制,它实现在方法调用和返回操作之中.\n\n虚拟机从方法常量池中的方法表结构中的`ACC_SYNCHRONIZED`访问标志来区分一个方法是否是同步方法.当调用同步方法时,调用指令将会检查方法的`ACC_SYNCHRONIZED`访问标志是否设置了,如果设置了,执行线程会先持有同步锁,然后执行方法.最后在方法结束时,释放掉同步锁. 在方法执行期间,执行线程有了同步锁,其他线程都无法再获得同一个同步锁.\n\n同步一段指令集序列, 通常是由java中`synchronized`块表示的. java虚拟机中有`monitorenter`和`monitorexit`俩个指令来支持`synchronized`语义.\n\n结构化锁定指的是在方法调用期间每一个同步锁退出斗鱼前面的同步锁进入相匹配的情形. 因为无法保证所有提交给java虚拟机执行的代码都满足结构化锁定,所以java虚拟机允许通过以下俩条规则来保证结构化锁定成立. (T代表一个线程, M代表一个同步锁)\n\n1. T在方法执行时持有的同步锁M的次数必须与T在此方法完成时释放同步锁M的次数想等\n2. 在方法调用过程中,任何时刻都不会出现线程T释放同步锁M的次数比T持有同步锁M次数多的情况\n","slug":"jvm7/字节码指令","published":1,"date":"2015-09-18T06:28:21.290Z","updated":"2015-09-18T06:17:57.011Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjea6000z74ufvuvb5jr2"},{"title":"垃圾收集器","_content":"# 垃圾收集器\n## 对象引用\n\n引用计数算法, 引用计数算法的问题是,它很难解决对象之间相互循环引用的问题\n```java\npublic class ReferenceCountingGC {\n\n    public Object instance = null;\n\n    private static final int _1MB = 1024 * 1024;\n\n    private byte[] bigSize = new byte[_1MB];\n\n    public static void main(String[] args) {\n        ReferenceCountingGC obj1 = new ReferenceCountingGC();\n        ReferenceCountingGC obj2 = new ReferenceCountingGC();\n\n        obj1.instance = obj2;\n        obj2.instance = obj1;\n\n        System.gc();\n    }\n}\n```\n#### 根搜索算法\n这个算法的基本思想是:通过一系列的名为\"GC Roots\"的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的.\n\n###### 在java语言里, 可作为GC Roots的对象包括以下几种:\n1. 虚拟机栈(栈帧中的本地变量表)中的引用对象.\n2. 方法区中的类静态属性引用的对象.\n3. 方法区中的常量引用对象\n4. 本地方法栈中JNI的引用的对象\n\n#### 再谈引用\n\nJDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用\n1. 强引用: 指的是在代码之中普遍存在的,类似`Object obj = new Object()` 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象\n2. 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常.\n3. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象\n4. 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知.\n\n\n## 垃圾回收算法\n#### 标记-清除算法\n\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95a.jpg)\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95b.jpg)\n###### 算法简介\n算法分为标记和清除俩个部分. 首先标记出要所有要回收的对象, 然后统一回收掉所有被标记的对象.\n\n###### 这种算法的缺点主要是:\n1. 效率问题. 标记和清除的效率都不高.\n2. 空间问题. 标记和清除之后会存在大量不连续空间碎片. 空间碎片太多可能导致,在程序以后运行过程中需要分配较大对象时,无法找到足够的内存连续内存,而不得不提前触发另一次的垃圾收集动作.\n\n#### 算法伪代码\n###### NEW操作\n```java\nNew():\n    ref <- allocate()  //分配新的内存到ref指针\n    if ref == null\n       collect()  //内存不足,则触发垃圾收集\n       ref <- allocate()\n       if ref == null\n          throw \"Out of Memory\"   //垃圾收集后仍然内存不足,则抛出Out of Memory错误\n          return ref\n\natomic collect():\n    markFromRoots()\n    sweep(HeapStart,HeapEnd)\n\n```\n###### mark算法\n```\nmarkFromRoots():\n    worklist <- empty\n    for each fld in Roots  //遍历所有mutator根对象\n        ref <- *fld\n        if ref != null && isNotMarked(ref)  //如果它是可达的而且没有被标记的,直接标记该对象并将其加到worklist中\n           setMarked(ref)\n           add(worklist,ref)\n           mark()\nmark():\n    while not isEmpty(worklist)\n          ref <- remove(worklist)  //将worklist的最后一个元素弹出,赋值给ref\n          for each fld in Pointers(ref)\n          //遍历ref对象的所有指针域,如果其指针域(child)是可达的,直接标记其为可达对象并且将其加入worklist中\n          //通过这样的方式来实现深度遍历,直到将该对象下面所有可以访问到的对象都标记为可达对象.\n                child <- *fld\n                if child != null && isNotMarked(child)\n                   setMarked(child)\n                   add(worklist,child)\n\n```\n###### sweep算法\n```\nsweep(start,end):\n    scan <- start\n   while scan < end\n       if isMarked(scan)\n          setUnMarked(scan)\n      else\n          free(scan)\n      scan <- nextObject(scan)\n```\n* 复制算法\n\n![复制算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95a.jpg)\n![复制算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95b.jpg)\n###### 算法原理\n为了解决效率问题, 复制算法将可用内存按照容量划分为大小相等的俩块,每次只使用其中的一块. 当这一块内存用完了,就将还活着的对象复制到另一块上面,然后再把已经使用过的内存一次清理掉.\n\n###### 缺陷解决\n这种算法实现简单,运行高效,只不过将原来内存缩小为原来一半,这实在是有点高. 不过现在的商业虚拟机都采用这种算法来收集新生代. 根据IBM研究, 新生代的对象98%都是朝生夕死, 所以并不需要按照1:1 的比例分配内存. 而是分为一块\n较大的Eden区和俩块较小的Survivor区. 每次都使用Eden和一块Survivor区,当回收时, 将Eden还活着的对象一次性拷贝到另一块Survivor区,最后清理掉Eden区和刚才使用过的Survivor区.\nHotSpot默认Eden和Survivor的大小比例是8:1, 也就是每次新生代可用内存空间为90%(8 + 1), 如果发现剩余的存活对象多余10%,另一块Survivor不够的话,需要依赖其他内存(老年代)进行分配担保.\n\n* 标记-整理算法\n[标记整理算法](http://www.jianshu.com/p/698eb5e1ccb9)\n![标记  - 整理算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95a.jpg)\n![标记  - 整理算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95b.jpg)\n\n复制算法在对象存活率较高的情况下需要执行多次复制操作,效率会变低,所以老年代一般不选用这个算法. 根据老年代的特点,就提出了标记-整理算法,标记过程和\"标记-清除算法\"一样,但后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉端边界以外的内存.\n\n* 分代收集算法\n这种算法的思想是:把java堆分为新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法.\n\n在新生代,每次垃圾收集时发现有大批对象死去,只有少量对象存活,那就采用复制算法,只要付出少量存活对象的复制成本就可以完成收集. 而老年代对象存活效率高,没有额外的空间对它进行分配担保,就必须采用\"标记清除\"或者\"标记整理\"来进行回收\n\n## 垃圾收集器\n![https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg](https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg)\n#### Serial收集器\nSerial收集器是最基本、历史最悠久的收集器,曾经（在JDK 1.3.1之前）是虚拟机`新生代`收集的唯一选择.\n\n###### Serial收集器运行原理\n看名字就知道,这个收集器是一个`单线程`的收集器,但它的“单线程”的意义并不仅仅是说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作,更重要的是在它进行垃圾收集时,必须暂停其他所有的工作线程（Sun将这件事情称之为“Stop The World”）,直到它收集结束.“Stop The World”这个名字也许听起来很酷,但这项工作实际上是由虚拟机在后台自动发起和自动完成的,在用户不可见的情况下把用户的正常工作的线程全部停掉,这对很多应用来说都是难以接受的.\n\n###### Serial收集器存在必要\n从JDK 1.3开始,一直到现在还没正式发布的JDK 1.7,HotSpot虚拟机开发团队为消除或减少工作线程因内存回收而导致停顿的努力一直在进行着,从`Serial`收集器到`Parallel`收集器,再到`ConcurrentMarkSweep（CMS）`现在正式发布的`Garbage First（G1）`收集器,我们看到了一个个越来越优秀（也越来越复杂）的收集器的出现,用户线程的停顿时间在不断缩短,但是仍然没有办法完全消除（这里暂不包括RTSJ中的收集器）.\n\n到这里,Serial收集器似乎成了一个老而无用,食之无味弃之可惜的鸡肋了,但实际上到现在为止,它依然是虚拟机运行在Client模式下的默认新生代收集器.它也有着优于其他收集器的地方：简单而高效(与其他收集器的单线程比）,对于限定单个CPU的环境来说,`Serial`收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率.在用户的桌面应用场景中,分配给虚拟机管理的内存一般来说不会很大,收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存,桌面应用基本上不会再大了）,停顿时间完全可以控制在几十毫秒最多一百多毫秒以内,只要不是频繁发生,这点停顿是可以接受的.所以,`Serial`收集器对于运行在Client模式下的虚拟机来说是一个很好的选择.\n\n#### ParNew收集器\n\n###### 对比`Serial`收集器\n`ParNew`收集器其实就是`Serial`收集器的多线程版本,除了使用多线程进行垃圾收集之外,其余行为包括Serial收集器可用的所有控制参数（例如：`-XX:SurvivorRatio`、 `-XX:PretenureSizeThreshold`、`-XX:HandlePromotionFailure`等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样,实现上这两种收集器也共用了相当多的代码.\n\n##### 为什么选择ParNew收集器\nParNew收集器除了多线程收集之外,其他与Serial收集器相比并没有太多创新之处,但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器,其中有一个与性能无关但很重要的原因是,除了Serial收集器外,目前只有它能与CMS收集器配合工作.\n\n> 在JDK 1.5时期,HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器Concurrent Mark Sweep）,这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器,它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作.\n\n不幸的是,CMS收集器作为老年代的收集器,却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择ParNew或Serial收集器中的一个.ParNew收集器也是使用`-XX: +UseConcMarkSweepGC`选项后的默认新生代收集器,也可以使用 `-XX:+UseParNewGC`选项来强制指定它.\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果,甚至由于存在线程交互的开销,该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器.当然,随着可以使用的CPU的数量的增加,它对于GC时系统资源的利用还是很有好处的.它默认开启的收集线程数与CPU的数量相同,在CPU非常多（譬如32个,现在CPU动辄就4核加超线程,服务器超过32个逻辑CPU的情况越来越多了）的环境下,可以使用`-XX:ParallelGCThreads`参数来限制垃圾收集的线程数.\n\n##### 注意  从ParNew收集器开始,后面还将会接触到几款并发和并行的收集器.在大家可能产生疑惑之前,有必要先解释两个名词：并发和并行.这两个名词都是并发编程中的概念,在谈论垃圾收集器的上下文语境中,他们可以解释为：\n* 并行（Parallel）：指多条垃圾收集线程并行工作,但此时用户线程仍然处于等待状态.\n* 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的,可能会交替执行）,用户程序继续运行,而垃圾收集程序运行于另一个CPU上.\n\n#### Parallel Scavege收集器\n\nParallel Scavenge收集器也是一个新生代收集器,它也是使用复制算法的收集器,又是并行的多线程收集器……看上去和ParNew都一样,那它有什么特别之处呢？\n\n###### Parallel Scavenge收集器的特点\n它的关注点与其他收集器不同,CMS等收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）.\n\n> 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）,虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%.\n\n停顿时间越短就越适合需要与用户交互的程序,良好的响应速度能提升用户的体验;而高吞吐量则可以最高效率地利用CPU时间,尽快地完成程序的运算任务,主要适合在后台运算而不需要太多交互的任务.\n\n###### Parallel Scavenge收集器设定\nParallel Scavenge收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集停顿时间的`-XX:MaxGCPauseMillis`参数及直接设置吞吐量大小的 `-XX:GCTimeRatio`参数.\n\n* `MaxGCPauseMillis` : 参数允许的值是一个大于0的毫秒数,收集器将尽力保证内存回收花费的时间不超过设定值.不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快,GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些,收集300MB新生代肯定比收集500MB快吧,这也直接导致垃圾收集发生得更频繁一些,原来10秒收集一次、每次停顿100毫秒,现在变成5秒收集一次、每次停顿70毫秒.停顿时间的确在下降,但吞吐量也降下来了.\n\n* `GCTimeRatio` : 参数的值应当是一个大于0小于100的整数,也就是垃圾收集时间占总时间的比率,相当于是吞吐量的倒数.如果把此参数设置为19,那允许的最大GC时间就占总时间的5%（即1 /（1+19））,默认值为99,就是允许最大1%（即1 /（1+99））的垃圾收集时间.\n\n由于与吞吐量关系密切,Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器.除上述两个参数之外,Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得关注.\n* `-XX:+UseAdaptiveSizePolicy` :这是一个开关参数,当这个参数打开之后,就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（`-XX:SurvivorRatio`）、晋升老年代对象年龄（`-XX:PretenureSizeThreshold`）等细节参数了,虚拟机会根据当前系统的运行情况收集性能监控信息,动态调整这些参数以提供最合适的停顿时间或最大的吞吐量,这种调节方式称为GC自适应的调节策略（GC Ergonomics）.\n> 如果读者对于收集器运作原理不太了解,手工优化存在困难的时候,使用Parallel Scavenge收集器配合自适应调节策略,把内存管理的调优任务交给虚拟机去完成将是一个很不错的选择.只需要把基本的内存数据设置好（如-Xmx设置最大堆）,然后使用`MaxGCPauseMillis`参数（更关注最大停顿时间）或`GCTimeRatio`参数（更关注吞吐量）给虚拟机设立一个优化目标,那具体细节参数的调节工作就由虚拟机完成了.自适应调节策略也是`Parallel Scavenge`收集器与`ParNew`收集器的一个重要区别.\n\n#### Serial Old收集器\n\nSerial Old是Serial收集器的老年代版本,它同样是一个单线程收集器,使用“标记-整理”算法.这个收集器的主要意义也是被Client模式下的虚拟机使用.如果在Server模式下,它主要还有两大用途：一个是在JDK 1.5及之前的版本中与Parallel Scavenge收集器搭配使用,另外一个就是作为CMS收集器的后备预案,在并发收集发生Concurrent Mode Failure的时候使用.\n\n#### Parallel old收集器\n\nParallel Old是Parallel Scavenge收集器的老年代版本,使用多线程和“标记－整理”算法.这个收集器是在JDK 1.6中才开始提供的,在此之前,新生代的Parallel Scavenge收集器一直处于比较尴尬的状态.原因是,如果新生代选择了Parallel Scavenge收集器,老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）.由于单线程的老年代Serial Old收集器在服务端应用性能上的“拖累”,即便使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果,又因为老年代收集中无法充分利用服务器多CPU的处理能力,在老年代很大而且硬件比较高级的环境中,这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”.\n\n直到Parallel Old收集器出现后,“吞吐量优先”收集器终于有了比较名副其实的应用组合,在注重吞吐量及CPU资源敏感的场合,都可以优先考虑Parallel Scavenge加Parallel Old收集器.\n\n#### CMS收集器\n\n###### 用途\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器.目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验.CMS收集器就非常符合这类应用的需求.\n\n###### 采用算法\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的,它的运作过程相对于前面几种收集器来说要更复杂一些,整个过程分为4个步骤,包括：\n1. 初始标记（CMS initial mark）\n2. 并发标记（CMS concurrent mark）\n3. 重新标记（CMS remark）\n4. 并发清除（CMS concurrent sweep）\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象,速度很快,并发标记阶段就是进行GC Roots Tracing的过程,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段稍长一些,但远比并发标记的时间短.\n\n由于整个过程中耗时最长的并发标记和并发清除过程中,收集器线程都可以与用户线程一起工作,所以总体上来说,CMS收集器的内存回收过程是与用户线程一起并发地执行的.通过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间.\n\nCMS是一款优秀的收集器,它的最主要优点在名字上已经体现出来了：并发收集、低停顿,Sun的一些官方文档里面也称之为并发低停顿收集器（Concurrent Low Pause Collector）.但是CMS还远达不到完美的程度,它有以下三个显著的缺点：\n\nCMS收集器对CPU资源非常敏感.其实,面向并发设计的程序都对CPU资源比较敏感.在并发阶段,它虽然不会导致用户线程停顿,但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢,总吞吐量会降低.CMS默认启动的回收线程数是（CPU数量+3）/ 4,也就是当CPU在4个以上时,并发回收时垃圾收集线程最多占用不超过25%的CPU资源.但是当CPU不足4个时（譬如2个）,那么CMS对用户程序的影响就可能变得很大,如果CPU负载本来就比较大的时候,还分出一半的运算能力去执行收集器线程,就可能导致用户程序的执行速度忽然降低了50%,这也很让人受不了.为了解决这种情况,虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep / i-CMS）的CMS收集器变种,所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样,就是在并发标记和并发清理的时候让GC线程、用户线程交替运行,尽量减少GC线程的独占资源的时间,这样整个垃圾收集的过程会更长,但对用户程序的影响就会显得少一些,速度下降也就没有那么明显,但是目前版本中,i-CMS已经被声明为“deprecated”,即不再提倡用户使用.\n\nCMS收集器无法处理浮动垃圾（Floating Garbage）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生.由于CMS并发清理阶段用户线程还在运行着,伴随程序的运行自然还会有新的垃圾不断产生,这一部分垃圾出现在标记过程之后,CMS无法在本次收集中处理掉它们,只好留待下一次GC时再将其清理掉.这一部分垃圾就称为“浮动垃圾”.也是由于在垃圾收集阶段用户线程还需要运行,即还需要预留足够的内存空间给用户线程使用,因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,需要预留一部分空间提供并发收集时的程序运作使用.在默认设置下,CMS收集器在老年代使用了68%的空间后就会被激活,这是一个偏保守的设置,如果在应用中老年代增长不是太快,可以适当调高参数`-XX:CMSInitiatingOccupancyFraction`的值来提高触发百分比,以便降低内存回收次数以获取更好的性能.要是CMS运行期间预留的内存无法满足程序需要,就会出现一次“Concurrent Mode Failure”失败,这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了.所以说参数`-XX:CMSInitiatingOccupancyFraction`设置得太高将会很容易导致大量“Concurrent Mode Failure”失败,性能反而降低.\n\n还有最后一个缺点,在本节在开头说过,CMS是一款基于“标记-清除”算法实现的收集器,如果读者对前面这种算法介绍还有印象的话,就可能想到这意味着收集结束时会产生大量空间碎片.空间碎片过多时,将会给大对象分配带来很大的麻烦,往往会出现老年代还有很大的空间剩余,但是无法找到足够大的连续空间来分配当前对象,不得不提前触发一次Full GC.为了解决这个问题,CMS收集器提供了一个`-XX:+UseCMSCompactAtFullCollection`开关参数,用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程,内存整理的过程是无法并发的.空间碎片问题没有了,但停顿时间不得不变长了.虚拟机设计者们还提供了另外一个参数`-XX: CMSFullGCsBeforeCompaction`,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的.\n\n#### G1收集器\n\nG1（Garbage First）收集器是当前收集器技术发展的最前沿成果,在JDK 1.6_Update14中提供了EarlyAccess版本的G1收集器以供试用.在将来JDK 1.7正式发布的时候,G1收集器很可能会有一个成熟的商用版本随之发布.这里只对G1收集器进行简单介绍.\n\nG1收集器是垃圾收集器理论进一步发展的产物,它与前面的CMS收集器相比有两个显著的改进：一是G1收集器是基于“标记-整理”算法实现的收集器,也就是说它不会产生空间碎片,这对于长时间运行的应用系统来说非常重要.二是它可以非常精确地控制停顿,\n既能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒,这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了.\n\nG1收集器可以实现在基本不牺牲吞吐量的前提下完成低停顿的内存回收,这是由于它能够极力地避免全区域的垃圾收集,之前的收集器进行收集的范围都是整个新生代或老年代,而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域（Region）,并且跟踪这些区域里面的垃圾堆积程度,在后台维护一个优先列表,每次根据允许的收集时间,优先回收垃圾最多的区域（这就是Garbage First名称的来由）.区域划分及有优先级的区域回收,保证了G1收集器在有限的时间内可以获得最高的收集效率.\n\n\n","source":"_posts/jvm7/垃圾收集.md","raw":"categories:\n- jvm7\ntitle: 垃圾收集器\n---\n# 垃圾收集器\n## 对象引用\n\n引用计数算法, 引用计数算法的问题是,它很难解决对象之间相互循环引用的问题\n```java\npublic class ReferenceCountingGC {\n\n    public Object instance = null;\n\n    private static final int _1MB = 1024 * 1024;\n\n    private byte[] bigSize = new byte[_1MB];\n\n    public static void main(String[] args) {\n        ReferenceCountingGC obj1 = new ReferenceCountingGC();\n        ReferenceCountingGC obj2 = new ReferenceCountingGC();\n\n        obj1.instance = obj2;\n        obj2.instance = obj1;\n\n        System.gc();\n    }\n}\n```\n#### 根搜索算法\n这个算法的基本思想是:通过一系列的名为\"GC Roots\"的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的.\n\n###### 在java语言里, 可作为GC Roots的对象包括以下几种:\n1. 虚拟机栈(栈帧中的本地变量表)中的引用对象.\n2. 方法区中的类静态属性引用的对象.\n3. 方法区中的常量引用对象\n4. 本地方法栈中JNI的引用的对象\n\n#### 再谈引用\n\nJDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用\n1. 强引用: 指的是在代码之中普遍存在的,类似`Object obj = new Object()` 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象\n2. 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常.\n3. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象\n4. 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知.\n\n\n## 垃圾回收算法\n#### 标记-清除算法\n\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95a.jpg)\n![标记-清除算法](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20-%20%E6%B8%85%E9%99%A4%E7%AE%97%E6%B3%95b.jpg)\n###### 算法简介\n算法分为标记和清除俩个部分. 首先标记出要所有要回收的对象, 然后统一回收掉所有被标记的对象.\n\n###### 这种算法的缺点主要是:\n1. 效率问题. 标记和清除的效率都不高.\n2. 空间问题. 标记和清除之后会存在大量不连续空间碎片. 空间碎片太多可能导致,在程序以后运行过程中需要分配较大对象时,无法找到足够的内存连续内存,而不得不提前触发另一次的垃圾收集动作.\n\n#### 算法伪代码\n###### NEW操作\n```java\nNew():\n    ref <- allocate()  //分配新的内存到ref指针\n    if ref == null\n       collect()  //内存不足,则触发垃圾收集\n       ref <- allocate()\n       if ref == null\n          throw \"Out of Memory\"   //垃圾收集后仍然内存不足,则抛出Out of Memory错误\n          return ref\n\natomic collect():\n    markFromRoots()\n    sweep(HeapStart,HeapEnd)\n\n```\n###### mark算法\n```\nmarkFromRoots():\n    worklist <- empty\n    for each fld in Roots  //遍历所有mutator根对象\n        ref <- *fld\n        if ref != null && isNotMarked(ref)  //如果它是可达的而且没有被标记的,直接标记该对象并将其加到worklist中\n           setMarked(ref)\n           add(worklist,ref)\n           mark()\nmark():\n    while not isEmpty(worklist)\n          ref <- remove(worklist)  //将worklist的最后一个元素弹出,赋值给ref\n          for each fld in Pointers(ref)\n          //遍历ref对象的所有指针域,如果其指针域(child)是可达的,直接标记其为可达对象并且将其加入worklist中\n          //通过这样的方式来实现深度遍历,直到将该对象下面所有可以访问到的对象都标记为可达对象.\n                child <- *fld\n                if child != null && isNotMarked(child)\n                   setMarked(child)\n                   add(worklist,child)\n\n```\n###### sweep算法\n```\nsweep(start,end):\n    scan <- start\n   while scan < end\n       if isMarked(scan)\n          setUnMarked(scan)\n      else\n          free(scan)\n      scan <- nextObject(scan)\n```\n* 复制算法\n\n![复制算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95a.jpg)\n![复制算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E5%A4%8D%E5%88%B6%E7%AE%97%E6%B3%95b.jpg)\n###### 算法原理\n为了解决效率问题, 复制算法将可用内存按照容量划分为大小相等的俩块,每次只使用其中的一块. 当这一块内存用完了,就将还活着的对象复制到另一块上面,然后再把已经使用过的内存一次清理掉.\n\n###### 缺陷解决\n这种算法实现简单,运行高效,只不过将原来内存缩小为原来一半,这实在是有点高. 不过现在的商业虚拟机都采用这种算法来收集新生代. 根据IBM研究, 新生代的对象98%都是朝生夕死, 所以并不需要按照1:1 的比例分配内存. 而是分为一块\n较大的Eden区和俩块较小的Survivor区. 每次都使用Eden和一块Survivor区,当回收时, 将Eden还活着的对象一次性拷贝到另一块Survivor区,最后清理掉Eden区和刚才使用过的Survivor区.\nHotSpot默认Eden和Survivor的大小比例是8:1, 也就是每次新生代可用内存空间为90%(8 + 1), 如果发现剩余的存活对象多余10%,另一块Survivor不够的话,需要依赖其他内存(老年代)进行分配担保.\n\n* 标记-整理算法\n[标记整理算法](http://www.jianshu.com/p/698eb5e1ccb9)\n![标记  - 整理算法a](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95a.jpg)\n![标记  - 整理算法b](https://raw.githubusercontent.com/wanggnim/GnimImage/master/jvm/%E6%A0%87%E8%AE%B0%20%20-%20%E6%95%B4%E7%90%86%E7%AE%97%E6%B3%95b.jpg)\n\n复制算法在对象存活率较高的情况下需要执行多次复制操作,效率会变低,所以老年代一般不选用这个算法. 根据老年代的特点,就提出了标记-整理算法,标记过程和\"标记-清除算法\"一样,但后续步骤不是直接对可回收对象进行清理,而是让所有存活的对象都向一端移动,然后直接清理掉端边界以外的内存.\n\n* 分代收集算法\n这种算法的思想是:把java堆分为新生代和老年代,这样就可以根据各个年代的特点采用最适当的收集算法.\n\n在新生代,每次垃圾收集时发现有大批对象死去,只有少量对象存活,那就采用复制算法,只要付出少量存活对象的复制成本就可以完成收集. 而老年代对象存活效率高,没有额外的空间对它进行分配担保,就必须采用\"标记清除\"或者\"标记整理\"来进行回收\n\n## 垃圾收集器\n![https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg](https://blogs.oracle.com/jonthecollector/resource/Collectors.jpg)\n#### Serial收集器\nSerial收集器是最基本、历史最悠久的收集器,曾经（在JDK 1.3.1之前）是虚拟机`新生代`收集的唯一选择.\n\n###### Serial收集器运行原理\n看名字就知道,这个收集器是一个`单线程`的收集器,但它的“单线程”的意义并不仅仅是说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作,更重要的是在它进行垃圾收集时,必须暂停其他所有的工作线程（Sun将这件事情称之为“Stop The World”）,直到它收集结束.“Stop The World”这个名字也许听起来很酷,但这项工作实际上是由虚拟机在后台自动发起和自动完成的,在用户不可见的情况下把用户的正常工作的线程全部停掉,这对很多应用来说都是难以接受的.\n\n###### Serial收集器存在必要\n从JDK 1.3开始,一直到现在还没正式发布的JDK 1.7,HotSpot虚拟机开发团队为消除或减少工作线程因内存回收而导致停顿的努力一直在进行着,从`Serial`收集器到`Parallel`收集器,再到`ConcurrentMarkSweep（CMS）`现在正式发布的`Garbage First（G1）`收集器,我们看到了一个个越来越优秀（也越来越复杂）的收集器的出现,用户线程的停顿时间在不断缩短,但是仍然没有办法完全消除（这里暂不包括RTSJ中的收集器）.\n\n到这里,Serial收集器似乎成了一个老而无用,食之无味弃之可惜的鸡肋了,但实际上到现在为止,它依然是虚拟机运行在Client模式下的默认新生代收集器.它也有着优于其他收集器的地方：简单而高效(与其他收集器的单线程比）,对于限定单个CPU的环境来说,`Serial`收集器由于没有线程交互的开销,专心做垃圾收集自然可以获得最高的单线程收集效率.在用户的桌面应用场景中,分配给虚拟机管理的内存一般来说不会很大,收集几十兆甚至一两百兆的新生代（仅仅是新生代使用的内存,桌面应用基本上不会再大了）,停顿时间完全可以控制在几十毫秒最多一百多毫秒以内,只要不是频繁发生,这点停顿是可以接受的.所以,`Serial`收集器对于运行在Client模式下的虚拟机来说是一个很好的选择.\n\n#### ParNew收集器\n\n###### 对比`Serial`收集器\n`ParNew`收集器其实就是`Serial`收集器的多线程版本,除了使用多线程进行垃圾收集之外,其余行为包括Serial收集器可用的所有控制参数（例如：`-XX:SurvivorRatio`、 `-XX:PretenureSizeThreshold`、`-XX:HandlePromotionFailure`等）、收集算法、Stop The World、对象分配规则、回收策略等都与Serial收集器完全一样,实现上这两种收集器也共用了相当多的代码.\n\n##### 为什么选择ParNew收集器\nParNew收集器除了多线程收集之外,其他与Serial收集器相比并没有太多创新之处,但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器,其中有一个与性能无关但很重要的原因是,除了Serial收集器外,目前只有它能与CMS收集器配合工作.\n\n> 在JDK 1.5时期,HotSpot推出了一款在强交互应用中几乎可称为有划时代意义的垃圾收集器—CMS收集器Concurrent Mark Sweep）,这款收集器是HotSpot虚拟机中第一款真正意义上的并发（Concurrent）收集器,它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作.\n\n不幸的是,CMS收集器作为老年代的收集器,却无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作,所以在JDK1.5中使用CMS来收集老年代的时候,新生代只能选择ParNew或Serial收集器中的一个.ParNew收集器也是使用`-XX: +UseConcMarkSweepGC`选项后的默认新生代收集器,也可以使用 `-XX:+UseParNewGC`选项来强制指定它.\n\nParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果,甚至由于存在线程交互的开销,该收集器在通过超线程技术实现的两个CPU的环境中都不能百分之百地保证能超越Serial收集器.当然,随着可以使用的CPU的数量的增加,它对于GC时系统资源的利用还是很有好处的.它默认开启的收集线程数与CPU的数量相同,在CPU非常多（譬如32个,现在CPU动辄就4核加超线程,服务器超过32个逻辑CPU的情况越来越多了）的环境下,可以使用`-XX:ParallelGCThreads`参数来限制垃圾收集的线程数.\n\n##### 注意  从ParNew收集器开始,后面还将会接触到几款并发和并行的收集器.在大家可能产生疑惑之前,有必要先解释两个名词：并发和并行.这两个名词都是并发编程中的概念,在谈论垃圾收集器的上下文语境中,他们可以解释为：\n* 并行（Parallel）：指多条垃圾收集线程并行工作,但此时用户线程仍然处于等待状态.\n* 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行的,可能会交替执行）,用户程序继续运行,而垃圾收集程序运行于另一个CPU上.\n\n#### Parallel Scavege收集器\n\nParallel Scavenge收集器也是一个新生代收集器,它也是使用复制算法的收集器,又是并行的多线程收集器……看上去和ParNew都一样,那它有什么特别之处呢？\n\n###### Parallel Scavenge收集器的特点\n它的关注点与其他收集器不同,CMS等收集器的关注点尽可能地缩短垃圾收集时用户线程的停顿时间,而Parallel Scavenge收集器的目标则是达到一个可控制的吞吐量（Throughput）.\n\n> 所谓吞吐量就是CPU用于运行用户代码的时间与CPU总消耗时间的比值,即吞吐量 = 运行用户代码时间 /（运行用户代码时间 + 垃圾收集时间）,虚拟机总共运行了100分钟,其中垃圾收集花掉1分钟,那吞吐量就是99%.\n\n停顿时间越短就越适合需要与用户交互的程序,良好的响应速度能提升用户的体验;而高吞吐量则可以最高效率地利用CPU时间,尽快地完成程序的运算任务,主要适合在后台运算而不需要太多交互的任务.\n\n###### Parallel Scavenge收集器设定\nParallel Scavenge收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集停顿时间的`-XX:MaxGCPauseMillis`参数及直接设置吞吐量大小的 `-XX:GCTimeRatio`参数.\n\n* `MaxGCPauseMillis` : 参数允许的值是一个大于0的毫秒数,收集器将尽力保证内存回收花费的时间不超过设定值.不过大家不要异想天开地认为如果把这个参数的值设置得稍小一点就能使得系统的垃圾收集速度变得更快,GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的：系统把新生代调小一些,收集300MB新生代肯定比收集500MB快吧,这也直接导致垃圾收集发生得更频繁一些,原来10秒收集一次、每次停顿100毫秒,现在变成5秒收集一次、每次停顿70毫秒.停顿时间的确在下降,但吞吐量也降下来了.\n\n* `GCTimeRatio` : 参数的值应当是一个大于0小于100的整数,也就是垃圾收集时间占总时间的比率,相当于是吞吐量的倒数.如果把此参数设置为19,那允许的最大GC时间就占总时间的5%（即1 /（1+19））,默认值为99,就是允许最大1%（即1 /（1+99））的垃圾收集时间.\n\n由于与吞吐量关系密切,Parallel Scavenge收集器也经常被称为“吞吐量优先”收集器.除上述两个参数之外,Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得关注.\n* `-XX:+UseAdaptiveSizePolicy` :这是一个开关参数,当这个参数打开之后,就不需要手工指定新生代的大小（-Xmn）、Eden与Survivor区的比例（`-XX:SurvivorRatio`）、晋升老年代对象年龄（`-XX:PretenureSizeThreshold`）等细节参数了,虚拟机会根据当前系统的运行情况收集性能监控信息,动态调整这些参数以提供最合适的停顿时间或最大的吞吐量,这种调节方式称为GC自适应的调节策略（GC Ergonomics）.\n> 如果读者对于收集器运作原理不太了解,手工优化存在困难的时候,使用Parallel Scavenge收集器配合自适应调节策略,把内存管理的调优任务交给虚拟机去完成将是一个很不错的选择.只需要把基本的内存数据设置好（如-Xmx设置最大堆）,然后使用`MaxGCPauseMillis`参数（更关注最大停顿时间）或`GCTimeRatio`参数（更关注吞吐量）给虚拟机设立一个优化目标,那具体细节参数的调节工作就由虚拟机完成了.自适应调节策略也是`Parallel Scavenge`收集器与`ParNew`收集器的一个重要区别.\n\n#### Serial Old收集器\n\nSerial Old是Serial收集器的老年代版本,它同样是一个单线程收集器,使用“标记-整理”算法.这个收集器的主要意义也是被Client模式下的虚拟机使用.如果在Server模式下,它主要还有两大用途：一个是在JDK 1.5及之前的版本中与Parallel Scavenge收集器搭配使用,另外一个就是作为CMS收集器的后备预案,在并发收集发生Concurrent Mode Failure的时候使用.\n\n#### Parallel old收集器\n\nParallel Old是Parallel Scavenge收集器的老年代版本,使用多线程和“标记－整理”算法.这个收集器是在JDK 1.6中才开始提供的,在此之前,新生代的Parallel Scavenge收集器一直处于比较尴尬的状态.原因是,如果新生代选择了Parallel Scavenge收集器,老年代除了Serial Old（PS MarkSweep）收集器外别无选择（还记得上面说过Parallel Scavenge收集器无法与CMS收集器配合工作吗？）.由于单线程的老年代Serial Old收集器在服务端应用性能上的“拖累”,即便使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化的效果,又因为老年代收集中无法充分利用服务器多CPU的处理能力,在老年代很大而且硬件比较高级的环境中,这种组合的吞吐量甚至还不一定有ParNew加CMS的组合“给力”.\n\n直到Parallel Old收集器出现后,“吞吐量优先”收集器终于有了比较名副其实的应用组合,在注重吞吐量及CPU资源敏感的场合,都可以优先考虑Parallel Scavenge加Parallel Old收集器.\n\n#### CMS收集器\n\n###### 用途\nCMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器.目前很大一部分的Java应用都集中在互联网站或B/S系统的服务端上,这类应用尤其重视服务的响应速度,希望系统停顿时间最短,以给用户带来较好的体验.CMS收集器就非常符合这类应用的需求.\n\n###### 采用算法\n从名字（包含“Mark Sweep”）上就可以看出CMS收集器是基于“标记-清除”算法实现的,它的运作过程相对于前面几种收集器来说要更复杂一些,整个过程分为4个步骤,包括：\n1. 初始标记（CMS initial mark）\n2. 并发标记（CMS concurrent mark）\n3. 重新标记（CMS remark）\n4. 并发清除（CMS concurrent sweep）\n\n其中初始标记、重新标记这两个步骤仍然需要“Stop The World”.初始标记仅仅只是标记一下GC Roots能直接关联到的对象,速度很快,并发标记阶段就是进行GC Roots Tracing的过程,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录,这个阶段的停顿时间一般会比初始标记阶段稍长一些,但远比并发标记的时间短.\n\n由于整个过程中耗时最长的并发标记和并发清除过程中,收集器线程都可以与用户线程一起工作,所以总体上来说,CMS收集器的内存回收过程是与用户线程一起并发地执行的.通过图3-10可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的时间.\n\nCMS是一款优秀的收集器,它的最主要优点在名字上已经体现出来了：并发收集、低停顿,Sun的一些官方文档里面也称之为并发低停顿收集器（Concurrent Low Pause Collector）.但是CMS还远达不到完美的程度,它有以下三个显著的缺点：\n\nCMS收集器对CPU资源非常敏感.其实,面向并发设计的程序都对CPU资源比较敏感.在并发阶段,它虽然不会导致用户线程停顿,但是会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢,总吞吐量会降低.CMS默认启动的回收线程数是（CPU数量+3）/ 4,也就是当CPU在4个以上时,并发回收时垃圾收集线程最多占用不超过25%的CPU资源.但是当CPU不足4个时（譬如2个）,那么CMS对用户程序的影响就可能变得很大,如果CPU负载本来就比较大的时候,还分出一半的运算能力去执行收集器线程,就可能导致用户程序的执行速度忽然降低了50%,这也很让人受不了.为了解决这种情况,虚拟机提供了一种称为“增量式并发收集器”（Incremental Concurrent Mark Sweep / i-CMS）的CMS收集器变种,所做的事情和单CPU年代PC机操作系统使用抢占式来模拟多任务机制的思想一样,就是在并发标记和并发清理的时候让GC线程、用户线程交替运行,尽量减少GC线程的独占资源的时间,这样整个垃圾收集的过程会更长,但对用户程序的影响就会显得少一些,速度下降也就没有那么明显,但是目前版本中,i-CMS已经被声明为“deprecated”,即不再提倡用户使用.\n\nCMS收集器无法处理浮动垃圾（Floating Garbage）,可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生.由于CMS并发清理阶段用户线程还在运行着,伴随程序的运行自然还会有新的垃圾不断产生,这一部分垃圾出现在标记过程之后,CMS无法在本次收集中处理掉它们,只好留待下一次GC时再将其清理掉.这一部分垃圾就称为“浮动垃圾”.也是由于在垃圾收集阶段用户线程还需要运行,即还需要预留足够的内存空间给用户线程使用,因此CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集,需要预留一部分空间提供并发收集时的程序运作使用.在默认设置下,CMS收集器在老年代使用了68%的空间后就会被激活,这是一个偏保守的设置,如果在应用中老年代增长不是太快,可以适当调高参数`-XX:CMSInitiatingOccupancyFraction`的值来提高触发百分比,以便降低内存回收次数以获取更好的性能.要是CMS运行期间预留的内存无法满足程序需要,就会出现一次“Concurrent Mode Failure”失败,这时候虚拟机将启动后备预案：临时启用Serial Old收集器来重新进行老年代的垃圾收集,这样停顿时间就很长了.所以说参数`-XX:CMSInitiatingOccupancyFraction`设置得太高将会很容易导致大量“Concurrent Mode Failure”失败,性能反而降低.\n\n还有最后一个缺点,在本节在开头说过,CMS是一款基于“标记-清除”算法实现的收集器,如果读者对前面这种算法介绍还有印象的话,就可能想到这意味着收集结束时会产生大量空间碎片.空间碎片过多时,将会给大对象分配带来很大的麻烦,往往会出现老年代还有很大的空间剩余,但是无法找到足够大的连续空间来分配当前对象,不得不提前触发一次Full GC.为了解决这个问题,CMS收集器提供了一个`-XX:+UseCMSCompactAtFullCollection`开关参数,用于在“享受”完Full GC服务之后额外免费附送一个碎片整理过程,内存整理的过程是无法并发的.空间碎片问题没有了,但停顿时间不得不变长了.虚拟机设计者们还提供了另外一个参数`-XX: CMSFullGCsBeforeCompaction`,这个参数用于设置在执行多少次不压缩的Full GC后,跟着来一次带压缩的.\n\n#### G1收集器\n\nG1（Garbage First）收集器是当前收集器技术发展的最前沿成果,在JDK 1.6_Update14中提供了EarlyAccess版本的G1收集器以供试用.在将来JDK 1.7正式发布的时候,G1收集器很可能会有一个成熟的商用版本随之发布.这里只对G1收集器进行简单介绍.\n\nG1收集器是垃圾收集器理论进一步发展的产物,它与前面的CMS收集器相比有两个显著的改进：一是G1收集器是基于“标记-整理”算法实现的收集器,也就是说它不会产生空间碎片,这对于长时间运行的应用系统来说非常重要.二是它可以非常精确地控制停顿,\n既能让使用者明确指定在一个长度为M毫秒的时间片段内,消耗在垃圾收集上的时间不得超过N毫秒,这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了.\n\nG1收集器可以实现在基本不牺牲吞吐量的前提下完成低停顿的内存回收,这是由于它能够极力地避免全区域的垃圾收集,之前的收集器进行收集的范围都是整个新生代或老年代,而G1将整个Java堆（包括新生代、老年代）划分为多个大小固定的独立区域（Region）,并且跟踪这些区域里面的垃圾堆积程度,在后台维护一个优先列表,每次根据允许的收集时间,优先回收垃圾最多的区域（这就是Garbage First名称的来由）.区域划分及有优先级的区域回收,保证了G1收集器在有限的时间内可以获得最高的收集效率.\n\n\n","slug":"jvm7/垃圾收集","published":1,"date":"2015-09-18T06:28:21.288Z","updated":"2015-09-18T06:16:50.617Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjea8001174uf6670uv36"},{"title":"各种内存异常","_content":"## 各种内存异常\n### java堆溢出\n\n###### 溢出代码\n\n```java\n  public class HeapOOM {\n\n\tstatic class OOMObject {\n\t}\n\n\t/**\n\t * -verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t * -XX:PrintGCDetails\n\t * -XX:SurvivorRatio=8\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tList<OOMObject> list = new ArrayList<>();\n\t\twhile(true) {\n\t\t\tlist.add(new OOMObject());\n\t\t}\n\t}\n\n}\n```\n###### 执行代码\n```\n\tjavac HeapOOM.java\n\tjava -verbose:gc -Xms20M -Xmx20M -Xmn10M   -XX:+PrintGCDetails  -XX:SurvivorRatio=8  HeapOOM\n\tpause\n```\n###### 解决方案\n```\n\t解决java堆内存溢出,一般的手段是通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出的堆转储快照进行分析.\n\t重点是确认内存中的对象是否是必要的,也就是先分清楚是内存泄漏还是内存溢出.\n\tA: 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,\n\t   并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位\n\t   出泄漏代码的位置.\n\tB: 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比\n\t   查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗.\n```\n### 虚拟机栈和本地方法栈溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t  * -Xoss 设置本地放发栈 但是此参数无效\n\t  * -Xss 虚拟机栈 设置此参数\n\t  * @param args\n\t  */\n\n\tpublic class JavaVMStackSOF {\n\n\t\tprivate int stackLength = 1;\n\n\t\tpublic void stackLeak() {\n\t\t\tstackLength ++;\n\t\t\tstackLeak();\n\t\t}\n\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackSOF oom = new JavaVMStackSOF();\n\t\t\ttry {\n\t\t\t\toom.stackLeak();\n\t\t\t} catch(Throwable e) {\n\t\t\t\tSystem.out.println(\"stack length:\" + oom.stackLength);\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic class JavaVMStackOOM {\n\t\tprivate void dontStop() {\n\t\t\twhile(true) {\n\n\t\t\t}\n\t\t}\n\n\t\tpublic void stackLeakByThread() {\n\t\t\twhile(true) {\n\t\t\t\tThread t = new Thread(new Runnable(){\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tdontStop();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackOM om = new JavaVMStackOM();\n\t\t\tom.stackLeakByThread();\n\t\t}\n\t}\n```\n###### 溢出剖析\n```\n\t以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.\n\t实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.\n\t如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否\n\t足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常.\n\n\t当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.\n\t如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度\n\t应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆\n\t和减少栈容量来换取更多的线程.\n```\n### 运行时常量池溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t * 运行时常量溢出\n\t * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class RuntimeConstantPoolOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\tList<String> list = new ArrayList<>();\n\t\t\tint i = 0;\n\t\t\twhile(true) {\n\t\t\t\tlist.add(String.valueOf(i++).intern());\n\t\t\t}\n\t\t}\n\t}\n```\n###### 溢出剖析\n```\n\t如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.\n\t该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String\n\t对象包含的字符串添加到常量池中,并返回次String对象音乐.\n```\n### 方法区溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t * 借助CGLib使得方法区内存溢出异常\n\t * -XX:PermSize10M -XX:MaxPermSize10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class JavaMethodAreaOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\twhile(true) {\n\t\t\t\tEnhancer enhancer = new Enhancer();\n\t\t\t\tenhancer.setSuperclass(OOMObject.class);\n\t\t\t\tenhancer.setUseCache(false);\n\t\t\t\tenhancer.setCallBack(new MethodInterceptor(){\n\t\t\t\t\tpublic Object intercept(Object obj, Method method, Object[] objs,\n\t\t\t\t\tMethodProxy proxy) throws Throwable {\n\t\t\t\t\t\treturn proxy.invokeSuper(obj, args);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tstatic class OOMObject {\n\n\t\t}\n\t}\n```\n###### 执行代码\n```\n\tjavac JavaMethodAreaOOMRun.java\n\tjava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun\npause\n```\n###### 原因剖析\n```\n\t方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.\n\t本例中使用的是CGLib, 还可以使用ASM等框架进行测试.\n\t方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用\n\t中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类)\n```\n\n### 本地内存直接溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M\n\t */\n\tpublic class DirectMemoryOOM {\n\t    private static final int _1MB = 1024 * 1024;\n\n\t    public static void main(String[] args) throws Exception {\n\t        Field unsafeField = Unsafe.class.getDeclaredFields()[0];\n\t        unsafeField.setAccessible(true);\n\t        Unsafe unsafe = (Unsafe)unsafeField.get(null);\n\t        while(true)\n\t            unsafe.allocateMemory(_1MB);\n\t    }\n}\n```\n###### 剖析原因\n```\n\t直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是\n\t设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时\n\t并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:\n\tunsafe.allocateMemory(_1MB);\n```\n","source":"_posts/jvm7/内存溢出.md","raw":"categories:\n- jvm7\ntitle: 各种内存异常\n---\n## 各种内存异常\n### java堆溢出\n\n###### 溢出代码\n\n```java\n  public class HeapOOM {\n\n\tstatic class OOMObject {\n\t}\n\n\t/**\n\t * -verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t * -XX:PrintGCDetails\n\t * -XX:SurvivorRatio=8\n\t * @param args\n\t */\n\tpublic static void main(String[] args) {\n\t\tList<OOMObject> list = new ArrayList<>();\n\t\twhile(true) {\n\t\t\tlist.add(new OOMObject());\n\t\t}\n\t}\n\n}\n```\n###### 执行代码\n```\n\tjavac HeapOOM.java\n\tjava -verbose:gc -Xms20M -Xmx20M -Xmn10M   -XX:+PrintGCDetails  -XX:SurvivorRatio=8  HeapOOM\n\tpause\n```\n###### 解决方案\n```\n\t解决java堆内存溢出,一般的手段是通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出的堆转储快照进行分析.\n\t重点是确认内存中的对象是否是必要的,也就是先分清楚是内存泄漏还是内存溢出.\n\tA: 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,\n\t   并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位\n\t   出泄漏代码的位置.\n\tB: 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比\n\t   查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗.\n```\n### 虚拟机栈和本地方法栈溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t  * -Xoss 设置本地放发栈 但是此参数无效\n\t  * -Xss 虚拟机栈 设置此参数\n\t  * @param args\n\t  */\n\n\tpublic class JavaVMStackSOF {\n\n\t\tprivate int stackLength = 1;\n\n\t\tpublic void stackLeak() {\n\t\t\tstackLength ++;\n\t\t\tstackLeak();\n\t\t}\n\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackSOF oom = new JavaVMStackSOF();\n\t\t\ttry {\n\t\t\t\toom.stackLeak();\n\t\t\t} catch(Throwable e) {\n\t\t\t\tSystem.out.println(\"stack length:\" + oom.stackLength);\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n\n\tpublic class JavaVMStackOOM {\n\t\tprivate void dontStop() {\n\t\t\twhile(true) {\n\n\t\t\t}\n\t\t}\n\n\t\tpublic void stackLeakByThread() {\n\t\t\twhile(true) {\n\t\t\t\tThread t = new Thread(new Runnable(){\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void run() {\n\t\t\t\t\t\tdontStop();\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tpublic static void main(String[] args) {\n\t\t\tJavaVMStackOM om = new JavaVMStackOM();\n\t\t\tom.stackLeakByThread();\n\t\t}\n\t}\n```\n###### 溢出剖析\n```\n\t以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.\n\t实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.\n\t如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否\n\t足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常.\n\n\t当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.\n\t如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度\n\t应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆\n\t和减少栈容量来换取更多的线程.\n```\n### 运行时常量池溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t * 运行时常量溢出\n\t * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class RuntimeConstantPoolOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\tList<String> list = new ArrayList<>();\n\t\t\tint i = 0;\n\t\t\twhile(true) {\n\t\t\t\tlist.add(String.valueOf(i++).intern());\n\t\t\t}\n\t\t}\n\t}\n```\n###### 溢出剖析\n```\n\t如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.\n\t该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String\n\t对象包含的字符串添加到常量池中,并返回次String对象音乐.\n```\n### 方法区溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t * 借助CGLib使得方法区内存溢出异常\n\t * -XX:PermSize10M -XX:MaxPermSize10M\n\t * @author mingwang\n\t *\n\t */\n\tpublic class JavaMethodAreaOOM {\n\n\t\tpublic static void main(String[] args) {\n\t\t\twhile(true) {\n\t\t\t\tEnhancer enhancer = new Enhancer();\n\t\t\t\tenhancer.setSuperclass(OOMObject.class);\n\t\t\t\tenhancer.setUseCache(false);\n\t\t\t\tenhancer.setCallBack(new MethodInterceptor(){\n\t\t\t\t\tpublic Object intercept(Object obj, Method method, Object[] objs,\n\t\t\t\t\tMethodProxy proxy) throws Throwable {\n\t\t\t\t\t\treturn proxy.invokeSuper(obj, args);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\n\t\tstatic class OOMObject {\n\n\t\t}\n\t}\n```\n###### 执行代码\n```\n\tjavac JavaMethodAreaOOMRun.java\n\tjava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun\npause\n```\n###### 原因剖析\n```\n\t方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.\n\t本例中使用的是CGLib, 还可以使用ASM等框架进行测试.\n\t方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用\n\t中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类)\n```\n\n### 本地内存直接溢出\n\n###### 溢出代码\n\n```java\n\t/**\n\t * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M\n\t */\n\tpublic class DirectMemoryOOM {\n\t    private static final int _1MB = 1024 * 1024;\n\n\t    public static void main(String[] args) throws Exception {\n\t        Field unsafeField = Unsafe.class.getDeclaredFields()[0];\n\t        unsafeField.setAccessible(true);\n\t        Unsafe unsafe = (Unsafe)unsafeField.get(null);\n\t        while(true)\n\t            unsafe.allocateMemory(_1MB);\n\t    }\n}\n```\n###### 剖析原因\n```\n\t直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是\n\t设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时\n\t并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:\n\tunsafe.allocateMemory(_1MB);\n```\n","slug":"jvm7/内存溢出","published":1,"date":"2015-09-18T06:28:21.287Z","updated":"2015-09-18T06:18:00.587Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeaa001374ufo222wu5i"},{"title":"内存分配","_content":"## 内存分配\n#### 对象优先在Eden分配\n\n大多数情况下,对象在新生代`Eden`区中分配.当`Eden`区没有足够的空间进行分配时,虚拟机将发起一次`Minor GC`.\n\n虚拟机提供了`-XX:+PrintGCDetails`这个收集器日志参数,告诉虚拟机在发生垃圾收集行为时打印内存回收日志,并且在进程退出的时候输出当前内存各区域的分配情况.在实际应用中,内存回收日志一般是打印到文件后通过日志工具进行分析.\n\n1. 新生代GC(`Minor GC`)：指发生在新生代的垃圾收集动作,因为Java对象大多都具备朝生夕灭的特性,所以`Minor GC`非常频繁,一般回收速度也比较快.\n2. 老年代GC(`Major GC/Full GC`)：指发生在老年代的GC,出现了Major GC,经常会伴随至少一次的Minor GC(但非绝对的,在ParallelScavenge收集器的收集策略里就有直接进行Major GC的策略选择过程).MajorGC的速度一般会比Minor GC慢10倍以上.\n\n###### 示例代码\n```java\nprivate static final int _1MB = 1024 #### 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  */\npublic static void testAllocation() {\n\t    byte[] allocation1, allocation2, allocation3, allocation4;\n\t    allocation1 = new byte[2 #### _1MB];\n\t    allocation2 = new byte[2 #### _1MB];\n\t    allocation3 = new byte[2 #### _1MB];\n\t    allocation4 = new byte[4 #### _1MB];  // 出现一次Minor GC\n}\n```\n###### 代码分析\n\n`testAllocation()`方法中,尝试分配3个2MB大小和1个4MB大小的对象, 在运行时通过`-Xms20M、 -Xmx20M`和`-Xmn10M`这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代.\n\n`-XX:SurvivorRatio=8`决定了新生代中Eden区与一个`Survivor`区的空间比例是8比1,从输出的结果也能清晰地看到`“eden space 8192K、from space 1024K、to space 1024K”`的信息,新生代总可用空间为`9216KB`(`Eden`区+1个`Survivor`区的总容量).\n\n执行`testAllocation()`中分配`allocation4`对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象).\n\n这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去.\n\n这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用).通过GC日志可以证实这一点.\n\n#### 大对象直接进入老年代\n\n所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组(笔者例子中的byte[]数组就是典型的大对象).大对象对虚拟机的内存分配来说就是一个坏消息(替Java虚拟机抱怨一句,比遇到一个大对象更加坏的消息 就是遇到一群“朝生夕灭”的“短命大对象”,写程序的时候应当避免),经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们.\n\n虚拟机提供了一个`-XX:PretenureSizeThreshold`参数,令大于这个设置值的对象直接在老年代中分配.这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(复习一下：新生代采用复制算法收集内存).\n\n执行代码清单3-4中的`testPretenureSizeThreshold()`方法后,我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为`PretenureSizeThreshold`被设置为3MB(就是3145728B,这个参数不能与`-Xmx`之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配.\n\n> 注意　`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效,`Parallel Scavenge`收集器不认识这个参数,\n>\n> `Parallel Scavenge`收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n\t  * -XX:PretenureSizeThreshold=3145728\n\t  */\n\tpublic static void testPretenureSizeThreshold() {\n\t\t　byte[] allocation;\n\t\t　allocation = new byte[4 #### _1MB];  //直接分配在老年代中\n\t}\n```\n#### 长期存活的对象将进入老年代\n\n虚拟机既然采用了分代收集的思想来管理内存,那内存回收时就必须能识别哪些对象应当放在新生代,哪些对象应放在老年代中.为了做到这点,虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活,\t并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数`-XX:MaxTenuringThreshold`来设置.\n\n读者可以试试分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行代码清单3-5中的`testTenuringThreshold()`方法,此方法中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用.\n\n###### 实例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold() {\n\t\t byte[] allocation1, allocation2, allocation3;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置\n\t\t allocation2 = new byte[4 #### _1MB];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation3 = null;\n\t\t allocation3 = new byte[4 #### _1MB];\n\t}\n```\n#### 动态年龄判断\n\n为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升老年代,如果在`Survivor`空间中相同年龄所有对象大小的总和大于`Survivor`空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到`MaxTenuringThreshold`中要求的年龄.\n\n执行代码清单3-6中的testTenuringThreshold2()方法,并设置参数`-XX: MaxTenuringThreshold=15`,会发现运行结果中`Survivor`的空间占用仍然为0%,而老年代比预期增加了`6%`,也就是说`allocation1、allocation2`对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold2() {\n\t\t byte[] allocation1, allocation2, allocation3, allocation4;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // allocation1+allocation2大于survivor空间的一半\n\t\t allocation2 = new byte[_1MB / 4];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation4 = new byte[4 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation4 = new byte[4 #### _1MB];\n\t}\n```\n#### 空间分配担保\n\n在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC.\n\n前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor\t无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的\t剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间.\n\n取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败,\t那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将\tHandlePromotionFailure开关打开,避免Full GC过于频繁,\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testHandlePromotion() {\n\t\t byte[] allocation1, allocation2, allocation3,\n\t\t allocation4, allocation5, allocation6, allocation7;\n\t\t allocation1 = new byte[2 #### _1MB];\n\t\t allocation2 = new byte[2 #### _1MB];\n\t\t allocation3 = new byte[2 #### _1MB];\n\t\t allocation1 = null;\n\t\t allocation4 = new byte[2 #### _1MB];\n\t\t allocation5 = new byte[2 #### _1MB];\n\t\t allocation6 = new byte[2 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation5 = null;\n\t\t allocation6 = null;\n\t\t allocation7 = new byte[2 #### _1MB];\n\t}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/jvm7/内存分配.md","raw":"categories:\n- jvm7\ntitle: 内存分配\n---\n## 内存分配\n#### 对象优先在Eden分配\n\n大多数情况下,对象在新生代`Eden`区中分配.当`Eden`区没有足够的空间进行分配时,虚拟机将发起一次`Minor GC`.\n\n虚拟机提供了`-XX:+PrintGCDetails`这个收集器日志参数,告诉虚拟机在发生垃圾收集行为时打印内存回收日志,并且在进程退出的时候输出当前内存各区域的分配情况.在实际应用中,内存回收日志一般是打印到文件后通过日志工具进行分析.\n\n1. 新生代GC(`Minor GC`)：指发生在新生代的垃圾收集动作,因为Java对象大多都具备朝生夕灭的特性,所以`Minor GC`非常频繁,一般回收速度也比较快.\n2. 老年代GC(`Major GC/Full GC`)：指发生在老年代的GC,出现了Major GC,经常会伴随至少一次的Minor GC(但非绝对的,在ParallelScavenge收集器的收集策略里就有直接进行Major GC的策略选择过程).MajorGC的速度一般会比Minor GC慢10倍以上.\n\n###### 示例代码\n```java\nprivate static final int _1MB = 1024 #### 1024;\n\n/**\n  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n  */\npublic static void testAllocation() {\n\t    byte[] allocation1, allocation2, allocation3, allocation4;\n\t    allocation1 = new byte[2 #### _1MB];\n\t    allocation2 = new byte[2 #### _1MB];\n\t    allocation3 = new byte[2 #### _1MB];\n\t    allocation4 = new byte[4 #### _1MB];  // 出现一次Minor GC\n}\n```\n###### 代码分析\n\n`testAllocation()`方法中,尝试分配3个2MB大小和1个4MB大小的对象, 在运行时通过`-Xms20M、 -Xmx20M`和`-Xmn10M`这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代.\n\n`-XX:SurvivorRatio=8`决定了新生代中Eden区与一个`Survivor`区的空间比例是8比1,从输出的结果也能清晰地看到`“eden space 8192K、from space 1024K、to space 1024K”`的信息,新生代总可用空间为`9216KB`(`Eden`区+1个`Survivor`区的总容量).\n\n执行`testAllocation()`中分配`allocation4`对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象).\n\n这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去.\n\n这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用).通过GC日志可以证实这一点.\n\n#### 大对象直接进入老年代\n\n所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组(笔者例子中的byte[]数组就是典型的大对象).大对象对虚拟机的内存分配来说就是一个坏消息(替Java虚拟机抱怨一句,比遇到一个大对象更加坏的消息 就是遇到一群“朝生夕灭”的“短命大对象”,写程序的时候应当避免),经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来“安置”它们.\n\n虚拟机提供了一个`-XX:PretenureSizeThreshold`参数,令大于这个设置值的对象直接在老年代中分配.这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(复习一下：新生代采用复制算法收集内存).\n\n执行代码清单3-4中的`testPretenureSizeThreshold()`方法后,我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为`PretenureSizeThreshold`被设置为3MB(就是3145728B,这个参数不能与`-Xmx`之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配.\n\n> 注意　`PretenureSizeThreshold`参数只对Serial和ParNew两款收集器有效,`Parallel Scavenge`收集器不认识这个参数,\n>\n> `Parallel Scavenge`收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8\n\t  * -XX:PretenureSizeThreshold=3145728\n\t  */\n\tpublic static void testPretenureSizeThreshold() {\n\t\t　byte[] allocation;\n\t\t　allocation = new byte[4 #### _1MB];  //直接分配在老年代中\n\t}\n```\n#### 长期存活的对象将进入老年代\n\n虚拟机既然采用了分代收集的思想来管理内存,那内存回收时就必须能识别哪些对象应当放在新生代,哪些对象应放在老年代中.为了做到这点,虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活,\t并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数`-XX:MaxTenuringThreshold`来设置.\n\n读者可以试试分别以`-XX:MaxTenuringThreshold=1`和`-XX:MaxTenuringThreshold=15`两种设置来执行代码清单3-5中的`testTenuringThreshold()`方法,此方法中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用.\n\n###### 实例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold() {\n\t\t byte[] allocation1, allocation2, allocation3;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置\n\t\t allocation2 = new byte[4 #### _1MB];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation3 = null;\n\t\t allocation3 = new byte[4 #### _1MB];\n\t}\n```\n#### 动态年龄判断\n\n为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到`MaxTenuringThreshold`才能晋升老年代,如果在`Survivor`空间中相同年龄所有对象大小的总和大于`Survivor`空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到`MaxTenuringThreshold`中要求的年龄.\n\n执行代码清单3-6中的testTenuringThreshold2()方法,并设置参数`-XX: MaxTenuringThreshold=15`,会发现运行结果中`Survivor`的空间占用仍然为0%,而老年代比预期增加了`6%`,也就是说`allocation1、allocation2`对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了.\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15\n\t  * -XX:+PrintTenuringDistribution\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testTenuringThreshold2() {\n\t\t byte[] allocation1, allocation2, allocation3, allocation4;\n\t\t allocation1 = new byte[_1MB / 4];\n\t\t  // allocation1+allocation2大于survivor空间的一半\n\t\t allocation2 = new byte[_1MB / 4];\n\t\t allocation3 = new byte[4 #### _1MB];\n\t\t allocation4 = new byte[4 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation4 = new byte[4 #### _1MB];\n\t}\n```\n#### 空间分配担保\n\n在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC.\n\n前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor\t无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的\t剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间.\n\n取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败,\t那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将\tHandlePromotionFailure开关打开,避免Full GC过于频繁,\n\n###### 示例代码\n```java\n\tprivate static final int _1MB = 1024 #### 1024;\n\n\t/**\n\t  * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M\n\t  * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure\n\t  */\n\t@SuppressWarnings(\"unused\")\n\tpublic static void testHandlePromotion() {\n\t\t byte[] allocation1, allocation2, allocation3,\n\t\t allocation4, allocation5, allocation6, allocation7;\n\t\t allocation1 = new byte[2 #### _1MB];\n\t\t allocation2 = new byte[2 #### _1MB];\n\t\t allocation3 = new byte[2 #### _1MB];\n\t\t allocation1 = null;\n\t\t allocation4 = new byte[2 #### _1MB];\n\t\t allocation5 = new byte[2 #### _1MB];\n\t\t allocation6 = new byte[2 #### _1MB];\n\t\t allocation4 = null;\n\t\t allocation5 = null;\n\t\t allocation6 = null;\n\t\t allocation7 = new byte[2 #### _1MB];\n\t}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"jvm7/内存分配","published":1,"date":"2015-09-18T06:28:21.286Z","updated":"2015-09-18T06:18:02.755Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjead001574ufa721erce"},{"title":"OQL","_content":"# OQL\n\n## SELECT\n`select`用于确定查询语句从堆转储快照中选择什么内容,如果需要显示堆转储快照中的对象,并且浏览这些对象的引用关系,可以使用`*`:\n\n```sql\nSELECT * FEOM java.lang.String\n```\n\n####选择特定的显示列\n查询也可以选择特定需要显示的字段:\n```sql\nSELECT toString(s), s.count, s.value From java.lang.String s\n```\n查询可以十一`@`符号来适应java对象的内存属性访问器\n```sql\nSELECT toString(s), s.@useHeapSize, s.retainedHeapSize From java.lang.String s\n```\n\n####使用列别名\n\n```sql\n\n```\n\n\n\n####拼合成为一个对象列表选择项目\n\n```sql\n\n```\n\n\n\n####排除重复对象\n\n```sql\n\n```\n\n\n\n##FROM\n\n####FROM子句指定需要查询的类\n\n```sql\n\n```\n\n\n\n####包含子类\n\n```sql\n\n```\n\n\n\n####禁止查询类实例\n\n\n```sql\n\n```\n\n\n## WHERE\n\n\n\n```sql\n\n```\n\n####>=,<=,>,<[NOT]LIKE,[NOT]IN\n\n\n```sql\n\n```\n\n\n####=,!=\n\n\n```sql\n\n```\n\n\n####AND\n\n\n```sql\n\n```\n\n\n####OR\n\n\n```sql\n\n```\n\n\n####文字表达式\n\n\n```sql\n\n```\n\n\n##属性访问器\n####访问堆存储快照中对象的字段\n\n\n```sql\n\n```\n\n\n####访问java bean属性\n\n\n```sql\n\n```\n\n\n####钓鱼OQL java语法\n\n\n```sql\n\n```\n\n\n####OQL内建函数\n\n\n\n```sql\n\n```\n\n##OQL语言的BNF范式\n\n\n```sql\n\n```\n\n","source":"_posts/jvm7/oql.md","raw":"categories:\n- jvm7\ntitle: OQL\n---\n# OQL\n\n## SELECT\n`select`用于确定查询语句从堆转储快照中选择什么内容,如果需要显示堆转储快照中的对象,并且浏览这些对象的引用关系,可以使用`*`:\n\n```sql\nSELECT * FEOM java.lang.String\n```\n\n####选择特定的显示列\n查询也可以选择特定需要显示的字段:\n```sql\nSELECT toString(s), s.count, s.value From java.lang.String s\n```\n查询可以十一`@`符号来适应java对象的内存属性访问器\n```sql\nSELECT toString(s), s.@useHeapSize, s.retainedHeapSize From java.lang.String s\n```\n\n####使用列别名\n\n```sql\n\n```\n\n\n\n####拼合成为一个对象列表选择项目\n\n```sql\n\n```\n\n\n\n####排除重复对象\n\n```sql\n\n```\n\n\n\n##FROM\n\n####FROM子句指定需要查询的类\n\n```sql\n\n```\n\n\n\n####包含子类\n\n```sql\n\n```\n\n\n\n####禁止查询类实例\n\n\n```sql\n\n```\n\n\n## WHERE\n\n\n\n```sql\n\n```\n\n####>=,<=,>,<[NOT]LIKE,[NOT]IN\n\n\n```sql\n\n```\n\n\n####=,!=\n\n\n```sql\n\n```\n\n\n####AND\n\n\n```sql\n\n```\n\n\n####OR\n\n\n```sql\n\n```\n\n\n####文字表达式\n\n\n```sql\n\n```\n\n\n##属性访问器\n####访问堆存储快照中对象的字段\n\n\n```sql\n\n```\n\n\n####访问java bean属性\n\n\n```sql\n\n```\n\n\n####钓鱼OQL java语法\n\n\n```sql\n\n```\n\n\n####OQL内建函数\n\n\n\n```sql\n\n```\n\n##OQL语言的BNF范式\n\n\n```sql\n\n```\n\n","slug":"jvm7/oql","published":1,"date":"2015-09-18T06:28:21.285Z","updated":"2015-09-18T06:18:07.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeaf001774ufhc6cqqmr"},{"title":"jstack_log","_content":"# jstack_log\n\n## jstack日志\n下面摘抄的是NETTY中空epoll的一段记录\n```\n\"nioEventLoopGroup-2461-1\" #4955 prio=10 os_prio=0 tid=0x00007fd857e9a000 nid=0x5e19 runnable [0x00007fd7374bc000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n\tat sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x00000000e673cf38> (a io.netty.channel.nio.SelectedSelectionKeySet)\n\t- locked <0x00000000e673cd30> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x00000000e673cc58> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- None\n```\n\n##### 第一行数据分析\n1. `nioEventLoopGroup-2461-1` 表示的是进程名字\n2. `#4955`\n3. `prio=10`\n4. `os_prio=0`\n5. `nid`:线程ID的16进制表示(可以通过`top -H`查看pid)\n6. `tid`:\n7. `runnable`\n8. `[0x00007fd7374bc000]`\n\n##### 线程堆栈信息\n1. `java.lang.Thread.State` 线程状态\n2. `locked` 锁住的资源,分别锁住了`<0x00000000e673cf38>`, `<0x00000000e673cd30>`, `<0x00000000e673cc58>`\n\n\n\n## java.lang.Thread.State 线程状态\n\n* ` Runnable ` : 线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行\n* `waiting for monitor entry` :  在等待进入一个临界区,所以它在`Entry Set`队列中等待.此时线程状态一般都是 `Blocked`:\n\t如果大量线程在`waiting for monitor entry`, 可能是一个全局锁阻塞住了大量线程.如果短时间内打印的 `thread dump` 文件反映,随着时间流逝,`waiting for monitor entry`的线程越来越多,没有减少的趋势,可能意味着某些线程在临界区里呆的时间太长了,以至于越来越多新线程迟迟无法进入临界区.\n\n* `waiting on condition` : 说明它在等待另一个条件的发生,来把自己唤醒,或者干脆它是调用了 `sleep(N)`.\n\t###### 此时线程状态大致为以下几种：<br>\n\t1. `java.lang.Thread.State: WAITING (parking)`：一直等那个条件发生；\n\t2. `java.lang.Thread.State: TIMED_WAITING` (`parking`或`sleeping`)：定时的,那个条件不到来,也将定时唤醒自己.\n\n\t如果大量线程在`waiting on condition`：可能是它们又跑去获取第三方资源,尤其是第三方网络资源,迟迟获取不到`Response`,导致大量线程进入等待状态.所以如果你发现有大量的线程都处在 `Wait on condition`,从线程堆栈看,正等待网络读写,这可能是一个网络瓶颈的征兆,因为网络阻塞导致线程无法执行.\n\n* `in Object.wait()` : 说明它获得了监视器之后,又调用了 `java.lang.Object.wait()` 方法.\t\n\t每个 Monitor在某个时刻,只能被一个线程拥有,该线程就是 `Active Thread`,而其它线程都是 `Waiting Thread`,分别在两个队列 `Entry Set`和 `Wait Set`里面等候.在 `Entry Set`中等待的线程状态是 `Waiting for monitor entry`,而在 `Wait Set`中等待的线程状态是 `in Object.wait()`.\n\t当线程获得了 `Monitor`,如果发现线程继续运行的条件没有满足,它则调用对象(一般就是被 `synchronized` 的对象)的 `wait()` 方法,放弃了 `Monitor`,进入 `Wait Set`队列.\n\n\t######此时线程状态大致为以下几种：<br>\n\t1. `java.lang.Thread.State: TIMED_WAITING (on object monitor)`; \n\t2. `java.lang.Thread.State: WAITING (on object monitor)`;\n","source":"_posts/jvm7/jstack_log.md","raw":"category: jvm7\ntitle: jstack_log\n---\n# jstack_log\n\n## jstack日志\n下面摘抄的是NETTY中空epoll的一段记录\n```\n\"nioEventLoopGroup-2461-1\" #4955 prio=10 os_prio=0 tid=0x00007fd857e9a000 nid=0x5e19 runnable [0x00007fd7374bc000]\n   java.lang.Thread.State: RUNNABLE\n\tat sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n\tat sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)\n\tat sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:79)\n\tat sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)\n\t- locked <0x00000000e673cf38> (a io.netty.channel.nio.SelectedSelectionKeySet)\n\t- locked <0x00000000e673cd30> (a java.util.Collections$UnmodifiableSet)\n\t- locked <0x00000000e673cc58> (a sun.nio.ch.EPollSelectorImpl)\n\tat sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)\n\tat io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:622)\n\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:310)\n\tat io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:116)\n\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:137)\n\tat java.lang.Thread.run(Thread.java:745)\n\n   Locked ownable synchronizers:\n\t- None\n```\n\n##### 第一行数据分析\n1. `nioEventLoopGroup-2461-1` 表示的是进程名字\n2. `#4955`\n3. `prio=10`\n4. `os_prio=0`\n5. `nid`:线程ID的16进制表示(可以通过`top -H`查看pid)\n6. `tid`:\n7. `runnable`\n8. `[0x00007fd7374bc000]`\n\n##### 线程堆栈信息\n1. `java.lang.Thread.State` 线程状态\n2. `locked` 锁住的资源,分别锁住了`<0x00000000e673cf38>`, `<0x00000000e673cd30>`, `<0x00000000e673cc58>`\n\n\n\n## java.lang.Thread.State 线程状态\n\n* ` Runnable ` : 线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行\n* `waiting for monitor entry` :  在等待进入一个临界区,所以它在`Entry Set`队列中等待.此时线程状态一般都是 `Blocked`:\n\t如果大量线程在`waiting for monitor entry`, 可能是一个全局锁阻塞住了大量线程.如果短时间内打印的 `thread dump` 文件反映,随着时间流逝,`waiting for monitor entry`的线程越来越多,没有减少的趋势,可能意味着某些线程在临界区里呆的时间太长了,以至于越来越多新线程迟迟无法进入临界区.\n\n* `waiting on condition` : 说明它在等待另一个条件的发生,来把自己唤醒,或者干脆它是调用了 `sleep(N)`.\n\t###### 此时线程状态大致为以下几种：<br>\n\t1. `java.lang.Thread.State: WAITING (parking)`：一直等那个条件发生；\n\t2. `java.lang.Thread.State: TIMED_WAITING` (`parking`或`sleeping`)：定时的,那个条件不到来,也将定时唤醒自己.\n\n\t如果大量线程在`waiting on condition`：可能是它们又跑去获取第三方资源,尤其是第三方网络资源,迟迟获取不到`Response`,导致大量线程进入等待状态.所以如果你发现有大量的线程都处在 `Wait on condition`,从线程堆栈看,正等待网络读写,这可能是一个网络瓶颈的征兆,因为网络阻塞导致线程无法执行.\n\n* `in Object.wait()` : 说明它获得了监视器之后,又调用了 `java.lang.Object.wait()` 方法.\t\n\t每个 Monitor在某个时刻,只能被一个线程拥有,该线程就是 `Active Thread`,而其它线程都是 `Waiting Thread`,分别在两个队列 `Entry Set`和 `Wait Set`里面等候.在 `Entry Set`中等待的线程状态是 `Waiting for monitor entry`,而在 `Wait Set`中等待的线程状态是 `in Object.wait()`.\n\t当线程获得了 `Monitor`,如果发现线程继续运行的条件没有满足,它则调用对象(一般就是被 `synchronized` 的对象)的 `wait()` 方法,放弃了 `Monitor`,进入 `Wait Set`队列.\n\n\t######此时线程状态大致为以下几种：<br>\n\t1. `java.lang.Thread.State: TIMED_WAITING (on object monitor)`; \n\t2. `java.lang.Thread.State: WAITING (on object monitor)`;\n","slug":"jvm7/jstack_log","published":1,"date":"2015-09-18T06:28:21.283Z","updated":"2015-09-18T06:11:59.647Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeah001974ufvei5k63c"},{"title":"运行时数据区","_content":"## 运行时数据区\n### PC寄存器 (线程独有)\n* 每一个虚拟机线程都有自己的线程寄存器\n* 寄存器里存储了java虚拟机正在执行的字节码指令(线程当前方法)的地址, 字节码解释器工作时就是通过改变这个计数器的值来选取下一条\n  需要执行的字节码指令,分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个计数器来完成\n* 由于java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方法来实现的,在任何一个确定的时刻,一个处理器只会执行一条线程   中的指令.因此为了线程切换后能恢复到正确的执行位置,每条线程都需要有一个独立的程序计数器,各条线程之间的计数器互不影响,独立\n  存储,称这类内存区域为\"线程私有\"的内存\n* 这是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域.\n\n寄存器集成在 CPU 里面,这是最快的数据访问存储区,但是寄存器的数量极其有限,所以寄存器由编译器根据需求进行分配,开发人员不能直接控制,也不能在程序中感觉到寄存器存在的迹象 。\n\n### java虚拟机栈 (线程独有)\n* 与线程同时创建,用于存储栈帧. 它的生命周期与线程相同.\n* 每个方法被执行的时候都会创建一个栈帧,用于存储局部变量表,操作数栈,动态连接,方法出口等信息.\n* 在java虚拟机中.对这个区域规定了俩种异常情况:\n\n   > 1. 如果请求的栈深度大于虚拟机所允许的深度,抛出StackOverflowError.<br>\n   > 2. 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常\n\n位于通用 RAM 中,存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中 。 在堆中产生了一个数组或对象后,还可以在栈中定义一个特殊的变量,让栈中这个变量的取值等于数组或对象在堆内存中的首地址,栈中的这个变量就成了数组或对象的引用变量 。\n\n### java堆\n* 是供各个线程共享的运行时内存\n* 所有类实例和数组对象分配内存的地方\n* 在虚拟机创建的时候该区域就创建了\n* 存储了内存管理系统(GC)\n* java虚拟机中规定,java堆可以处于物理上不连续的内存空间中,逻辑上是连续的即可.在设计时,既可以设计成固定大小的,也可以设计成\n  可拓展的.\n* 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError\n* 需要说明的一点的是,随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上\n  分配也不是那么绝对了\n\n  > 简单介绍一下,java堆内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 如果从内存分配的角都看,线程共享的java对可能还可能划分出多个线程私有的分配缓冲区.\n\n一种通用性的内存池 (也存在于 RAM 中)， 用于存放所以的 JAVA 对象。 Java 的堆是一个运行时数据区 , 对象被存储在堆中 。 这些对象通过 new 等指令建立， 它们不需要程序代码 来显式的释放。 因此， 在堆里分配存储有很大的灵活性 。 堆的缺点是,由于要在运行时动态分配内存,存取速度较慢 。\n\n### 方法区\n* 虚拟机启动时创建\n* 供各个线程共享的运行时内存\n* 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容\n* java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以\n  选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样\"永久存在\". 这个区域的\n  回收目标是针对常量池的回收和对类型的卸载.\n* 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError.\n\n###### 运行时常量池\n\n运行时常量池是方法区的一部分.\n\nClass文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.\n这部分内容将在类加载后存放到方法区的运行时常量池中.\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是`String#intern()`在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示.\n\n它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用\n\njava 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 。 常量池其实也就是一个内存空间,不同于使用 `new` 关键字创建的对象所在的堆空间 。 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型\n\n\n###### 回收方法区\n在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此.\n\n###### 永久代的垃圾回收主要是回收俩部分内容:\n*. 废弃常量\n\n回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串\"ABC\"已经进入了常量池,但是当前系统中没有任何一个String对象是叫做\"ABC\"的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个\"ABC\"常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似.\n\n* 无用的类\n\n判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件:\n\n\t> 1. 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.<br.>\n\t> 2. 加载该类的ClassLoader已经被回收.<br.>\n\t> 3. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类.\n\n虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用`-verbose:Class`及\n`-XX:+TraceClassLoading`,`-XX:+TraceClassUnLoading`查看类的加载和卸载信息.`-verbose:Class`和`-XX:+TraceClassLoading`可以在Product版的虚拟机中使用,但是`-XX:+TraceClassLoading`参数需要fastdebug版的虚拟机支持\n\n### 直接内存\n* 直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致\n  OutOfMemoryError异常出现\n* 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的\n  DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据.\n* 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器\n  寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于\n  物理内存限制,从而导致动态拓展时,出现OutOfMemoryError.\n\n### 本地方法栈\n* 用来支持native方法\n\n### 静态存储\n\n静态存储里存放程序运行时一直存在的数据 。 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 。 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 。\n\n## 栈帧\n* 用来存储数据和部分过程结果的数据结构, 同时也用来处理动态连接, 方法返回值和异常分派\n* 随着方法的调用而创建,随着方法的调用结束而销毁. (结束也包含异常情况)\n* 其内存分配在虚拟机栈之中, 每一个栈帧都有自己的本地变量表, 操作数栈, 和指向当前方法所属的类的运行时常量池.\n\n### 局部变量表\n* 其长度在编译器决定\n* 一个局部变量可以保存boolean, byte, char, short, int, float, reference,returnAddress类型的数据.俩个局部变量可以\n  保存一个long或者double类型的变量.\n* java虚拟机使用局部变量表来完成方法调用时的参数传递. 当调用一个方法时, 它的参数将会传递至从0开始的连续的变量表位置上.\n* 当调用一个实例方法时,第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用.后续的其他参数将会传递至从1开始的连续的\n  局部变量表位置上\n* 虚拟机通过索引定位的方式使用局部变量表,索引值的范围是从0开始到局部变量表最大的Slot数量.\n```\n\t局部变量表中的Slot是可重用的,方法体定义的变量,其作用域并不一定会覆盖整个方法体,如果当前字节码PC计数器的值\n\t已经超出了某个变量的作用域,那么这个变量对应的Slot就可以交给其他变量使用. 这样的设计不仅仅是为了节省栈空间,\n\t在某些情况下Slot的复用会直接影响到系统的垃圾收集行为\n```\n```java\npublic class CollectSlot1 {\n\n    public static void main(String[] args) {\n        byte[] placeholder = new byte[64 * 1024 * 1024];\n        System.gc();\n    }\n}\n\npublic class CollectSlot2 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        System.gc();\n    }\n}\n\npublic class CollectSlot3 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        int a = 0;\n        System.gc();\n    }\n}\n\npublic class CollectSlot4 {\n\n    public static void main(String[] args) {\n        int a = 0;\n        System.gc();\n    }\n}\n\n运行时,加上 -verbose:gc 参数,来查看垃圾收集过程.\n```\n###### 运行结果,CollectSlot1和CollectSlot2并没有执行垃圾回收. 而CollectSlot3却执行了垃圾收集\n###### 运行分析\n\nplaceholder能否被回收的根本原因就是:局部变量表中的Slot是否还存有关于placeholder数组对象的引用.在CollectSlot2中,代码虽然已经离开了placeholder的作用域,但在此之后,没有任何局部变量表的读写操作,placeholder原本所占用的Slot还没有被其他变量所复用,所以作为GC Roots一部分的局部变量表仍然保持着对它的关联.\n\n这种关联没有被及时打断,在绝大部分情况下影响都很轻微.但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了占用了大量内存,实际上已经不会再被使用的变量,手动将其设置为null值就不是一个毫无意义的操作.\n\n这种操作可以作为一种在极特殊情景(对象内存占用大,此方法的栈帧长时间不能被回收,方法调用次数达不到JIT的编译条件)下的奇技来使用. 但不应当对赋null值操作有过多的依赖.\n\n应该以恰当的作用域来控制变量回收时间才是最优雅的解决方法.(如CollectSlot3)\n\n另外赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.字节码被编译为本地代码后,对GC Roots的枚举也与解释执行时期有所差别,CollectSlot2在经过JIT编译后,System.gc() 执行时就可以正确回收掉内存,而无需写成CollectSlot3\n\n关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在\"准备阶段\".类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 所以 CollectSlot4 并不能运行,编译器能在编译器期间检查并提示这一点.\n\n### 操作数栈\n* 每个栈帧内部都包含一个称为操作数栈先进后出栈.\n* 其栈帧长度在编译器决定.\n* 栈帧在刚创建的时候, 操作数栈是空的, java虚拟机提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.\n* 也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈\n* 在调用方法时, 操作数栈也用来准备调用方法的参数以及接受方法返回结果.\n* 每个操作数栈的位置可以保存一个java虚拟机定义的任意数据类型的值,包括long和double类型\n* 在任意时刻,操作数都会有一个确定的栈深度, 一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度\n\n操作数栈也称为操作栈,它是一个先入后出栈.同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double. 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值.\n\n当一个方法开始执行的时候,这个方法的操作数栈是空的,在方法的执行过程中,会有各种字节码指令向操作数栈写入和提取内容,也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.\n\n举个例子,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈.\n\n操作数栈元素的数据类型必须与字节码指令的序列严格匹配,在编译程序代码的时候,编译器要严格保证这一点,在类校验阶段的数据流分析中还要再次验证这一点.再以上的iadd指令为例,这个指令用于整数相加,它在执行时,最接近栈顶的俩个元素的类型必须是int性,不能出现一个long和一个float使用iadd命令相加的情况.\n\n另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递:\n\n![俩个栈帧之间的数据共享]()\n\njava虚拟机解释执行引擎称为\"基于栈的执行引擎\",其中所指的栈就是操作数栈.\n\n\n### 动态连接\n* 每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.\n* 在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.\n* 类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.\n* 由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响\n\n每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的`动态连接`.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接\n\n### 方法正常调用完成\n* 当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等\n* 使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行\n\n### 方法调用非正常完成\n* 指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常\n\n\n### 方法返回地址\n\n当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口.\n\n另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的.\n\n无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息.\n\n方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等.\n\n## 方法调用\n方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用.\n\n### 解析\n继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为`解析(Resolution)`.\n\n在java语言中,符合\"编译器可知,运行期不可变\"这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析.\n\n###### 与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令:\n* `invokestatic`: 调用静态方法\n* `invokespecial`:调用实例构造器`<init>`方法,私有方法和父类方法\n* `invokevirtual`:调用所有的虚方法\n* `invokeinterface`:调用接口方法,会在运行时再确定一个实现此接口的对象\n\n只要能被`invokestatic`, `invokespecial`指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为`非虚方法`,与此相反,其他方法就称为`虚方法`(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法`sayHello()`只可能属于类型`StaticResolution`,没有任何手段可以覆盖或者隐藏这个方法.\n\n```java\npublic class StaticResolution {\n\n    public static void sayHello() {\n        System.out.println(\"hello\");\n    }\n\n    public static void main(String[] args) {\n        StaticResolution.sayHello();\n    }\n}\n\n```\n通过javap查看字节码:\n```java\npublic static void main(java.lang.String[]);\n   descriptor: ([Ljava/lang/String;)V\n   flags: ACC_PUBLIC, ACC_STATIC\n   Code:\n     stack=0, locals=1, args_size=1\n        0: invokestatic  #5                  // Method sayHello:()V\n        3: return\n     LineNumberTable:\n       line 9: 0\n       line 10: 3\n\n```\n\njava中的非虚方法除了使用`invokestatic`和`invokespecial`调用的方法之外还有一种,就是被`final`修饰的方法.虽然`final`方法是使用`invokespecial`指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法.\n\n解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.\n\n\n\n\n\n\n\n\n\n","source":"_posts/jvm7/java虚拟机结构.md","raw":"category: jvm7\ntitle: 运行时数据区\n---\n## 运行时数据区\n### PC寄存器 (线程独有)\n* 每一个虚拟机线程都有自己的线程寄存器\n* 寄存器里存储了java虚拟机正在执行的字节码指令(线程当前方法)的地址, 字节码解释器工作时就是通过改变这个计数器的值来选取下一条\n  需要执行的字节码指令,分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个计数器来完成\n* 由于java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方法来实现的,在任何一个确定的时刻,一个处理器只会执行一条线程   中的指令.因此为了线程切换后能恢复到正确的执行位置,每条线程都需要有一个独立的程序计数器,各条线程之间的计数器互不影响,独立\n  存储,称这类内存区域为\"线程私有\"的内存\n* 这是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域.\n\n寄存器集成在 CPU 里面,这是最快的数据访问存储区,但是寄存器的数量极其有限,所以寄存器由编译器根据需求进行分配,开发人员不能直接控制,也不能在程序中感觉到寄存器存在的迹象 。\n\n### java虚拟机栈 (线程独有)\n* 与线程同时创建,用于存储栈帧. 它的生命周期与线程相同.\n* 每个方法被执行的时候都会创建一个栈帧,用于存储局部变量表,操作数栈,动态连接,方法出口等信息.\n* 在java虚拟机中.对这个区域规定了俩种异常情况:\n\n   > 1. 如果请求的栈深度大于虚拟机所允许的深度,抛出StackOverflowError.<br>\n   > 2. 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常\n\n位于通用 RAM 中,存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中 。 在堆中产生了一个数组或对象后,还可以在栈中定义一个特殊的变量,让栈中这个变量的取值等于数组或对象在堆内存中的首地址,栈中的这个变量就成了数组或对象的引用变量 。\n\n### java堆\n* 是供各个线程共享的运行时内存\n* 所有类实例和数组对象分配内存的地方\n* 在虚拟机创建的时候该区域就创建了\n* 存储了内存管理系统(GC)\n* java虚拟机中规定,java堆可以处于物理上不连续的内存空间中,逻辑上是连续的即可.在设计时,既可以设计成固定大小的,也可以设计成\n  可拓展的.\n* 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError\n* 需要说明的一点的是,随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上\n  分配也不是那么绝对了\n\n  > 简单介绍一下,java堆内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 如果从内存分配的角都看,线程共享的java对可能还可能划分出多个线程私有的分配缓冲区.\n\n一种通用性的内存池 (也存在于 RAM 中)， 用于存放所以的 JAVA 对象。 Java 的堆是一个运行时数据区 , 对象被存储在堆中 。 这些对象通过 new 等指令建立， 它们不需要程序代码 来显式的释放。 因此， 在堆里分配存储有很大的灵活性 。 堆的缺点是,由于要在运行时动态分配内存,存取速度较慢 。\n\n### 方法区\n* 虚拟机启动时创建\n* 供各个线程共享的运行时内存\n* 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容\n* java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以\n  选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样\"永久存在\". 这个区域的\n  回收目标是针对常量池的回收和对类型的卸载.\n* 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError.\n\n###### 运行时常量池\n\n运行时常量池是方法区的一部分.\n\nClass文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.\n这部分内容将在类加载后存放到方法区的运行时常量池中.\n\n运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是`String#intern()`在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示.\n\n它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用\n\njava 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 。 常量池其实也就是一个内存空间,不同于使用 `new` 关键字创建的对象所在的堆空间 。 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型\n\n\n###### 回收方法区\n在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此.\n\n###### 永久代的垃圾回收主要是回收俩部分内容:\n*. 废弃常量\n\n回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串\"ABC\"已经进入了常量池,但是当前系统中没有任何一个String对象是叫做\"ABC\"的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个\"ABC\"常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似.\n\n* 无用的类\n\n判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件:\n\n\t> 1. 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.<br.>\n\t> 2. 加载该类的ClassLoader已经被回收.<br.>\n\t> 3. 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类.\n\n虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用`-verbose:Class`及\n`-XX:+TraceClassLoading`,`-XX:+TraceClassUnLoading`查看类的加载和卸载信息.`-verbose:Class`和`-XX:+TraceClassLoading`可以在Product版的虚拟机中使用,但是`-XX:+TraceClassLoading`参数需要fastdebug版的虚拟机支持\n\n### 直接内存\n* 直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致\n  OutOfMemoryError异常出现\n* 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的\n  DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据.\n* 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器\n  寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于\n  物理内存限制,从而导致动态拓展时,出现OutOfMemoryError.\n\n### 本地方法栈\n* 用来支持native方法\n\n### 静态存储\n\n静态存储里存放程序运行时一直存在的数据 。 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 。 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 。\n\n## 栈帧\n* 用来存储数据和部分过程结果的数据结构, 同时也用来处理动态连接, 方法返回值和异常分派\n* 随着方法的调用而创建,随着方法的调用结束而销毁. (结束也包含异常情况)\n* 其内存分配在虚拟机栈之中, 每一个栈帧都有自己的本地变量表, 操作数栈, 和指向当前方法所属的类的运行时常量池.\n\n### 局部变量表\n* 其长度在编译器决定\n* 一个局部变量可以保存boolean, byte, char, short, int, float, reference,returnAddress类型的数据.俩个局部变量可以\n  保存一个long或者double类型的变量.\n* java虚拟机使用局部变量表来完成方法调用时的参数传递. 当调用一个方法时, 它的参数将会传递至从0开始的连续的变量表位置上.\n* 当调用一个实例方法时,第0个局部变量一定是用来存储被调用的实例方法所在的对象的引用.后续的其他参数将会传递至从1开始的连续的\n  局部变量表位置上\n* 虚拟机通过索引定位的方式使用局部变量表,索引值的范围是从0开始到局部变量表最大的Slot数量.\n```\n\t局部变量表中的Slot是可重用的,方法体定义的变量,其作用域并不一定会覆盖整个方法体,如果当前字节码PC计数器的值\n\t已经超出了某个变量的作用域,那么这个变量对应的Slot就可以交给其他变量使用. 这样的设计不仅仅是为了节省栈空间,\n\t在某些情况下Slot的复用会直接影响到系统的垃圾收集行为\n```\n```java\npublic class CollectSlot1 {\n\n    public static void main(String[] args) {\n        byte[] placeholder = new byte[64 * 1024 * 1024];\n        System.gc();\n    }\n}\n\npublic class CollectSlot2 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        System.gc();\n    }\n}\n\npublic class CollectSlot3 {\n\n    public static void main(String[] args) {\n        {\n            byte[] placeholder = new byte[64 * 1024 * 1024];\n        }\n        int a = 0;\n        System.gc();\n    }\n}\n\npublic class CollectSlot4 {\n\n    public static void main(String[] args) {\n        int a = 0;\n        System.gc();\n    }\n}\n\n运行时,加上 -verbose:gc 参数,来查看垃圾收集过程.\n```\n###### 运行结果,CollectSlot1和CollectSlot2并没有执行垃圾回收. 而CollectSlot3却执行了垃圾收集\n###### 运行分析\n\nplaceholder能否被回收的根本原因就是:局部变量表中的Slot是否还存有关于placeholder数组对象的引用.在CollectSlot2中,代码虽然已经离开了placeholder的作用域,但在此之后,没有任何局部变量表的读写操作,placeholder原本所占用的Slot还没有被其他变量所复用,所以作为GC Roots一部分的局部变量表仍然保持着对它的关联.\n\n这种关联没有被及时打断,在绝大部分情况下影响都很轻微.但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了占用了大量内存,实际上已经不会再被使用的变量,手动将其设置为null值就不是一个毫无意义的操作.\n\n这种操作可以作为一种在极特殊情景(对象内存占用大,此方法的栈帧长时间不能被回收,方法调用次数达不到JIT的编译条件)下的奇技来使用. 但不应当对赋null值操作有过多的依赖.\n\n应该以恰当的作用域来控制变量回收时间才是最优雅的解决方法.(如CollectSlot3)\n\n另外赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.字节码被编译为本地代码后,对GC Roots的枚举也与解释执行时期有所差别,CollectSlot2在经过JIT编译后,System.gc() 执行时就可以正确回收掉内存,而无需写成CollectSlot3\n\n关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在\"准备阶段\".类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 所以 CollectSlot4 并不能运行,编译器能在编译器期间检查并提示这一点.\n\n### 操作数栈\n* 每个栈帧内部都包含一个称为操作数栈先进后出栈.\n* 其栈帧长度在编译器决定.\n* 栈帧在刚创建的时候, 操作数栈是空的, java虚拟机提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.\n* 也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈\n* 在调用方法时, 操作数栈也用来准备调用方法的参数以及接受方法返回结果.\n* 每个操作数栈的位置可以保存一个java虚拟机定义的任意数据类型的值,包括long和double类型\n* 在任意时刻,操作数都会有一个确定的栈深度, 一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度\n\n操作数栈也称为操作栈,它是一个先入后出栈.同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double. 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值.\n\n当一个方法开始执行的时候,这个方法的操作数栈是空的,在方法的执行过程中,会有各种字节码指令向操作数栈写入和提取内容,也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.\n\n举个例子,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈.\n\n操作数栈元素的数据类型必须与字节码指令的序列严格匹配,在编译程序代码的时候,编译器要严格保证这一点,在类校验阶段的数据流分析中还要再次验证这一点.再以上的iadd指令为例,这个指令用于整数相加,它在执行时,最接近栈顶的俩个元素的类型必须是int性,不能出现一个long和一个float使用iadd命令相加的情况.\n\n另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递:\n\n![俩个栈帧之间的数据共享]()\n\njava虚拟机解释执行引擎称为\"基于栈的执行引擎\",其中所指的栈就是操作数栈.\n\n\n### 动态连接\n* 每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.\n* 在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.\n* 类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.\n* 由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响\n\n每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的`动态连接`.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接\n\n### 方法正常调用完成\n* 当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等\n* 使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行\n\n### 方法调用非正常完成\n* 指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常\n\n\n### 方法返回地址\n\n当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口.\n\n另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的.\n\n无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息.\n\n方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等.\n\n## 方法调用\n方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用.\n\n### 解析\n继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为`解析(Resolution)`.\n\n在java语言中,符合\"编译器可知,运行期不可变\"这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析.\n\n###### 与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令:\n* `invokestatic`: 调用静态方法\n* `invokespecial`:调用实例构造器`<init>`方法,私有方法和父类方法\n* `invokevirtual`:调用所有的虚方法\n* `invokeinterface`:调用接口方法,会在运行时再确定一个实现此接口的对象\n\n只要能被`invokestatic`, `invokespecial`指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为`非虚方法`,与此相反,其他方法就称为`虚方法`(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法`sayHello()`只可能属于类型`StaticResolution`,没有任何手段可以覆盖或者隐藏这个方法.\n\n```java\npublic class StaticResolution {\n\n    public static void sayHello() {\n        System.out.println(\"hello\");\n    }\n\n    public static void main(String[] args) {\n        StaticResolution.sayHello();\n    }\n}\n\n```\n通过javap查看字节码:\n```java\npublic static void main(java.lang.String[]);\n   descriptor: ([Ljava/lang/String;)V\n   flags: ACC_PUBLIC, ACC_STATIC\n   Code:\n     stack=0, locals=1, args_size=1\n        0: invokestatic  #5                  // Method sayHello:()V\n        3: return\n     LineNumberTable:\n       line 9: 0\n       line 10: 3\n\n```\n\njava中的非虚方法除了使用`invokestatic`和`invokespecial`调用的方法之外还有一种,就是被`final`修饰的方法.虽然`final`方法是使用`invokespecial`指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法.\n\n解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.\n\n\n\n\n\n\n\n\n\n","slug":"jvm7/java虚拟机结构","published":1,"date":"2015-09-18T06:28:21.282Z","updated":"2015-09-18T06:12:03.655Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeai001b74uf2sdo6mzl"},{"title":"gc_log","_content":"# gc_log\n### gc log\n我使用`-Xmx2048m -Xms2048M  -Xmn1048m`的内存分配方式启动一个JVM,下面是其中一段GC 日志\n```\n{Heap before GC invocations=196 (full 0):\n par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)\n  to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times: user=0.03 sys=0.00, real=0.00 secs]\nHeap after GC invocations=197 (full 0):\n par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)\n  to   space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n}\n```\n\n\n1. `Heap before GC invocations=196 (full 0)`:\n    这一行表示在调用第196GC, 第0次full GC之前的jvm内存分配情况.\n2. `par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    这一行的意思是新生代总共分配了873856K内存,使用了699148K的内存.\n3. `eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)`:\n    新生代的eden区分配了699136K内存,并且使用了100%\n4. `from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)`:\n    survivor1区分配了174720K内存,没有使用\n6. `to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)`:\n    survivor2区分配了174720K内存,没有使用\n5. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`\n    采用并发标记清除算法对新生代共分配1048576K, 其中有3377K大小在使用着\n7. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n    采用并发标记清除算法对永久代共分配21248K大小内存,使用了9252K.\n8. `670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times:`: user=0.03 sys=0.00, real=0.00 secs]`:\n    开始gc,ParNew垃圾收集器的新生代经过0.0047350秒后,将699148K内存进行垃圾收集, gc后有10K内存在使用.\n9. `Heap after GC invocations=197 (full 0)`:\n    在对堆进行197次gc后的内存分配情况：\n10. `par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    新生代分配了873856K大小，使用了10K\n11. `eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)`:\n    新生代eden区分配了699136K大小,使用了0k\n12. `from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)`:\n    新生代的survivor1区分配了174720K,使用了0k\n13. `to space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)`:\n    新生代的survivor2区分配了174720K,使用了0k\n14. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`:\n15. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/jvm7/gc_log.md","raw":"category: jvm7\ntitle: gc_log\n---\n# gc_log\n### gc log\n我使用`-Xmx2048m -Xms2048M  -Xmn1048m`的内存分配方式启动一个JVM,下面是其中一段GC 日志\n```\n{Heap before GC invocations=196 (full 0):\n par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)\n  to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times: user=0.03 sys=0.00, real=0.00 secs]\nHeap after GC invocations=197 (full 0):\n par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)\n  eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)\n  from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)\n  to   space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)\n concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)\n concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)\n}\n```\n\n\n1. `Heap before GC invocations=196 (full 0)`:\n    这一行表示在调用第196GC, 第0次full GC之前的jvm内存分配情况.\n2. `par new generation   total 873856K, used 699148K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    这一行的意思是新生代总共分配了873856K内存,使用了699148K的内存.\n3. `eden space 699136K, 100% used [0x000000077ae00000, 0x00000007a58c0000, 0x00000007a58c0000)`:\n    新生代的eden区分配了699136K内存,并且使用了100%\n4. `from space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c30d8, 0x00000007b0360000)`:\n    survivor1区分配了174720K内存,没有使用\n6. `to   space 174720K,   0% used [0x00000007b0360000, 0x00000007b0360000, 0x00000007bae00000)`:\n    survivor2区分配了174720K内存,没有使用\n5. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`\n    采用并发标记清除算法对新生代共分配1048576K, 其中有3377K大小在使用着\n7. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n    采用并发标记清除算法对永久代共分配21248K大小内存,使用了9252K.\n8. `670.529: [GC670.529: [ParNew: 699148K->10K(873856K), 0.0047350 secs] 702525K->3387K(1922432K), 0.0048480 secs] [Times:`: user=0.03 sys=0.00, real=0.00 secs]`:\n    开始gc,ParNew垃圾收集器的新生代经过0.0047350秒后,将699148K内存进行垃圾收集, gc后有10K内存在使用.\n9. `Heap after GC invocations=197 (full 0)`:\n    在对堆进行197次gc后的内存分配情况：\n10. `par new generation   total 873856K, used 10K [0x000000077ae00000, 0x00000007bae00000, 0x00000007bae00000)`:\n    新生代分配了873856K大小，使用了10K\n11. `eden space 699136K,   0% used [0x000000077ae00000, 0x000000077ae00000, 0x00000007a58c0000)`:\n    新生代eden区分配了699136K大小,使用了0k\n12. `from space 174720K,   0% used [0x00000007b0360000, 0x00000007b03628d8, 0x00000007bae00000)`:\n    新生代的survivor1区分配了174720K,使用了0k\n13. `to space 174720K,   0% used [0x00000007a58c0000, 0x00000007a58c0000, 0x00000007b0360000)`:\n    新生代的survivor2区分配了174720K,使用了0k\n14. `concurrent mark-sweep generation total 1048576K, used 3377K [0x00000007bae00000, 0x00000007fae00000, 0x00000007fae00000)`:\n15. `concurrent-mark-sweep perm gen total 21248K, used 9252K [0x00000007fae00000, 0x00000007fc2c0000, 0x0000000800000000)`:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"jvm7/gc_log","published":1,"date":"2015-09-18T06:28:21.280Z","updated":"2015-09-18T06:12:08.016Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeal001d74ufb6mvxix5"},{"title":"class文件格式","_content":"# class文件格式\n## ClassFile 结构\n```\n  u4              magic;\n  u2              minor_version;\n  u2              major_version;\n  u2              constant_pool_count;\n  cp_info         constant_pool[constant_pool_count - 1];\n  u2              access_flags;\n  u2              this_class;\n  u2              super_class;\n  u2              interfaces_count;\n  u2              interfaces[interfaces_count];\n  u2              fields_count;\n  field_info      fields[fields_count];\n  u2              methods_count;\n  method_info     methods[methods_count];\n  u2              attributes_count;\n  attribute_info  attributes[attributes_count];\n```\n### magic\n\nMagic的唯一作用是确定这个文件是否是一个能被虚拟机所接受的Class文件.魔数固定值为0xCAFEBABY,不会改变\n\n### minor_version, major_version\n\nminor_version副版本号. major_version主版本号, 二者共同构成Class文件版本号.假设minor_version为m, major_version为M, 那么class文件的版本号为M.m.在JDK版本在1.k(k>=2)以上时, class文件的版本范围为(45.0 ~ 44+k.0)\n\n### constant_pool_count\n\n此值等于常量池中的成员数加1. 常量池表的索引值只有大于0且小于constant_pool_count 时才会被认为是有效的,对于long和double例外\n\n### constant_pool[] (常量池)\n\n是一种表结构, 它包含Class文件结构及其子结构中所引用的所有字符串常量, 类, 或接口名, 字段名和其他常量.如上文所说,常量池主要存放俩大类常量:字面量和符号引用. 字面量包括:文本字符串,被声明为final的常量值.而符号引用则包括了下列三种常量:\n1. 类和接口的全限定名.\n2. 字段的名称和描述符\n3. 方法的名称和描述符\n\n在class文件中并不会保存各个方法和字段的最终内存布局信息.当虚拟机运行时,会从常量池获得对应的符合引用,再在类创建或运行时解析并翻译到具体的内存地址之中.常量池中每一项常量都是一个表,下面列举了这11种表结构\n\n###### 常量池11种表结构\n\n|项目                            |类型|描述                                              |\n|--------------------------------|---:|-------------------------------------------------:|\n|<red>CONSTANT_Utf8_info</red>   |UTF-8编码的字符串                                      |\n|tag                             |u1  |值为1                                             |\n|length                          |u2  |UTF-8编码的字符串占用了字节数                     |\n|bytes                           |u1  |长度为length的UTF-8的字符串                       |\n|CONSTANT_Integer_info           |整型字面量                                             |\n|tag                             |u1  |值为3                                             |\n|bytes                           |u4  |按照高位在前存储的int值                           |\n|CONSTANT_Float_info             |浮点型字面量                                           |\n|tag                             |u1  |值为4                                             |\n|bytes                           |u4  |按照高位在前存储的值float                         |\n|CONSTANT_Long_info              |长整型字面量                                           |\n|tag                             |u1  |值为5                                             |\n|bytes                           |u8  |按照高位在前存储的float值                         |\n|CONSTANT_Double_info            |双精度浮点型字面量                                     |\n|tag                             |u1  |值为6                                             |\n|bytes                           |u8  |按照高位在前存储的double值                        |\n|CONSTANT_Class_info             |类或接口的符号引用                                     |\n|tag                             |u1  |值为7                                             |\n|bytes                           |u2  |指定全限定名常量项的索引                          |\n|CONSTANT_String_info            |字符串型字面量                                         |\n|tag                             |u1  |值为8                                             |\n|bytes                           |u4  |指向字符串字面量的索引                            |\n|CONSTANT_Fieldref_info          |字段的符号引用                                         |\n|tag                             |u1  |值为9                                             |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_Methodref_info         |类中方法的符号引用                                     |\n|tag                             |u1  |值为10                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_InterfaceMethodref_info|接口中方法的引用                                       |\n|tag                             |u1  |值为11                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_NameAndType_info       |字段或方法的部分符号引用                               |\n|tag                             |u1  |值为12                                            |\n|index                           |u2  |指向该字段或方法名称常量项的索引                  |\n|index                           |u2  |指向该字段或方法描述符常量项的索引                |\n\n\n### access_flags\n\n是一种掩码标志, 用于表示某个类或者接口的访问权限及属性.\n\n###### access_flags 的取值范围和相应含义表\n\n|标志名         |值     |含义                                                              |\n|---------------|------:|-----------------------------------------------------------------:|\n|ACC_PUBLIC     |0x0001 |声明为public,可以被包外访问                                       |\n|ACC_FINAL      |0x0010 |声明为final,不允许有子类                                          |\n|ACC_SUPER      |0x0020 |当用到invokespecial指令时,需要特殊处理的父类方法                  |\n|ACC_INTERFACE  |0x0200 |标志定义的是接口而不是类                                          |\n|ACC_ABSTRACT   |0x0400 |声明为abstract, 不能被实例化                                      |\n|ACC_SYNTHETIC  |0x1000 |声明为synthetic, 标志为非java源码生成的                           |\n|ACC_ANNOTATION |0x2000 |标志为注解类型                                                    |\n|ACC_ENUM       |0x4000 |标志为枚举类型,意味着它或者它的父类被声明为枚举                   |\n\n当设置上ACC_INTERFACE意味着它是接口而不是类, 反之是类而不是接口. 当带有该标志,同时也设置了 ACC_ABSTRACT,则不能再设置ACC_FINAL,ACC_SUPER,ACC_ENUM..\n\n\n### this_class\n\n类索引用于确定这个的全限定名, this_class类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.java通过this_class, super_class, interfaces 来确定这个类的继承关系\n\n### super_class\n\n当前类的父类. 由于java是单继承体制, 所以父类索引只有一个.类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量. 而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### interfaces_count\n\n该类实现了接口的数量.\n\n### interfaces\n\n该类实现的接口列表. 类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.\n而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### fields_count\n\n用于描述接口或类中声明的字段数量.\n\n### fields 字段表\n\n用于描述接口或类中声明的字段.字段表中包括了类级变量或实例级变量, 但不包括在方法内部声明的变量.每个表中字段中的信息有:字段的作用域(public, private, protected修饰符), 实例变量还是类变量, 可变性(final),并发可见性(volatile), 可否序列化(transient), 字段数据类型, 字段名称.\n\n字段表中不会出现从父类或者父接口中继承而来的字段, 但有可能列出原本java代码中不存在呃字段, 例如在内部类中为了保持对外部类的访问性, 会自动添加指向外部类实例的字段. 另外在java语言中字段是无法重载的, 无论俩个字段的数据类型,修饰符是否相同, 都必须使用不一样的名称, 但是对于字节码来讲, 如果俩个描述符不同, 那字段重名就是合法的.\n\n######字段表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### access_flags\n\n|标志名称        |标识符   | 二进制           |    含义                       |\n|----------------|--------:|-----------------:|------------------------------:|\n|ACC_PUBLIC      |0x0001   |1                 |字段是否是 public              |\n|ACC_PRIVATE     |0x0002   |10                |字段是否是private              |\n|ACC_PROTECTED   |0x0004   |100               |字段是否是protected            |\n|ACC_STATIC      |0x0008   |1000              |字段是否是static               |\n|ACC_FINAL       |0x0010   |10000             |字段是否是final                |\n|ACC_VOLATILE    |0x0040   |1000000           |字段是否是volatile             |\n|ACC_TRANSIENT   |0x0080   |10000000          |字段是否是transient            |\n|ACC_SYNTHETIC   |0x1000   |1000000000000     |字段是否是由编译器自动产生的   |\n|ACC_ENUM        |0x4000   |100000000000000   |字段是否是enum                 |\n\n\n  通过`access_flags` 我们可以很容易的看出`ACC_PUBLIC, ACC_PRIVATE, ACC_PROTECTED`三个标记中最多只能选择其一.而且`ACC_FINAL` 和 `ACC_VOLATILE` 不能同时选择.\n\n\n### methods_count\n\n方法表中的方法的数量\n\n### methods\n\nClass文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法.\n\n如果父类方法在子类中没有被重写, 方法表集合中就不会出现来自父类的方法信息. 但同样的,有可能出现由编译器自动添加的方法, 最经典的就是类构造器<clinit>和实例构造器<init>\n\n在java语言中重载一个方法,除了要与愿方法具有相同的简单名称之外, 还要求必须拥有一个与原方法不同的签名特征, 签名特征就是一个方法中各个参数在常量池的字段符号引用的集合, 也就是因为\n返回值不会包含在签名特征之中, 因此java语言里无法仅仅靠返回值的不同来对一个方法进行重载.但是在class文件格式之中,签名的范围更大一些,只要描述符不是完全一致的俩个方法也可以共存.\n也就是说俩个方法具有相同的名称和特征签名,但返回值不同,那么也是可以合法共存于一个class文件中.\n\n###### 方法表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### 方法访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                             |\n|----------------|--------:|---------------:|--------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |方法是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |方法是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |方法是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |方法是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |方法是否是final                  |\n|ACC_SYNCHRONIZED|0x0020   |100000          |方法是否是synchronized           |\n|ACC_BRIDGE      |0x0040   |1000000         |方法是否是由编译器产生的桥接方法 |\n|ACC_VARARGS     |0x0080   |10000000        |方法是否是接受不确定参数         |\n|ACC_NATIVE      |0x0100   |100000000       |方法是否是native                 |\n|ACC_ABSTRACT    |0x0400   |10000000000     |方法是否是abstract               |\n|ACC_STRICT      |0x0800   |100000000000    |方法是否是strictfp               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |方法是否是由编译器自动产生的     |\n\n### attributes_count\n\n属性表里的属性数量\n\n### attributes\n\n###### 属性表\n\n|属性名称             |使用位置           |含义                                    |\n|---------------------|------------------:|---------------------------------------:|\n|Code                 |方法表             |java代码编译成的字节码指令              |\n|ConstantValue        |字段表             |final关键字定义的常量值                 |\n|Deprecated           |类,方法表,字段表   |被声明为deprecated的方法和字段          |\n|Exceptions           |方法表             |方法抛出的异常                          |\n|InnerClass           |类文件             |内部类列表                              |\n|LineNumberTable      |Code属性           |java源码的行号和字节码指令的对应关系    |\n|LocalVariableTable   |Code属性           |方法的局部的变量描述                    |\n|SourceFile           |类文件             |原文件名称                              |\n|Synthetic            |类,字段表,方法表   |标志方法或字段为编译器自动生成的        |\n\n\n属性表在Class文件,字段表,方法表中都可以携带自己的属性表集合.\n\n#### Code属性\n\n|类型             |名称                     |数量                  |\n|-----------------|------------------------:|---------------------:|\n|u2               |attribute_name_index     |1                     |\n|u4               |attribute_length         |1                     |\n|u2               |max_stack                |1                     |\n|u2               |max_locals               |1                     |\n|u4               |code_length              |1                     |\n|u1               |code                     |code_length           |\n|u2               |exception_table_length   |1                     |\n|exception_info   |exception_table          |exception_table_length|\n|u2               |attributes_count         |1                     |\n|attribute_info   |attributes               |attributes_count      |\n\n\n1. attribute_name_index  是一项指向CONSTANT_Utf8_info型常量. 常量值固定为\"Code\",它代表了该属性的属性名称.\n2. attribute_length  该值代表了属性值的长度, 由于属性名称索引和属性长度一共是6个字节, 所以属性值的长度固定为整个属性表的长度\n3. max_stack  该值代表了操作数栈深度的最大值.虚拟机运行时需要根据这个值来分配栈帧中的操作数栈深度.\n4. max_locals 该值代表了局部变量所需的存储空间. max_locals的单位是Slot, Slot是虚拟机为局部变量分配空间所使用的最小单位.\n   对应byte, char, float, int, short, boolean, refrence, returnAddress 等长度不超过32位的数据类型,每个局部\n   变量占用一个Slot, 而double和long这俩种64位的数据类型则需要2个solt来存放.\n   方法参数,显式异常处理器的参数,方法体中定义的局部变量都需要使用局部变量来存放.\n   需要注意的是,并不是在方法中用到了多少个局部变量,就把这些局部变量所占的Slot之和作为max_locals的值,\n   原因是局部变量表中的Slot可以重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的Slot就可以被其他的\n   局部变量所使用,编译器会根据变量的作用域来分类Solt并分配给各个变量使用.\n5. code_length 代表字节码长度, 虽然该值是一个u4类型的长度值,但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令。如果超过这个指令,javac编译器会拒绝编译.\n6. code 用于存储字节码指令的一系列字节流. 每个字节码指令都是一个u1类型的单字节,当虚拟机读取到Code中的一个字节码时,就可以相应的找出这个字节码代表的是什么指令, 并且可以知道这条指令后面是否需要跟随参数,以及参数如何理解.\n7. exception_table_length\n8. exception_table\n9. attributes_count\n10. attributes\n\n\n#### Exceptions 属性\n\nExceptions属性是在与方法表中与Code属性平级的一项属性, 这与异常表是不同的. Exceptions属性的作用是列举出方法中\n可能抛出的受检查异常,也就是方法描述时throws关键字后面列举的异常\n\n###### Exceptions属性表结构\n\n|类型  |名称                   |数量                   |\n|------|----------------------:|----------------------:|\n|u2    |attribute_name_index   |1                      |\n|u4    |attribute_length       |1                      |\n|u2    |number_of_exceptions   |1                      |\n|u2    |exception_index_table  |number_of_exceptions   |\n\n```\n   number_of_exceptions 表示方法可能抛出number_of_exceptions种受检查异常, 每一种受检查异常都是要一个\n   exception_index_table表示. exception_index_table指向一个常量池CONSTANT_Class_info类型的常量索引\n```\n#### LineNumberTable属性\n\n\n用于描述java源码行号与字节码之间的对应关系. 它并不是运行时必须的属性. 但默认的会生成到Class文件中,\n可以使用javac中-g:none或者-g:lines选项来取消它. 取消的后果是在抛出异常时,堆栈中将不会显示错的行号,\n并且在断点时,无法按照源码设置断点.\n\n\n#### LocalVariableTable 属性\n\n\n 用于描述栈帧中局部变量表中的变量与java源码中定义的变量之间的关系. 它并不是运行时必须的属性.默认也不会\n 生成到Class文件中, 可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息. 如果没有生成这项信息,\n 最大的影响是当其他人引用这个方法时,所有的参数名都将丢失,IDE可能使用诸如arg0, arg1之类的占位符来代替原有的参数名\n\n###### LocalVarialTable属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |local_variable_table_length  |1                             |\n|local_variable_info  |local_variable_table         |local_variable_table_length   |\n\nlocal_variable_info项目结构\n\n|类型  |名称              |数量|\n|------|-----------------:|---:|\n|u2    |start_pc          |1   |\n|u2    |length            |1   |\n|u2    |name_index        |1   |\n|u2    |descriptor_index  |1   |\n|u2    |index             |1   |\n\n\n1. local_variable_info代表了一个栈帧与源码中的局部变量的联系.\n2. start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,俩者结合起来就是这个局部变量在字节码之中的作用域范围.\n3. name_index和descriptor指向的是常量池中CONSTANT_Utf8_info型常量的索引. 分别代表了局部变量名称及其描述符\n4. index是这个局部变量在栈帧局部变量表中Solt的位置.\n5. 在JDK1.5引入泛型之后,引入了一个LocalVarialTypeTable,这个新增的属性结构和LocalVarialTable非常相似,它仅仅是把记录的字段的描述符descriptor_index换成了字段的特征签名,对于非泛型类型来说,描述符和特征签名能描述的信息基本是一致的. 但是引入泛型之后,由于描述符中泛型化的参数被擦除掉了,描述符就不能准确地描述泛型信息了,因此引入了LocalVarialTypeTable\n\n\n#### SourceFile 属性\n\n\n该属性用来记录生成这个Class文件的源码文件名称,该属性也是可选的,可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息.\n\n###### SourceFile属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |sourcefile_index             |1                             |\n\n#### ConstantValue\n\n1. 该属性的作用是通知虚拟机自动为静态变量赋值. 只有被static修饰的变量才可以使用这项属性.\n2. 对于非static类型变量的赋值是在实例构造器<init>方法中进行的.\n3. 对于static类型的变量,有俩种赋值方式选择:\n   > A: 在类构造器<clinit>中进行\n   > B: 使用ConstantValue属性来赋值\n  \n前Sun Javac编译器的选择是:如果同时使用final和static来修饰一个变量, 并且这个变量的数据类型是基本类型或者String的话, 就生成ConstantValue属性来初始化, 否则在<clinit>中进行初始化.\n\n\n###### ConstantValue属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |constantvalue_index          |1                             |\n\n\nConstantValue属性是一个定长属性,它的attribute_length数据值必须为2. constantvalue_index代表了常量池中一个字面量的音乐,根据字段类型的不同,字面量可以是CONSTANT_Long_info, CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_integer_info,CONSTANT_String_info常量中的一种.\n\n\n#### InnerClass\n\n用于记录内部类和宿主类之间的关系.如果一个类中定义了内部类,那么编译器会为它以及包含的内部类生成InnerClass属性.\n\n###### InnerClass 属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |number_of_classes            |1                             |\n|inner_classes_info   |inner_classes                |number_of_classes             |\n\n###### inner_classes_info表结构\n\n|类型  |名称                        |数量|\n|------|---------------------------:|---:|\n|u2    |inner_class_info_index      |1   |\n|u2    |outer_class_info_index      |1   |\n|u2    |inner_name_index            |1   |\n|u2    |inner_class_access_flags    |1   |\n\n\n1. inner_class_info_index和outer_class_info_index分别指向常量池中CONSTANT_Class_info型常量索引.\n   分别代表内部类和宿主类的符号引用\n2. inner_name_index指向常量池中CONSTANT_Utf8_info型常量索引. 代表这个内部类的名称.如果是匿名内部类则为0\n3. inner_class_access_flags是内部类的访问标志,\n\n###### inner_class_access_flags访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                               |\n|----------------|--------:|---------------:|----------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |内部类是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |内部类是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |内部类是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |内部类是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |内部类是否是final                  |\n|ACC_INTERFACE   |0x0020   |100000          |内部类是否是synchronized           |\n|ACC_ABSTRACT    |0x0400   |10000000000     |内部类是否是abstract               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |内部类是否是由并非用户代码产生的   |\n|ACC_ANNOTATION  |0x2000   |100000000000    |内部类是否是一个注解               |\n|ACC_ENUM        |0x4000   |100000000000    |内部类是否是一个枚举               |\n\n#### Deprecated, Synthetic\n\n\n这俩个属性属于标志型的布尔属性,只有存在不存在的区别.Deprecated 表示某个类或者字段或者方法被作者不再推荐使用,在代码中通过@Deprecated标注Synthetic 代码该字段或者方法并不是由java源码直接产生的,而是由编译器自行添加的.\n\n在JDK1.5以后,标志一个类,字段,方法是编译器自动产生的,也可以设置他们的访问标志中的ACC_SYNTHETIC标志位,最典型的例子就是Bridge Method了. 所有由非用户产生的类,字段,方法都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位,唯一例外的就是<init>和<clinit>方法.\n\n\n","source":"_posts/jvm7/class文件格式.md","raw":"category: jvm7\ntitle: class文件格式\n---\n# class文件格式\n## ClassFile 结构\n```\n  u4              magic;\n  u2              minor_version;\n  u2              major_version;\n  u2              constant_pool_count;\n  cp_info         constant_pool[constant_pool_count - 1];\n  u2              access_flags;\n  u2              this_class;\n  u2              super_class;\n  u2              interfaces_count;\n  u2              interfaces[interfaces_count];\n  u2              fields_count;\n  field_info      fields[fields_count];\n  u2              methods_count;\n  method_info     methods[methods_count];\n  u2              attributes_count;\n  attribute_info  attributes[attributes_count];\n```\n### magic\n\nMagic的唯一作用是确定这个文件是否是一个能被虚拟机所接受的Class文件.魔数固定值为0xCAFEBABY,不会改变\n\n### minor_version, major_version\n\nminor_version副版本号. major_version主版本号, 二者共同构成Class文件版本号.假设minor_version为m, major_version为M, 那么class文件的版本号为M.m.在JDK版本在1.k(k>=2)以上时, class文件的版本范围为(45.0 ~ 44+k.0)\n\n### constant_pool_count\n\n此值等于常量池中的成员数加1. 常量池表的索引值只有大于0且小于constant_pool_count 时才会被认为是有效的,对于long和double例外\n\n### constant_pool[] (常量池)\n\n是一种表结构, 它包含Class文件结构及其子结构中所引用的所有字符串常量, 类, 或接口名, 字段名和其他常量.如上文所说,常量池主要存放俩大类常量:字面量和符号引用. 字面量包括:文本字符串,被声明为final的常量值.而符号引用则包括了下列三种常量:\n1. 类和接口的全限定名.\n2. 字段的名称和描述符\n3. 方法的名称和描述符\n\n在class文件中并不会保存各个方法和字段的最终内存布局信息.当虚拟机运行时,会从常量池获得对应的符合引用,再在类创建或运行时解析并翻译到具体的内存地址之中.常量池中每一项常量都是一个表,下面列举了这11种表结构\n\n###### 常量池11种表结构\n\n|项目                            |类型|描述                                              |\n|--------------------------------|---:|-------------------------------------------------:|\n|<red>CONSTANT_Utf8_info</red>   |UTF-8编码的字符串                                      |\n|tag                             |u1  |值为1                                             |\n|length                          |u2  |UTF-8编码的字符串占用了字节数                     |\n|bytes                           |u1  |长度为length的UTF-8的字符串                       |\n|CONSTANT_Integer_info           |整型字面量                                             |\n|tag                             |u1  |值为3                                             |\n|bytes                           |u4  |按照高位在前存储的int值                           |\n|CONSTANT_Float_info             |浮点型字面量                                           |\n|tag                             |u1  |值为4                                             |\n|bytes                           |u4  |按照高位在前存储的值float                         |\n|CONSTANT_Long_info              |长整型字面量                                           |\n|tag                             |u1  |值为5                                             |\n|bytes                           |u8  |按照高位在前存储的float值                         |\n|CONSTANT_Double_info            |双精度浮点型字面量                                     |\n|tag                             |u1  |值为6                                             |\n|bytes                           |u8  |按照高位在前存储的double值                        |\n|CONSTANT_Class_info             |类或接口的符号引用                                     |\n|tag                             |u1  |值为7                                             |\n|bytes                           |u2  |指定全限定名常量项的索引                          |\n|CONSTANT_String_info            |字符串型字面量                                         |\n|tag                             |u1  |值为8                                             |\n|bytes                           |u4  |指向字符串字面量的索引                            |\n|CONSTANT_Fieldref_info          |字段的符号引用                                         |\n|tag                             |u1  |值为9                                             |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_Methodref_info         |类中方法的符号引用                                     |\n|tag                             |u1  |值为10                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_InterfaceMethodref_info|接口中方法的引用                                       |\n|tag                             |u1  |值为11                                            |\n|index                           |u2  |指向声明字段的类或接口描述符CONSTANT_Class_info   |\n|index                           |u2  |指向字段描述符CONSTANT_NameAndType的索引项        |\n|CONSTANT_NameAndType_info       |字段或方法的部分符号引用                               |\n|tag                             |u1  |值为12                                            |\n|index                           |u2  |指向该字段或方法名称常量项的索引                  |\n|index                           |u2  |指向该字段或方法描述符常量项的索引                |\n\n\n### access_flags\n\n是一种掩码标志, 用于表示某个类或者接口的访问权限及属性.\n\n###### access_flags 的取值范围和相应含义表\n\n|标志名         |值     |含义                                                              |\n|---------------|------:|-----------------------------------------------------------------:|\n|ACC_PUBLIC     |0x0001 |声明为public,可以被包外访问                                       |\n|ACC_FINAL      |0x0010 |声明为final,不允许有子类                                          |\n|ACC_SUPER      |0x0020 |当用到invokespecial指令时,需要特殊处理的父类方法                  |\n|ACC_INTERFACE  |0x0200 |标志定义的是接口而不是类                                          |\n|ACC_ABSTRACT   |0x0400 |声明为abstract, 不能被实例化                                      |\n|ACC_SYNTHETIC  |0x1000 |声明为synthetic, 标志为非java源码生成的                           |\n|ACC_ANNOTATION |0x2000 |标志为注解类型                                                    |\n|ACC_ENUM       |0x4000 |标志为枚举类型,意味着它或者它的父类被声明为枚举                   |\n\n当设置上ACC_INTERFACE意味着它是接口而不是类, 反之是类而不是接口. 当带有该标志,同时也设置了 ACC_ABSTRACT,则不能再设置ACC_FINAL,ACC_SUPER,ACC_ENUM..\n\n\n### this_class\n\n类索引用于确定这个的全限定名, this_class类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.java通过this_class, super_class, interfaces 来确定这个类的继承关系\n\n### super_class\n\n当前类的父类. 由于java是单继承体制, 所以父类索引只有一个.类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量. 而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### interfaces_count\n\n该类实现了接口的数量.\n\n### interfaces\n\n该类实现的接口列表. 类型为u2, 指向一个类型为CONSTANT_Class_info 的类描述符常量.\n而CONSTANT_Class_info 类型中的索引值指向了 CONSTANT_Utf8_info 类型的常量中的全限定名字符串.\n\n### fields_count\n\n用于描述接口或类中声明的字段数量.\n\n### fields 字段表\n\n用于描述接口或类中声明的字段.字段表中包括了类级变量或实例级变量, 但不包括在方法内部声明的变量.每个表中字段中的信息有:字段的作用域(public, private, protected修饰符), 实例变量还是类变量, 可变性(final),并发可见性(volatile), 可否序列化(transient), 字段数据类型, 字段名称.\n\n字段表中不会出现从父类或者父接口中继承而来的字段, 但有可能列出原本java代码中不存在呃字段, 例如在内部类中为了保持对外部类的访问性, 会自动添加指向外部类实例的字段. 另外在java语言中字段是无法重载的, 无论俩个字段的数据类型,修饰符是否相同, 都必须使用不一样的名称, 但是对于字节码来讲, 如果俩个描述符不同, 那字段重名就是合法的.\n\n######字段表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### access_flags\n\n|标志名称        |标识符   | 二进制           |    含义                       |\n|----------------|--------:|-----------------:|------------------------------:|\n|ACC_PUBLIC      |0x0001   |1                 |字段是否是 public              |\n|ACC_PRIVATE     |0x0002   |10                |字段是否是private              |\n|ACC_PROTECTED   |0x0004   |100               |字段是否是protected            |\n|ACC_STATIC      |0x0008   |1000              |字段是否是static               |\n|ACC_FINAL       |0x0010   |10000             |字段是否是final                |\n|ACC_VOLATILE    |0x0040   |1000000           |字段是否是volatile             |\n|ACC_TRANSIENT   |0x0080   |10000000          |字段是否是transient            |\n|ACC_SYNTHETIC   |0x1000   |1000000000000     |字段是否是由编译器自动产生的   |\n|ACC_ENUM        |0x4000   |100000000000000   |字段是否是enum                 |\n\n\n  通过`access_flags` 我们可以很容易的看出`ACC_PUBLIC, ACC_PRIVATE, ACC_PROTECTED`三个标记中最多只能选择其一.而且`ACC_FINAL` 和 `ACC_VOLATILE` 不能同时选择.\n\n\n### methods_count\n\n方法表中的方法的数量\n\n### methods\n\nClass文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法.\n\n如果父类方法在子类中没有被重写, 方法表集合中就不会出现来自父类的方法信息. 但同样的,有可能出现由编译器自动添加的方法, 最经典的就是类构造器<clinit>和实例构造器<init>\n\n在java语言中重载一个方法,除了要与愿方法具有相同的简单名称之外, 还要求必须拥有一个与原方法不同的签名特征, 签名特征就是一个方法中各个参数在常量池的字段符号引用的集合, 也就是因为\n返回值不会包含在签名特征之中, 因此java语言里无法仅仅靠返回值的不同来对一个方法进行重载.但是在class文件格式之中,签名的范围更大一些,只要描述符不是完全一致的俩个方法也可以共存.\n也就是说俩个方法具有相同的名称和特征签名,但返回值不同,那么也是可以合法共存于一个class文件中.\n\n###### 方法表结构\n\n|类型             |名称               |数量               |\n|-----------------|------------------:|------------------:|\n|u2               |access_flags       |1                  |\n|u2               |name_index         |1                  |\n|u2               |descriptor_index   |1                  |\n|u2               |attributes_count   |1                  |\n|attribute_info   |attributes         |attributes_count   |\n\n###### 方法访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                             |\n|----------------|--------:|---------------:|--------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |方法是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |方法是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |方法是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |方法是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |方法是否是final                  |\n|ACC_SYNCHRONIZED|0x0020   |100000          |方法是否是synchronized           |\n|ACC_BRIDGE      |0x0040   |1000000         |方法是否是由编译器产生的桥接方法 |\n|ACC_VARARGS     |0x0080   |10000000        |方法是否是接受不确定参数         |\n|ACC_NATIVE      |0x0100   |100000000       |方法是否是native                 |\n|ACC_ABSTRACT    |0x0400   |10000000000     |方法是否是abstract               |\n|ACC_STRICT      |0x0800   |100000000000    |方法是否是strictfp               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |方法是否是由编译器自动产生的     |\n\n### attributes_count\n\n属性表里的属性数量\n\n### attributes\n\n###### 属性表\n\n|属性名称             |使用位置           |含义                                    |\n|---------------------|------------------:|---------------------------------------:|\n|Code                 |方法表             |java代码编译成的字节码指令              |\n|ConstantValue        |字段表             |final关键字定义的常量值                 |\n|Deprecated           |类,方法表,字段表   |被声明为deprecated的方法和字段          |\n|Exceptions           |方法表             |方法抛出的异常                          |\n|InnerClass           |类文件             |内部类列表                              |\n|LineNumberTable      |Code属性           |java源码的行号和字节码指令的对应关系    |\n|LocalVariableTable   |Code属性           |方法的局部的变量描述                    |\n|SourceFile           |类文件             |原文件名称                              |\n|Synthetic            |类,字段表,方法表   |标志方法或字段为编译器自动生成的        |\n\n\n属性表在Class文件,字段表,方法表中都可以携带自己的属性表集合.\n\n#### Code属性\n\n|类型             |名称                     |数量                  |\n|-----------------|------------------------:|---------------------:|\n|u2               |attribute_name_index     |1                     |\n|u4               |attribute_length         |1                     |\n|u2               |max_stack                |1                     |\n|u2               |max_locals               |1                     |\n|u4               |code_length              |1                     |\n|u1               |code                     |code_length           |\n|u2               |exception_table_length   |1                     |\n|exception_info   |exception_table          |exception_table_length|\n|u2               |attributes_count         |1                     |\n|attribute_info   |attributes               |attributes_count      |\n\n\n1. attribute_name_index  是一项指向CONSTANT_Utf8_info型常量. 常量值固定为\"Code\",它代表了该属性的属性名称.\n2. attribute_length  该值代表了属性值的长度, 由于属性名称索引和属性长度一共是6个字节, 所以属性值的长度固定为整个属性表的长度\n3. max_stack  该值代表了操作数栈深度的最大值.虚拟机运行时需要根据这个值来分配栈帧中的操作数栈深度.\n4. max_locals 该值代表了局部变量所需的存储空间. max_locals的单位是Slot, Slot是虚拟机为局部变量分配空间所使用的最小单位.\n   对应byte, char, float, int, short, boolean, refrence, returnAddress 等长度不超过32位的数据类型,每个局部\n   变量占用一个Slot, 而double和long这俩种64位的数据类型则需要2个solt来存放.\n   方法参数,显式异常处理器的参数,方法体中定义的局部变量都需要使用局部变量来存放.\n   需要注意的是,并不是在方法中用到了多少个局部变量,就把这些局部变量所占的Slot之和作为max_locals的值,\n   原因是局部变量表中的Slot可以重用,当代码执行超出一个局部变量的作用域时,这个局部变量所占的Slot就可以被其他的\n   局部变量所使用,编译器会根据变量的作用域来分类Solt并分配给各个变量使用.\n5. code_length 代表字节码长度, 虽然该值是一个u4类型的长度值,但是虚拟机规范中限制了一个方法不允许超过65535条字节码指令。如果超过这个指令,javac编译器会拒绝编译.\n6. code 用于存储字节码指令的一系列字节流. 每个字节码指令都是一个u1类型的单字节,当虚拟机读取到Code中的一个字节码时,就可以相应的找出这个字节码代表的是什么指令, 并且可以知道这条指令后面是否需要跟随参数,以及参数如何理解.\n7. exception_table_length\n8. exception_table\n9. attributes_count\n10. attributes\n\n\n#### Exceptions 属性\n\nExceptions属性是在与方法表中与Code属性平级的一项属性, 这与异常表是不同的. Exceptions属性的作用是列举出方法中\n可能抛出的受检查异常,也就是方法描述时throws关键字后面列举的异常\n\n###### Exceptions属性表结构\n\n|类型  |名称                   |数量                   |\n|------|----------------------:|----------------------:|\n|u2    |attribute_name_index   |1                      |\n|u4    |attribute_length       |1                      |\n|u2    |number_of_exceptions   |1                      |\n|u2    |exception_index_table  |number_of_exceptions   |\n\n```\n   number_of_exceptions 表示方法可能抛出number_of_exceptions种受检查异常, 每一种受检查异常都是要一个\n   exception_index_table表示. exception_index_table指向一个常量池CONSTANT_Class_info类型的常量索引\n```\n#### LineNumberTable属性\n\n\n用于描述java源码行号与字节码之间的对应关系. 它并不是运行时必须的属性. 但默认的会生成到Class文件中,\n可以使用javac中-g:none或者-g:lines选项来取消它. 取消的后果是在抛出异常时,堆栈中将不会显示错的行号,\n并且在断点时,无法按照源码设置断点.\n\n\n#### LocalVariableTable 属性\n\n\n 用于描述栈帧中局部变量表中的变量与java源码中定义的变量之间的关系. 它并不是运行时必须的属性.默认也不会\n 生成到Class文件中, 可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息. 如果没有生成这项信息,\n 最大的影响是当其他人引用这个方法时,所有的参数名都将丢失,IDE可能使用诸如arg0, arg1之类的占位符来代替原有的参数名\n\n###### LocalVarialTable属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |local_variable_table_length  |1                             |\n|local_variable_info  |local_variable_table         |local_variable_table_length   |\n\nlocal_variable_info项目结构\n\n|类型  |名称              |数量|\n|------|-----------------:|---:|\n|u2    |start_pc          |1   |\n|u2    |length            |1   |\n|u2    |name_index        |1   |\n|u2    |descriptor_index  |1   |\n|u2    |index             |1   |\n\n\n1. local_variable_info代表了一个栈帧与源码中的局部变量的联系.\n2. start_pc和length属性分别代表了这个局部变量的生命周期开始的字节码偏移量及其作用范围覆盖的长度,俩者结合起来就是这个局部变量在字节码之中的作用域范围.\n3. name_index和descriptor指向的是常量池中CONSTANT_Utf8_info型常量的索引. 分别代表了局部变量名称及其描述符\n4. index是这个局部变量在栈帧局部变量表中Solt的位置.\n5. 在JDK1.5引入泛型之后,引入了一个LocalVarialTypeTable,这个新增的属性结构和LocalVarialTable非常相似,它仅仅是把记录的字段的描述符descriptor_index换成了字段的特征签名,对于非泛型类型来说,描述符和特征签名能描述的信息基本是一致的. 但是引入泛型之后,由于描述符中泛型化的参数被擦除掉了,描述符就不能准确地描述泛型信息了,因此引入了LocalVarialTypeTable\n\n\n#### SourceFile 属性\n\n\n该属性用来记录生成这个Class文件的源码文件名称,该属性也是可选的,可以使用javac中-g:none或者-g:vars选项来取消或者生成这项信息.\n\n###### SourceFile属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |sourcefile_index             |1                             |\n\n#### ConstantValue\n\n1. 该属性的作用是通知虚拟机自动为静态变量赋值. 只有被static修饰的变量才可以使用这项属性.\n2. 对于非static类型变量的赋值是在实例构造器<init>方法中进行的.\n3. 对于static类型的变量,有俩种赋值方式选择:\n   > A: 在类构造器<clinit>中进行\n   > B: 使用ConstantValue属性来赋值\n  \n前Sun Javac编译器的选择是:如果同时使用final和static来修饰一个变量, 并且这个变量的数据类型是基本类型或者String的话, 就生成ConstantValue属性来初始化, 否则在<clinit>中进行初始化.\n\n\n###### ConstantValue属性结构\n\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |constantvalue_index          |1                             |\n\n\nConstantValue属性是一个定长属性,它的attribute_length数据值必须为2. constantvalue_index代表了常量池中一个字面量的音乐,根据字段类型的不同,字面量可以是CONSTANT_Long_info, CONSTANT_Float_info,CONSTANT_Double_info,CONSTANT_integer_info,CONSTANT_String_info常量中的一种.\n\n\n#### InnerClass\n\n用于记录内部类和宿主类之间的关系.如果一个类中定义了内部类,那么编译器会为它以及包含的内部类生成InnerClass属性.\n\n###### InnerClass 属性结构\n|类型                 |名称                         |数量                          |\n|---------------------|----------------------------:|-----------------------------:|\n|u2                   |attribute_name_index         |1                             |\n|u4                   |attribute_length             |1                             |\n|u2                   |number_of_classes            |1                             |\n|inner_classes_info   |inner_classes                |number_of_classes             |\n\n###### inner_classes_info表结构\n\n|类型  |名称                        |数量|\n|------|---------------------------:|---:|\n|u2    |inner_class_info_index      |1   |\n|u2    |outer_class_info_index      |1   |\n|u2    |inner_name_index            |1   |\n|u2    |inner_class_access_flags    |1   |\n\n\n1. inner_class_info_index和outer_class_info_index分别指向常量池中CONSTANT_Class_info型常量索引.\n   分别代表内部类和宿主类的符号引用\n2. inner_name_index指向常量池中CONSTANT_Utf8_info型常量索引. 代表这个内部类的名称.如果是匿名内部类则为0\n3. inner_class_access_flags是内部类的访问标志,\n\n###### inner_class_access_flags访问标志\n\n|标志名称        |标识符   |二进制表示      |含义                               |\n|----------------|--------:|---------------:|----------------------------------:|\n|ACC_PUBLIC      |0x0001   |1               |内部类是否是public                 |\n|ACC_PRIVATE     |0x0002   |10              |内部类是否是private                |\n|ACC_PROTECTED   |0x0004   |100             |内部类是否是protected              |\n|ACC_STATIC      |0x0008   |1000            |内部类是否是static                 |\n|ACC_FINAL       |0x0010   |10000           |内部类是否是final                  |\n|ACC_INTERFACE   |0x0020   |100000          |内部类是否是synchronized           |\n|ACC_ABSTRACT    |0x0400   |10000000000     |内部类是否是abstract               |\n|ACC_SYNTHETIC   |0x1000   |1000000000000   |内部类是否是由并非用户代码产生的   |\n|ACC_ANNOTATION  |0x2000   |100000000000    |内部类是否是一个注解               |\n|ACC_ENUM        |0x4000   |100000000000    |内部类是否是一个枚举               |\n\n#### Deprecated, Synthetic\n\n\n这俩个属性属于标志型的布尔属性,只有存在不存在的区别.Deprecated 表示某个类或者字段或者方法被作者不再推荐使用,在代码中通过@Deprecated标注Synthetic 代码该字段或者方法并不是由java源码直接产生的,而是由编译器自行添加的.\n\n在JDK1.5以后,标志一个类,字段,方法是编译器自动产生的,也可以设置他们的访问标志中的ACC_SYNTHETIC标志位,最典型的例子就是Bridge Method了. 所有由非用户产生的类,字段,方法都应当至少设置Synthetic属性或者ACC_SYNTHETIC标志位,唯一例外的就是<init>和<clinit>方法.\n\n\n","slug":"jvm7/class文件格式","published":1,"date":"2015-09-18T06:28:21.278Z","updated":"2015-09-18T06:11:06.132Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeam001f74uf34kwc13g"},{"title":"java虚拟机参数","_content":"# java虚拟机参数\n\n\n## 内存管理参数\n* `-XDisableExplicitGC`: 忽略来自System.gc()方法触发的垃圾收集\n* `-XExplicitGCInvokesConcurrent`:  当收到System.gc()方法提交的垃圾收集申请时,使用CMS收集器收集\n* `-XUseSerialGC`: 打开此开关后使用Serial + Serial Old的收集器组合进行内存回收.\n* `-XUseParNewGC`: 虚拟机运行在Client模式下的默认值,打开此开关后,使用ParNew+Seial Old的收集器组合进行垃圾收集\n* `-XUseConcMarkSweepGc`:  打开次开关后使用`: ParNew+CMS+Serial Old`: 收集器组合进行垃圾收集.如果CMS收集器出现`: Concurrent Mode Failure`: ,则`: Seial Old`: 收集器将作为后备收集器.\n* `-XUseParallelGC`: 虚拟机运行在Server模式下的默认值,打开此开关后,使用Parallel Scavenge + Serial Old的收集器组合进行内存回收\n* `-XUseParaelOldGC`: 打开此开关后,使用Parallel Scavenge + Parallel Old的收集器组合进行内存回收\n* `-XSurvivorRatio`:  新生代中Eden区和Survivor区的容量比值(默认为8)\n* `-XPretenureSizeThreshold`: 直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配\n* `-XMaxTenuringThreshold`: 晋升到老年代的对象年龄,每个对象在坚持过一次Minor GC之后,年龄就+1,当超过这个参数值时就进入老年代\n* `-XUseAdaptiveSizePolicy`: 动态调整java堆中各个区域的大小及进入老年代的年龄\n* `-XHandlePromotionFailure`: 是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况\n* `-XParallelGCThreads`: 设置并行GC时进行内存回收的线程数(少于或等于8个CPU时默认值为CPU数量值,多于8个CPU时比CPU数量值小)\n* `-XGCTimeRatio`: GC时间占总时间的比率.仅在使用Parallel Scavenge收集器时生效\n* `-XMaxGCPauseMillis`: 设置GC最大停顿时间.仅在使用Parallel Scavenge收集器时生效\n* `-XCMSInitiatingOccupancyFraction`: 设置CMS收集器在老年代空间被使用多少后触发垃圾收集\n* `-XUseCMSCompactAtFullCollection`: 设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理\n* `-XCMSFullGCBeforeCompaction`: 设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理\n* `-XScavengeBeforeFullGC`: 在Full GC发生之前触发一次Minor GC\n* `-XUseGCOverheadLimit`: 禁止GC过程无限制的执行,如果过于频繁,就直接发生OutOfMemory\n* `-XUseTLAB`: 优先在本地线程缓冲区中分配对象,避免分配内存时的锁定过程\n* `-XMaxHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲大于指定比率时自动收缩\n* `-XMinHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲小于指定比率时自动收缩\n* `-XMaxPermSize`: 永久代的最大值\n* `-Xms` : 初始堆大小\n* `-Xmx` : 最大堆大小\n* `-Xmn` : 设置年轻代大小. 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小.(Xms 必须大于  Xmn)\n\n## 即时编译参数\n* `CompileThreshold`: 触发即时编译的阈值\n* `OnStackReplacePercentage`: OSR比率,它是OSR即时编译阈值计算公司的一个参数,用于代替BackEdgeThreshold参数控制回边计数器的实际溢出阈值\n* `ReservedCodeCacheSize`: 即时编译器编译的代码缓存使得最大值\n\n## 类型加载参数\n* `UseSplitVerifier`: 使用依赖StackMapTable信息的类型检查代替数据流分析,以加快字节码校验速度\n* `FailOverToOldVerier`: 当类型校验失败时,是否允许回到老的类型推到校验方式进行校验,如果开启则允许\n* `RelaxAccessControlCheck`: 在校验阶段放松对类型访问性的限制\n\n## 多线程相关参数\n* `UseSpinning`: 开启自旋锁以免线程频繁的挂起和唤醒\n* `PreBlockSpin`: 使用自旋锁时默认的自旋次数\n* `UseThreadPriorities`: 使用本地线程优先级\n* `UseBiaseLocking`: 是否使用偏向锁,如果开启则使用\n* `UseFastAccessorMethods`: 当频繁反射执行某个方法时,生成字节码来加快反射的执行速度\n\n## 性能参数\n* `AggressiveOpts`: 使用激进的优化特征,这些特征一般是具备正面和负面双重影响的,需要根据具体应用特点分析才能判定是否对性能有好处\n* `UseLargePages`: 如果可能,使用大内存分页,这项特性需要操作系统的支持\n* `LargePageSizeInBytes`: 使用指定大小的内存分页,这项特性需要操作系统的支持\n* `StringCache`: 是否使用字符串缓存,开启则使用\n\n## 调试参数\n* `HeapDumpOnOutOfMemoryError`: 在发生内存溢出异常时是否生成堆转储快照,关闭则不生成\n* `OnOutOfMemoryError`: 当虚拟机抛出内存溢出异常时,执行指令的命令\n* `OnError`: 当虚拟机抛出ERROR异常时,执行指令的命令\n* `PrintClassHistogram`: 使用[ctrl]-[break]快捷键输出类统计状态,相当于jmap-histo的功能\n* `PrintConcurrentLocks`: 打印J.U.C中的状态\n* `PrintCommandLineFlags`: 打印启动虚拟机时输入的非稳定参数\n* `PrintGC`: 打印GC信息\n* `PrintCompilation`: 显示所有可设置的参数及它们的值(***从JDK 6 update 21开始才可以用)\n* `PrintGCDetails`: 打印GC的详细信息\n* `PrintGCTimesStamps`: 打印GC停顿耗时\n* `PrintTenuingDistribution`: 打印GC后新生代各个年龄对象的大小\n* `TraceClassLoading`: 打印类加载信息\n* `TraceClassUnloading`: 打印类卸载信息\n* `PrintInlining`: 打印方法内联信息\n* `PrintCFGToFile`: 将CFG图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `PrintIdealGraphFile`: 将Ideal图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `UnlockDiagnosticVMOptions`: 让虚拟机进入诊断模式,一些参数(如PrintAssembly)需要在诊断模式中才能使用\n* `PrintAssembly`: 打印即时编译后的二进制信息\n\n\n## 参数组合\n* 给远程服务器加debug\n```\n-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10020\n```\n\n## 其他参数\n\n#### Behavioral Options\n* `OptionAndDefaultValue` :  Description\n* `-XX:+UseVMInterruptibleIO` :  Thread interrupt before or with EINTR for I/O operations results in OS_INTRPT.\n* `-XX:+MaxFDLimit` :  Bump the number of file descriptors to max.\n* `-XX:-UseConcMarkSweepGC` :  Use concurrent mark-sweep collection for the old generation.\n* `-XX:-UseParallelOldGC` :  Use parallel garbage collection for the full collections. Enabling this option automatically sets -XX:+UseParallelGC.\n* `-XX:+UseAltSigs` :  Use alternate signals instead of SIGUSR1 and SIGUSR2 for VM internal signals. (Introduced in 1.3.1 update 9, 1.4.1. Relevant to Solaris only.)\n* `-XX:+FailOverToOldVerifier` :  Fail over to old verifier when the new type checker fails.\n* `-XX:-AllowUserSignalHandlers` :  Do not complain if the application installs signal handlers. (Relevant to Solaris and Linux only.)\n* `OptionAndDefaultValue` :  Description\n* `-XX:NewRatio=n` :  Ratio of old/new generation sizes. The default value is 2.\n* `-XX:ConcGCThreads=n` :  Number of threads concurrent garbage collectors will use. The default value varies with the platform on which the JVM is running.\n* `-XX:+UseG1GC` :  Use the Garbage First (G1) Collector\n* `-XX:InitiatingHeapOccupancyPercent=n` :  Percentage of the (entire) heap occupancy to start a concurrent GC cycle. It is used by GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap, not just one of the generations (e.g., G1). A value of 0 denotes 'do constant GC cycles'. The default value is 45.\n* `-XX:G1HeapRegionSize=n` :  With G1 the Java heap is subdivided into uniformly sized regions. This sets the size of the individual sub-divisions. The default value of this parameter is determined ergonomically based upon heap size. The minimum value is 1Mb and the maximum value is 32Mb.\n* `-XX:G1ReservePercent=n` :  Sets the amount of heap that is reserved as a false ceiling to reduce the possibility of promotion failure. The default value is 10.\n* `OptionAndDefaultValue` :  Description\n* `-XX:AllocatePrefetchStyle=1` :  Generated code style for prefetch instructions.\n* `-XX:+UseMPSS` :  Use Multiple Page Size Support w/4mb pages for the heap. Do not use with ISM as this replaces the need for ISM. (Introduced in 1.4.0 update 1, Relevant to Solaris 9 and newer.) [1.4.1 and earlier: false]\n* `-XX:NewSize=2m` :  Default size of new generation (in bytes) [5.0 and newer: 64 bit VMs are scaled 30% larger; x86: 1m; x86, 5.0 and older: 640k]\n* `-XX:AllocatePrefetchLines=1` :  Number of cache lines to load after the last object allocation using prefetch instructions generated in JIT compiled code. Default values are 1 if the last allocated object was an instance and 3 if it was an array.\n* `-XX:+OptimizeStringConcat` :  Optimize String concatenation operations where possible. (Introduced in Java 6 Update 20)\n* `-XX:-UseISM` :  Use Intimate Shared Memory. [Not accepted for non-Solaris platforms.] For details, see Intimate Shared Memory.\n* `-XX:NewRatio=2` :  Ratio of old/new generation sizes. [Sparc -client: 8; x86 -server: 8; x86 -client: 12.]-client: 4 (1.3) 8 (1.3.1+), x86: 12]\n* `-XX:MaxNewSize=size` :  Maximum size of new generation (in bytes). Since 1.4, MaxNewSize is computed as a function of NewRatio. [1.3.1 Sparc: 32m; 1.3.1 x86: 2.5m.]\n* `-XX:ThreadStackSize=512` :  Thread Stack Size (in Kbytes). (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.]\n* `-XX:+UseCompressedStrings` :  Use a byte[] for Strings which can be represented as pure ASCII. (Introduced in Java 6 Update 21 Performance Release)\n* `-XX:+UseBiasedLocking` :  Enable biased locking. For more details, see this tuning example. (Introduced in 5.0 update 6.) [5.0: false]\n* `OptionAndDefaultValue` :  Description\n* `-XX:LoopUnrollLimit=n` :  Unroll loop bodies with server compiler intermediate representation node count less than this value. The limit used by the server compiler is a function of this value, not the actual value. The default value varies with the platform on which the JVM is running.\n* `-XX:GCLogFileSize=8K` :  The size of the log file at which point the log will be rotated, must be >= 8K.\n* `-XX:HeapDumpPath=./java_pid<pid>.hprof` :  Path to directory or filename for heap dump. Manageable. (Introduced in 1.4.2 update 12, 5.0 update 7.)\n* `-XX:+PerfDataSaveToFile` :  Saves jvmstat binary data on exit.\n* `-Xloggc:<filename>` :  Log GC verbose output to specified file. The verbose output is controlled by the normal verbose GC flags.\n* `-XX:+AlwaysPreTouch` :  Pre-touch the Java heap during JVM initialization. Every page of the heap is thus demand-zeroed during initialization rather than incrementally during application execution.\n* `-XX:InlineSmallCode=n` :  Inline a previously compiled method only if its generated native code size is less than this. The default value varies with the platform on which the JVM is running.\n* `-XX:InitialTenuringThreshold=7` :  Sets the initial tenuring threshold for use in adaptive GC sizing in the parallel young collector. The tenuring threshold is the number of times an object survives a young collection before being promoted to the old, or tenured, generation.\n* `-XX:+UseCompressedOops` :  Enables the use of compressed pointers (object references represented as 32 bit offsets instead of 64-bit pointers) for optimized 64-bit performance with Java heap sizes less than 32gb.\n* `-XX:-PrintAdaptiveSizePolicy` :  Enables printing of information about adaptive generation sizing.\n* `-XX:AllocatePrefetchDistance=n` :  Sets the prefetch distance for object allocation. Memory about to be written with the value of new objects is prefetched into cache at this distance (in bytes) beyond the address of the last allocated object. Each Java thread has its own allocation point. The default value varies with the platform on which the JVM is running.\n* `-XX:MaxInlineSize=35` :  Maximum bytecode size of a method to be inlined.\n* `-XX:-UseGCLogFileRotation` :  Enabled GC log rotation, requires -Xloggc.\n* `-XX:-CITime` :  Prints time spent in JIT Compiler. (Introduced in 1.4.0.)\n* `-XX:-TraceClassResolution` :  Trace constant pool resolutions. (Introduced in 1.4.2.)\n* `-XX:FreqInlineSize=n` :  Maximum bytecode size of a frequently executed method to be inlined. The default value varies with the platform on which the JVM is running.\n* `-XX:-TraceLoaderConstraints` :  Trace recording of loader constraints. (Introduced in 6.)\n* `-XX:ErrorFile=./hs_err_pid<pid>.log` :  If an error occurs, save the error data to this file. (Introduced in 6.)\n* `-XX:NumberOfGClogFiles=1` :  Set the number of files to use when rotating logs, must be >= 1. The rotated log files will use the following naming scheme, <filename>.0, <filename>.1, ..., <filename>.n-1.\n* `-XX:-ExtendedDTraceProbes` :  Enable performance-impacting dtrace probes. (Introduced in 6. Relevant to Solaris only.)\n* `-XX:-PrintTenuringDistribution` :  Print tenuring age information.\n","source":"_posts/jvm7/JVM 参数.md","raw":"category: jvm7\ntitle: java虚拟机参数\n---\n# java虚拟机参数\n\n\n## 内存管理参数\n* `-XDisableExplicitGC`: 忽略来自System.gc()方法触发的垃圾收集\n* `-XExplicitGCInvokesConcurrent`:  当收到System.gc()方法提交的垃圾收集申请时,使用CMS收集器收集\n* `-XUseSerialGC`: 打开此开关后使用Serial + Serial Old的收集器组合进行内存回收.\n* `-XUseParNewGC`: 虚拟机运行在Client模式下的默认值,打开此开关后,使用ParNew+Seial Old的收集器组合进行垃圾收集\n* `-XUseConcMarkSweepGc`:  打开次开关后使用`: ParNew+CMS+Serial Old`: 收集器组合进行垃圾收集.如果CMS收集器出现`: Concurrent Mode Failure`: ,则`: Seial Old`: 收集器将作为后备收集器.\n* `-XUseParallelGC`: 虚拟机运行在Server模式下的默认值,打开此开关后,使用Parallel Scavenge + Serial Old的收集器组合进行内存回收\n* `-XUseParaelOldGC`: 打开此开关后,使用Parallel Scavenge + Parallel Old的收集器组合进行内存回收\n* `-XSurvivorRatio`:  新生代中Eden区和Survivor区的容量比值(默认为8)\n* `-XPretenureSizeThreshold`: 直接晋升到老年代的对象大小,设置这个参数后,大于这个参数的对象将直接在老年代分配\n* `-XMaxTenuringThreshold`: 晋升到老年代的对象年龄,每个对象在坚持过一次Minor GC之后,年龄就+1,当超过这个参数值时就进入老年代\n* `-XUseAdaptiveSizePolicy`: 动态调整java堆中各个区域的大小及进入老年代的年龄\n* `-XHandlePromotionFailure`: 是否允许分配担保失败,即老年代的剩余空间不足以应付新生代的整个Eden和Survivor区的所有对象都存活的极端情况\n* `-XParallelGCThreads`: 设置并行GC时进行内存回收的线程数(少于或等于8个CPU时默认值为CPU数量值,多于8个CPU时比CPU数量值小)\n* `-XGCTimeRatio`: GC时间占总时间的比率.仅在使用Parallel Scavenge收集器时生效\n* `-XMaxGCPauseMillis`: 设置GC最大停顿时间.仅在使用Parallel Scavenge收集器时生效\n* `-XCMSInitiatingOccupancyFraction`: 设置CMS收集器在老年代空间被使用多少后触发垃圾收集\n* `-XUseCMSCompactAtFullCollection`: 设置CMS收集器在完成垃圾收集后是否要进行一次内存碎片整理\n* `-XCMSFullGCBeforeCompaction`: 设置CMS收集器在进行若干次垃圾收集后再启动一次内存碎片整理\n* `-XScavengeBeforeFullGC`: 在Full GC发生之前触发一次Minor GC\n* `-XUseGCOverheadLimit`: 禁止GC过程无限制的执行,如果过于频繁,就直接发生OutOfMemory\n* `-XUseTLAB`: 优先在本地线程缓冲区中分配对象,避免分配内存时的锁定过程\n* `-XMaxHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲大于指定比率时自动收缩\n* `-XMinHeapFreeRatio`: 当Xmx值比Xms值大时,堆可以动态收缩和扩展,这个参数控制当堆空闲小于指定比率时自动收缩\n* `-XMaxPermSize`: 永久代的最大值\n* `-Xms` : 初始堆大小\n* `-Xmx` : 最大堆大小\n* `-Xmn` : 设置年轻代大小. 整个JVM内存大小=年轻代大小 + 年老代大小 + 持久代大小.(Xms 必须大于  Xmn)\n\n## 即时编译参数\n* `CompileThreshold`: 触发即时编译的阈值\n* `OnStackReplacePercentage`: OSR比率,它是OSR即时编译阈值计算公司的一个参数,用于代替BackEdgeThreshold参数控制回边计数器的实际溢出阈值\n* `ReservedCodeCacheSize`: 即时编译器编译的代码缓存使得最大值\n\n## 类型加载参数\n* `UseSplitVerifier`: 使用依赖StackMapTable信息的类型检查代替数据流分析,以加快字节码校验速度\n* `FailOverToOldVerier`: 当类型校验失败时,是否允许回到老的类型推到校验方式进行校验,如果开启则允许\n* `RelaxAccessControlCheck`: 在校验阶段放松对类型访问性的限制\n\n## 多线程相关参数\n* `UseSpinning`: 开启自旋锁以免线程频繁的挂起和唤醒\n* `PreBlockSpin`: 使用自旋锁时默认的自旋次数\n* `UseThreadPriorities`: 使用本地线程优先级\n* `UseBiaseLocking`: 是否使用偏向锁,如果开启则使用\n* `UseFastAccessorMethods`: 当频繁反射执行某个方法时,生成字节码来加快反射的执行速度\n\n## 性能参数\n* `AggressiveOpts`: 使用激进的优化特征,这些特征一般是具备正面和负面双重影响的,需要根据具体应用特点分析才能判定是否对性能有好处\n* `UseLargePages`: 如果可能,使用大内存分页,这项特性需要操作系统的支持\n* `LargePageSizeInBytes`: 使用指定大小的内存分页,这项特性需要操作系统的支持\n* `StringCache`: 是否使用字符串缓存,开启则使用\n\n## 调试参数\n* `HeapDumpOnOutOfMemoryError`: 在发生内存溢出异常时是否生成堆转储快照,关闭则不生成\n* `OnOutOfMemoryError`: 当虚拟机抛出内存溢出异常时,执行指令的命令\n* `OnError`: 当虚拟机抛出ERROR异常时,执行指令的命令\n* `PrintClassHistogram`: 使用[ctrl]-[break]快捷键输出类统计状态,相当于jmap-histo的功能\n* `PrintConcurrentLocks`: 打印J.U.C中的状态\n* `PrintCommandLineFlags`: 打印启动虚拟机时输入的非稳定参数\n* `PrintGC`: 打印GC信息\n* `PrintCompilation`: 显示所有可设置的参数及它们的值(***从JDK 6 update 21开始才可以用)\n* `PrintGCDetails`: 打印GC的详细信息\n* `PrintGCTimesStamps`: 打印GC停顿耗时\n* `PrintTenuingDistribution`: 打印GC后新生代各个年龄对象的大小\n* `TraceClassLoading`: 打印类加载信息\n* `TraceClassUnloading`: 打印类卸载信息\n* `PrintInlining`: 打印方法内联信息\n* `PrintCFGToFile`: 将CFG图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `PrintIdealGraphFile`: 将Ideal图信息输出到文件,只有DEBUG版虚拟机才支持此参数\n* `UnlockDiagnosticVMOptions`: 让虚拟机进入诊断模式,一些参数(如PrintAssembly)需要在诊断模式中才能使用\n* `PrintAssembly`: 打印即时编译后的二进制信息\n\n\n## 参数组合\n* 给远程服务器加debug\n```\n-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=10020\n```\n\n## 其他参数\n\n#### Behavioral Options\n* `OptionAndDefaultValue` :  Description\n* `-XX:+UseVMInterruptibleIO` :  Thread interrupt before or with EINTR for I/O operations results in OS_INTRPT.\n* `-XX:+MaxFDLimit` :  Bump the number of file descriptors to max.\n* `-XX:-UseConcMarkSweepGC` :  Use concurrent mark-sweep collection for the old generation.\n* `-XX:-UseParallelOldGC` :  Use parallel garbage collection for the full collections. Enabling this option automatically sets -XX:+UseParallelGC.\n* `-XX:+UseAltSigs` :  Use alternate signals instead of SIGUSR1 and SIGUSR2 for VM internal signals. (Introduced in 1.3.1 update 9, 1.4.1. Relevant to Solaris only.)\n* `-XX:+FailOverToOldVerifier` :  Fail over to old verifier when the new type checker fails.\n* `-XX:-AllowUserSignalHandlers` :  Do not complain if the application installs signal handlers. (Relevant to Solaris and Linux only.)\n* `OptionAndDefaultValue` :  Description\n* `-XX:NewRatio=n` :  Ratio of old/new generation sizes. The default value is 2.\n* `-XX:ConcGCThreads=n` :  Number of threads concurrent garbage collectors will use. The default value varies with the platform on which the JVM is running.\n* `-XX:+UseG1GC` :  Use the Garbage First (G1) Collector\n* `-XX:InitiatingHeapOccupancyPercent=n` :  Percentage of the (entire) heap occupancy to start a concurrent GC cycle. It is used by GCs that trigger a concurrent GC cycle based on the occupancy of the entire heap, not just one of the generations (e.g., G1). A value of 0 denotes 'do constant GC cycles'. The default value is 45.\n* `-XX:G1HeapRegionSize=n` :  With G1 the Java heap is subdivided into uniformly sized regions. This sets the size of the individual sub-divisions. The default value of this parameter is determined ergonomically based upon heap size. The minimum value is 1Mb and the maximum value is 32Mb.\n* `-XX:G1ReservePercent=n` :  Sets the amount of heap that is reserved as a false ceiling to reduce the possibility of promotion failure. The default value is 10.\n* `OptionAndDefaultValue` :  Description\n* `-XX:AllocatePrefetchStyle=1` :  Generated code style for prefetch instructions.\n* `-XX:+UseMPSS` :  Use Multiple Page Size Support w/4mb pages for the heap. Do not use with ISM as this replaces the need for ISM. (Introduced in 1.4.0 update 1, Relevant to Solaris 9 and newer.) [1.4.1 and earlier: false]\n* `-XX:NewSize=2m` :  Default size of new generation (in bytes) [5.0 and newer: 64 bit VMs are scaled 30% larger; x86: 1m; x86, 5.0 and older: 640k]\n* `-XX:AllocatePrefetchLines=1` :  Number of cache lines to load after the last object allocation using prefetch instructions generated in JIT compiled code. Default values are 1 if the last allocated object was an instance and 3 if it was an array.\n* `-XX:+OptimizeStringConcat` :  Optimize String concatenation operations where possible. (Introduced in Java 6 Update 20)\n* `-XX:-UseISM` :  Use Intimate Shared Memory. [Not accepted for non-Solaris platforms.] For details, see Intimate Shared Memory.\n* `-XX:NewRatio=2` :  Ratio of old/new generation sizes. [Sparc -client: 8; x86 -server: 8; x86 -client: 12.]-client: 4 (1.3) 8 (1.3.1+), x86: 12]\n* `-XX:MaxNewSize=size` :  Maximum size of new generation (in bytes). Since 1.4, MaxNewSize is computed as a function of NewRatio. [1.3.1 Sparc: 32m; 1.3.1 x86: 2.5m.]\n* `-XX:ThreadStackSize=512` :  Thread Stack Size (in Kbytes). (0 means use default stack size) [Sparc: 512; Solaris x86: 320 (was 256 prior in 5.0 and earlier); Sparc 64 bit: 1024; Linux amd64: 1024 (was 0 in 5.0 and earlier); all others 0.]\n* `-XX:+UseCompressedStrings` :  Use a byte[] for Strings which can be represented as pure ASCII. (Introduced in Java 6 Update 21 Performance Release)\n* `-XX:+UseBiasedLocking` :  Enable biased locking. For more details, see this tuning example. (Introduced in 5.0 update 6.) [5.0: false]\n* `OptionAndDefaultValue` :  Description\n* `-XX:LoopUnrollLimit=n` :  Unroll loop bodies with server compiler intermediate representation node count less than this value. The limit used by the server compiler is a function of this value, not the actual value. The default value varies with the platform on which the JVM is running.\n* `-XX:GCLogFileSize=8K` :  The size of the log file at which point the log will be rotated, must be >= 8K.\n* `-XX:HeapDumpPath=./java_pid<pid>.hprof` :  Path to directory or filename for heap dump. Manageable. (Introduced in 1.4.2 update 12, 5.0 update 7.)\n* `-XX:+PerfDataSaveToFile` :  Saves jvmstat binary data on exit.\n* `-Xloggc:<filename>` :  Log GC verbose output to specified file. The verbose output is controlled by the normal verbose GC flags.\n* `-XX:+AlwaysPreTouch` :  Pre-touch the Java heap during JVM initialization. Every page of the heap is thus demand-zeroed during initialization rather than incrementally during application execution.\n* `-XX:InlineSmallCode=n` :  Inline a previously compiled method only if its generated native code size is less than this. The default value varies with the platform on which the JVM is running.\n* `-XX:InitialTenuringThreshold=7` :  Sets the initial tenuring threshold for use in adaptive GC sizing in the parallel young collector. The tenuring threshold is the number of times an object survives a young collection before being promoted to the old, or tenured, generation.\n* `-XX:+UseCompressedOops` :  Enables the use of compressed pointers (object references represented as 32 bit offsets instead of 64-bit pointers) for optimized 64-bit performance with Java heap sizes less than 32gb.\n* `-XX:-PrintAdaptiveSizePolicy` :  Enables printing of information about adaptive generation sizing.\n* `-XX:AllocatePrefetchDistance=n` :  Sets the prefetch distance for object allocation. Memory about to be written with the value of new objects is prefetched into cache at this distance (in bytes) beyond the address of the last allocated object. Each Java thread has its own allocation point. The default value varies with the platform on which the JVM is running.\n* `-XX:MaxInlineSize=35` :  Maximum bytecode size of a method to be inlined.\n* `-XX:-UseGCLogFileRotation` :  Enabled GC log rotation, requires -Xloggc.\n* `-XX:-CITime` :  Prints time spent in JIT Compiler. (Introduced in 1.4.0.)\n* `-XX:-TraceClassResolution` :  Trace constant pool resolutions. (Introduced in 1.4.2.)\n* `-XX:FreqInlineSize=n` :  Maximum bytecode size of a frequently executed method to be inlined. The default value varies with the platform on which the JVM is running.\n* `-XX:-TraceLoaderConstraints` :  Trace recording of loader constraints. (Introduced in 6.)\n* `-XX:ErrorFile=./hs_err_pid<pid>.log` :  If an error occurs, save the error data to this file. (Introduced in 6.)\n* `-XX:NumberOfGClogFiles=1` :  Set the number of files to use when rotating logs, must be >= 1. The rotated log files will use the following naming scheme, <filename>.0, <filename>.1, ..., <filename>.n-1.\n* `-XX:-ExtendedDTraceProbes` :  Enable performance-impacting dtrace probes. (Introduced in 6. Relevant to Solaris only.)\n* `-XX:-PrintTenuringDistribution` :  Print tenuring age information.\n","slug":"jvm7/JVM 参数","published":1,"date":"2015-09-18T06:28:21.276Z","updated":"2015-09-18T06:11:55.214Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeap001h74ufktvs4a39"},{"title":"java集合","_content":"\n##### 单线程集合\n这一部分介绍的是不支持多线程的集合.这些集合都在java.util包里.其中一些在Java 1.0的时候就有了(现在已经弃用),其中大多数在Java 1.4中重新发布.枚举集合在Java 1.5中重新发布,\n并且从这个版本之后所有的集合都支持泛型.PriorityQueue也在Java 1.5中加入.非线程安全的集合架构的最后一个版本是ArrayDeque ,也在Java 1.6中重新发布了.\n\n\n### List\n\n* `LinkedList`：\n\t`Deque`实现：每一个节点都保存着上一个节点和下一个节点的指针.这就意味着数据的存取和更新具有线性复杂度(这也是一个最佳化的实现,每次操作都不会遍历数组一半以上,操作成本最高的元素就是数组中间的那个).如果想写出高效的LinkedList代码可以使用 ListIterators .如果你想用一个Queue/Deque实现的话(你只需读取第一个和最后一个元素就行了)——考虑用ArrayDeque代替.\n\n* `Vector`：\n\n\t一个带有线程同步方法的ArrayList版本.现在直接用ArrayList代替了.\n\n* `ArrayList`：\n\t最有用的List集合实现.由一个整形数字或数组存储了集合的大小(数组中第一个没有使用的元素).像所有的List集合一样,ArrayList可以在必要的时候扩展它的大小.ArrayList访问元素的时间开销固定.在尾部添加元素成本低(为常数复杂度),而在头部添加元素成本很高(线性复杂度).\n\t这是由ArrayList的实现原理——所有的元素的从角标为0开始一个接着一个排列造成的.也就是说,从要插入的元素位置往后,每个元素都要向后移动一个位置.CPU缓存友好的集合是基于数组的.(其实也不是很友好,因为有时数组会包含对象,这样存储的只是指向实际对象的指针).\n\n\n### Maps\n* `HashMap`：\n\t最常用的Map实现.只是将一个键和值相对应,并没有其他的功能.对于复杂的hashCode method,get/put方法有固定的复杂度.就是一张hash表,键和值都没有排序.Hashtable 的后继者HashMap 是作为JDK1.2中的集合框架的一部分出现的,它通过提供一个不同步的基类和一个同步的包装器Collections.synchronizedMap ,解决了线程安全性问题.\n\n* `EnumMap`：\n\n\t枚举作为键值的Map.因为键的数量相对固定,所以在内部用一个数组储存对应值.通常来说,效率要高于HashMap.\n\n* `HashTable`：\n\n\t旧HashMap的同步版本,新的代码中也使用了HashMap.是同步的(而HashMap是不同步的).所以如果在线程安全的环境下应该多使用HashMap,而不是Hashtable,因为Hashtable对同步有额外的开销.提供了一种易于使用的、线程安全的、关联的map功能.然而,线程安全性付出代价是――Hashtable 的所有方法都是同步的.\n\n* `IdentityHashMap`：\n\n\t这是一个特殊的Map版本,它违背了一般Map的规则`：它使用 “==” 来比较引用而不是调用Object.equals来判断相等.这个特性使得此集合在遍历图表的算法中非常实用——可以方便地在IdentityHashMap中存储处理过的节点以及相关的数据.\n\n* `LinkedHashMap `：\n\n\t保存了插入时的顺序.HashMap和LinkedList的结合,所有元素的插入顺序存储在LinkedList中.这就是为什么迭代LinkedHashMap的条目(entry)、键和值的时候总是遵循插入的顺序.在JDK中,这是每元素消耗内存最大的集合.\n\n* `TreeMap`：\n\n\t以红-黑树结构为基础,键值按顺序排列.一种基于已排序且带导向信息Map的红黑树.每次插入都会按照自然顺序或者给定的比较器排序.\n这个Map需要实现equals方法和Comparable/Comparator.compareTo需要前后一致.这个类实现了一个NavigableMap接口`：可以带有与键数量不同的入口,可以得到键的上一个或者下一个入口,可以得到另一Map某一范围的键(大致和SQL的BETWEEN运算符相同),以及其他的一些方法.\n\n* `WeakHashMap`：\n\n\t这种Map通常用在数据缓存中.它将键存储在WeakReference中,就是说,如果没有强引用指向键对象的话,这些键就可以被垃圾回收线程回收.值被保存在强引用中.因此,你要确保没有引用从值指向键或者将值也保存在弱引用中m.put(key, new WeakReference(value)).\n\n\n### Sets\n* `HashSet`：\n\n\t一个基于HashMap的Set实现.其中,所有的值为“假值”(同一个Object对象具备和HashMap同样的性能.基于这个特性,这个数据结构会消耗更多不必要的内存.\n\n* `EnumSet`：\n\n\t值为枚举类型的Set.Java的每一个enum都映射成一个不同的int.这就允许使用BitSet——一个类似的集合结构,其中每一比特都映射成不同的enum. EnumSet有两种实现,RegularEnumSet——由一个单独的long存储(能够存储64个枚举值,99.9%的情况下是够用的),JumboEnumSet——由long[]存储.\n\n* `BitSet`：\n\n\t一个比特Set.需要时常考虑用BitSet处理一组密集的整数Set(比如从一个预先知道的数字开始的id集合).这个类用 long[]来存储bit.\n\n* `LinkedHashMap`：\n\n\t与HashSet一样,这个类基于LinkedHashMap实现.这是唯一一个保持了插入顺序的Set.\n\n* `TreeSet`：\n\n\t与HashSet类似.这个类是基于一个TreeMap实例的.这是在单线程部分唯一一个排序的Set.\n","source":"_posts/java集合.md","raw":"title: java集合\n---\n\n##### 单线程集合\n这一部分介绍的是不支持多线程的集合.这些集合都在java.util包里.其中一些在Java 1.0的时候就有了(现在已经弃用),其中大多数在Java 1.4中重新发布.枚举集合在Java 1.5中重新发布,\n并且从这个版本之后所有的集合都支持泛型.PriorityQueue也在Java 1.5中加入.非线程安全的集合架构的最后一个版本是ArrayDeque ,也在Java 1.6中重新发布了.\n\n\n### List\n\n* `LinkedList`：\n\t`Deque`实现：每一个节点都保存着上一个节点和下一个节点的指针.这就意味着数据的存取和更新具有线性复杂度(这也是一个最佳化的实现,每次操作都不会遍历数组一半以上,操作成本最高的元素就是数组中间的那个).如果想写出高效的LinkedList代码可以使用 ListIterators .如果你想用一个Queue/Deque实现的话(你只需读取第一个和最后一个元素就行了)——考虑用ArrayDeque代替.\n\n* `Vector`：\n\n\t一个带有线程同步方法的ArrayList版本.现在直接用ArrayList代替了.\n\n* `ArrayList`：\n\t最有用的List集合实现.由一个整形数字或数组存储了集合的大小(数组中第一个没有使用的元素).像所有的List集合一样,ArrayList可以在必要的时候扩展它的大小.ArrayList访问元素的时间开销固定.在尾部添加元素成本低(为常数复杂度),而在头部添加元素成本很高(线性复杂度).\n\t这是由ArrayList的实现原理——所有的元素的从角标为0开始一个接着一个排列造成的.也就是说,从要插入的元素位置往后,每个元素都要向后移动一个位置.CPU缓存友好的集合是基于数组的.(其实也不是很友好,因为有时数组会包含对象,这样存储的只是指向实际对象的指针).\n\n\n### Maps\n* `HashMap`：\n\t最常用的Map实现.只是将一个键和值相对应,并没有其他的功能.对于复杂的hashCode method,get/put方法有固定的复杂度.就是一张hash表,键和值都没有排序.Hashtable 的后继者HashMap 是作为JDK1.2中的集合框架的一部分出现的,它通过提供一个不同步的基类和一个同步的包装器Collections.synchronizedMap ,解决了线程安全性问题.\n\n* `EnumMap`：\n\n\t枚举作为键值的Map.因为键的数量相对固定,所以在内部用一个数组储存对应值.通常来说,效率要高于HashMap.\n\n* `HashTable`：\n\n\t旧HashMap的同步版本,新的代码中也使用了HashMap.是同步的(而HashMap是不同步的).所以如果在线程安全的环境下应该多使用HashMap,而不是Hashtable,因为Hashtable对同步有额外的开销.提供了一种易于使用的、线程安全的、关联的map功能.然而,线程安全性付出代价是――Hashtable 的所有方法都是同步的.\n\n* `IdentityHashMap`：\n\n\t这是一个特殊的Map版本,它违背了一般Map的规则`：它使用 “==” 来比较引用而不是调用Object.equals来判断相等.这个特性使得此集合在遍历图表的算法中非常实用——可以方便地在IdentityHashMap中存储处理过的节点以及相关的数据.\n\n* `LinkedHashMap `：\n\n\t保存了插入时的顺序.HashMap和LinkedList的结合,所有元素的插入顺序存储在LinkedList中.这就是为什么迭代LinkedHashMap的条目(entry)、键和值的时候总是遵循插入的顺序.在JDK中,这是每元素消耗内存最大的集合.\n\n* `TreeMap`：\n\n\t以红-黑树结构为基础,键值按顺序排列.一种基于已排序且带导向信息Map的红黑树.每次插入都会按照自然顺序或者给定的比较器排序.\n这个Map需要实现equals方法和Comparable/Comparator.compareTo需要前后一致.这个类实现了一个NavigableMap接口`：可以带有与键数量不同的入口,可以得到键的上一个或者下一个入口,可以得到另一Map某一范围的键(大致和SQL的BETWEEN运算符相同),以及其他的一些方法.\n\n* `WeakHashMap`：\n\n\t这种Map通常用在数据缓存中.它将键存储在WeakReference中,就是说,如果没有强引用指向键对象的话,这些键就可以被垃圾回收线程回收.值被保存在强引用中.因此,你要确保没有引用从值指向键或者将值也保存在弱引用中m.put(key, new WeakReference(value)).\n\n\n### Sets\n* `HashSet`：\n\n\t一个基于HashMap的Set实现.其中,所有的值为“假值”(同一个Object对象具备和HashMap同样的性能.基于这个特性,这个数据结构会消耗更多不必要的内存.\n\n* `EnumSet`：\n\n\t值为枚举类型的Set.Java的每一个enum都映射成一个不同的int.这就允许使用BitSet——一个类似的集合结构,其中每一比特都映射成不同的enum. EnumSet有两种实现,RegularEnumSet——由一个单独的long存储(能够存储64个枚举值,99.9%的情况下是够用的),JumboEnumSet——由long[]存储.\n\n* `BitSet`：\n\n\t一个比特Set.需要时常考虑用BitSet处理一组密集的整数Set(比如从一个预先知道的数字开始的id集合).这个类用 long[]来存储bit.\n\n* `LinkedHashMap`：\n\n\t与HashSet一样,这个类基于LinkedHashMap实现.这是唯一一个保持了插入顺序的Set.\n\n* `TreeSet`：\n\n\t与HashSet类似.这个类是基于一个TreeMap实例的.这是在单线程部分唯一一个排序的Set.\n","slug":"java集合","published":1,"date":"2015-09-16T00:49:50.093Z","updated":"2015-06-24T05:50:58.352Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeat001j74ufjh3tdqrl"},{"title":"JAVA钩子程序","_content":"# java hook\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```\nnohup java HookTest &\n```\n#### 关闭程序\n```\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\t\n\tpublic static void exec() {\n\t\texec();\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\t\t\n\t\tSystem.out.println(\"Main over\");\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试\n```java\n\n```","source":"_posts/java_hook.md","raw":"title: JAVA钩子程序\n---\n# java hook\n\n### 触发的时机有：\n1. 程序正常退出或者调用System.exit方法，如果是多线程环境，要求是最后一个非守护线程终止，\n2. JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。\n\n### 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点：\n1. 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。\n2. 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。\n3. 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响，我最近发现的一个bug就是这种情况，场景是钩子要关闭文件句柄，但因为同时server还接收提交请求，结果文件又被打开，造成不想要的结果。\n4. 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。\n\n#### 使用信号触发JVM的钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\twhile(true){}\n\t}\n\n\tstatic class Hook extends Thread{\n\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 运行钩子程序\n```\nnohup java HookTest &\n```\n#### 关闭程序\n```\nkill HookTest_PID\n```\n我们可以在nohup程序中看到Hook execute!!!输出\n\n\n#### 测试JVM堆栈溢出后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\texec();\n\t}\n\t\n\tpublic static void exec() {\n\t\texec();\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试程序正常结束后也会调用钩子程序\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试调用exit后直接关闭JVM\n```java\npublic class HookTest {\n\n\tpublic static void main(String[] args) {\n\t\tRuntime.getRuntime().addShutdownHook(new Hook());\n\t\tSystem.exit(0);\n\t\t\n\t\tSystem.out.println(\"Main over\");\n\t}\n\t\n\tstatic class Hook extends Thread{\n\t\t\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tSystem.out.println(\"Hook execute!!!\");\n\t\t}\n\t}\n}\n```\n\n#### 测试\n```java\n\n```","slug":"java_hook","published":1,"date":"2015-07-07T11:45:28.285Z","updated":"2015-06-15T04:47:53.735Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeau001k74uf1m2tqec7"},{"title":"JAVA IO","_content":"# IO模型\n\n\n## IO概念\n\nLinux的内核将所有外部设备都可以看做一个文件来操作。那么我们对与外部设备的操作都可以看做对文件进行操作。我们对一个文件的读写，都通过调用内核提供的系统调用；内核给我们返回一个file descriptor（fd,文件描述符）。而对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符）。描述符就是一个数字，指向内核中一个结构体（文件路径，数据区，等一些属性）。那么我们的应用程序对文件的读写就通过对描述符的读写完成。\n\nlinux将内存分为内核区，用户区。linux内核给我们管理所有的硬件资源，应用程序通过调用系统调用和内核交互，达到使用硬件资源的目的。应用程序通过系统调用read发起一个读操作，这时候内核创建一个文件描述符，并通过驱动程序向硬件发送读指令，并将读的的数据放在这个描述符对应结构体的内核缓存区中，然后再把这个数据读到用户进程空间中，这样完成了一次读操作；但是大家都知道I/O设备相比cpu的速度是极慢的。linux提供的read系统调用，也是一个阻塞函数。这样我们的应用进程在发起read系统调用时，就必须阻塞，就进程被挂起而等待文件描述符的读就绪，那么什么是文件描述符读就绪，什么是写就绪？\n\n* 读就绪：就是这个文件描述符的接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的当前大小；\n* 写就绪：该描述符发送缓冲区的可用空间字节数大于等于描述符发送缓冲区低水位标记的当前大小。（如果是socket fd，说明上一个数据已经发送完成）。\n\n接收低水位标记和发送低水位标记：由应用程序指定，比如应用程序指定接收低水位为64个字节。那么接收缓冲区有64个字节，才算fd读就绪；\n综上所述，一个基本的IO，它会涉及到两个系统对象，一个是调用这个IO的进程对象，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：\n\n* 通过read系统调用想内核发起读请求。\n* 内核向硬件发送读指令，并等待读就绪。 \n* 内核把将要读取的数据复制到描述符所指向的内核缓存区中。\n* 将数据从内核缓存区拷贝到用户进程空间中。\n\n### 整个I/O流经历一下几个节点:\n\n1. File System – 文件系统会根据文件与Block的映射关系,通过`File System Manager`将文件划分为多个Block,请求发送给HBA.\n2. HBA  – HBA执行对这一系列的更小的工作单元进行操作,将这部分I/O转换为Fibre Channel协议,包装成不超过2KB的Frame传输到下一个连接节点FC Switch.\n3. FC Switch          – FC Switch会通过FC Fabric网络将这些Frame发送到存储系统的前端口（Front Adapter）.\n4. Storage FA         – 存储前端口会将这些FC 的Frame重新封装成和HBA初始发送I/O一致,然后FA会将数据传输到阵列缓存Storage Array Cache）\n5. Storage Array Cache – 阵列缓存处理I/O通常有两种情况:\n    * 直接返回数据已经写入的讯号给HBA,这种叫作回写,也是大多数存储阵列处理的方式.\n    * 数据写入缓存然后再刷新到物理磁盘,叫做写透.I/O存放在缓存中以后,交由后端控制器（Disk Adapter）继续处理,完成后再返回数据已经写入的讯号给HBA.\n6. Disk Adapter       – 上述两种方式,最后都会将I/O最后写入到物理磁盘中.这个过程由后端Disk Adapter控制,一个I/O会变成两个或者多个实际的I/O.\n\n##### 根据上述的I/O流向的来看,一个完整的I/O传输,经过的会消耗时间的节点可以概括为以下几个:\n\n1. CPU – RAM, 完成主机文件系统到HBA的操作.\n2. HBA – FA,完成在光纤网络中的传输过程.\n3. FA – Cache,存储前端卡将数据写入到缓存的时间.\n4. DA – Drive,存储后端卡将数据从缓存写入到物理磁盘的时间.\n\n## IO类型\n\n### 阻塞IO\n最流行的I/O模型是阻塞I/O模型，缺省情形下，所有文件操作都是阻塞的。我们以套接口为例来讲解此模型。在进程空间中调用recvfrom，其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回，期间一直在等待。我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的。\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n进程把一个套接口设置成非阻塞是在通知内核：当所请求的I/O操作不能满足要求时候，不把本进程投入睡眠，而是返回一个错误。也就是说当数据没有到达时并不等待，而是以一个错误返回。\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n\n通过上面，我们知道，所有的IO操作在默认情况下，都是属于阻塞IO。尽管上图中所示的反复请求的非阻塞IO的效率底下（需要反复在用户空间和进程空间切换和判断，把一个原本属于IO密集的操作变为IO密集和计算密集的操作），但是在后面IO复用中，需要把IO的操作设置为非阻塞的，此时程序将会阻塞在select和poll系统调用中。把一个IO设置为非阻塞IO有两种方式：在创建文件描述符时，指定该文件描述符的操作为非阻塞；在创建文件描述符以后，调用fcntl()函数设置相应的文件描述符为非阻塞。\n创建描述符时，利用open函数和socket函数的标志设置返回的fd/socket描述符为O_NONBLOCK。\n\n```c\nint sd=socket(int domain, int type|O_NONBLOCK, int protocol);  \nint fd=open(const char *pathname, int flags|O_NONBLOCK);  \n```\n创建描述符后，通过调用fcntl函数设置描述符的属性为O_NONBLOCK\n```c\n#include <unistd.h>  \n#include <fcntl.h>  \n  \nint fcntl(int fd, int cmd, ... /* arg */ );  \n  \n//例子  \nif (fcntl(fd, F_SETFL, fcntl(sockfd, F_GETFL, 0)|O_NONBLOCK) == -1) {  \n    return -1;  \n}  \n    return 0;  \n}  \n```\n\n### SIGIO\n首先开启套接口信号驱动I/O功能, 并通过系统调用sigaction安装一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据报准备好被读时，就为该进程生成一个SIGIO信号。随即可以在信号处理程序中调用recvfrom来读数据报，井通知主循环数据已准备好被处理中。也可以通知主循环，让它来读数据报。\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### select and poll\nlinux提供select/poll，进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select;这样select/poll可以帮我们侦测许多fd是否就绪。但是select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限。linux还提供了一个epoll系统调用，epoll是基于事件驱动方式，而不是顺序扫描,当有fd就绪时，立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n##### IO复用详解\n\n在IO编程过程中，当需要处理多个请求的时，可以使用多线程和IO复用的方式进行处理。上面的图介绍了整个IO复用的过程，它通过把多个IO的阻塞复用到一个select之类的阻塞上，从而使得系统在单线程的情况下同时支持处理多个请求。和多线程/进程比较，I/O多路复用的最大优势是系统开销小，系统不需要建立新的进程或者线程，也不必维护这些线程和进程。IO复用常见的应用场景：\n1. 客户程序需要同时处理交互式的输入和服务器之间的网络连接。\n2. 客户端需要对多个网络连接作出反应。\n3. 服务器需要同时处理多个处于监听状态和多个连接状态的套接字\n4. 服务器需要处理多种网络协议的套接字。\n\n### windows的IOCP\n告知内核启动某个操作，并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们。这种模型与信号驱动模型的主要区别是：信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；异步I/O模型：由内核通知我们I/O操作何时完成。\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝。可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上，数据无需流经应用程序。本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销，然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能。\n\n\n###### 数据传输：传统方法\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换。在内部，发出 `sys_read()`(或等效内容)以从文件中读取数据。直接内存存取(`direct memory access`，DMA)引擎执行了第一次拷贝，它从磁盘中读取文件内容，然后将它们存储到一个内核地址空间缓存区中。\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区，read() 调用返回。该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换)。现在数据被储存在用户地址空间缓冲区。\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换。数据被第三次拷贝，并被再次放置在内核地址空间缓冲区。但是这一次放置的缓冲区不同，该缓冲区与目标套接字相关联。\n4. `send()` 系统调用返回，结果导致了第四次的上下文切换。DMA 引擎将数据从内核缓冲区传到协议引擎，第四次拷贝独立地、异步地发生 。\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下。但是之所以引入中间内核缓冲区的目的是想提高性能。在读取方面使用中间内核缓冲区，可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时，充当 “预读高速缓存(readahead cache)” 的角色。这在所需数据量小于内核缓冲区大小时极大地提高了性能。在写入方面的中间缓冲区则可以让写入过程异步完成。\n\n不幸的是，如果所需数据量远大于内核缓冲区大小的话，这个方法本身可能成为一个性能瓶颈。数据在被最终传入到应用程序前，在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次。\n\n零拷贝通过消除这些冗余的数据拷贝而提高了性能。\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区。然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区。\n\n2. 数据的第三次复制发生在 DMA 引擎将数据从内核套接字缓冲区传到协议引擎时。\n\t改进的地方：我们将上下文切换的次数从四次减少到了两次，将数据复制的次数从四次减少到了三次(其中只有一次涉及到了 CPU)。但是这个代码尚未达到我们的零拷贝要求。如果底层网络接口卡支持收集操作 的话，那么我们就可以进一步减少内核的数据复制。在 Linux 内核 2.4 及后期版本中，套接字缓冲区描述符就做了相应调整，以满足该需求。这种方法不仅可以减少多个上下文切换，还可以消除需要涉及 CPU 的重复的数据拷贝。对于用户方面，用法还是一样的，但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区。\nB. 数据未被拷贝到套接字缓冲区。取而代之的是，只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区。DMA 引擎直接把数据从内核缓冲区传输到协议引擎，从而消除了剩下的最后一次 CPU 拷贝。\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n\n\n\n## JAVA IO\n### io#interface\n\n* [Closeable]()\n\tCloseable 是可以关闭的数据源或目标。调用 close 方法可释放对象保存的资源（如打开文件）。\n* [DataInput]()\n\tDataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据。同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具。\n\n\t对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）。如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException。尤其在输入流已关闭的情况下，将抛出 IOException。\n* [DataOutput]()\n\t\n\tDataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流。同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具。\n\t\n\t对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException。\n\t\n* [Externalizable]()\n\t\n\tExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成。如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段。\n\t\n* [FileFilter](TestFileFilter.java)\n\n\t检测文件是否存在。FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法，\n\t而FilenameFilter 是按照目录和文件名的方式来工作的。\n\n* [FilenameFilter]()\n\n* [Flushable]()\n\t实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中。写入流的所有I/O类都实现了Flushable接口。\n* [ObjectInput]()\n* [ObjectInputValidation]()\n\t序列化流验证机制. 一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题。但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息。Java序列化提供一套验证机制。序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n* [ObjectOutput]()\n* [ObjectStreamConstants]()\n\tJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值。Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分。现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中。 \n* [Serializable]()\n\n### io#class\n\n* [BufferedInputStream]()\n\n\tBufferedInputStream是一个带有缓冲区域的InputStream, 支持“mark()标记”和“reset()重置方法”。输入到byte[]数组里.\n* [BufferedOutputStream]()\n\t缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\n\n* [BufferedReader]()\n\n\tBufferedReader 从字符输入流中读取文本，缓冲各个字符。提供字符、数组和行的高效读取。\n\n* [BufferedWriter]()\n\n\t>1. 支持字符串输出\n\t2. 支持换行输出\n\t3. 支持文件追加输出\n\n* [ByteArrayInputStream]()\n\n\t从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。\n* [ByteArrayOutputStream]()\n\n\t输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何IOException。\n\n* [CharArrayReader]()\n\t与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n\n* [CharArrayWriter]()\n\t向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write \n* [Console]()\n\t专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n\t\n* [DataInputStream]()\n\t用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n* [DataOutputStream]()\n\t用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”。\n* [File]()\n```\n\t1. 删除文件\n\t2. 文件重命名\n\t3. 创建新的文件\n\t4. 创建新的文件\n\t5. 获取文件的最后修改时间\n\t6. 设置文件只读\n\t7. 设置文件可写\n\t8. 获取文件长度(总字节数)\n\t9. 获取文件路径\n\t10. 获取绝对文件路径\n\t11. 文件是否隐藏\n\t12. 获得剩余磁盘空间？\n\t13. 拷贝文件夹\n\t14. 遍历文件夹\n\t15. 检查文件夹是否为空？\n```\n* [FileDescriptor]()\n\t用来表示开放文件、开放套接字等。当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。\n\t\n\t类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件，打开的套接字或其他来源或字节的接收器。以下是关于FileDescriptor要点：\n\t1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它。\n\t2. 应用程序不应创建自己的文件描述符。\n\n* [FileInputStream]()\n\t一个字节一个字节的从文件里读取数据\n\t\n* [FileOutputStream]()\n\t一个字节一个字节的向文件里输出数据\n\n* [FilePermission]()\n\n* [FileReader]()\n\t一个字符一个字符地读取\n\n* [FileWriter]()\n\n\t一个字符一个字符地输出\n\n* [FilterInputStream]()\n\n\t用来“封装其它的输入流，并为它们提供额外的功能”。它的常用的子类有BufferedInputStream和DataInputStream。\n\n* [FilterOutputStream]()\n\n\t作用是用来“封装其它的输出流，并为它们提供额外的功能”。它主要包括BufferedOutputStream, \n\tDataOutputStream和PrintStream。\n\n* [FilterReader]()\n\n\t用于读取已过滤的字符流的抽象类。抽象类 FilterReader 自身提供了一些将所有请求传递给所包含的流的默认方法。\n\n* [FilterWriter]()\n\n\t用于写入已过滤的字符流的抽象类。抽象类 FilterWriter 自身提供了一些将所有请求传递给所包含的流的默认方法\n\n* [InputStream]()\n\n\n* [InputStreamReader]()\n\n\t是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。\n\t将“字节输入流”转换成“字符输入流”。它继承于Reader。\n\n* [LineNumberInputStream]()\n\n\t此类是一个输入流过滤器，它提供跟踪当前行号的附加功能。行是以回车符 ('\\r')、换行符 ('\\n')或回车符后面紧跟换行符结尾的字节序列。在所有这三种情况下，都以单个换行符形式返回行终止字符。行号以 0 开头，并在 read 返回换行符时递增 1。\n\n* [LineNumberReader]()\n\n\t跟踪行号的缓冲字符输入流。此类定义了方法 setLineNumber(int) 和 getLineNumber()，它们可分别用于设置和获取当前行号。默认情况下，行编号从 0 开始。该行号随数据读取在每个行结束符处递增，并且可以通过调用 \n\tsetLineNumber(int) 更改行号。但要注意的是，setLineNumber(int) 不会实际更改流中的当前位置；它只更改将由getLineNumber() 返回的值。可认为行在遇到以下符号之一时结束：换行符（'\\n'）、回车符（'\\r'）、回车后紧跟换行符。\n\n* [ObjectInputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectOutputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectStreamField]()\n\n\tSerializable 类中 Serializable 字段的描述。ObjectStreamField 的数组用于声明类的 Serializable 字段。\n\n* [OutputStream]()\n\n\n* [OutputStreamWriter]()\n\n\tOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n\n* [PipedInputStream]()\n\n\t管道输入流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedOutputStream]()\n\n\t管道输出流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedReader]()\n\n\tPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n* [PipedWriter]()\n\n\tPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n* [PrintStream]()\n\n\t打印输出流, 用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream 永远不会抛出 IOException；PrintStream 提供了自动flush 和 字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\n* [PrintWriter]()\n\n\t用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\n* [PushbackInputStream]()\n\n\t拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n* [PushbackReader]()\n\n\t允许将字符推回到流的字符流 reader。\n\n* [RandomAccessFile]()\n\n\t用来访问那些保存数据记录的文件的，你就可以用seek( )方法来访问记录，并进行读写了。这些记录的大小不必相同；但是其大小和位置必须是可知的。但是该类仅限于操作文件。\n\n* [SequenceInputStream]()\n\n\t从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。 SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，\n\t接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n* [SerializablePermission]()\n\n\n* [StreamTokenizer]()\n\n\t获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。\n\t该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n* [StringBufferInputStream]()\n\n\n* [StringReader]()\n\n\n* [StringWriter]()\n\n\n### nio\n\n* [Buffer](java/src/test/io/robertsing/cookios/nio/TestBuffer.java)\n\n\n* [ByteBuffer](java/src/test/io/robertsing/cookios/nio/TestByteBuffer.java)\n\n\n* [ByteOrder](java/src/test/io/robertsing/cookios/nio/TestByteOrder.java)\n\n\n* [CharBuffer](java/src/test/io/robertsing/cookios/nio/TestCharBuffer.java)\n\n\n* [DoubleBuffer](java/src/test/io/robertsing/cookios/nio/TestDoubleBuffer.java)\n\n\n* [FloatBuffer](java/src/test/io/robertsing/cookios/nio/TestFloatBuffer.java)\n\n\n* [IntBuffer](java/src/test/io/robertsing/cookios/nio/TestIntBuffer.java)\n\n\n* [LongBuffer](java/src/test/io/robertsing/cookios/nio/TestLongBuffer.java)\n\n\n* [MappedByteBuffer](java/src/test/io/robertsing/cookios/nio/TestMappedByteBuffer.java)\n\n\n* [ShortBuffer](java/src/test/io/robertsing/cookios/nio/TestShortBuffer.java)\n\n\n### nio#channels#Interfaces\n\n* [AsynchronousByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousByteChannel.java)\n\n\n* [AsynchronousChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannel.java)\n\n\n* [ByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestByteChannel.java)\n\n\n* [Channel](java/src/test/io/robertsing/cookios/nio/channels/TestChannel.java)\n\n\n* [CompletionHandler](java/src/test/io/robertsing/cookios/nio/channels/TestCompletionHandler.java)\n\n\n* [GatheringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestGatheringByteChannel.java)\n\n\n* [InterruptibleChannel](java/src/test/io/robertsing/cookios/nio/channels/TestInterruptibleChannel.java)\n\n\n* [MulticastChannel](java/src/test/io/robertsing/cookios/nio/channels/TestMulticastChannel.java)\n\n\n* [NetworkChannel](java/src/test/io/robertsing/cookios/nio/channels/TestNetworkChannel.java)\n\n\n* [ReadableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestReadableByteChannel.java)\n\n\n* [ScatteringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestScatteringByteChannel.java)\n\n\n* [SeekableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSeekableByteChannel.java)\n\n\n* [WritableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestWritableByteChannel.java)\n\n\n### nio#channels#Classes\n\n* [AsynchronousChannelGroup](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannelGroup.java)\n\n\n* [AsynchronousFileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousFileChannel.java)\n\n\n* [AsynchronousServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousServerSocketChannel.java)\n\n\n* [AsynchronousSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousSocketChannel.java)\n\n\n* [Channels](java/src/test/io/robertsing/cookios/nio/channels/TestChannels.java)\n\n\n* [DatagramChannel](java/src/test/io/robertsing/cookios/nio/channels/TestDatagramChannel.java)\n\n\n* [FileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.java)\n\n\n* [FileChannel.MapMode](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.MapMode.java)\n\n\n* [FileLock](java/src/test/io/robertsing/cookios/nio/channels/TestFileLock.java)\n\n\n* [MembershipKey](java/src/test/io/robertsing/cookios/nio/channels/TestMembershipKey.java)\n\n\n* [Pipe](java/src/test/io/robertsing/cookios/nio/channels/TestPipe.java)\n\n\n* [SelectableChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSelectableChannel.java)\n\n\n* [SelectionKey](java/src/test/io/robertsing/cookios/nio/channels/TestSelectionKey.java)\n\n\n* [Selector](java/src/test/io/robertsing/cookios/nio/channels/TestSelector.java)\n\n\n* [ServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestServerSocketChannel.java)\n\n\n* [SocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSocketChannel.java)\n\n\n### nio#file#Interfaces\n\n* [CopyOption](java/src/test/io/robertsing/cookios/nio/file/TestCopyOption.java)\n\n\n* [DirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestDirectoryStream.java)\n\n\t遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n\n* [FileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestFileVisitor.java)\n\n\t@SimpleFileVisitor\n\n* [OpenOption](java/src/test/io/robertsing/cookios/nio/file/TestOpenOption.java)\n\n\n* [Path](java/src/test/io/robertsing/cookios/nio/file/TestPath.java)\n\n\n* [PathMatcher](java/src/test/io/robertsing/cookios/nio/file/TestPathMatcher.java)\n\n\n* [SecureDirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestSecureDirectoryStream.java)\n\n\n* [Watchable](java/src/test/io/robertsing/cookios/nio/file/TestWatchable.java)\n\n\n* [WatchEvent](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.java)\n\n\n* [WatchEvent.Kind](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Kind.java)\n\n\n* [WatchEvent.Modifier](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Modifier.java)\n\n\n* [WatchKey](java/src/test/io/robertsing/cookios/nio/file/TestWatchKey.java)\n\n\n* [WatchService](java/src/test/io/robertsing/cookios/niofile//TestWatchService.java)\n\n\n### nio#file#Classes\n\n* [Files]()\n\n\t1. copy\n\t2. createDirectories\n\t3. createDirectory\n\t4. createFile\n\t5. createLink\n\t6. createSymbolicLink\n\t7. createTempDirectory\n\t8. createTempFile\n\t9. delete\n\t10. deleteIfExists\n\t11. exists\n\t12. getAttribute\n\t13. getFileAttributeView\n\t14. getFileStore\n\t15. getLastModifiedTime\n\t16. getOwner\n\t17. getPosixFilePermissions\n\t18. isDirectory\n\t19. isExecutable\n\t20. isHidden\n\t21. isReadable\n\t22. isRegularFile\n\t23. isSameFile\n\t24. isSymbolicLink\n\t25. isWritable\n\t26. move\n\t27. newBufferedReader\n\t28. newBufferedWriter\n\t29. newByteChannel\n\t30. newDirectoryStream\n\t31. newInputStream\n\t32. newOutputStream\n\t33. notExists\n\t34. probeContentType\n\t35. readAllBytes\n\t36. readAllLines\n\t37. readAttributes\n\t38. readSymbolicLink\n\t39. setAttribute\n\t40. setLastModifiedTime\n\t41. setOwner\n\t42. setPosixFilePermissions\n\t43. walkFileTree\n\t44. write\n\n\n* [FileStore]()\n\n\t代表了真正的存储设备，提供了设备的详尽信息\n\n* [FileSystem](java/src/test/io/robertsing/cookios/nio/file/TestFileSystem.java)\n\n\n* [FileSystems](java/src/test/io/robertsing/cookios/nio/file/TestFileSystems.java)\n\n\n* [LinkPermission](java/src/test/io/robertsing/cookios/nio/file/TestLinkPermission.java)\n\n\n* [Paths](java/src/test/io/robertsing/cookios/nio/file/TestPaths.java)\n\n\n* [SimpleFileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestSimpleFileVisitor.java)\n\n\t与DirectoryStream 不同的是，这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n\n* [StandardWatchEventKinds](java/src/test/io/robertsing/cookios/nio/file/TestStandardWatchEventKinds.java)\n\n\n### nio#charset\n\n* [Charset](java/src/test/io/robertsing/cookios/nio/charset/TestCharset.java)\n\n\n* [CharsetDecoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetDecoder.java)\n\n\n* [CharsetEncoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetEncoder.java)\n\n\n* [CoderResult](java/src/test/io/robertsing/cookios/nio/charset/TestCoderResult.java)\n\n\n* [CodingErrorAction](java/src/test/io/robertsing/cookios/nio/charset/TestCodingErrorAction.java)\n\n\n* [StandardCharsets](java/src/test/io/robertsing/cookios/nio/charset/TestStandardCharsets.java)\n\n\n\n\n","source":"_posts/io.md","raw":"title: JAVA IO\n---\n# IO模型\n\n\n## IO概念\n\nLinux的内核将所有外部设备都可以看做一个文件来操作。那么我们对与外部设备的操作都可以看做对文件进行操作。我们对一个文件的读写，都通过调用内核提供的系统调用；内核给我们返回一个file descriptor（fd,文件描述符）。而对一个socket的读写也会有相应的描述符，称为socketfd(socket描述符）。描述符就是一个数字，指向内核中一个结构体（文件路径，数据区，等一些属性）。那么我们的应用程序对文件的读写就通过对描述符的读写完成。\n\nlinux将内存分为内核区，用户区。linux内核给我们管理所有的硬件资源，应用程序通过调用系统调用和内核交互，达到使用硬件资源的目的。应用程序通过系统调用read发起一个读操作，这时候内核创建一个文件描述符，并通过驱动程序向硬件发送读指令，并将读的的数据放在这个描述符对应结构体的内核缓存区中，然后再把这个数据读到用户进程空间中，这样完成了一次读操作；但是大家都知道I/O设备相比cpu的速度是极慢的。linux提供的read系统调用，也是一个阻塞函数。这样我们的应用进程在发起read系统调用时，就必须阻塞，就进程被挂起而等待文件描述符的读就绪，那么什么是文件描述符读就绪，什么是写就绪？\n\n* 读就绪：就是这个文件描述符的接收缓冲区中的数据字节数大于等于套接字接收缓冲区低水位标记的当前大小；\n* 写就绪：该描述符发送缓冲区的可用空间字节数大于等于描述符发送缓冲区低水位标记的当前大小。（如果是socket fd，说明上一个数据已经发送完成）。\n\n接收低水位标记和发送低水位标记：由应用程序指定，比如应用程序指定接收低水位为64个字节。那么接收缓冲区有64个字节，才算fd读就绪；\n综上所述，一个基本的IO，它会涉及到两个系统对象，一个是调用这个IO的进程对象，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段：\n\n* 通过read系统调用想内核发起读请求。\n* 内核向硬件发送读指令，并等待读就绪。 \n* 内核把将要读取的数据复制到描述符所指向的内核缓存区中。\n* 将数据从内核缓存区拷贝到用户进程空间中。\n\n### 整个I/O流经历一下几个节点:\n\n1. File System – 文件系统会根据文件与Block的映射关系,通过`File System Manager`将文件划分为多个Block,请求发送给HBA.\n2. HBA  – HBA执行对这一系列的更小的工作单元进行操作,将这部分I/O转换为Fibre Channel协议,包装成不超过2KB的Frame传输到下一个连接节点FC Switch.\n3. FC Switch          – FC Switch会通过FC Fabric网络将这些Frame发送到存储系统的前端口（Front Adapter）.\n4. Storage FA         – 存储前端口会将这些FC 的Frame重新封装成和HBA初始发送I/O一致,然后FA会将数据传输到阵列缓存Storage Array Cache）\n5. Storage Array Cache – 阵列缓存处理I/O通常有两种情况:\n    * 直接返回数据已经写入的讯号给HBA,这种叫作回写,也是大多数存储阵列处理的方式.\n    * 数据写入缓存然后再刷新到物理磁盘,叫做写透.I/O存放在缓存中以后,交由后端控制器（Disk Adapter）继续处理,完成后再返回数据已经写入的讯号给HBA.\n6. Disk Adapter       – 上述两种方式,最后都会将I/O最后写入到物理磁盘中.这个过程由后端Disk Adapter控制,一个I/O会变成两个或者多个实际的I/O.\n\n##### 根据上述的I/O流向的来看,一个完整的I/O传输,经过的会消耗时间的节点可以概括为以下几个:\n\n1. CPU – RAM, 完成主机文件系统到HBA的操作.\n2. HBA – FA,完成在光纤网络中的传输过程.\n3. FA – Cache,存储前端卡将数据写入到缓存的时间.\n4. DA – Drive,存储后端卡将数据从缓存写入到物理磁盘的时间.\n\n## IO类型\n\n### 阻塞IO\n最流行的I/O模型是阻塞I/O模型，缺省情形下，所有文件操作都是阻塞的。我们以套接口为例来讲解此模型。在进程空间中调用recvfrom，其系统调用直到数据报到达且被拷贝到应用进程的缓冲区中或者发生错误才返回，期间一直在等待。我们就说进程在从调用recvfrom开始到它返回的整段时间内是被阻塞的。\n![阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/阻塞IO.jpg)\n\n### 非阻塞IO\n进程把一个套接口设置成非阻塞是在通知内核：当所请求的I/O操作不能满足要求时候，不把本进程投入睡眠，而是返回一个错误。也就是说当数据没有到达时并不等待，而是以一个错误返回。\n![非阻塞IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/非阻塞IO.jpg)\n\n通过上面，我们知道，所有的IO操作在默认情况下，都是属于阻塞IO。尽管上图中所示的反复请求的非阻塞IO的效率底下（需要反复在用户空间和进程空间切换和判断，把一个原本属于IO密集的操作变为IO密集和计算密集的操作），但是在后面IO复用中，需要把IO的操作设置为非阻塞的，此时程序将会阻塞在select和poll系统调用中。把一个IO设置为非阻塞IO有两种方式：在创建文件描述符时，指定该文件描述符的操作为非阻塞；在创建文件描述符以后，调用fcntl()函数设置相应的文件描述符为非阻塞。\n创建描述符时，利用open函数和socket函数的标志设置返回的fd/socket描述符为O_NONBLOCK。\n\n```c\nint sd=socket(int domain, int type|O_NONBLOCK, int protocol);  \nint fd=open(const char *pathname, int flags|O_NONBLOCK);  \n```\n创建描述符后，通过调用fcntl函数设置描述符的属性为O_NONBLOCK\n```c\n#include <unistd.h>  \n#include <fcntl.h>  \n  \nint fcntl(int fd, int cmd, ... /* arg */ );  \n  \n//例子  \nif (fcntl(fd, F_SETFL, fcntl(sockfd, F_GETFL, 0)|O_NONBLOCK) == -1) {  \n    return -1;  \n}  \n    return 0;  \n}  \n```\n\n### SIGIO\n首先开启套接口信号驱动I/O功能, 并通过系统调用sigaction安装一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据报准备好被读时，就为该进程生成一个SIGIO信号。随即可以在信号处理程序中调用recvfrom来读数据报，井通知主循环数据已准备好被处理中。也可以通知主循环，让它来读数据报。\n![信号驱动IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/信号驱动IO.jpg)\n\n### select and poll\nlinux提供select/poll，进程通过将一个或多个fd传递给select或poll系统调用，阻塞在select;这样select/poll可以帮我们侦测许多fd是否就绪。但是select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限。linux还提供了一个epoll系统调用，epoll是基于事件驱动方式，而不是顺序扫描,当有fd就绪时，立即回调函数rollback；\n![IO复用.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/IO复用.jpg)\n\n##### IO复用详解\n\n在IO编程过程中，当需要处理多个请求的时，可以使用多线程和IO复用的方式进行处理。上面的图介绍了整个IO复用的过程，它通过把多个IO的阻塞复用到一个select之类的阻塞上，从而使得系统在单线程的情况下同时支持处理多个请求。和多线程/进程比较，I/O多路复用的最大优势是系统开销小，系统不需要建立新的进程或者线程，也不必维护这些线程和进程。IO复用常见的应用场景：\n1. 客户程序需要同时处理交互式的输入和服务器之间的网络连接。\n2. 客户端需要对多个网络连接作出反应。\n3. 服务器需要同时处理多个处于监听状态和多个连接状态的套接字\n4. 服务器需要处理多种网络协议的套接字。\n\n### windows的IOCP\n告知内核启动某个操作，并让内核在整个操作完成后(包括将数据从内核拷贝到用户自己的缓冲区)通知我们。这种模型与信号驱动模型的主要区别是：信号驱动I/O：由内核通知我们何时可以启动一个I/O操作；异步I/O模型：由内核通知我们I/O操作何时完成。\n![异步IO.jpg](https://raw.githubusercontent.com/wanggnim/website/images/net/异步IO.jpg)\n\n\n\n## 零拷贝\n\nJava 类库通过 `java.nio.channels.FileChannel` 中的 `transferTo()` 方法来在 Linux 和 UNIX 系统上支持零拷贝。可以使用 `transferTo()` 方法直接将字节从它被调用的通道上传输到另外一个可写字节通道上，数据无需流经应用程序。本文首先展示了通过传统拷贝语义进行的简单文件传输引发的开销，然后展示了使用 `transferTo()` 零拷贝技巧如何提高性能。\n\n\n###### 数据传输：传统方法\n![传统的数据拷贝方法.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_copy.jpg)\n![传统上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transfer_context.gif)\n\n1. read() 调用引发了一次从用户模式到内核模式的上下文切换。在内部，发出 `sys_read()`(或等效内容)以从文件中读取数据。直接内存存取(`direct memory access`，DMA)引擎执行了第一次拷贝，它从磁盘中读取文件内容，然后将它们存储到一个内核地址空间缓存区中。\n2. 所需的数据被从读取缓冲区拷贝到用户缓冲区，read() 调用返回。该调用的返回引发了内核模式到用户模式的上下文切换(又一次上下文切换)。现在数据被储存在用户地址空间缓冲区。\n3. `send()` 套接字调用引发了从用户模式到内核模式的上下文切换。数据被第三次拷贝，并被再次放置在内核地址空间缓冲区。但是这一次放置的缓冲区不同，该缓冲区与目标套接字相关联。\n4. `send()` 系统调用返回，结果导致了第四次的上下文切换。DMA 引擎将数据从内核缓冲区传到协议引擎，第四次拷贝独立地、异步地发生 。\n\n使用中间内核缓冲区(而不是直接将数据传输到用户缓冲区)看起来可能有点效率低下。但是之所以引入中间内核缓冲区的目的是想提高性能。在读取方面使用中间内核缓冲区，可以允许内核缓冲区在应用程序不需要内核缓冲区内的全部数据时，充当 “预读高速缓存(readahead cache)” 的角色。这在所需数据量小于内核缓冲区大小时极大地提高了性能。在写入方面的中间缓冲区则可以让写入过程异步完成。\n\n不幸的是，如果所需数据量远大于内核缓冲区大小的话，这个方法本身可能成为一个性能瓶颈。数据在被最终传入到应用程序前，在磁盘、内核缓冲区和用户缓冲区中被拷贝了多次。\n\n零拷贝通过消除这些冗余的数据拷贝而提高了性能。\n\n![使用 transferTo() 方法的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_copy.gif)\n![使用 transferTo() 方法的上下文切换.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_context.gif)\n\n1. transferTo() 方法引发 DMA 引擎将文件内容拷贝到一个读取缓冲区。然后由内核将数据拷贝到与输出套接字相关联的内核缓冲区。\n\n2. 数据的第三次复制发生在 DMA 引擎将数据从内核套接字缓冲区传到协议引擎时。\n\t改进的地方：我们将上下文切换的次数从四次减少到了两次，将数据复制的次数从四次减少到了三次(其中只有一次涉及到了 CPU)。但是这个代码尚未达到我们的零拷贝要求。如果底层网络接口卡支持收集操作 的话，那么我们就可以进一步减少内核的数据复制。在 Linux 内核 2.4 及后期版本中，套接字缓冲区描述符就做了相应调整，以满足该需求。这种方法不仅可以减少多个上下文切换，还可以消除需要涉及 CPU 的重复的数据拷贝。对于用户方面，用法还是一样的，但是内部操作已经发生了改变：\n\nA. transferTo() 方法引发 DMA 引擎将文件内容拷贝到内核缓冲区。\nB. 数据未被拷贝到套接字缓冲区。取而代之的是，只有包含关于数据的位置和长度的信息的描述符被追加到了套接字缓冲区。DMA 引擎直接把数据从内核缓冲区传输到协议引擎，从而消除了剩下的最后一次 CPU 拷贝。\n\n![结合使用 transferTo() 和收集操作时的数据拷贝.gif](https://raw.githubusercontent.com/wanggnim/website/images/net/transferTo_collect.gif)\n\n\n\n## JAVA IO\n### io#interface\n\n* [Closeable]()\n\tCloseable 是可以关闭的数据源或目标。调用 close 方法可释放对象保存的资源（如打开文件）。\n* [DataInput]()\n\tDataInput 接口用于从二进制流中读取字节，并重构所有 Java 基本类型数据。同时还提供根据 UTF-8 修改版格式的数据重构 String 的工具。\n\n\t对于此接口中的所有数据读取例程来说，如果在读取到所需字节数的数据之前已经到达文件末尾 (end of file)，则都将抛出 EOFException（IOException 的一种）。如果因为文件末尾以外的其他原因无法读取字节，则抛出 IOException而不是 EOFException。尤其在输入流已关闭的情况下，将抛出 IOException。\n* [DataOutput]()\n\t\n\tDataOutput 接口用于将任意 Java 基本类型转换为一系列字节，并将这些字节写入二进制流。同时还提供了一个将 String 转换成 UTF-8 修改版格式并写入所得到的系列字节的工具。\n\t\n\t对于此接口中写入字节的所有方法，如果由于某种原因无法写入某个字节，则抛出 IOException。\n\t\n* [Externalizable]()\n\t\n\tExternalizable继承于Serializable，当使用该接口时，序列化的细节需要由程序员去完成。如上所示的代码，由于writeExternal()与readExternal()方法未作任何处理，那么该序列化行为将不会保存/读取任何一个字段。\n\t\n* [FileFilter](TestFileFilter.java)\n\n\t检测文件是否存在。FileFilter 和他的前身FilenameFilter 唯一的不同是FileFilter 提供文件对象的访问方法，\n\t而FilenameFilter 是按照目录和文件名的方式来工作的。\n\n* [FilenameFilter]()\n\n* [Flushable]()\n\t实现了Flushable接口的类的对象，可以强制将缓存的输出写入到与对象关联的流中。写入流的所有I/O类都实现了Flushable接口。\n* [ObjectInput]()\n* [ObjectInputValidation]()\n\t序列化流验证机制. 一般情况下，我们认为序列化流中的数据总是与最初写到流中的数据一致，这并没有问题。但当黑客获取流信息并篡改一些敏感信息重新序列化到流中后，用户通过反序列化得到的将是被篡改的信息。Java序列化提供一套验证机制。序列化类通过实现 java.io.ObjectInputValidation接口，就可以做到验证了\n* [ObjectOutput]()\n* [ObjectStreamConstants]()\n\tJava序列化序列化对象的信息包括：类元数据描述、类的属性、父类信息以及属性域的值。Java将这些信息分成3部分：序列化头信息、类的描述部分以及属性域的值部分。现在对a.txt文件加以分析，其中包含一些序列化机制中提供的特殊字段，这些字段被定义在java.io.ObjectStreamConstants接口中。 \n* [Serializable]()\n\n### io#class\n\n* [BufferedInputStream]()\n\n\tBufferedInputStream是一个带有缓冲区域的InputStream, 支持“mark()标记”和“reset()重置方法”。输入到byte[]数组里.\n* [BufferedOutputStream]()\n\t缓冲输出流。它继承于FilterOutputStream。作用是为另一个输出流提供“缓冲功能”。输出byte[]字节数组\n\n* [BufferedReader]()\n\n\tBufferedReader 从字符输入流中读取文本，缓冲各个字符。提供字符、数组和行的高效读取。\n\n* [BufferedWriter]()\n\n\t>1. 支持字符串输出\n\t2. 支持换行输出\n\t3. 支持文件追加输出\n\n* [ByteArrayInputStream]()\n\n\t从byte[]数组中读取数据到缓存中.可以将字节数组转化为输入流此类中的方法在关闭此流后仍可被调用，而不会产生任何 IOException。\n* [ByteArrayOutputStream]()\n\n\t输出数据到byte[]数组里，可以捕获内存缓冲区的数据，转换成字节数组。缓冲区会随着数据的不断写入而自动增长。可使用 toByteArray()和 toString()获取数据。\t关闭 ByteArrayOutputStream 无效。此类中的方法在关闭此流后仍可被调用，而不会产生任何IOException。\n\n* [CharArrayReader]()\n\t与ByteArrayInputStream对应。 支持mark和reset读取char[] 数组\n\n* [CharArrayWriter]()\n\t向内部char[] 缓冲区存储数据.  支持rest, 文件追加写操作, 支持string write \n* [Console]()\n\t专用来访问基于字符的控制台设备。如果你的Java程序要与Windows下的cmd或者Linux下的Terminal交互，就可以用这个Java Console类java.io.Console 只能用在标准输入、输出流未被重定向的原始控制台中使用，在 Eclipse 或者其他 IDE 的控制台是用不了的。\n\t\n* [DataInputStream]()\n\t用来装饰其它输入流，它“允许应用程序以与机器无关方式从底层输入流中读取基本 Java 数据类型”\n* [DataOutputStream]()\n\t用来装饰其它输出流，将DataOutputStream和DataInputStream输入流配合使用，“允许应用程序以与机器无关方式从底层输入流中读写基本 Java 数据类型”。\n* [File]()\n```\n\t1. 删除文件\n\t2. 文件重命名\n\t3. 创建新的文件\n\t4. 创建新的文件\n\t5. 获取文件的最后修改时间\n\t6. 设置文件只读\n\t7. 设置文件可写\n\t8. 获取文件长度(总字节数)\n\t9. 获取文件路径\n\t10. 获取绝对文件路径\n\t11. 文件是否隐藏\n\t12. 获得剩余磁盘空间？\n\t13. 拷贝文件夹\n\t14. 遍历文件夹\n\t15. 检查文件夹是否为空？\n```\n* [FileDescriptor]()\n\t用来表示开放文件、开放套接字等。当FileDescriptor表示某文件时，我们可以通俗的将FileDescriptor看成是该文件。但是，我们不能直接通过FileDescriptor对该文件进行操作；若需要通过FileDescriptor对该文件进行操作，则需要新创建FileDescriptor对应的FileOutputStream，再对文件进行操作。\n\t\n\t类实例作为一个不透明的句柄底层机器特有的结构表示一个打开的文件，打开的套接字或其他来源或字节的接收器。以下是关于FileDescriptor要点：\n\t1. 主要实际使用的文件描述符是创建一个FileInputStream或FileOutputStream来遏制它。\n\t2. 应用程序不应创建自己的文件描述符。\n\n* [FileInputStream]()\n\t一个字节一个字节的从文件里读取数据\n\t\n* [FileOutputStream]()\n\t一个字节一个字节的向文件里输出数据\n\n* [FilePermission]()\n\n* [FileReader]()\n\t一个字符一个字符地读取\n\n* [FileWriter]()\n\n\t一个字符一个字符地输出\n\n* [FilterInputStream]()\n\n\t用来“封装其它的输入流，并为它们提供额外的功能”。它的常用的子类有BufferedInputStream和DataInputStream。\n\n* [FilterOutputStream]()\n\n\t作用是用来“封装其它的输出流，并为它们提供额外的功能”。它主要包括BufferedOutputStream, \n\tDataOutputStream和PrintStream。\n\n* [FilterReader]()\n\n\t用于读取已过滤的字符流的抽象类。抽象类 FilterReader 自身提供了一些将所有请求传递给所包含的流的默认方法。\n\n* [FilterWriter]()\n\n\t用于写入已过滤的字符流的抽象类。抽象类 FilterWriter 自身提供了一些将所有请求传递给所包含的流的默认方法\n\n* [InputStream]()\n\n\n* [InputStreamReader]()\n\n\t是字节流通向字符流的桥梁：它使用指定的 charset 读写字节并将其解码为字符。\n\t将“字节输入流”转换成“字符输入流”。它继承于Reader。\n\n* [LineNumberInputStream]()\n\n\t此类是一个输入流过滤器，它提供跟踪当前行号的附加功能。行是以回车符 ('\\r')、换行符 ('\\n')或回车符后面紧跟换行符结尾的字节序列。在所有这三种情况下，都以单个换行符形式返回行终止字符。行号以 0 开头，并在 read 返回换行符时递增 1。\n\n* [LineNumberReader]()\n\n\t跟踪行号的缓冲字符输入流。此类定义了方法 setLineNumber(int) 和 getLineNumber()，它们可分别用于设置和获取当前行号。默认情况下，行编号从 0 开始。该行号随数据读取在每个行结束符处递增，并且可以通过调用 \n\tsetLineNumber(int) 更改行号。但要注意的是，setLineNumber(int) 不会实际更改流中的当前位置；它只更改将由getLineNumber() 返回的值。可认为行在遇到以下符号之一时结束：换行符（'\\n'）、回车符（'\\r'）、回车后紧跟换行符。\n\n* [ObjectInputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectOutputStream]()\n\n\t用于从底层输入流中读取对象类型的数据和对象类型的数据写入到底层输出流。将对象中所有成员变量的取值保存起来就等于保存了对象，将对象中所有成员变量的取值还原就相等于读取了对象。\n\n* [ObjectStreamField]()\n\n\tSerializable 类中 Serializable 字段的描述。ObjectStreamField 的数组用于声明类的 Serializable 字段。\n\n* [OutputStream]()\n\n\n* [OutputStreamWriter]()\n\n\tOutputStreamWriter 将字节流转换为字符流。是字节流通向字符流的桥梁。如果不指定字符集编码，该解码过程将使用平台默认的字符编码，如：GBK。\n\n* [PipedInputStream]()\n\n\t管道输入流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedOutputStream]()\n\n\t管道输出流是让多线程可以通过管道进行线程间的通讯\n\n* [PipedReader]()\n\n\tPipedWriter 是字符管道输出流,可以通过管道进行线程间的通讯。\n\n* [PipedWriter]()\n\n\tPipedReader 是字符管道输入流,可以通过管道进行线程间的通讯。\n\n* [PrintStream]()\n\n\t打印输出流, 用来装饰其它输出流。它能为其他输出流添加了功能，使它们能够方便地打印各种数据值表示形式。PrintStream 永远不会抛出 IOException；PrintStream 提供了自动flush 和 字符集设置功能。所谓自动flush，就是往PrintStream写入的数据会立刻调用flush()函数。\n\n* [PrintWriter]()\n\n\t用于向文本输出流打印对象的格式化表示形式。它实现在 PrintStream 中的所有 print 方法。它不包含用于写入原始字节的方法，对于这些字节，程序应该使用未编码的字节流进行写入。\n\n* [PushbackInputStream]()\n\n\t拥有一个PushBack缓冲区，从PushbackInputStream读出数据后，只要PushBack缓冲区没有满，就可以使用unread()将数据推回流的前端。\n\n* [PushbackReader]()\n\n\t允许将字符推回到流的字符流 reader。\n\n* [RandomAccessFile]()\n\n\t用来访问那些保存数据记录的文件的，你就可以用seek( )方法来访问记录，并进行读写了。这些记录的大小不必相同；但是其大小和位置必须是可知的。但是该类仅限于操作文件。\n\n* [SequenceInputStream]()\n\n\t从多个输入流中向程序读入数据。此时，可以使用合并流，将多个输入流合并成一个SequenceInputStream流对象。 SequenceInputStream会将与之相连接的流集组合成一个输入流并从第一个输入流开始读取，直到到达文件末尾，\n\t接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末 尾为止。 合并流的作用是将多个源合并合一个源。\n\n* [SerializablePermission]()\n\n\n* [StreamTokenizer]()\n\n\t获取输入流并将其解析为“标记”，允许一次读取一个标记。解析过程由一个表和许多可以设置为各种状态的标志控制。\n\t该流的标记生成器可以识别标识符、数字、引用的字符串和各种注释样式等。\n\n* [StringBufferInputStream]()\n\n\n* [StringReader]()\n\n\n* [StringWriter]()\n\n\n### nio\n\n* [Buffer](java/src/test/io/robertsing/cookios/nio/TestBuffer.java)\n\n\n* [ByteBuffer](java/src/test/io/robertsing/cookios/nio/TestByteBuffer.java)\n\n\n* [ByteOrder](java/src/test/io/robertsing/cookios/nio/TestByteOrder.java)\n\n\n* [CharBuffer](java/src/test/io/robertsing/cookios/nio/TestCharBuffer.java)\n\n\n* [DoubleBuffer](java/src/test/io/robertsing/cookios/nio/TestDoubleBuffer.java)\n\n\n* [FloatBuffer](java/src/test/io/robertsing/cookios/nio/TestFloatBuffer.java)\n\n\n* [IntBuffer](java/src/test/io/robertsing/cookios/nio/TestIntBuffer.java)\n\n\n* [LongBuffer](java/src/test/io/robertsing/cookios/nio/TestLongBuffer.java)\n\n\n* [MappedByteBuffer](java/src/test/io/robertsing/cookios/nio/TestMappedByteBuffer.java)\n\n\n* [ShortBuffer](java/src/test/io/robertsing/cookios/nio/TestShortBuffer.java)\n\n\n### nio#channels#Interfaces\n\n* [AsynchronousByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousByteChannel.java)\n\n\n* [AsynchronousChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannel.java)\n\n\n* [ByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestByteChannel.java)\n\n\n* [Channel](java/src/test/io/robertsing/cookios/nio/channels/TestChannel.java)\n\n\n* [CompletionHandler](java/src/test/io/robertsing/cookios/nio/channels/TestCompletionHandler.java)\n\n\n* [GatheringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestGatheringByteChannel.java)\n\n\n* [InterruptibleChannel](java/src/test/io/robertsing/cookios/nio/channels/TestInterruptibleChannel.java)\n\n\n* [MulticastChannel](java/src/test/io/robertsing/cookios/nio/channels/TestMulticastChannel.java)\n\n\n* [NetworkChannel](java/src/test/io/robertsing/cookios/nio/channels/TestNetworkChannel.java)\n\n\n* [ReadableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestReadableByteChannel.java)\n\n\n* [ScatteringByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestScatteringByteChannel.java)\n\n\n* [SeekableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSeekableByteChannel.java)\n\n\n* [WritableByteChannel](java/src/test/io/robertsing/cookios/nio/channels/TestWritableByteChannel.java)\n\n\n### nio#channels#Classes\n\n* [AsynchronousChannelGroup](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousChannelGroup.java)\n\n\n* [AsynchronousFileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousFileChannel.java)\n\n\n* [AsynchronousServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousServerSocketChannel.java)\n\n\n* [AsynchronousSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestAsynchronousSocketChannel.java)\n\n\n* [Channels](java/src/test/io/robertsing/cookios/nio/channels/TestChannels.java)\n\n\n* [DatagramChannel](java/src/test/io/robertsing/cookios/nio/channels/TestDatagramChannel.java)\n\n\n* [FileChannel](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.java)\n\n\n* [FileChannel.MapMode](java/src/test/io/robertsing/cookios/nio/channels/TestFileChannel.MapMode.java)\n\n\n* [FileLock](java/src/test/io/robertsing/cookios/nio/channels/TestFileLock.java)\n\n\n* [MembershipKey](java/src/test/io/robertsing/cookios/nio/channels/TestMembershipKey.java)\n\n\n* [Pipe](java/src/test/io/robertsing/cookios/nio/channels/TestPipe.java)\n\n\n* [SelectableChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSelectableChannel.java)\n\n\n* [SelectionKey](java/src/test/io/robertsing/cookios/nio/channels/TestSelectionKey.java)\n\n\n* [Selector](java/src/test/io/robertsing/cookios/nio/channels/TestSelector.java)\n\n\n* [ServerSocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestServerSocketChannel.java)\n\n\n* [SocketChannel](java/src/test/io/robertsing/cookios/nio/channels/TestSocketChannel.java)\n\n\n### nio#file#Interfaces\n\n* [CopyOption](java/src/test/io/robertsing/cookios/nio/file/TestCopyOption.java)\n\n\n* [DirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestDirectoryStream.java)\n\n\t遍历某个文件夹内的所有文件,但是不会遍历子目录. 也就是这会遍历当前路径中的所有文件\n\n* [FileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestFileVisitor.java)\n\n\t@SimpleFileVisitor\n\n* [OpenOption](java/src/test/io/robertsing/cookios/nio/file/TestOpenOption.java)\n\n\n* [Path](java/src/test/io/robertsing/cookios/nio/file/TestPath.java)\n\n\n* [PathMatcher](java/src/test/io/robertsing/cookios/nio/file/TestPathMatcher.java)\n\n\n* [SecureDirectoryStream](java/src/test/io/robertsing/cookios/nio/file/TestSecureDirectoryStream.java)\n\n\n* [Watchable](java/src/test/io/robertsing/cookios/nio/file/TestWatchable.java)\n\n\n* [WatchEvent](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.java)\n\n\n* [WatchEvent.Kind](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Kind.java)\n\n\n* [WatchEvent.Modifier](java/src/test/io/robertsing/cookios/nio/file/TestWatchEvent.Modifier.java)\n\n\n* [WatchKey](java/src/test/io/robertsing/cookios/nio/file/TestWatchKey.java)\n\n\n* [WatchService](java/src/test/io/robertsing/cookios/niofile//TestWatchService.java)\n\n\n### nio#file#Classes\n\n* [Files]()\n\n\t1. copy\n\t2. createDirectories\n\t3. createDirectory\n\t4. createFile\n\t5. createLink\n\t6. createSymbolicLink\n\t7. createTempDirectory\n\t8. createTempFile\n\t9. delete\n\t10. deleteIfExists\n\t11. exists\n\t12. getAttribute\n\t13. getFileAttributeView\n\t14. getFileStore\n\t15. getLastModifiedTime\n\t16. getOwner\n\t17. getPosixFilePermissions\n\t18. isDirectory\n\t19. isExecutable\n\t20. isHidden\n\t21. isReadable\n\t22. isRegularFile\n\t23. isSameFile\n\t24. isSymbolicLink\n\t25. isWritable\n\t26. move\n\t27. newBufferedReader\n\t28. newBufferedWriter\n\t29. newByteChannel\n\t30. newDirectoryStream\n\t31. newInputStream\n\t32. newOutputStream\n\t33. notExists\n\t34. probeContentType\n\t35. readAllBytes\n\t36. readAllLines\n\t37. readAttributes\n\t38. readSymbolicLink\n\t39. setAttribute\n\t40. setLastModifiedTime\n\t41. setOwner\n\t42. setPosixFilePermissions\n\t43. walkFileTree\n\t44. write\n\n\n* [FileStore]()\n\n\t代表了真正的存储设备，提供了设备的详尽信息\n\n* [FileSystem](java/src/test/io/robertsing/cookios/nio/file/TestFileSystem.java)\n\n\n* [FileSystems](java/src/test/io/robertsing/cookios/nio/file/TestFileSystems.java)\n\n\n* [LinkPermission](java/src/test/io/robertsing/cookios/nio/file/TestLinkPermission.java)\n\n\n* [Paths](java/src/test/io/robertsing/cookios/nio/file/TestPaths.java)\n\n\n* [SimpleFileVisitor](java/src/test/io/robertsing/cookios/nio/file/TestSimpleFileVisitor.java)\n\n\t与DirectoryStream 不同的是，这个类会遍历目录下包括子目录的所有文件并且提供了多种处理接口方法.\n\n* [StandardWatchEventKinds](java/src/test/io/robertsing/cookios/nio/file/TestStandardWatchEventKinds.java)\n\n\n### nio#charset\n\n* [Charset](java/src/test/io/robertsing/cookios/nio/charset/TestCharset.java)\n\n\n* [CharsetDecoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetDecoder.java)\n\n\n* [CharsetEncoder](java/src/test/io/robertsing/cookios/nio/charset/TestCharsetEncoder.java)\n\n\n* [CoderResult](java/src/test/io/robertsing/cookios/nio/charset/TestCoderResult.java)\n\n\n* [CodingErrorAction](java/src/test/io/robertsing/cookios/nio/charset/TestCodingErrorAction.java)\n\n\n* [StandardCharsets](java/src/test/io/robertsing/cookios/nio/charset/TestStandardCharsets.java)\n\n\n\n\n","slug":"io","published":1,"date":"2015-09-16T04:04:20.602Z","updated":"2015-06-27T05:53:05.468Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeaw001l74uf66bsqpwt"},{"title":"Idea快捷键","_content":"\n## windows下的快捷键\n\n#### 编辑区域快捷键\n* 上下行移动 ： `ctrl + shift + ↑/↓`\n* 在文件变更处跳转：`ctrl + alt + shift + ↑/↓`\n* Eclipse Outline ： `ctrl + f12`\n\n#### VCS快捷键\n* show diff ：`ctrl + d`","source":"_posts/idea快捷键.md","raw":"title: Idea快捷键\n---\n\n## windows下的快捷键\n\n#### 编辑区域快捷键\n* 上下行移动 ： `ctrl + shift + ↑/↓`\n* 在文件变更处跳转：`ctrl + alt + shift + ↑/↓`\n* Eclipse Outline ： `ctrl + f12`\n\n#### VCS快捷键\n* show diff ：`ctrl + d`","slug":"idea快捷键","published":1,"date":"2015-07-01T06:22:02.130Z","updated":"2015-07-01T02:24:13.156Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeax001m74ufbh838btn"},{"title":"haskell","_content":"\n#类型系统\n\n## 数据类型\n在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.\n在Haskell中所有的数据类型都必须首字母都必须大写.\n\n在GHCI中我们可以通过`::t`命令来查看一个数据类型或者函数类型.\n\n我们可以通过下面的语法声明一个数据\n```\nvar :: 数据类型\nvar = 数据初始值\n```\n或者我们可以将这俩行并为一行\n```\nvar = 数据初始值 :: 数据类型\n```\n\n### Bool类型\n\n我们声明一个bool类型的数据,并将其初始化为`True`\n```haskell\ntrue = True :: Bool\n```\n\n\n### Char类型\n\n单字符类型\n```haskell\nchar = 'a' :: Char\n\nchar = '\\100' :: Char\n\nchar = '\\n' :: Char\n```\n\n### Int类型\n有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`-2^31~2^31-1`\n```haskell\nint = -1 :: Int\n```\n\n### Word类型\n有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`0~2^32-1`\n```haskell\nimport Data.Word\n\nword = 1 :: Word\n```\n\n### Integer类型\n任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关.\n\n当数据不指明类型时,Integer是整数的默认类型\n```haskell\ninteger = 199999 :: Integer\n```\n\n### Float类型\n单精度浮点小数\n```haskell\nfloat = 1.1 :: Float\n```\n\n### Double类型\n双精度浮点小数\n```haskell\ndouble = 1.11111 :: Double\n```\n\n### Rational类型\n有理数类型\n```haskell\nrational = 1 / 500 :: Rational\n```\n\n### String类型\n`String`的类型为`[Char]`\n```haskell\nstring = \"char array\" :: String\n```\n\n### 元组类型\n元祖用`(,)`表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组).\n\n一旦确定了元件的个数和元件的类型,那他们就是不可再变的.\n```haskell\ntuple = (123, \"abc\") :: (Int, [Char])\n```\n\n### 列表类型\n列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变.\n```haskell\nlist = [123, 8, 9] :: [Int]\n```\n\n#### 拼接列表\n采用`x:xs`的形式进行拼接列表, `x`代表一个元素, `xs`代表一个列表.\n```haskell\nlist = [123, 8, 9]\n\nnewList = 1 : list\n```\n\n#### 多维列表\n\n```haskell\nmulList = [[]]  -- 列表中套有一个列表,类似于2维数组\n\nmulList = [[[]]]\n```\n\n## 类型别名\n我们可以使用`type`关键字将复杂类型起一个简单的名字\n\n```haskell\ntype NewType = (Int, Int)\n```\n\n接下来我们就可以使用这个类型了\n```haskell\npoint :: NewType\npoint = (1, 2)\n```\n\n`type`关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型.\n\n\n## 类型类\n\n\n## Eq\n```haskell\n\n```\n\n## Ord\n```haskell\n\n```\n\n## Enum\n```haskell\n\n```\n\n## Bounded\n```haskell\n\n```\n\n## Num\n```haskell\n\n```\n\n## Show\n```haskell\n\n```\n\n\n# 表达式\n## 条件表达式\n\n```haskell\nisOne :: Int -> Bool\nisOne arg =\n    if arg == 1 then True\n    else False\n```\n\n## 情况分析表达式\n与`switch case`类似,只不过情况分析表达式没有`break`, 使用`_`作为通配符.\n```haskell\nmonth :: Int -> Int\nmonth n = case n of\n    1 -> 31\n    2 -> 28\n    12 -> 31\n    _ -> error \"error\"\n```\n\n## 守卫表达式\n\n```haskell\nabs :: Num a => a -> a\nabs n | n > 0 = n\n      | otherwise = -n\n```\n\n## 匹配模式表达式\n\n```haskell\nmonth :: Int -> Int\nmonth 1 = 31\nmonth 2 = 28\nmonth 3 = 21\nmonth 12 = 31\nmonth _ = error \"error\"\n```\n\n# 运算符\n```\n优先级9 : !!, .\n优先级8 : ^, ^^, **\n优先级7 : *, /, div,   mod, rem, quot\n优先级6 : +, -\n优先级5 : :, ++\n优先级4 : ==, /=, <, <=, >, >=,     elem, notElem\n优先级3 : &&\n优先级2 : ||\n优先级1 : >>, >>=\n优先级0 : $, $!, $!!seq\n```\n> 凡是英文运算符,其前后都必须带有`标点\n\n# 函数\n我们采用如下格式定义一个函数\n```\n函数名 :: 参数1的类型 -> 参数2的类型 -> ... -> 结果类型 (1)\n函数名 参数1 参数2 ... = 函数体                         (2)\n```\n1. 定义函数签名\n2. 定义函数\n\n下面我们举例出多种函数定义变体形式:\n\n### 带有类型类的函数定义\n\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n### 带有多个类型的函数定义\n\n```haskell\nadd :: (Show t, Int t) => t -> t -> t\nadd x y = x + y\n```\n\n#### 不带有类型类的函数定义\n```haskell\nadd :: Int -> Int -> Int\nadd x y = x + y\n```\n\n#### 函数定义\n```haskell\nadd x y = x + y :: Int\n```\n\n#### 类型自动推断的函数定义\n```haskell\nadd x y = x + y\n```\n\n#### 函数后跟'\n在函数名后加一个`'`,与原函数这代表着俩个函数.\n```haskell\nadd' :: Num t => t -> t -> t\nadd' x y = x + y\n\nadd :: Num t => t -> t -> t\nadd x y = x + y\n\n```\n\n## 函数类型\n### 柯里化函数\n当调用一个N参数的函数时, 传递M个参数(N < M),那么该参数返回的结果也是一个函数.这个过程称为柯里化.\n\n但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用.\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n当我们只向`add`函数传递一个参数`5`的时候,我们会得到下面一个这样子的函数:\n```haskell\nadd 5 y = 5 + y\n\n函数类型为:\nadd :: Num t => t -> t\n```\n\n### 偏函数\n如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数.\n\n\n### 非柯里化函数\n非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数.\n```haskell\nadd :: Num t => (t ,t) -> t\nadd (x, y) = x + y\n```\n\n### 多态函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n### 重载类型函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n## lambada\n\n## 参数绑定\n### let...in...\n`let`里定义的部分会在函数体中进行替换\n#### 替换表达式\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c =\n    let p = (a + b + c) / 2\n    in sqrt (p * (p - a) * (p - b) * (p - c))\n```\n#### 替换多个表达式\n```haskell\n\n```\n#### 替换函数\n```haskell\n\n```\n\n### where\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c = sqrt (p * (p - a) * (p - b) * (p - c))\n    where p = (a + b + c) / 2\n```\n\n#### 常用函数\n* 恒值函数id\n\n```haskell\n\n```\n* 常数函数const\n\n```haskell\n\n```\n* 参数反置函数flip\n\n```haskell\n\n```\n* 错误函数error\n\n```haskell\n\n```\n* undifine函数\n\n```haskell\n\n```\n* min/max函数\n\n```haskell\n\n```\n\n## 内置函数\n#### 列表函数\n* null\n\n```haskell\n\n```\n* length\n\n```haskell\n\n```\n* !!\n\n```haskell\n\n```\n* reverse\n\n```haskell\n\n```\n* head\n\n```haskell\n\n```\n* last\n\n```haskell\n\n```\n* tail\n\n```haskell\n\n```\n* init\n\n```haskell\n\n```\n* map\n\n\n```haskell\n\n```\n* filter\n\n```haskell\n\n```\n* take\n\n```haskell\n\n```\n* drop\n\n```haskell\n\n```\n* span\n\n```haskell\n\n```\n* break\n\n```haskell\n\n```\n* takeWhile\n\n```haskell\n\n```\n* dropWhile\n\n```haskell\n\n```\n* spiltAt\n\n```haskell\n\n```\n* repeat\n\n```haskell\n\n```\n* replicate\n\n```haskell\n\n```\n* any\n\n```haskell\n\n```\n* all\n\n```haskell\n\n```\n* elem\n\n```haskell\n\n```\n* notelem\n\n```haskell\n\n```\n* iterate\n\n```haskell\n\n```\n* until\n\n```haskell\n\n```\n* zip\n\n```haskell\n\n```\n* concat\n\n```haskell\n\n```\n* concatMap\n\n```haskell\n\n```\n\n#### 字符串\n* show\n\n```haskell\n\n```\n* read\n\n```haskell\n\n```\n* lines\n\n```haskell\n\n```\n* unlines\n\n```haskell\n\n```\n* word\n\n```haskell\n\n```\n* unword\n\n```haskell\n\n```\n\n\n#### 字符库\n* Data.char\n\n```haskell\n\n```\n\n#### 位函数库\n* Data.Bits\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n","source":"_posts/haskell.md","raw":"title: haskell\n---\n\n#类型系统\n\n## 数据类型\n在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.\n在Haskell中所有的数据类型都必须首字母都必须大写.\n\n在GHCI中我们可以通过`::t`命令来查看一个数据类型或者函数类型.\n\n我们可以通过下面的语法声明一个数据\n```\nvar :: 数据类型\nvar = 数据初始值\n```\n或者我们可以将这俩行并为一行\n```\nvar = 数据初始值 :: 数据类型\n```\n\n### Bool类型\n\n我们声明一个bool类型的数据,并将其初始化为`True`\n```haskell\ntrue = True :: Bool\n```\n\n\n### Char类型\n\n单字符类型\n```haskell\nchar = 'a' :: Char\n\nchar = '\\100' :: Char\n\nchar = '\\n' :: Char\n```\n\n### Int类型\n有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`-2^31~2^31-1`\n```haskell\nint = -1 :: Int\n```\n\n### Word类型\n有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是`0~2^32-1`\n```haskell\nimport Data.Word\n\nword = 1 :: Word\n```\n\n### Integer类型\n任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关.\n\n当数据不指明类型时,Integer是整数的默认类型\n```haskell\ninteger = 199999 :: Integer\n```\n\n### Float类型\n单精度浮点小数\n```haskell\nfloat = 1.1 :: Float\n```\n\n### Double类型\n双精度浮点小数\n```haskell\ndouble = 1.11111 :: Double\n```\n\n### Rational类型\n有理数类型\n```haskell\nrational = 1 / 500 :: Rational\n```\n\n### String类型\n`String`的类型为`[Char]`\n```haskell\nstring = \"char array\" :: String\n```\n\n### 元组类型\n元祖用`(,)`表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组).\n\n一旦确定了元件的个数和元件的类型,那他们就是不可再变的.\n```haskell\ntuple = (123, \"abc\") :: (Int, [Char])\n```\n\n### 列表类型\n列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变.\n```haskell\nlist = [123, 8, 9] :: [Int]\n```\n\n#### 拼接列表\n采用`x:xs`的形式进行拼接列表, `x`代表一个元素, `xs`代表一个列表.\n```haskell\nlist = [123, 8, 9]\n\nnewList = 1 : list\n```\n\n#### 多维列表\n\n```haskell\nmulList = [[]]  -- 列表中套有一个列表,类似于2维数组\n\nmulList = [[[]]]\n```\n\n## 类型别名\n我们可以使用`type`关键字将复杂类型起一个简单的名字\n\n```haskell\ntype NewType = (Int, Int)\n```\n\n接下来我们就可以使用这个类型了\n```haskell\npoint :: NewType\npoint = (1, 2)\n```\n\n`type`关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型.\n\n\n## 类型类\n\n\n## Eq\n```haskell\n\n```\n\n## Ord\n```haskell\n\n```\n\n## Enum\n```haskell\n\n```\n\n## Bounded\n```haskell\n\n```\n\n## Num\n```haskell\n\n```\n\n## Show\n```haskell\n\n```\n\n\n# 表达式\n## 条件表达式\n\n```haskell\nisOne :: Int -> Bool\nisOne arg =\n    if arg == 1 then True\n    else False\n```\n\n## 情况分析表达式\n与`switch case`类似,只不过情况分析表达式没有`break`, 使用`_`作为通配符.\n```haskell\nmonth :: Int -> Int\nmonth n = case n of\n    1 -> 31\n    2 -> 28\n    12 -> 31\n    _ -> error \"error\"\n```\n\n## 守卫表达式\n\n```haskell\nabs :: Num a => a -> a\nabs n | n > 0 = n\n      | otherwise = -n\n```\n\n## 匹配模式表达式\n\n```haskell\nmonth :: Int -> Int\nmonth 1 = 31\nmonth 2 = 28\nmonth 3 = 21\nmonth 12 = 31\nmonth _ = error \"error\"\n```\n\n# 运算符\n```\n优先级9 : !!, .\n优先级8 : ^, ^^, **\n优先级7 : *, /, div,   mod, rem, quot\n优先级6 : +, -\n优先级5 : :, ++\n优先级4 : ==, /=, <, <=, >, >=,     elem, notElem\n优先级3 : &&\n优先级2 : ||\n优先级1 : >>, >>=\n优先级0 : $, $!, $!!seq\n```\n> 凡是英文运算符,其前后都必须带有`标点\n\n# 函数\n我们采用如下格式定义一个函数\n```\n函数名 :: 参数1的类型 -> 参数2的类型 -> ... -> 结果类型 (1)\n函数名 参数1 参数2 ... = 函数体                         (2)\n```\n1. 定义函数签名\n2. 定义函数\n\n下面我们举例出多种函数定义变体形式:\n\n### 带有类型类的函数定义\n\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n### 带有多个类型的函数定义\n\n```haskell\nadd :: (Show t, Int t) => t -> t -> t\nadd x y = x + y\n```\n\n#### 不带有类型类的函数定义\n```haskell\nadd :: Int -> Int -> Int\nadd x y = x + y\n```\n\n#### 函数定义\n```haskell\nadd x y = x + y :: Int\n```\n\n#### 类型自动推断的函数定义\n```haskell\nadd x y = x + y\n```\n\n#### 函数后跟'\n在函数名后加一个`'`,与原函数这代表着俩个函数.\n```haskell\nadd' :: Num t => t -> t -> t\nadd' x y = x + y\n\nadd :: Num t => t -> t -> t\nadd x y = x + y\n\n```\n\n## 函数类型\n### 柯里化函数\n当调用一个N参数的函数时, 传递M个参数(N < M),那么该参数返回的结果也是一个函数.这个过程称为柯里化.\n\n但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用.\n```haskell\nadd :: Num t => t -> t -> t\nadd x y = x + y\n```\n\n当我们只向`add`函数传递一个参数`5`的时候,我们会得到下面一个这样子的函数:\n```haskell\nadd 5 y = 5 + y\n\n函数类型为:\nadd :: Num t => t -> t\n```\n\n### 偏函数\n如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数.\n\n\n### 非柯里化函数\n非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数.\n```haskell\nadd :: Num t => (t ,t) -> t\nadd (x, y) = x + y\n```\n\n### 多态函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n### 重载类型函数\n```haskell\n\n```\n\n```haskell\n\n```\n\n## lambada\n\n## 参数绑定\n### let...in...\n`let`里定义的部分会在函数体中进行替换\n#### 替换表达式\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c =\n    let p = (a + b + c) / 2\n    in sqrt (p * (p - a) * (p - b) * (p - c))\n```\n#### 替换多个表达式\n```haskell\n\n```\n#### 替换函数\n```haskell\n\n```\n\n### where\n```haskell\ns :: Double -> Double -> Double -> Double\ns a b c = sqrt (p * (p - a) * (p - b) * (p - c))\n    where p = (a + b + c) / 2\n```\n\n#### 常用函数\n* 恒值函数id\n\n```haskell\n\n```\n* 常数函数const\n\n```haskell\n\n```\n* 参数反置函数flip\n\n```haskell\n\n```\n* 错误函数error\n\n```haskell\n\n```\n* undifine函数\n\n```haskell\n\n```\n* min/max函数\n\n```haskell\n\n```\n\n## 内置函数\n#### 列表函数\n* null\n\n```haskell\n\n```\n* length\n\n```haskell\n\n```\n* !!\n\n```haskell\n\n```\n* reverse\n\n```haskell\n\n```\n* head\n\n```haskell\n\n```\n* last\n\n```haskell\n\n```\n* tail\n\n```haskell\n\n```\n* init\n\n```haskell\n\n```\n* map\n\n\n```haskell\n\n```\n* filter\n\n```haskell\n\n```\n* take\n\n```haskell\n\n```\n* drop\n\n```haskell\n\n```\n* span\n\n```haskell\n\n```\n* break\n\n```haskell\n\n```\n* takeWhile\n\n```haskell\n\n```\n* dropWhile\n\n```haskell\n\n```\n* spiltAt\n\n```haskell\n\n```\n* repeat\n\n```haskell\n\n```\n* replicate\n\n```haskell\n\n```\n* any\n\n```haskell\n\n```\n* all\n\n```haskell\n\n```\n* elem\n\n```haskell\n\n```\n* notelem\n\n```haskell\n\n```\n* iterate\n\n```haskell\n\n```\n* until\n\n```haskell\n\n```\n* zip\n\n```haskell\n\n```\n* concat\n\n```haskell\n\n```\n* concatMap\n\n```haskell\n\n```\n\n#### 字符串\n* show\n\n```haskell\n\n```\n* read\n\n```haskell\n\n```\n* lines\n\n```haskell\n\n```\n* unlines\n\n```haskell\n\n```\n* word\n\n```haskell\n\n```\n* unword\n\n```haskell\n\n```\n\n\n#### 字符库\n* Data.char\n\n```haskell\n\n```\n\n#### 位函数库\n* Data.Bits\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n*\n\n```haskell\n\n```\n","slug":"haskell","published":1,"date":"2015-09-16T05:15:52.115Z","updated":"2015-09-16T05:14:13.646Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeb1001n74ufc56s0uc9"},{"title":"groovy","_content":"> 本文是对Groovy部分官方文档进行了翻译\n\n# 注释\n## 单行注释\n想要使用单行注释, 使用`//`就可以了.  本行中`//`后续的内容都会被认为是注释的一部分\n```groovy\n// a standalone single line comment\nprintln \"hello\" // a comment till the end of the line\n```\n\n## 多行注释\n多行注释从`/*`开始, 直到`*/`结束(跨行也包含在内)\n```groovy\n/* a standalone multiline comment\nspanning two lines */\nprintln \"hello\" /* a multiline comment starting\nat the end of a statement */\nprintln 1 /* one */ + 2 /* two */\n```\n### GroovyDoc 注释\n`GroovyDoc` 注释也是多行的, 但是它是以`/**`开始, `*/`结束定义的.\n这种注释一般用于以下情况：\n* 类型定义(包含 classes, interfaces, enums, annotations)\n* 字段和属性定义\n* 方法定义\n\n```groovy\n/**\n  * A Class description\n  */\n class Person {\n     /** the name of the person */\n     String name\n\n     /**\n      * Creates a greeting method for a certain person.\n      *\n      * @param otherPerson the person to greet\n      * @return ag reeting message\n      */\n     String greet(String otherPerson) {\n        \"Hello ${otherPerson}\"\n     }\n }\n```\n\n## Shebang line\n除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了`groovy`,并且在`PATH`里进行了配置)\n\n```groovy\n#!/usr/bin/env groovy\nprintln \"Hello from the shebang line\"\n```\n`#`字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误.\n\n# 标识符\n\n## 普通标识符\n\n标识符以一个`字母`或者`$`或者`_`开始, 不能以数字打头.\n如果以字母打头,他们在下列范围内\n\n* 'a' to 'z' (lowercase ascii letter)\n* 'A' to 'Z' (uppercase ascii letter)\n* '\\u00C0' to '\\u00D6'\n* '\\u00D8' to '\\u00F6'\n* '\\u00F8' to '\\u00FF'\n* '\\u0100' to '\\uFFFE'\n\n剩下的字符就可以包含字母或者数字了.  下面列举了一些合法的标识符：\n```groovy\ndef name\ndef item3\ndef with_underscore\ndef $dollarStart\n```\n下面是一些非法的标识符\n```groovy\ndef 3tier\ndef a+b\ndef a#b\n```\n`.`后面的关键字也是合法的标识符\n```groovy\nfoo.as\nfoo.assert\nfoo.break\nfoo.case\nfoo.catch\n```\n\n## 带引号的标识符\n\n带引号的标识符出现在`.\\`. 例如`person.name`表达式中的`name`部分能通过这俩种方式引起来`person.\"name\"`或者`person.\\'name'`. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号,\n```groovy\ndef map = [:]\n\nmap.\"an identifier with a space and double quotes\" = \"ALLOWED\"\nmap.'with-dash-signs-and-single-quotes' = \"ALLOWED\"\n\nassert map.\"an identifier with a space and double quotes\" == \"ALLOWED\"\nassert map.'with-dash-signs-and-single-quotes' == \"ALLOWED\"\n```\n\n正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的\n```groovy\nmap.'single quote'\nmap.\"double quote\"\nmap.'''triple single quote'''\nmap.\"\"\"triple double quote\"\"\"\nmap./slashy string/\nmap.$/dollar slashy string/$\n```\n\nstrings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier:\n```groovy\ndef firstname = \"Homer\"\nmap.\"Simson-${firstname}\" = \"Homer Simson\"\n\nassert map.'Simson-Homer' == \"Homer Simson\"\n```\n\n# 字符串\nText literals are represented in the form of chain of characters called strings. Groovy lets you instantiate `java.lang.String` objects, as well as GStrings (`groovy.lang.GString`) which are also called interpolated strings in other programming languages.\n\n在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化`java.lang.String`,像  GStrings (`groovy.lang.GString`)那样, (GString还被称为插值字符串)\n\n## 单引号字符\nSingle quoted strings are a series of characters surrounded by single quotes:\n\n单引号字符串是通过单引号括起来的一列字符\n```groovy\n'a single quoted string'\n```\nSingle quoted strings are plain `java.lang.String` and don’t support interpolation.\n\n单引号字符和`java.lang.String`是同一个东西, 同时它也不允许插值的出现\n## 字符串连接\n\nGroovy里所有的字符串都可以通过 `+` 连接起来\n```groovy\nassert 'ab' == 'a' + 'b'\n```\n\n## 三重单引号字符串\n\n三重单引号字符串 是通过三个单引号 包围起来的字符序列.\n```groovy\n'''a triple single quoted string'''\n```\n三重单引号字符串就是纯`java.lang.String` 而且不允许插值.\n三重单引号字符串可以多行赋值.\n```groovy\ndef aMultilineString = '''line one\nline two\nline three'''\n```\n\n如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用`String#stripIndent()` 去除掉缩进. `String#stripMargin()`方法会通过分割符从字符串的开头\n```groovy\ndef startingAndEndingWithANewline = '''\nline one\nline two\nline three\n'''\n```\n\n你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash:\n```groovy\ndef strippedFirstNewline = '''\\\nline one\nline two\nline three\n'''\n\nassert !strippedFirstNewline.startsWith('\\n')\n```\n\n### 更换特殊字符\n\n可以通过`\\`字符在`''`继续引用`'`\n```groovy\n'an escaped single quote: \\' needs a backslash'\n```\n\n当然也可以通过`\\`来引用它自身\n```groovy\n'an escaped escape character: \\\\ needs a double backslash'\n```\n\n还有一些其他的特殊字符需要`\\`来引用\n```groovy\nEscape sequence\tCharacter\n'\\t'\ttabulation\n'\\b'\tbackspace\n'\\n'\tnewline\n'\\r'\tcarriage return\n'\\f'\tformfeed\n'\\\\'\tbackslash\n'\\''\tsingle quote (for single quoted and triple single quoted strings)\n'\\\"'\tdouble quote (for double quoted and triple double quoted strings)\n```\n### Unicode 转义序列\n\n有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如`backslash`, 在u后跟4个16进制数字即可.\n\n```groovy\n'The Euro currency symbol: \\u20AC'\n```\n## 双引号包含的 string\n\n通过双引号包括起来的字符串\n```groovy\n\"a double quoted string\"\n```\nTo escape a double quote, you can use the backslash character: \"A double quote: \\\"\".\n\n当双引号字符串内没有插值(${})的时候, 那它就等同于`java.lang.String`, 当有插值的时候那么双引号字符串就是`groovy.lang.GString`的实例\n\n### String 插值\n\n任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过`${}` 或者 `$`来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式`toString()`方法,通过传递一个String参数.\n\n下面的例子展示的是字符串里的占位符定位本地变量\n```groovy\ndef name = 'Guillaume' // a plain string\ndef greeting = \"Hello ${name}\"\n\nassert greeting.toString() == 'Hello Guillaume'\n```\n\n但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式\n\n```groovy\ndef sum = \"The sum of 2 and 3 equals ${2 + 3}\"\nassert sum.toString() == 'The sum of 2 and 3 equals 5'\n```\n\n其实并不是只有表达式允许出现在`${}`表达式里. Statements 同样可以在`${}` 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在`${}`里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如`\"The sum of 1 and 2 is equal to ${def a = 1; def b = 2; a + b}\"` 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.\n除了` ${}`占位符之外, 我们也可以使用`$`标记前缀点缀表达式：\n\n```groovy\ndef person = [name: 'Guillaume', age: 36]\nassert \"$person.name is $person.age years old\" == 'Guillaume is 36 years old'\n```\n但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.\n下面给出了一个定义成数字形式的变量.\n```groovy\ndef number = 3.14\n```\n\n下面的 statement 将会抛出一个`groovy.lang.MissingPropertyException` 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性.\n```groovy\nshouldFail(MissingPropertyException) {\n    println \"$number.toString()\"\n}\n```\n你可以理解成解析器会将`\"$number.toString()\"` 解释成 `\"${number.toString}()\"`.如果你想要在GString中避免`$`或者`${}` 称为插值的话,只需要在它们前面加上`\\`即可.\n\n```groovy\nassert '${name}' == \"\\${name}\"\n```\n### 特殊插值形式-闭包表达式\n\n到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时`${→}`,这个表达式实际上就是一个闭包表达式.\n\n```groovy\ndef sParameterLessClosure = \"1 + 2 == ${-> 3}\" (1)\nassert sParameterLessClosure == '1 + 2 == 3'\n\ndef sOneParamClosure = \"1 + 2 == ${ w -> w << 3}\" (2)\nassert sOneParamClosure == '1 + 2 == 3'\n```\n1. 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参\n2. 上例中,闭包中使用了一个`java.io.StringWriter argument`参数, 我们可以使用`<<`操作符添加内容.不论任何情况, 占位符都被嵌入了闭包.\n\n上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算:\n\n```groovy\ndef number = 1 (1)\ndef eagerGString = \"value == ${number}\"\ndef lazyGString = \"value == ${ -> number }\"\n\nassert eagerGString == \"value == 1\" (2)\nassert lazyGString ==  \"value == 1\" (3)\n\nnumber = 2 (4)\nassert eagerGString == \"value == 1\" (5)\nassert lazyGString ==  \"value == 2\" (6)\n```\n1\tWe define a number variable containing 1 that we then interpolate within two GStrings, as an expression in eagerGString and as a closure in lazyGString.\n2\tWe expect the resulting string to contain the same string value of 1 for eagerGString.\n3\tSimilarily for lazyGString\n4\tThen we change the value of the variable to a new number\n5\tWith a plain interpolated expression, the value was actually bound at the time of creation of the GString.\n6\tBut with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value.\nAn embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed.\n\n1. 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中,\n2. 我们希望eagerGString 产生的字符串包含着相同的值 1\n3. 同样我们也希望lazyGString 产生的字符串包含着相同的值 1\n4. 然后我们将number改变一个值.\n5.\n6.\n\n### Inteoperability with Java\n当一个方法(不管是在Java还是在Groovy中定义的)带有一个`java.lang.String`参数, 但我们传递一个`groovy.lang.GString instance`实例, GString会自动调用toString()方法.\n\n```groovy\nString takeString(String message) {         (4)\n    assert message instanceof String        (5)\n    return message\n}\n\ndef message = \"The message is ${'hello'}\"   (1)\nassert message instanceof GString           (2)\n\ndef result = takeString(message)            (3)\nassert result instanceof String\nassert result == 'The message is hello'\n```\n1. 首先我们创建一个GString变量\n2. 然后我们检查一下声明的变量是否是GString的实例\n3. 接着我们向一个方法(参数为String类型)传递GString类型变量\n4. takeString()显式地指出了它唯一的参数为String\n5. 我们再次验证所需的参数是String 而不是GString\n\n\n### GString and String hashCodes\n\n尽管插值字符串能被用来代替`Java strings`, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是`immutable`, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的.\n\n```groovy\nassert \"one: ${1}\".hashCode() != \"one: 1\".hashCode()\n```\n\nGString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString.\n```groovy\ndef key = \"a\"\ndef m = [\"${key}\": \"letter ${key}\"]     (1)\n\nassert m[\"a\"] == null                   (2)\n```\n1. map使用一对键值被创建了出来,其key是GString类型\n2. 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode\n\n## Triple double quoted string\n\n三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样)\n```groovy\ndef name = 'Groovy'\ndef template = \"\"\"\n    Dear Mr ${name},\n\n    You're the winner of the lottery!\n\n    Yours sincerly,\n\n    Dave\n\"\"\"\n\nassert template.toString().contains('Groovy')\n```\n\n在三重双引号字符串中,不管是双引号还是单引号都不需要escaped\n\n## Slashy string\n除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的.\n\n```groovy\ndef fooPattern = /.*foo.*/\nassert fooPattern == '.*foo.*'\n```\n\n只有在`/ slashes`中需要使用\\ 来escaped\n```groovy\ndef escapeSlash = /The character \\/ is a forward slash/\nassert escapeSlash == 'The character / is a forward slash'\n```\n\nSlashy字符串也可以是多行的\n```groovy\ndef multilineSlashy = /one\n    two\n    three/\n\nassert multilineSlashy.contains('\\n')\n```\n\nSlashy字符串也可以插值形式出现(像GString一样)\n```groovy\ndef color = 'blue'\ndef interpolatedSlashy = /a ${color} car/\n\nassert interpolatedSlashy == 'a blue car'\n```\n\n下面有一些常识方面的东西需要你知道：\n`//`不会被解释为空Slashy字符串,这代表着行注释.\n\n```groovy\nassert '' == //\n```\n\n## Dollar slashy string\n\nDollar slashy字符串 通过`$/``/$` 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义\n```groovy\ndef name = \"Guillaume\"\ndef date = \"April, 1st\"\n\ndef dollarSlashy = $/\n    Hello $name,\n    today we're ${date}.\n\n    $ dollar sign\n    $$ escaped dollar sign\n    \\ backslash\n    / forward slash\n    $/ escaped forward slash\n    $/$ escaped dollar slashy string delimiter\n/$\n\nassert [\n    'Guillaume',\n    'April, 1st',\n    '$ dollar sign',\n    '$ escaped dollar sign',\n    '\\\\ backslash',\n    '/ forward slash',\n        '$/ escaped forward slash',\n        '/$ escaped dollar slashy string delimiter'\n\n        ].each { dollarSlashy.contains(it) }\n```\n\n## Characters\n\n不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量\n```groovy\nchar c1 = 'A' (1)\nassert c1 instanceof Character\n\ndef c2 = 'B' as char (2)\nassert c2 instanceof Character\n\ndef c3 = (char)'C' (3)\nassert c3 instanceof Character\n```\n1. 通过指定char类型来显式地声明一个character变量\n2. 通过操作符强制转换类型\n3. 通过强制转换成指定类型\n\n# Numbers\n\nGroovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现)\n\n## Integral literals\n\nThe integral literal types are the same as in Java:\n\n证书类型变量和Java里的一样\n\n* byte\n* char\n* short\n* int\n* long\n* java.lang.BigInteger\n\nYou can create integral numbers of those types with the following declarations:\n\n可以通过以下声明方式创建整数类型变量\n```groovy\n// primitive types\nbyte  b = 1\nchar  c = 2\nshort s = 3\nint   i = 4\nlong  l = 5\n\n// infinite precision\nBigInteger bi =  6\n```\n如果使用`def`关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型\n```groovy\ndef a = 1\nassert a instanceof Integer\n\n// Integer.MAX_VALUE\ndef b = 2147483647\nassert b instanceof Integer\n\n// Integer.MAX_VALUE + 1\ndef c = 2147483648\nassert c instanceof Long\n\n// Long.MAX_VALUE\ndef d = 9223372036854775807\nassert d instanceof Long\n\n// Long.MAX_VALUE + 1\ndef e = 9223372036854775808\nassert e instanceof BigInteger\n```\nAs well as for negative numbers:\n```groovy\ndef na = -1\nassert na instanceof Integer\n\n// Integer.MIN_VALUE\ndef nb = -2147483648\nassert nb instanceof Integer\n\n// Integer.MIN_VALUE - 1\ndef nc = -2147483649\nassert nc instanceof Long\n\n// Long.MIN_VALUE\ndef nd = -9223372036854775808\nassert nd instanceof Long\n\n// Long.MIN_VALUE - 1\ndef ne = -9223372036854775809\nassert ne instanceof BigInteger\n```\n\n### Alternative non-base 10 representations\n\n#### Binary literal\n\n在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据.\n```groovy\nint xInt = 0b10101111\nassert xInt == 175\n\nshort xShort = 0b11001001\nassert xShort == 201 as short\n\nbyte xByte = 0b11\nassert xByte == 3 as byte\n\nlong xLong = 0b101101101101\nassert xLong == 2925l\n\nBigInteger xBigInteger = 0b111100100001\nassert xBigInteger == 3873g\n\nint xNegativeInt = -0b10101111\nassert xNegativeInt == -175\n```\n#### Octal literal\n\n8进制的电话,只需要开头是0后跟要表示的8进制数即可.\n```groovy\nint xInt = 077\nassert xInt == 63\n\nshort xShort = 011\nassert xShort == 9 as short\n\nbyte xByte = 032\nassert xByte == 26 as byte\n\nlong xLong = 0246\nassert xLong == 166l\n\nBigInteger xBigInteger = 01111\nassert xBigInteger == 585g\n\nint xNegativeInt = -077\nassert xNegativeInt == -63\n```\n#### Hexadecimal literal\n\nHexadecimal numbers are specified in the typical format of 0x followed by hex digits.\n\n16进制的电话,只需要开头是0x后跟要表示的16进制数即可.\n```groovy\n\nint xInt = 0x77\nassert xInt == 119\n\nshort xShort = 0xaa\nassert xShort == 170 as short\n\nbyte xByte = 0x3a\nassert xByte == 58 as byte\n\nlong xLong = 0xffff\nassert xLong == 65535l\n\nBigInteger xBigInteger = 0xaaaa\nassert xBigInteger == 43690g\n\nDouble xDouble = new Double('0x1.0p0')\nassert xDouble == 1.0d\n\nint xNegativeInt = -0x77\nassert xNegativeInt == -119\n```\n\n## Decimal literals\n\n小数字面量和在java 里一样\n* float\n* double\n* java.lang.BigDecimal\n\n可以通过下面的方式创建小数类型的number\n```groovy\n// primitive types\nfloat  f = 1.234\ndouble d = 2.345\n\n// infinite precision\nBigDecimal bd =  3.456\n```\nDecimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent:\n\n\n```groovy\nassert 1e3  ==  1_000.0\nassert 2E4  == 20_000.0\nassert 3e+1 ==     30.0\nassert 4E-2 ==      0.04\nassert 5e-1 ==      0.5\n```\nConveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types.\n\nDecimal numbers can’t be represented using a binary, octal or hexadecimal representation.\n\n\n## Underscore in literals\n\nWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups:\n\n\n```groovy\nlong creditCardNumber = 1234_5678_9012_3456L\nlong socialSecurityNumbers = 999_99_9999L\ndouble monetaryAmount = 12_345_132.12\nlong hexBytes = 0xFF_EC_DE_5E\nlong hexWords = 0xFFEC_DE5E\nlong maxLong = 0x7fff_ffff_ffff_ffffL\nlong alsoMaxLong = 9_223_372_036_854_775_807L\nlong bytes = 0b11010010_01101001_10010100_10010010\n```\n\n## Number type suffixes\n\n我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制)\n```java\nType\t\t\tSuffix\nBigInteger\t\tG or g\nLong\t\t\tL or l\nInteger\t\t\tI or i\nBigDecimal\t\tG or g\nDouble\t\t\tD or d\nFloat\t\t\tF or f\n```\n```groovy\nassert 42I == new Integer('42')\nassert 42i == new Integer('42') // lowercase i more readable\nassert 123L == new Long(\"123\") // uppercase L more readable\nassert 2147483648 == new Long('2147483648') // Long type used, value too large for an Integer\nassert 456G == new BigInteger('456')\nassert 456g == new BigInteger('456')\nassert 123.45 == new BigDecimal('123.45') // default BigDecimal type used\nassert 1.200065D == new Double('1.200065')\nassert 1.234F == new Float('1.234')\nassert 1.23E23D == new Double('1.23E23')\nassert 0b1111L.class == Long // binary\nassert 0xFFi.class == Integer // hexadecimal\nassert 034G.class == BigInteger // octal\n```\n## Math operations\n\n尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型\n\n* byte, char, short 和 int 之间的二进制计算返回的是int类型\n* byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型\n* BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型\n* float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型\n* 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型.\n\nThe following table summarizes those rules:\n```groovy\n\n```\n\n由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字.\n\n### The case of the division operator\n\nThe division operators / (and /= for division and assignment) produce a double result if either operand is a float or double, and a BigDecimal result otherwise (when both operands are any combination of an integral type short, char, byte, int, long, BigInteger or BigDecimal).\n\nBigDecimal division is performed with the divide() method if the division is exact (ie. yielding a result that can be represented within the bounds of the same precision and scale), or using a MathContext with a precision of the maximum of the two operands' precision plus an extra precision of 10, and a scale of the maximum of 10 and the maximum of the operands' scale.\n\nFor integer division like in Java, you should use the intdiv() method, as Groovy doesn’t provide a dedicated integer division operator symbol.\n\n除法操作符`/`(和`/=`)会得到一个double类型的结果,\n\n### The case of the power operator\n\nGroovy 里有一种强大的操作符`**`, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型\n\n#### 如果exponent为小数类型\n```java\n1. 如果结果能表示为Integer类型,那就返回Integer类型\n2. 否则如果结果能表示为Long类型,那就返回Long类型\n3. 否则的话就返回Double\n```\n\n#### 如果exponent为整数类型\n```\n1. 如果exponent负数负数, 那就返回Integer, Long 或者Double,\n2. 如果exponent是正数或者0, 那就要根据base来判断了\n\tA. 如果base是 BigDecimal, 那就返回BigDecimal类型\n\tB. 如果base是 BigInteger, 那就返回BigInteger类型\n\tC. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger\n\tD. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger\n```\n\n#### 示例\n```groovy\n// base and exponent are ints and the result can be represented by an Integer\nassert    2    **   3    instanceof Integer    //  8\nassert   10    **   9    instanceof Integer    //  1_000_000_000\n\n// the base is a long, so fit the result in a Long\n// (although it could have fit in an Integer)\nassert    5L   **   2    instanceof Long       //  25\n\n// the result can't be represented as an Integer or Long, so return a BigInteger\nassert  100    **  10    instanceof BigInteger //  10e20\nassert 1234    ** 123    instanceof BigInteger //  170515806212727042875...\n\n// the base is a BigDecimal and the exponent a negative int\n// but the result can be represented as an Integer\nassert    0.5  **  -2    instanceof Integer    //  4\n\n// the base is an int, and the exponent a negative float\n// but again, the result can be represented as an Integer\nassert    1    **  -0.3f instanceof Integer    //  1\n\n// the base is an int, and the exponent a negative int\n// but the result will be calculated as a Double\n// (both base and exponent are actually converted to doubles)\nassert   10    **  -1    instanceof Double     //  0.1\n\n// the base is a BigDecimal, and the exponent is an int, so return a BigDecimal\nassert    1.2  **  10    instanceof BigDecimal //  6.1917364224\n\n// the base is a float or double, and the exponent is an int\n// but the result can only be represented as a Double value\nassert    3.4f **   5    instanceof Double     //  454.35430372146965\nassert    5.6d **   2    instanceof Double     //  31.359999999999996\n\n// the exponent is a decimal value\n// and the result can only be represented as a Double value\nassert    7.8  **   1.9  instanceof Double     //  49.542708423868476\nassert    2    **   0.1f instanceof Double     //  1.0717734636432956\n```\n\n\n# Booleans\nBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false.\n```groovy\ndef myBooleanVariable = true\nboolean untypedBooleanVar = false\nbooleanField = true\n```\ntrue and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators.\n\nIn addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.\n\n\n# IO\n## 读文件\n作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line ->\n    println line\n}\n```\n\n`eachLine`方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量:\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line, nb ->\n    println \"Line $nb: $line\"\n}\n```\n无论由于什么原因, 当`eachLine`中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效.\n\n例如, 某种情况你使用了`Reader`, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭.\n```groovy\ndef count = 0, MAXSIZE = 3\nnew File(baseDir,\"haiku.txt\").withReader { reader ->\n    while (reader.readLine()) {\n        if (++count > MAXSIZE) {\n            throw new RuntimeException('Haiku should only have 3 verses')\n        }\n    }\n}\n```\n\n如果你想要把文本文件中每一行都放进一个list中, 你可以这么做:\n```groovy\ndef list = new File(baseDir, 'haiku.txt').collect {it}\n```\n\n或者你想利用操作符将文件中每一行都添加到一个数组中:\n```groovy\ndef array = new File(baseDir, 'haiku.txt') as String[]\n```\n\n下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里:\n```groovy\nbyte[] contents = file.bytes\n```\n\n如下例,我们轻松地获得了一个输入流.\n```groovy\ndef is = new File(baseDir,'haiku.txt').newInputStream()\n// do something ...\nis.close()\n```\n\n上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法`withInputStream`, 这个方法可以帮我们自动的关闭输入流.\n```groovy\nnew File(baseDir,'haiku.txt').withInputStream { stream ->\n    // do something ...\n}\n```\n\n## 写文件\n\n有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件\n```groovy\nnew File(baseDir,'haiku.txt').withWriter('utf-8') { writer ->\n    writer.writeLine 'Into the ancient pond'\n    writer.writeLine 'A frog jumps'\n    writer.writeLine 'Water’s sound!'\n}\n```\n\n但对于一个要求很简单的需求来说,我们可以使用`<<`向文件中写\n```groovy\nnew File(baseDir,'haiku.txt') << '''Into the ancient pond\nA frog jumps\nWater’s sound!'''\n```\n\n当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节:\n```groovy\nfile.bytes = [66,22,11]\n```\n\n当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流.\n```groovy\ndef os = new File(baseDir,'data.bin').newOutputStream()\n// do something ...\nos.close()\n```\n\n同`newInputStream`一样,`newOutputStream`同样需要手动关闭, ok,你大概想到了`withOutputStream`:\n```groovy\nnew File(baseDir,'data.bin').withOutputStream { stream ->\n    // do something ...\n}\n```\n\n## 遍历文件\n\n在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作:\n```groovy\ndir.eachFile { file ->                      (1)\n    println file.name\n}\ndir.eachFileMatch(~/.*\\.txt/) { file ->     (2)\n    println file.name\n}\n```\n\n1. 在目录下的每个文件上执行闭包操作.\n2. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作.\n\n也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用`eachFileRecurse`\n```groovy\ndir.eachFileRecurse { file ->                      (1)\n    println file.name\n}\n\ndir.eachFileRecurse(FileType.FILES) { file ->      (2)\n    println file.name\n}\n```\n1. 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作\n2. 对目录里进行递归查找,但是只查找文件.\n\n```groovy\ndir.traverse { file ->\n    if (file.directory && file.name=='bin') {\n        FileVisitResult.TERMINATE                   (1)\n    } else {\n        println file.name\n        FileVisitResult.CONTINUE                    (2)\n    }\n\n}\n```\n1. 如果找到的文件是目录,且它的名字是\"dir\", 则停止遍历\n2.  打印出文件的名字,接着遍历\n\n## 序列化\n\n在java中会使用`java.io.DataOutputStream` 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化:\n```groovy\nboolean b = true\nString message = 'Hello from Groovy'\n// Serialize data into a file\nfile.withDataOutputStream { out ->\n    out.writeBoolean(b)\n    out.writeUTF(message)\n}\n// ...\n// Then read it back\nfile.withDataInputStream { input ->\n    assert input.readBoolean() == b\n    assert input.readUTF() == message\n}\n```\n\n同样,如果这个数据实例了序列化接口`Serializable`, 你可以使用 object output stream将整个数据序列化到文件:\n```groovy\nPerson p = new Person(name:'Bob', age:76)\n// Serialize data into a file\nfile.withObjectOutputStream { out ->\n    out.writeObject(p)\n}\n// ...\n// Then read it back\nfile.withObjectInputStream { input ->\n    def p2 = input.readObject()\n    assert p2.name == p.name\n    assert p2.age == p.age\n}\n```\n\n## 执行命令\n\n前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令.\n\nGroovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的`execute()`. 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令.\n```groovy\ndef process = \"ls -l\".execute()             (1)\nprintln \"Found text ${process.text}\"        (2)\n```\n1. 在外部过程(external process)执行ls命令\n2. 获得命令的输出,并输出\n\n`execute()`方法返回一个`java.lang.Process`实例, 随后选择一种输出流`in/out/err`, 同时检查`exit`值,查看是否命令执行完毕.\n\n下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出.\n```groovy\n            def process = \"ls -l\".execute()             (1)\n            process.in.eachLine { line ->               (2)\n                println line                            (3)\n            }\n            assert process instanceof Process\n        }\n    }\n\n    void testProcessConsumeOutput() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                File file = null\n                def tmpDir = b.tmp {\n                    file = 'foo.tmp'('foo')\n                }\n                assert file.exists()\n                def p = \"rm -f foo.tmp\".execute([], tmpDir)\n                p.consumeProcessOutput()\n                p.waitFor()\n                assert !file.exists()\n            }\n\n        }\n    }\n\n    void testProcessPipe() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                def proc1, proc2, proc3, proc4\n                proc1 = 'ls'.execute()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc1 | proc2 | proc3 | proc4\n                proc4.waitFor()\n                if (proc4.exitValue()) {\n                    println proc4.err.text\n                } else {\n                    println proc4.text\n                }\n\n                def sout = new StringBuilder()\n                def serr = new StringBuilder()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc4.consumeProcessOutput(sout, serr)\n                proc2 | proc3 | proc4\n                [proc2, proc3].each { it.consumeProcessErrorStream(serr) }\n                proc2.withWriter { writer ->\n                    writer << 'testfile.groovy'\n                }\n                proc4.waitForOrKill(1000)\n                println \"Standard output: $sout\"\n                println \"Standard error: $serr\"\n            }\n        }\n    }\n\n    public static class Person implements Serializable {\n        String name\n        int age\n    }\n}\n```\n\n1\texecutes the ls command in an external process\n2\tfor each line of the input stream of the process\n3\tprint the line\n1. 在外部进程中执行ls命令\n2.\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input).\n\n\nRemember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write:\n\n```groovy\ndef process = \"dir\".execute()\nprintln \"${process.text}\"\n```\n\n接着你会收到一个异常`IOException`,异常信息为`Cannot run program \"dir\": CreateProcess error=2`,系统找不到指定的文件.\n\n这是因为`dir`是内建于`windows shell(cmd.ext)`, 想要使用那个命令,你要像下面这个样操作:\n```groovy\ndef process = \"cmd /c dir\".execute()\nprintln \"${process.text}\"\n```\n\n还有,因为上述的功能是在内部使用的`java.lang.Process`, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的:\n\n> Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\nBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier.\n\n现在演示一下,如何输出进程里所有的输出(包括error stream).\n```groovy\ndef p = \"rm -f foo.tmp\".execute([], tmpDir)\np.consumeProcessOutput()\np.waitFor()\n```\n\n`consumeProcessOutput`仍然有很多对`StringBuffer`, `InputStream`, `OutputStream`等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 [GDK API for java.lang.Process](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Process.html)\n\n另外, `pipeTo`命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例:\n\n```groovy\nproc1 = 'ls'.execute()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc1 | proc2 | proc3 | proc4\nproc4.waitFor()\nif (proc4.exitValue()) {\n    println proc4.err.text\n} else {\n    println proc4.text\n}\n```\nConsuming errors\n```groovy\ndef sout = new StringBuilder()\ndef serr = new StringBuilder()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc4.consumeProcessOutput(sout, serr)\nproc2 | proc3 | proc4\n[proc2, proc3].each { it.consumeProcessErrorStream(serr) }\nproc2.withWriter { writer ->\n    writer << 'testfile.groovy'\n}\nproc4.waitForOrKill(1000)\nprintln \"Standard output: $sout\"\nprintln \"Standard error: $serr\"\n```\n\n# 集合\n\nGroovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法.\n## Lists\n\nGroovy使用了一种被`[]`括起来,值通过`,`分割的语法 定义list. Groovy list 采用的是 JDK里`java.util.List`的实现, 因为它自身并没有定义自己的集合类.\nGroovy list 的默认实现是`java.util.ArrayList`, 在后面我们可以看到其他形式的list\n\n```groovy\ndef numbers = [1, 2, 3]         (1)\n\nassert numbers instanceof List  (2)\nassert numbers.size() == 3      (3)\n```\n\n1. 我们定义了一个Number类型的List,然后将这个list分配给一个变量\n2. 判断list是 Java’s `java.util.List` interface 的实例\n3. list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素\n\n在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样：\n```groovy\ndef heterogeneous = [1, \"a\", true]  (1)\n```\n1. 我们定义了一个包含有number,string,boolean 三个类型的list\n\n在上面我们提到过, list实际上是`java.util.ArrayList`实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现\n```groovy\ndef arrayList = [1, 2, 3]\nassert arrayList instanceof java.util.ArrayList\n\ndef linkedList = [2, 3, 4] as LinkedList    (1)\nassert linkedList instanceof java.util.LinkedList\n\nLinkedList otherLinked = [3, 4, 5]          (2)\nassert otherLinked instanceof java.util.LinkedList\n```\n1. 我们使用操作符强制将类型显式地声明为`java.util.LinkedList`\n2. 我们使用显式声明方式, 将list声明为`java.util.LinkedList`\n\n我们可以通过`[]`下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用`<<`操作符向list里追加元素\n```groovy\ndef letters = ['a', 'b', 'c', 'd']\n\nassert letters[0] == 'a'     (1)\nassert letters[1] == 'b'\n\nassert letters[-1] == 'd'    (2)\nassert letters[-2] == 'c'\n\nletters[2] = 'C'             (3)\nassert letters[2] == 'C'\n\nletters << 'e'               (4)\nassert letters[ 4] == 'e'\nassert letters[-1] == 'e'\n\nassert letters[1, 3] == ['b', 'd']         (5)\nassert letters[2..4] == ['C', 'd', 'e']    (6)\n```\n\n1. 访问第一个元素(从这可以看出,list的下标是从0开始的)\n2. 通过-1 下标访问list中的最后一个元素.\n3. 使用下标对list中第三个元素重新赋值\n4. 使用`<<`向list尾部添加一个元素\n5. 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list\n6. 使用值域符来访问list中一定范围内的值.\n\n由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list\n```groovy\ndef multi = [[0, 1], [2, 3]]     (1)\nassert multi[1][0] == 2          (2)\n```\n\n1. 定义了一个包含Number类型list的list\n2. 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素)\n\n### List literals\n\n你可以像下面这样创建集合, 注意`[]`是空集合表达式.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.get(2) == 7\nassert list[2] == 7\nassert list instanceof java.util.List\n\ndef emptyList = []\nassert emptyList.size() == 0\nemptyList.add(5)\nassert emptyList.size() == 1\n```groovy\n\n每一个list表达式都是实现自`java.util.List`\n\n当然list也可以指定其具体的实现类型\n```groovy\ndef list1 = ['a', 'b', 'c']\n//construct a new list, seeded with the same items as in list1\ndef list2 = new ArrayList<String>(list1)\n\nassert list2 == list1 // == checks that each corresponding element is the same\n\n// clone() can also be called\ndef list3 = list1.clone()\nassert list3 == list1\n```\n\nlist本质上是一个有序的对象集合.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.size() == 4\nassert list.getClass() == ArrayList     // the specific kind of list being used\n\nassert list[2] == 7                     // indexing starts at 0\nassert list.getAt(2) == 7               // equivalent method to subscript operator []\nassert list.get(2) == 7                 // alternative method\n\nlist[2] = 9\nassert list == [5, 6, 9, 8,]           // trailing comma OK\n\nlist.putAt(2, 10)                       // equivalent method to [] when value being changed\nassert list == [5, 6, 10, 8]\nassert list.set(2, 11) == 10            // alternative method that returns old value\nassert list == [5, 6, 11, 8]\n\nassert ['a', 1, 'a', 'a', 2.5, 2.5f, 2.5d, 'hello', 7g, null, 9 as byte]\n//objects can be of different types; duplicates allowed\n\nassert [1, 2, 3, 4, 5][-1] == 5             // use negative indices to count from the end\nassert [1, 2, 3, 4, 5][-2] == 4\nassert [1, 2, 3, 4, 5].getAt(-2) == 4       // getAt() available with negative index...\ntry {\n    [1, 2, 3, 4, 5].get(-2)                 // but negative index not allowed with get()\n    assert false\n} catch (e) {\n    assert e instanceof ArrayIndexOutOfBoundsException\n}\n```\n\n### List as a boolean expression\n\nlist还可以计算出boolean表达式.\n```groovy\nassert ![]             // an empty list evaluates as false\n\n//all other lists, irrespective of contents, evaluate as true\nassert [1] && ['a'] && [0] && [0.0] && [false] && [null]\n```\n\n### Iterating on a list\n\n可以通过`each`, `eachWithIndex`遍历整个集合.\n```groovy\n[1, 2, 3].each {\n    println \"Item: $it\" // `it` is an implicit parameter corresponding to the current element\n}\n['a', 'b', 'c'].eachWithIndex { it, i -> // `it` is the current element, while `i` is the index\n    println \"$i: $it\"\n}\n```\n\n在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过`collect`方法实现.\n```groovy\nassert [1, 2, 3].collect { it * 2 } == [2, 4, 6]\n\n// shortcut syntax instead of collect\nassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect { it.multiply(2) }\n\ndef list = [0]\n// it is possible to give `collect` the list which collects the elements\nassert [1, 2, 3].collect(list) { it * 2 } == [0, 2, 4, 6]\nassert list == [0, 2, 4, 6]\n```\n\n### Manipulating lists\n\n#### Filtering and searching\n\n[Groovy development kit](http://www.groovy-lang.org/gdk.html)提供了许多强大有趣的方法用来强化标准集合:\n\n```groovy\nassert [1, 2, 3].find { it > 1 } == 2           // find 1st element matching criteria\nassert [1, 2, 3].findAll { it > 1 } == [2, 3]   // find all elements matching critieria\nassert ['a', 'b', 'c', 'd', 'e'].findIndexOf {      // find index of 1st element matching criteria\n    it in ['c', 'e', 'g']\n} == 2\n\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('c') == 2  // index returned\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('z') == -1 // index -1 means value not in list\nassert ['a', 'b', 'c', 'd', 'c'].lastIndexOf('c') == 4\n\nassert [1, 2, 3].every { it < 5 }               // returns true if all elements match the predicate\nassert ![1, 2, 3].every { it < 3 }\nassert [1, 2, 3].any { it > 2 }                 // returns true if any element matches the predicate\nassert ![1, 2, 3].any { it > 3 }\n\nassert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() method\nassert ['a', 'b', 'c', 'd', 'e'].sum {\n    it == 'a' ? 1 : it == 'b' ? 2 : it == 'c' ? 3 : it == 'd' ? 4 : it == 'e' ? 5 : 0\n    // custom value to use in sum\n} == 15\nassert ['a', 'b', 'c', 'd', 'e'].sum { ((char) it) - ((char) 'a') } == 10\nassert ['a', 'b', 'c', 'd', 'e'].sum() == 'abcde'\nassert [['a', 'b'], ['c', 'd']].sum() == ['a', 'b', 'c', 'd']\n\n// an initial value can be provided\nassert [].sum(1000) == 1000\nassert [1, 2, 3].sum(1000) == 1006\n\nassert [1, 2, 3].join('-') == '1-2-3'           // String joining\nassert [1, 2, 3].inject('counting: ') {\n    str, item -> str + item                     // reduce operation\n} == 'counting: 123'\nassert [1, 2, 3].inject(0) { count, item ->\n    count + item\n} == 6\n```\n\n下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子:\n```groovy\ndef list = [9, 4, 2, 10, 5]\nassert list.max() == 10\nassert list.min() == 2\n\n// we can also compare single characters, as anything comparable\nassert ['x', 'y', 'a', 'z'].min() == 'a'\n\n// we can use a closure to specify the sorting behaviour\ndef list2 = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list2.max { it.size() } == 'xyzuvw'\nassert list2.min { it.size() } == 'z'\n```\n\n在闭包里,你还可以自定义一个比较规则.\n```groovy\nComparator mc = { a, b -> a == b ? 0 : (a < b ? -1 : 1) }\n\ndef list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list.max(mc) == 11\nassert list.min(mc) == -13\n\nComparator mc2 = { a, b -> a == b ? 0 : (Math.abs(a) < Math.abs(b)) ? -1 : 1 }\n\n\nassert list.max(mc2) == -13\nassert list.min(mc2) == -1\n\nassert list.max { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -13\nassert list.min { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -1\n```\n\n#### Adding or removing elements\n\n我们可以使用`[]`去声明一个新的空list, 然后使用`<<`向list追加元素\n```groovy\ndef list = []\nassert list.empty\n\nlist << 5\nassert list.size() == 1\n\nlist << 7 << 'i' << 11\nassert list == [5, 7, 'i', 11]\n\nlist << ['m', 'o']\nassert list == [5, 7, 'i', 11, ['m', 'o']]\n\n//first item in chain of << is target list\nassert ([1, 2] << 3 << [4, 5] << 6) == [1, 2, 3, [4, 5], 6]\n\n//using leftShift is equivalent to using <<\nassert ([1, 2, 3] << 4) == ([1, 2, 3].leftShift(4))\n```groovy\nWe can add to a list in many ways:\n```groovy\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]\n// equivalent to calling the `plus` method\nassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]\n\ndef a = [1, 2, 3]\na += 4      // creates a new list and assigns it to `a`\na += [5, 6]\nassert a == [1, 2, 3, 4, 5, 6]\n\nassert [1, *[222, 333], 456] == [1, 222, 333, 456]\nassert [*[1, 2, 3]] == [1, 2, 3]\nassert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ndef list = [1, 2]\nlist.add(3)\nlist.addAll([5, 4])\nassert list == [1, 2, 3, 5, 4]\n\nlist = [1, 2]\nlist.add(1, 3) // add 3 just before index 1\nassert list == [1, 3, 2]\n\nlist.addAll(2, [5, 4]) //add [5,4] just before index 2\nassert list == [1, 3, 5, 4, 2]\n\nlist = ['a', 'b', 'z', 'e', 'u', 'v', 'g']\nlist[8] = 'x' // the [] operator is growing the list as needed\n// nulls inserted if required\nassert list == ['a', 'b', 'z', 'e', 'u', 'v', 'g', null, 'x']\n```\n\n在list中`+`的语义并没有发生变化,这是何等的重要啊~~~ 与`<<`相比, `+`会创建一个新的list,  但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题.\n\n`Groovy development kit`同样提供了很多便捷的方式从list里删除元素:\n```groovy\nassert ['a','b','c','b','b'] - 'c' == ['a','b','b','b']\nassert ['a','b','c','b','b'] - 'b' == ['a','c']\nassert ['a','b','c','b','b'] - ['b','c'] == ['a']\n\ndef list = [1,2,3,4,3,2,1]\nlist -= 3           // creates a new list by removing `3` from the original one\nassert list == [1,2,4,2,1]\nassert ( list -= [2,4] ) == [1,1]\n```\n同样,你也能通过索引的方式从list里删除元素.\n```groovy\ndef list = [1,2,3,4,5,6,2,2,1]\nassert list.remove(2) == 3          // remove the third element, and return it\nassert list == [1,2,4,5,6,2,2,1]\n```\n假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用`remove`方法.\n```groovy\ndef list= ['a','b','c','b','b']\nassert list.remove('c')             // remove 'c', and return true because element removed\nassert list.remove('b')             // remove first 'b', and return true because element removed\n\nassert ! list.remove('z')           // return false because no elements removed\nassert list == ['a','b','b']\n```\n如果你想要将list清空的话,只需要调用`clear`方法即可\n```groovy\ndef list= ['a',2,'c',4]\nlist.clear()\nassert list == []\n```\n\n#### Set operations\n\n`Groovy development kit`还包含很多逻辑运算的方法\n```groovy\nassert 'a' in ['a','b','c']             // returns true if an element belongs to the list\nassert ['a','b','c'].contains('a')      // equivalent to the `contains` method in Java\nassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are found\n\nassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some value\nassert [1,2,3,3,3,3,4,5].count {\n    it%2==0                             // count the number of elements which match the predicate\n} == 2\n\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]\n\nassert [1,2,3].disjoint( [4,6,9] )\nassert ![1,2,3].disjoint( [2,4,6] )\n```\n\n#### Sorting\n\nGroovy还提供了很多使用闭包比较器的排序操作\n```groovy\nassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]\n\ndef list = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list.sort {\n    it.size()\n} == ['z', 'abc', '321', 'Hello', 'xyzuvw']\n\ndef list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list2.sort { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } ==\n        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\nComparator mc = { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 }\n\n// JDK 8+ only\n// list2.sort(mc)\n// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\ndef list3 = [6, -3, 9, 2, -7, 1, 5]\n\nCollections.sort(list3)\nassert list3 == [-7, -3, 1, 2, 5, 6, 9]\n\nCollections.sort(list3, mc)\nassert list3 == [1, 2, -3, 5, 6, -7, 9]\n```\n\n#### Duplicating elements\n\n`roovy development kit`还通过重载操作符的方式, 内部提供了一些方法进行list元素复制.\n```groovy\nassert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]\nassert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]\nassert Collections.nCopies(3, 'b') == ['b', 'b', 'b']\n\n// nCopies from the JDK has different semantics than multiply for lists\nassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2]\n```\n\n## Arrays\n\nGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型\n```groovy\nString[] arrStr = ['Ananas', 'Banana', 'Kiwi']  (1)\n\nassert arrStr instanceof String[]    (2)\nassert !(arrStr instanceof List)\n\ndef numArr = [1, 2, 3] as int[]      (3)\n\nassert numArr instanceof int[]       (4)\nassert numArr.size() == 3\n```\n\n1. 使用显式变量类型定义了一个字符串数组\n2. 断言刚才创建的数组是否是string类型\n3. 使用操作符定义一个int数组\n4. 断言刚才创建的数组是否是int类型\n\n我们也可以创建出一个多维数组\n```groovy\ndef matrix3 = new Integer[3][3]         (1)\nassert matrix3.size() == 3\n\nInteger[][] matrix2                     (2)\nmatrix2 = [[1, 2], [3, 4]]\nassert matrix2 instanceof Integer[][]\n```\n1. 我们指定了新数组的边界\n2. 当然我们也可以不指定它的边界\n\n访问数组元素和访问list元素的方式相同\n```groovy\nString[] names = ['Cédric', 'Guillaume', 'Jochen', 'Paul']\nassert names[0] == 'Cédric'     (1)\n\nnames[2] = 'Blackdrag'          (2)\nassert names[2] == 'Blackdrag'\n```\n1\tRetrieve the first element of the array\n2\tSet the value of the third element of the array to a new value\n1. 检索数组中第一个元素\n2. 对数组中第三个元素重新赋值\n\nGroovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包\n\n## Maps\n有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被`[]`括起来, 通过`,`分割键值对, 键值通过`:`分割\n```groovy\ndef colors = [red: '#FF0000', green: '#00FF00', blue: '#0000FF']   (1)\n\nassert colors['red'] == '#FF0000'    (2)\nassert colors.green  == '#00FF00'    (3)\n\ncolors['pink'] = '#FF00FF'           (4)\ncolors.yellow  = '#FFFF00'           (5)\n\nassert colors.pink == '#FF00FF'\nassert colors['yellow'] == '#FFFF00'\n\nassert colors instanceof java.util.LinkedHashMap\n```\n\n1. 我们定义了一个string类型的代表颜色名字的数组,\n2. 然后使用下标来检索map中是否包含red这个key\n3. 我们还可以直接使用`.`来索引到某个key\n4. 我们可以使用下标向map中添加一个新的键值对\n5. 我们也可以使用`.`添加一个新的键值对\n\nGroovy创建的map类型默认的是`java.util.LinkedHashMap`\n\n当你想要访问一个不存在的key时：\n```groovy\nassert colors.unknown == null\n```\n你将检索出一个null的结果\n\n在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key：\n\n```groovy\ndef numbers = [1: 'one', 2: 'two']\n\nassert numbers[1] == 'one'\n```\n\n我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key：\n\n```groovy\ndef key = 'name'\ndef person = [key: 'Guillaume']      (1)\n\nassert !person.containsKey('name')   (2)\nassert person.containsKey('key')     (3)\n```\n1. 与`\\'Guillaume'` 关联的key实际上是`\"key\"`这个字符串, 而不是这个key的引用值`'name'`\n2. map中不包含`'name'`key\n3. 取而代之的是map中包含一个`\"key\"`的字符串\n\n你可以向map中传递一个引号字符串作为key,例如`[\"name\": \"Guillaume\"]`.\n\n```groovy\nperson = [(key): 'Guillaume']        (1)\n\nassert person.containsKey('name')    (2)\nassert !person.containsKey('key')    (3)\n```\n1\tThis time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key\n2\tThe map does contain the name key\n3\tBut the map doesn’t contain the key key as before\n1.\n2.\n3.\n\n### Map literals\n\n在Groovy中可以使用`[:]` 创建一个map.\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.get('name') == 'Gromit'\nassert map.get('id') == 1234\nassert map['name'] == 'Gromit'\nassert map['id'] == 1234\nassert map instanceof java.util.Map\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.put(\"foo\", 5)\nassert emptyMap.size() == 1\nassert emptyMap.get(\"foo\") == 5\n```\n\nMap的key默认是`string`, 例如`[a:1]`等同于`['a':1]`. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量a`put`进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用`()`key进行转义了.\n```groovy\ndef a = 'Bob'\ndef ages = [a: 43]\nassert ages['Bob'] == null // `Bob` is not found\nassert ages['a'] == 43     // because `a` is a literal!\n\nages = [(a): 43]            // now we escape `a` by using parenthesis\nassert ages['Bob'] == 43   // and the value is found!\n```\n\n通过下面的方式你可以轻松克隆一个map\n```groovy\ndef map = [\n        simple : 123,\n        complex: [a: 1, b: 2]\n]\ndef map2 = map.clone()\nassert map2.get('simple') == map.get('simple')\nassert map2.get('complex') == map.get('complex')\nmap2.get('complex').put('c', 3)\nassert map.get('complex').get('c') == 3\n```\n\n### Map property notation\n\nMaps和beans也是非常相像的, 所以你可以对map使用`get/set`操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key.\n\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.name == 'Gromit'     // can be used instead of map.get('Gromit')\nassert map.id == 1234\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.foo = 5\nassert emptyMap.size() == 1\nassert emptyMap.foo == 5\n```\n\n注意:`map.foo`总是会在map中查找key`foo`. 这意味着,\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.class == null\nassert map.get('class') == null\nassert map.getClass() == LinkedHashMap // this is probably what you want\n\nmap = [1      : 'a',\n       (true) : 'p',\n       (false): 'q',\n       (null) : 'x',\n       'null' : 'z']\nassert map.containsKey(1) // 1 is not an identifier so used as is\nassert map.true == null\nassert map.false == null\nassert map.get(true) == 'p'\nassert map.get(false) == 'q'\nassert map.null == 'z'\nassert map.get(null) == 'x'\n```\n\n### Iterating on maps\n\n`Groovy development kit`还提供了`eachWithIndex`方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的.\n```groovy\ndef map = [\n        Bob  : 42,\n        Alice: 54,\n        Max  : 33\n]\n\n// `entry` is a map entry\nmap.each { entry ->\n    println \"Name: $entry.key Age: $entry.value\"\n}\n\n// `entry` is a map entry, `i` the index in the map\nmap.eachWithIndex { entry, i ->\n    println \"$i - Name: $entry.key Age: $entry.value\"\n}\n\n// Alternatively you can use key and value directly\nmap.each { key, value ->\n    println \"Name: $key Age: $value\"\n}\n\n// Key, value and i as the index in the map\nmap.eachWithIndex { key, value, i ->\n    println \"$i - Name: $key Age: $value\"\n}\n```\n\n### Manipulating maps\n\n#### Adding or removing elements\n\n向map中添加元素你可以使用`put`方法, `下标`, `putAll`方法.\n```groovy\ndef defaults = [1: 'a', 2: 'b', 3: 'c', 4: 'd']\ndef overrides = [2: 'z', 5: 'x', 13: 'x']\n\ndef result = new LinkedHashMap(defaults)\nresult.put(15, 't')\nresult[17] = 'u'\nresult.putAll(overrides)\nassert result == [1: 'a', 2: 'z', 3: 'c', 4: 'd', 5: 'x', 13: 'x', 15: 't', 17: 'u']\n```\n\n如果想要删除map中全部的元素,可以使用`clear`方法.\n```groovy\ndef m = [1:'a', 2:'b']\nassert m.get(1) == 'a'\nm.clear()\nassert m == [:]\n```\n\n通过map字面量标记创建的map会使用`object`的`equals`方法和`hashcode`方法.\n\n还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样.\n```groovy\ndef key = 'some key'\ndef map = [:]\ndef gstringKey = \"${key.toUpperCase()}\"\nmap.put(gstringKey,'value')\nassert map.get('SOME KEY') == null\n```\n\n#### Keys, values and entries\n\n我们可以在视图中inspect`keys, values, and entries`\n```groovy\ndef map = [1:'a', 2:'b', 3:'c']\n\ndef entries = map.entrySet()\nentries.each { entry ->\n  assert entry.key in [1,2,3]\n  assert entry.value in ['a','b','c']\n}\n\ndef keys = map.keySet()\nassert keys == [1,2,3] as Set\n```\n\nMutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values.\n\n\n#### Filtering and searching\n\nThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists:\n\n```groovy\ndef people = [\n    1: [name:'Bob', age: 32, gender: 'M'],\n    2: [name:'Johnny', age: 36, gender: 'M'],\n    3: [name:'Claire', age: 21, gender: 'F'],\n    4: [name:'Amy', age: 54, gender:'F']\n]\n\ndef bob = people.find { it.value.name == 'Bob' } // find a single entry\ndef females = people.findAll { it.value.gender == 'F' }\n\n// both return entries, but you can use collect to retrieve the ages for example\ndef ageOfBob = bob.value.age\ndef agesOfFemales = females.collect {\n    it.value.age\n}\n\nassert ageOfBob == 32\nassert agesOfFemales == [21,54]\n\n// but you could also use a key/pair value as the parameters of the closures\ndef agesOfMales = people.findAll { id, person ->\n    person.gender == 'M'\n}.collect { id, person ->\n    person.age\n}\nassert agesOfMales == [32, 36]\n\n// `every` returns true if all entries match the predicate\nassert people.every { id, person ->\n    person.age > 18\n}\n\n// `any` returns true if any entry matches the predicate\n\nassert people.any { id, person ->\n    person.age == 54\n}\n```\n\n#### Grouping\n\nWe can group a list into a map using some criteria:\n\n```groovy\nassert ['a', 7, 'b', [2, 3]].groupBy {\n    it.class\n} == [(String)   : ['a', 'b'],\n      (Integer)  : [7],\n      (ArrayList): [[2, 3]]\n]\n\nassert [\n        [name: 'Clark', city: 'London'], [name: 'Sharma', city: 'London'],\n        [name: 'Maradona', city: 'LA'], [name: 'Zhang', city: 'HK'],\n        [name: 'Ali', city: 'HK'], [name: 'Liu', city: 'HK'],\n].groupBy { it.city } == [\n        London: [[name: 'Clark', city: 'London'],\n                 [name: 'Sharma', city: 'London']],\n        LA    : [[name: 'Maradona', city: 'LA']],\n        HK    : [[name: 'Zhang', city: 'HK'],\n                 [name: 'Ali', city: 'HK'],\n                 [name: 'Liu', city: 'HK']],\n]\n```\n\n## Ranges\n\nRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List.\n\nRanges defined with the .. notation are inclusive (that is the list contains the from and to value).\n\nRanges defined with the ..< notation are half-open, they include the first value but not the last value.\n\n```groovy\n// an inclusive range\ndef range = 5..8\nassert range.size() == 4\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert range.contains(8)\n\n// lets use a half-open range\nrange = 5..<8\nassert range.size() == 3\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert !range.contains(8)\n\n//get the end points of the range without using indexes\nrange = 1..10\nassert range.from == 1\nassert range.to == 10\n```\n\nNote that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value.\n\nRanges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:\n\n# Parsing and producing JSON\n\nGroovy 原生支持Groovy对象和JSON之间的转换. `groovy.json`包内的类用于JSON的序列化和解析功能\n\n# JsonSlurper\n\n`JsonSlurper`用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如`maps</code>, `lists</code>, 或者其他原生基本类型 `Integer</code>, `Double</code>, `Boolean</code>, `String`。\n\n这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如`parseText</code>, `parseFile` 等.下面这个例子中我们使用了 `parseText` 方法, 它会解析一个JSON字符串, 然后递归地将它转换成`list</code>, `map`结构. 一些其他的`parse*</code> 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样.\n\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"name\": \"John Doe\" } /* some comment */')\n\nassert object instanceof Map\nassert object.name == 'John Doe'\n```\n\n需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. `JsonSlurper`根据[ECMA-404 JSON Interchange Standard](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)定义来解析JSON, 同时支持JavaScript的注释和时间类型.\n\n除了支持maps之外, `JsonSlurper` 还支持将JSON数组解析成list的功能\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\nJSON标准上只支持下面这些原生数据类型：`string</code>, `number</code>, `object</code>, `true</code>, `false</code>, `null</code>. `JsonSlurper` 将那些JSON类型转换成Groovy类型.\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText '''\n    { \"simple\": 123,\n      \"fraction\": 123.66,\n      \"exponential\": 123e12\n    }'''\n\nassert object instanceof Map\nassert object.simple.class == Integer\nassert object.fraction.class == BigDecimal\nassert object.exponential.class == BigDecimal\n```\n\n`JsonSlurper` 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上`JsonSlurper`的结果遵循`GPath`表达式. `GPath`是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如`XmlSlurper`支持`XML` 就是其中一个例子)\n\n如果想要了解更多的内容, 你可以直接去[GPath expressions](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#gpath_expressions)看一看.\n下面给出了JSON类型与Groovy数据类型之间的对应关系.\n```groovy\nJSON\t\t\tGroovy\nstring\t\t\tjava.lang.String\nnumber\t\t\tjava.lang.BigDecimal or java.lang.Integer\nobject\t\t\tjava.util.LinkedHashMap\narray\t\t\tjava.util.ArrayList\ntrue\t\t\ttrue\nfalse\t\t\tfalse\nnull\t\t\tnull\ndate\t\t\tjava.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format\n```\n\n如果JSON中的一个值是`null</code>, `JsonSlurper`支持它转换成Groovy中的`null</code>.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。\n\n## Parser Variants\n\nGroovy 有多个`JsonSlurper` 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介:\n\n`JsonParserCharArray` 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as \"chopping\") and operates on them.\n\n\n* `JsonFastParser`解析器是`JsonParserCharArray`解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. `JsonFastParser`解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. `JsonFastParser`采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用`JsonFastParser</code>, 那么给你的建议是保持`JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制.\n\n* `JsonParserLax` 是`JsonFastParser`的一个变种实现. 它与`JsonFastParser` 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar</code>. 例如,在下面例子中它支持不带引号的字符串注释.\n\n`JsonParserUsingCharacterSource` 用于解析非常大的文件. 它使用一种称为<code>\"character windowing\"</code>的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定\n\n`JsonSlurper`的默认实现是 `JsonParserCharArray</code>.  `JsonParserType`包含了解析器种类的枚举类型:\n\n```groovy\nImplementation\t\t\t\t\tConstant\nJsonParserCharArray\t\t\t\tJsonParserType#CHAR_BUFFER\nJsonFastParser\t\t\t\t\tJsonParserType#INDEX_OVERLAY\nJsonParserLax\t\t\t\t\tJsonParserType#LAX\nJsonParserUsingCharacterSource\tJsonParserType#CHARACTER_SOURCE\n```\n\n如果想要改变解析器的实现也非常简单, 只需要通过调用`JsonSlurper#setType()</code>方法给`JsonParserType`设置上不同的值就可以了\n\n```groovy\ndef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\n## JsonOutput\n\n`JsonOutput`用于将Groovy对象序列化成JSON字符串. \n\n`JsonOutput` 重载了`toJson`静态方法. 每个不同的`toJson`方法都会接受一个不同的参数类型. \n\n`toJson`方法返回的是一个包含JSOn格式的字符串\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n```\n\n`JsonOutput`不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs</code>(一种比较老的Groovy对象)\n```groovy\nclass Person { String name }\n\ndef json = JsonOutput.toJson([ new Person(name: 'John'), new Person(name: 'Max') ])\n\nassert json == '[{\"name\":\"John\"},{\"name\":\"Max\"}]'\n```\n\n刚才那个例子中, JSON输出默认没有进行pretty输出. 因此`JsonSlurper`还提供了`prettyPrint`方法\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n\nassert JsonOutput.prettyPrint(json) == '''\\\n{\n    \"name\": \"John Doe\",\n    \"age\": 42\n}'''.stripIndent()\n```\n\n`prettyPrint`方法只接受一个String类型的字符串, 它不能和`JsonOutput`里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances.\n\n在Groovy中还可以使用`JsonBuilder</code>, `StreamingJsonBuilder`方式创建JSON. 这俩个构建起都提供了一个`DSL</code>, 当构建器生成一个JSON的时候,可以制定一个对象图.\n\n\n```groovy\n// an inclusive range\ndef range = 'a'..'d'\nassert range.size() == 4\nassert range.get(2) == 'c'\nassert range[2] == 'c'\nassert range instanceof java.util.List\nassert range.contains('a')\nassert range.contains('d')\nassert !range.contains('e')\n```\n\nYou can iterate on a range using a classic for loop:\n\n```groovy\nfor (i in 1..10) {\n    println \"Hello ${i}\"\n}\n```\n\nbut alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method:\n\n```groovy\n(1..10).each { i ->\n    println \"Hello ${i}\"\n}\n```\n\nRanges can be also used in the switch statement:\n\n```\nswitch (years) {\n    case 1..10: interestRate = 0.076; break;\n    case 11..25: interestRate = 0.052; break;\n    default: interestRate = 0.037;\n}\n```\n\n# Syntax enhancements for collections\n\n## GPath support\n\nThanks to the support of property notation for both lists and maps, Groovy provides syntactic sugar making it really easy to deal with nested collections, as illustrated in the following examples:\n\n```groovy\ndef listOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22]]\nassert listOfMaps.a == [11, 21] //GPath notation\nassert listOfMaps*.a == [11, 21] //spread dot notation\n\nlistOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22], null]\nassert listOfMaps*.a == [11, 21, null] // caters for null values\nassert listOfMaps*.a == listOfMaps.collect { it?.a } //equivalent notation\n// But this will only collect non-null values\nassert listOfMaps.a == [11,21]\n```\n\n## Spread operator\n\nThe spread operator can be used to \"inline\" a collection into another. It is syntactic sugar which often avoids calls to putAll and facilitates the realization of one-liners:\n\n```groovy\nassert [ 'z': 900,\n         *: ['a': 100, 'b': 200], 'a': 300] == ['a': 300, 'b': 200, 'z': 900]\n//spread map notation in map definition\nassert [*: [3: 3, *: [5: 5]], 7: 7] == [3: 3, 5: 5, 7: 7]\n\ndef f = { [1: 'u', 2: 'v', 3: 'w'] }\nassert [*: f(), 10: 'zz'] == [1: 'u', 10: 'zz', 2: 'v', 3: 'w']\n//spread map notation in function arguments\nf = { map -> map.c }\nassert f(*: ['a': 10, 'b': 20, 'c': 30], 'e': 50) == 30\n\nf = { m, i, j, k -> [m, i, j, k] }\n//using spread map notation with mixed unnamed and named arguments\nassert f('e': 100, *[4, 5], *: ['a': 10, 'b': 20, 'c': 30], 6) ==\n        [[\"e\": 100, \"b\": 20, \"c\": 30, \"a\": 10], 4, 5, 6]\n```\n\n### 2.4.3. The star-dot `*.' operator\n\nThe \"star-dot\" operator is a shortcut operator allowing you to call a method or a property on all elements of a collection:\n\n```groovy\nassert [1, 3, 5] == ['a', 'few', 'words']*.size()\n\nclass Person {\n    String name\n    int age\n}\ndef persons = [new Person(name:'Hugo', age:17), new Person(name:'Sandra',age:19)]\nassert [17, 19] == persons*.age\n```\n\n## Slicing with the subscript operator\n\nYou can index into lists, arrays, maps using the subscript expression. It is interesting that strings are considered as special kinds of collections in that context:\n\n```groovy\ndef text = 'nice cheese gromit!'\ndef x = text[2]\n\nassert x == 'c'\nassert x.class == String\n\ndef sub = text[5..10]\nassert sub == 'cheese'\n\ndef list = [10, 11, 12, 13]\ndef answer = list[2,3]\nassert answer == [12,13]\n```\n\nNotice that you can use ranges to extract part of a collection:\n\n```groovy\nlist = 100..200\nsub = list[1, 3, 20..25, 33]\nassert sub == [101, 103, 120, 121, 122, 123, 124, 125, 133]\n```\n\nThe subscript operator can be used to update an existing collection (for collection type which are not immutable):\n\n```groovy\nlist = ['a','x','x','d']\nlist[1..2] = ['b','c']\nassert list == ['a','b','c','d']\n```\n\nIt is worth noting that negative indices are allowed, to extract more easily from the end of a collection:\n\nYou can use negative indices to count from the end of the List, array, String etc.\n\n```groovy\ntext = \"nice cheese gromit!\"\nx = text[-1]\nassert x == \"!\"\n\ndef name = text[-7..-2]\nassert name == \"gromit\"\n```\n\nEventually, if you use a backwards range (the starting index is greater than the end index), then the answer is reversed.\n\n```groovy\ntext = \"nice cheese gromit!\"\nname = text[3..1]\nassert name == \"eci\"\n```\n\n# Scripting Ant tasks\n\n虽然`Ant`只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用`build.xml`文件或者`Jelly`脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程.\n\nGroovy提供了一个辅助类`AntBuilder`帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们.\n\n`AntBuilder`通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息.\n```groovy\ndef ant = new AntBuilder()          \nant.echo('hello from Ant!')        \n```\n\n1. 创建一个`AntBuilder`实例\n2. 执行`AntBuilder`实例的echo task\n\n假设,现在你需要创建一个ZIP文件：\n```groovy\ndef ant = new AntBuilder()\nant.zip(destfile: 'sources.zip', basedir: 'src')\n```\n\n在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过`AntBuilder`拷贝一组文件.\n```groovy\n// lets just call one task\nant.echo(\"hello\")\n\n// here is an example of a block of Ant inside GroovyMarkup\nant.sequential {\n    echo(\"inside sequential\")\n    def myDir = \"target/AntTest/\"\n    mkdir(dir: myDir)\n    copy(todir: myDir) {\n        fileset(dir: \"src/test\") {\n            include(name: \"**/*.groovy\")\n        }\n    }\n    echo(\"done\")\n}\n\n// now lets do some normal Groovy again\ndef file = new File(ant.project.baseDir,\"target/AntTest/groovy/util/AntTest.groovy\")\nassert file.exists()\n```\n\n下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配.\n```groovy\n// lets create a scanner of filesets\ndef scanner = ant.fileScanner {\n    fileset(dir:\"src/test\") {\n        include(name:\"**/Ant*.groovy\")\n    }\n}\n\n// now lets iterate over\ndef found = false\nfor (f in scanner) {\n    println(\"Found file $f\")\n    found = true\n    assert f instanceof File\n    assert f.name.endsWith(\".groovy\")\n}\nassert found\n```\n\nOr execute a JUnit test:\n\n下面我们执行JUnit\n```groovy\n// lets create a scanner of filesets\nant.junit {\n    test(name:'groovy.util.SomethingThatDoesNotExist')\n}\n```\n\n现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件.\n```groovy\nant.echo(file:'Temp.java', '''\n    class Temp {\n        public static void main(String[] args) {\n            System.out.println(\"Hello\");\n        }\n    }\n''')\nant.javac(srcdir:'.', includes:'Temp.java', fork:'true')\nant.java(classpath:'.', classname:'Temp', fork:'true')\nant.echo('Done')\n```\n\n需要提及的是, `AntBuilder`是内嵌于`Gradle`中的. 你可以像在Groovy中那样, 在`Gradle`使用`AntBuilder`","source":"_posts/groovy.md","raw":"title: groovy\n---\n> 本文是对Groovy部分官方文档进行了翻译\n\n# 注释\n## 单行注释\n想要使用单行注释, 使用`//`就可以了.  本行中`//`后续的内容都会被认为是注释的一部分\n```groovy\n// a standalone single line comment\nprintln \"hello\" // a comment till the end of the line\n```\n\n## 多行注释\n多行注释从`/*`开始, 直到`*/`结束(跨行也包含在内)\n```groovy\n/* a standalone multiline comment\nspanning two lines */\nprintln \"hello\" /* a multiline comment starting\nat the end of a statement */\nprintln 1 /* one */ + 2 /* two */\n```\n### GroovyDoc 注释\n`GroovyDoc` 注释也是多行的, 但是它是以`/**`开始, `*/`结束定义的.\n这种注释一般用于以下情况：\n* 类型定义(包含 classes, interfaces, enums, annotations)\n* 字段和属性定义\n* 方法定义\n\n```groovy\n/**\n  * A Class description\n  */\n class Person {\n     /** the name of the person */\n     String name\n\n     /**\n      * Creates a greeting method for a certain person.\n      *\n      * @param otherPerson the person to greet\n      * @return ag reeting message\n      */\n     String greet(String otherPerson) {\n        \"Hello ${otherPerson}\"\n     }\n }\n```\n\n## Shebang line\n除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了`groovy`,并且在`PATH`里进行了配置)\n\n```groovy\n#!/usr/bin/env groovy\nprintln \"Hello from the shebang line\"\n```\n`#`字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误.\n\n# 标识符\n\n## 普通标识符\n\n标识符以一个`字母`或者`$`或者`_`开始, 不能以数字打头.\n如果以字母打头,他们在下列范围内\n\n* 'a' to 'z' (lowercase ascii letter)\n* 'A' to 'Z' (uppercase ascii letter)\n* '\\u00C0' to '\\u00D6'\n* '\\u00D8' to '\\u00F6'\n* '\\u00F8' to '\\u00FF'\n* '\\u0100' to '\\uFFFE'\n\n剩下的字符就可以包含字母或者数字了.  下面列举了一些合法的标识符：\n```groovy\ndef name\ndef item3\ndef with_underscore\ndef $dollarStart\n```\n下面是一些非法的标识符\n```groovy\ndef 3tier\ndef a+b\ndef a#b\n```\n`.`后面的关键字也是合法的标识符\n```groovy\nfoo.as\nfoo.assert\nfoo.break\nfoo.case\nfoo.catch\n```\n\n## 带引号的标识符\n\n带引号的标识符出现在`.\\`. 例如`person.name`表达式中的`name`部分能通过这俩种方式引起来`person.\"name\"`或者`person.\\'name'`. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号,\n```groovy\ndef map = [:]\n\nmap.\"an identifier with a space and double quotes\" = \"ALLOWED\"\nmap.'with-dash-signs-and-single-quotes' = \"ALLOWED\"\n\nassert map.\"an identifier with a space and double quotes\" == \"ALLOWED\"\nassert map.'with-dash-signs-and-single-quotes' == \"ALLOWED\"\n```\n\n正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的\n```groovy\nmap.'single quote'\nmap.\"double quote\"\nmap.'''triple single quote'''\nmap.\"\"\"triple double quote\"\"\"\nmap./slashy string/\nmap.$/dollar slashy string/$\n```\n\nstrings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier:\n```groovy\ndef firstname = \"Homer\"\nmap.\"Simson-${firstname}\" = \"Homer Simson\"\n\nassert map.'Simson-Homer' == \"Homer Simson\"\n```\n\n# 字符串\nText literals are represented in the form of chain of characters called strings. Groovy lets you instantiate `java.lang.String` objects, as well as GStrings (`groovy.lang.GString`) which are also called interpolated strings in other programming languages.\n\n在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化`java.lang.String`,像  GStrings (`groovy.lang.GString`)那样, (GString还被称为插值字符串)\n\n## 单引号字符\nSingle quoted strings are a series of characters surrounded by single quotes:\n\n单引号字符串是通过单引号括起来的一列字符\n```groovy\n'a single quoted string'\n```\nSingle quoted strings are plain `java.lang.String` and don’t support interpolation.\n\n单引号字符和`java.lang.String`是同一个东西, 同时它也不允许插值的出现\n## 字符串连接\n\nGroovy里所有的字符串都可以通过 `+` 连接起来\n```groovy\nassert 'ab' == 'a' + 'b'\n```\n\n## 三重单引号字符串\n\n三重单引号字符串 是通过三个单引号 包围起来的字符序列.\n```groovy\n'''a triple single quoted string'''\n```\n三重单引号字符串就是纯`java.lang.String` 而且不允许插值.\n三重单引号字符串可以多行赋值.\n```groovy\ndef aMultilineString = '''line one\nline two\nline three'''\n```\n\n如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用`String#stripIndent()` 去除掉缩进. `String#stripMargin()`方法会通过分割符从字符串的开头\n```groovy\ndef startingAndEndingWithANewline = '''\nline one\nline two\nline three\n'''\n```\n\n你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash:\n```groovy\ndef strippedFirstNewline = '''\\\nline one\nline two\nline three\n'''\n\nassert !strippedFirstNewline.startsWith('\\n')\n```\n\n### 更换特殊字符\n\n可以通过`\\`字符在`''`继续引用`'`\n```groovy\n'an escaped single quote: \\' needs a backslash'\n```\n\n当然也可以通过`\\`来引用它自身\n```groovy\n'an escaped escape character: \\\\ needs a double backslash'\n```\n\n还有一些其他的特殊字符需要`\\`来引用\n```groovy\nEscape sequence\tCharacter\n'\\t'\ttabulation\n'\\b'\tbackspace\n'\\n'\tnewline\n'\\r'\tcarriage return\n'\\f'\tformfeed\n'\\\\'\tbackslash\n'\\''\tsingle quote (for single quoted and triple single quoted strings)\n'\\\"'\tdouble quote (for double quoted and triple double quoted strings)\n```\n### Unicode 转义序列\n\n有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如`backslash`, 在u后跟4个16进制数字即可.\n\n```groovy\n'The Euro currency symbol: \\u20AC'\n```\n## 双引号包含的 string\n\n通过双引号包括起来的字符串\n```groovy\n\"a double quoted string\"\n```\nTo escape a double quote, you can use the backslash character: \"A double quote: \\\"\".\n\n当双引号字符串内没有插值(${})的时候, 那它就等同于`java.lang.String`, 当有插值的时候那么双引号字符串就是`groovy.lang.GString`的实例\n\n### String 插值\n\n任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过`${}` 或者 `$`来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式`toString()`方法,通过传递一个String参数.\n\n下面的例子展示的是字符串里的占位符定位本地变量\n```groovy\ndef name = 'Guillaume' // a plain string\ndef greeting = \"Hello ${name}\"\n\nassert greeting.toString() == 'Hello Guillaume'\n```\n\n但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式\n\n```groovy\ndef sum = \"The sum of 2 and 3 equals ${2 + 3}\"\nassert sum.toString() == 'The sum of 2 and 3 equals 5'\n```\n\n其实并不是只有表达式允许出现在`${}`表达式里. Statements 同样可以在`${}` 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在`${}`里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如`\"The sum of 1 and 2 is equal to ${def a = 1; def b = 2; a + b}\"` 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.\n除了` ${}`占位符之外, 我们也可以使用`$`标记前缀点缀表达式：\n\n```groovy\ndef person = [name: 'Guillaume', age: 36]\nassert \"$person.name is $person.age years old\" == 'Guillaume is 36 years old'\n```\n但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.\n下面给出了一个定义成数字形式的变量.\n```groovy\ndef number = 3.14\n```\n\n下面的 statement 将会抛出一个`groovy.lang.MissingPropertyException` 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性.\n```groovy\nshouldFail(MissingPropertyException) {\n    println \"$number.toString()\"\n}\n```\n你可以理解成解析器会将`\"$number.toString()\"` 解释成 `\"${number.toString}()\"`.如果你想要在GString中避免`$`或者`${}` 称为插值的话,只需要在它们前面加上`\\`即可.\n\n```groovy\nassert '${name}' == \"\\${name}\"\n```\n### 特殊插值形式-闭包表达式\n\n到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时`${→}`,这个表达式实际上就是一个闭包表达式.\n\n```groovy\ndef sParameterLessClosure = \"1 + 2 == ${-> 3}\" (1)\nassert sParameterLessClosure == '1 + 2 == 3'\n\ndef sOneParamClosure = \"1 + 2 == ${ w -> w << 3}\" (2)\nassert sOneParamClosure == '1 + 2 == 3'\n```\n1. 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参\n2. 上例中,闭包中使用了一个`java.io.StringWriter argument`参数, 我们可以使用`<<`操作符添加内容.不论任何情况, 占位符都被嵌入了闭包.\n\n上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算:\n\n```groovy\ndef number = 1 (1)\ndef eagerGString = \"value == ${number}\"\ndef lazyGString = \"value == ${ -> number }\"\n\nassert eagerGString == \"value == 1\" (2)\nassert lazyGString ==  \"value == 1\" (3)\n\nnumber = 2 (4)\nassert eagerGString == \"value == 1\" (5)\nassert lazyGString ==  \"value == 2\" (6)\n```\n1\tWe define a number variable containing 1 that we then interpolate within two GStrings, as an expression in eagerGString and as a closure in lazyGString.\n2\tWe expect the resulting string to contain the same string value of 1 for eagerGString.\n3\tSimilarily for lazyGString\n4\tThen we change the value of the variable to a new number\n5\tWith a plain interpolated expression, the value was actually bound at the time of creation of the GString.\n6\tBut with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value.\nAn embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed.\n\n1. 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中,\n2. 我们希望eagerGString 产生的字符串包含着相同的值 1\n3. 同样我们也希望lazyGString 产生的字符串包含着相同的值 1\n4. 然后我们将number改变一个值.\n5.\n6.\n\n### Inteoperability with Java\n当一个方法(不管是在Java还是在Groovy中定义的)带有一个`java.lang.String`参数, 但我们传递一个`groovy.lang.GString instance`实例, GString会自动调用toString()方法.\n\n```groovy\nString takeString(String message) {         (4)\n    assert message instanceof String        (5)\n    return message\n}\n\ndef message = \"The message is ${'hello'}\"   (1)\nassert message instanceof GString           (2)\n\ndef result = takeString(message)            (3)\nassert result instanceof String\nassert result == 'The message is hello'\n```\n1. 首先我们创建一个GString变量\n2. 然后我们检查一下声明的变量是否是GString的实例\n3. 接着我们向一个方法(参数为String类型)传递GString类型变量\n4. takeString()显式地指出了它唯一的参数为String\n5. 我们再次验证所需的参数是String 而不是GString\n\n\n### GString and String hashCodes\n\n尽管插值字符串能被用来代替`Java strings`, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是`immutable`, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的.\n\n```groovy\nassert \"one: ${1}\".hashCode() != \"one: 1\".hashCode()\n```\n\nGString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString.\n```groovy\ndef key = \"a\"\ndef m = [\"${key}\": \"letter ${key}\"]     (1)\n\nassert m[\"a\"] == null                   (2)\n```\n1. map使用一对键值被创建了出来,其key是GString类型\n2. 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode\n\n## Triple double quoted string\n\n三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样)\n```groovy\ndef name = 'Groovy'\ndef template = \"\"\"\n    Dear Mr ${name},\n\n    You're the winner of the lottery!\n\n    Yours sincerly,\n\n    Dave\n\"\"\"\n\nassert template.toString().contains('Groovy')\n```\n\n在三重双引号字符串中,不管是双引号还是单引号都不需要escaped\n\n## Slashy string\n除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的.\n\n```groovy\ndef fooPattern = /.*foo.*/\nassert fooPattern == '.*foo.*'\n```\n\n只有在`/ slashes`中需要使用\\ 来escaped\n```groovy\ndef escapeSlash = /The character \\/ is a forward slash/\nassert escapeSlash == 'The character / is a forward slash'\n```\n\nSlashy字符串也可以是多行的\n```groovy\ndef multilineSlashy = /one\n    two\n    three/\n\nassert multilineSlashy.contains('\\n')\n```\n\nSlashy字符串也可以插值形式出现(像GString一样)\n```groovy\ndef color = 'blue'\ndef interpolatedSlashy = /a ${color} car/\n\nassert interpolatedSlashy == 'a blue car'\n```\n\n下面有一些常识方面的东西需要你知道：\n`//`不会被解释为空Slashy字符串,这代表着行注释.\n\n```groovy\nassert '' == //\n```\n\n## Dollar slashy string\n\nDollar slashy字符串 通过`$/``/$` 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义\n```groovy\ndef name = \"Guillaume\"\ndef date = \"April, 1st\"\n\ndef dollarSlashy = $/\n    Hello $name,\n    today we're ${date}.\n\n    $ dollar sign\n    $$ escaped dollar sign\n    \\ backslash\n    / forward slash\n    $/ escaped forward slash\n    $/$ escaped dollar slashy string delimiter\n/$\n\nassert [\n    'Guillaume',\n    'April, 1st',\n    '$ dollar sign',\n    '$ escaped dollar sign',\n    '\\\\ backslash',\n    '/ forward slash',\n        '$/ escaped forward slash',\n        '/$ escaped dollar slashy string delimiter'\n\n        ].each { dollarSlashy.contains(it) }\n```\n\n## Characters\n\n不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量\n```groovy\nchar c1 = 'A' (1)\nassert c1 instanceof Character\n\ndef c2 = 'B' as char (2)\nassert c2 instanceof Character\n\ndef c3 = (char)'C' (3)\nassert c3 instanceof Character\n```\n1. 通过指定char类型来显式地声明一个character变量\n2. 通过操作符强制转换类型\n3. 通过强制转换成指定类型\n\n# Numbers\n\nGroovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现)\n\n## Integral literals\n\nThe integral literal types are the same as in Java:\n\n证书类型变量和Java里的一样\n\n* byte\n* char\n* short\n* int\n* long\n* java.lang.BigInteger\n\nYou can create integral numbers of those types with the following declarations:\n\n可以通过以下声明方式创建整数类型变量\n```groovy\n// primitive types\nbyte  b = 1\nchar  c = 2\nshort s = 3\nint   i = 4\nlong  l = 5\n\n// infinite precision\nBigInteger bi =  6\n```\n如果使用`def`关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型\n```groovy\ndef a = 1\nassert a instanceof Integer\n\n// Integer.MAX_VALUE\ndef b = 2147483647\nassert b instanceof Integer\n\n// Integer.MAX_VALUE + 1\ndef c = 2147483648\nassert c instanceof Long\n\n// Long.MAX_VALUE\ndef d = 9223372036854775807\nassert d instanceof Long\n\n// Long.MAX_VALUE + 1\ndef e = 9223372036854775808\nassert e instanceof BigInteger\n```\nAs well as for negative numbers:\n```groovy\ndef na = -1\nassert na instanceof Integer\n\n// Integer.MIN_VALUE\ndef nb = -2147483648\nassert nb instanceof Integer\n\n// Integer.MIN_VALUE - 1\ndef nc = -2147483649\nassert nc instanceof Long\n\n// Long.MIN_VALUE\ndef nd = -9223372036854775808\nassert nd instanceof Long\n\n// Long.MIN_VALUE - 1\ndef ne = -9223372036854775809\nassert ne instanceof BigInteger\n```\n\n### Alternative non-base 10 representations\n\n#### Binary literal\n\n在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据.\n```groovy\nint xInt = 0b10101111\nassert xInt == 175\n\nshort xShort = 0b11001001\nassert xShort == 201 as short\n\nbyte xByte = 0b11\nassert xByte == 3 as byte\n\nlong xLong = 0b101101101101\nassert xLong == 2925l\n\nBigInteger xBigInteger = 0b111100100001\nassert xBigInteger == 3873g\n\nint xNegativeInt = -0b10101111\nassert xNegativeInt == -175\n```\n#### Octal literal\n\n8进制的电话,只需要开头是0后跟要表示的8进制数即可.\n```groovy\nint xInt = 077\nassert xInt == 63\n\nshort xShort = 011\nassert xShort == 9 as short\n\nbyte xByte = 032\nassert xByte == 26 as byte\n\nlong xLong = 0246\nassert xLong == 166l\n\nBigInteger xBigInteger = 01111\nassert xBigInteger == 585g\n\nint xNegativeInt = -077\nassert xNegativeInt == -63\n```\n#### Hexadecimal literal\n\nHexadecimal numbers are specified in the typical format of 0x followed by hex digits.\n\n16进制的电话,只需要开头是0x后跟要表示的16进制数即可.\n```groovy\n\nint xInt = 0x77\nassert xInt == 119\n\nshort xShort = 0xaa\nassert xShort == 170 as short\n\nbyte xByte = 0x3a\nassert xByte == 58 as byte\n\nlong xLong = 0xffff\nassert xLong == 65535l\n\nBigInteger xBigInteger = 0xaaaa\nassert xBigInteger == 43690g\n\nDouble xDouble = new Double('0x1.0p0')\nassert xDouble == 1.0d\n\nint xNegativeInt = -0x77\nassert xNegativeInt == -119\n```\n\n## Decimal literals\n\n小数字面量和在java 里一样\n* float\n* double\n* java.lang.BigDecimal\n\n可以通过下面的方式创建小数类型的number\n```groovy\n// primitive types\nfloat  f = 1.234\ndouble d = 2.345\n\n// infinite precision\nBigDecimal bd =  3.456\n```\nDecimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent:\n\n\n```groovy\nassert 1e3  ==  1_000.0\nassert 2E4  == 20_000.0\nassert 3e+1 ==     30.0\nassert 4E-2 ==      0.04\nassert 5e-1 ==      0.5\n```\nConveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types.\n\nDecimal numbers can’t be represented using a binary, octal or hexadecimal representation.\n\n\n## Underscore in literals\n\nWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups:\n\n\n```groovy\nlong creditCardNumber = 1234_5678_9012_3456L\nlong socialSecurityNumbers = 999_99_9999L\ndouble monetaryAmount = 12_345_132.12\nlong hexBytes = 0xFF_EC_DE_5E\nlong hexWords = 0xFFEC_DE5E\nlong maxLong = 0x7fff_ffff_ffff_ffffL\nlong alsoMaxLong = 9_223_372_036_854_775_807L\nlong bytes = 0b11010010_01101001_10010100_10010010\n```\n\n## Number type suffixes\n\n我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制)\n```java\nType\t\t\tSuffix\nBigInteger\t\tG or g\nLong\t\t\tL or l\nInteger\t\t\tI or i\nBigDecimal\t\tG or g\nDouble\t\t\tD or d\nFloat\t\t\tF or f\n```\n```groovy\nassert 42I == new Integer('42')\nassert 42i == new Integer('42') // lowercase i more readable\nassert 123L == new Long(\"123\") // uppercase L more readable\nassert 2147483648 == new Long('2147483648') // Long type used, value too large for an Integer\nassert 456G == new BigInteger('456')\nassert 456g == new BigInteger('456')\nassert 123.45 == new BigDecimal('123.45') // default BigDecimal type used\nassert 1.200065D == new Double('1.200065')\nassert 1.234F == new Float('1.234')\nassert 1.23E23D == new Double('1.23E23')\nassert 0b1111L.class == Long // binary\nassert 0xFFi.class == Integer // hexadecimal\nassert 034G.class == BigInteger // octal\n```\n## Math operations\n\n尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型\n\n* byte, char, short 和 int 之间的二进制计算返回的是int类型\n* byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型\n* BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型\n* float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型\n* 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型.\n\nThe following table summarizes those rules:\n```groovy\n\n```\n\n由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字.\n\n### The case of the division operator\n\nThe division operators / (and /= for division and assignment) produce a double result if either operand is a float or double, and a BigDecimal result otherwise (when both operands are any combination of an integral type short, char, byte, int, long, BigInteger or BigDecimal).\n\nBigDecimal division is performed with the divide() method if the division is exact (ie. yielding a result that can be represented within the bounds of the same precision and scale), or using a MathContext with a precision of the maximum of the two operands' precision plus an extra precision of 10, and a scale of the maximum of 10 and the maximum of the operands' scale.\n\nFor integer division like in Java, you should use the intdiv() method, as Groovy doesn’t provide a dedicated integer division operator symbol.\n\n除法操作符`/`(和`/=`)会得到一个double类型的结果,\n\n### The case of the power operator\n\nGroovy 里有一种强大的操作符`**`, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型\n\n#### 如果exponent为小数类型\n```java\n1. 如果结果能表示为Integer类型,那就返回Integer类型\n2. 否则如果结果能表示为Long类型,那就返回Long类型\n3. 否则的话就返回Double\n```\n\n#### 如果exponent为整数类型\n```\n1. 如果exponent负数负数, 那就返回Integer, Long 或者Double,\n2. 如果exponent是正数或者0, 那就要根据base来判断了\n\tA. 如果base是 BigDecimal, 那就返回BigDecimal类型\n\tB. 如果base是 BigInteger, 那就返回BigInteger类型\n\tC. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger\n\tD. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger\n```\n\n#### 示例\n```groovy\n// base and exponent are ints and the result can be represented by an Integer\nassert    2    **   3    instanceof Integer    //  8\nassert   10    **   9    instanceof Integer    //  1_000_000_000\n\n// the base is a long, so fit the result in a Long\n// (although it could have fit in an Integer)\nassert    5L   **   2    instanceof Long       //  25\n\n// the result can't be represented as an Integer or Long, so return a BigInteger\nassert  100    **  10    instanceof BigInteger //  10e20\nassert 1234    ** 123    instanceof BigInteger //  170515806212727042875...\n\n// the base is a BigDecimal and the exponent a negative int\n// but the result can be represented as an Integer\nassert    0.5  **  -2    instanceof Integer    //  4\n\n// the base is an int, and the exponent a negative float\n// but again, the result can be represented as an Integer\nassert    1    **  -0.3f instanceof Integer    //  1\n\n// the base is an int, and the exponent a negative int\n// but the result will be calculated as a Double\n// (both base and exponent are actually converted to doubles)\nassert   10    **  -1    instanceof Double     //  0.1\n\n// the base is a BigDecimal, and the exponent is an int, so return a BigDecimal\nassert    1.2  **  10    instanceof BigDecimal //  6.1917364224\n\n// the base is a float or double, and the exponent is an int\n// but the result can only be represented as a Double value\nassert    3.4f **   5    instanceof Double     //  454.35430372146965\nassert    5.6d **   2    instanceof Double     //  31.359999999999996\n\n// the exponent is a decimal value\n// and the result can only be represented as a Double value\nassert    7.8  **   1.9  instanceof Double     //  49.542708423868476\nassert    2    **   0.1f instanceof Double     //  1.0717734636432956\n```\n\n\n# Booleans\nBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false.\n```groovy\ndef myBooleanVariable = true\nboolean untypedBooleanVar = false\nbooleanField = true\n```\ntrue and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators.\n\nIn addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.\n\n\n# IO\n## 读文件\n作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line ->\n    println line\n}\n```\n\n`eachLine`方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量:\n```groovy\nnew File(baseDir, 'haiku.txt').eachLine { line, nb ->\n    println \"Line $nb: $line\"\n}\n```\n无论由于什么原因, 当`eachLine`中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效.\n\n例如, 某种情况你使用了`Reader`, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭.\n```groovy\ndef count = 0, MAXSIZE = 3\nnew File(baseDir,\"haiku.txt\").withReader { reader ->\n    while (reader.readLine()) {\n        if (++count > MAXSIZE) {\n            throw new RuntimeException('Haiku should only have 3 verses')\n        }\n    }\n}\n```\n\n如果你想要把文本文件中每一行都放进一个list中, 你可以这么做:\n```groovy\ndef list = new File(baseDir, 'haiku.txt').collect {it}\n```\n\n或者你想利用操作符将文件中每一行都添加到一个数组中:\n```groovy\ndef array = new File(baseDir, 'haiku.txt') as String[]\n```\n\n下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里:\n```groovy\nbyte[] contents = file.bytes\n```\n\n如下例,我们轻松地获得了一个输入流.\n```groovy\ndef is = new File(baseDir,'haiku.txt').newInputStream()\n// do something ...\nis.close()\n```\n\n上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法`withInputStream`, 这个方法可以帮我们自动的关闭输入流.\n```groovy\nnew File(baseDir,'haiku.txt').withInputStream { stream ->\n    // do something ...\n}\n```\n\n## 写文件\n\n有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件\n```groovy\nnew File(baseDir,'haiku.txt').withWriter('utf-8') { writer ->\n    writer.writeLine 'Into the ancient pond'\n    writer.writeLine 'A frog jumps'\n    writer.writeLine 'Water’s sound!'\n}\n```\n\n但对于一个要求很简单的需求来说,我们可以使用`<<`向文件中写\n```groovy\nnew File(baseDir,'haiku.txt') << '''Into the ancient pond\nA frog jumps\nWater’s sound!'''\n```\n\n当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节:\n```groovy\nfile.bytes = [66,22,11]\n```\n\n当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流.\n```groovy\ndef os = new File(baseDir,'data.bin').newOutputStream()\n// do something ...\nos.close()\n```\n\n同`newInputStream`一样,`newOutputStream`同样需要手动关闭, ok,你大概想到了`withOutputStream`:\n```groovy\nnew File(baseDir,'data.bin').withOutputStream { stream ->\n    // do something ...\n}\n```\n\n## 遍历文件\n\n在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作:\n```groovy\ndir.eachFile { file ->                      (1)\n    println file.name\n}\ndir.eachFileMatch(~/.*\\.txt/) { file ->     (2)\n    println file.name\n}\n```\n\n1. 在目录下的每个文件上执行闭包操作.\n2. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作.\n\n也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用`eachFileRecurse`\n```groovy\ndir.eachFileRecurse { file ->                      (1)\n    println file.name\n}\n\ndir.eachFileRecurse(FileType.FILES) { file ->      (2)\n    println file.name\n}\n```\n1. 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作\n2. 对目录里进行递归查找,但是只查找文件.\n\n```groovy\ndir.traverse { file ->\n    if (file.directory && file.name=='bin') {\n        FileVisitResult.TERMINATE                   (1)\n    } else {\n        println file.name\n        FileVisitResult.CONTINUE                    (2)\n    }\n\n}\n```\n1. 如果找到的文件是目录,且它的名字是\"dir\", 则停止遍历\n2.  打印出文件的名字,接着遍历\n\n## 序列化\n\n在java中会使用`java.io.DataOutputStream` 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化:\n```groovy\nboolean b = true\nString message = 'Hello from Groovy'\n// Serialize data into a file\nfile.withDataOutputStream { out ->\n    out.writeBoolean(b)\n    out.writeUTF(message)\n}\n// ...\n// Then read it back\nfile.withDataInputStream { input ->\n    assert input.readBoolean() == b\n    assert input.readUTF() == message\n}\n```\n\n同样,如果这个数据实例了序列化接口`Serializable`, 你可以使用 object output stream将整个数据序列化到文件:\n```groovy\nPerson p = new Person(name:'Bob', age:76)\n// Serialize data into a file\nfile.withObjectOutputStream { out ->\n    out.writeObject(p)\n}\n// ...\n// Then read it back\nfile.withObjectInputStream { input ->\n    def p2 = input.readObject()\n    assert p2.name == p.name\n    assert p2.age == p.age\n}\n```\n\n## 执行命令\n\n前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令.\n\nGroovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的`execute()`. 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令.\n```groovy\ndef process = \"ls -l\".execute()             (1)\nprintln \"Found text ${process.text}\"        (2)\n```\n1. 在外部过程(external process)执行ls命令\n2. 获得命令的输出,并输出\n\n`execute()`方法返回一个`java.lang.Process`实例, 随后选择一种输出流`in/out/err`, 同时检查`exit`值,查看是否命令执行完毕.\n\n下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出.\n```groovy\n            def process = \"ls -l\".execute()             (1)\n            process.in.eachLine { line ->               (2)\n                println line                            (3)\n            }\n            assert process instanceof Process\n        }\n    }\n\n    void testProcessConsumeOutput() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                File file = null\n                def tmpDir = b.tmp {\n                    file = 'foo.tmp'('foo')\n                }\n                assert file.exists()\n                def p = \"rm -f foo.tmp\".execute([], tmpDir)\n                p.consumeProcessOutput()\n                p.waitFor()\n                assert !file.exists()\n            }\n\n        }\n    }\n\n    void testProcessPipe() {\n        if (unixlike) {\n            doInTmpDir { b ->\n                def proc1, proc2, proc3, proc4\n                proc1 = 'ls'.execute()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc1 | proc2 | proc3 | proc4\n                proc4.waitFor()\n                if (proc4.exitValue()) {\n                    println proc4.err.text\n                } else {\n                    println proc4.text\n                }\n\n                def sout = new StringBuilder()\n                def serr = new StringBuilder()\n                proc2 = 'tr -d o'.execute()\n                proc3 = 'tr -d e'.execute()\n                proc4 = 'tr -d i'.execute()\n                proc4.consumeProcessOutput(sout, serr)\n                proc2 | proc3 | proc4\n                [proc2, proc3].each { it.consumeProcessErrorStream(serr) }\n                proc2.withWriter { writer ->\n                    writer << 'testfile.groovy'\n                }\n                proc4.waitForOrKill(1000)\n                println \"Standard output: $sout\"\n                println \"Standard error: $serr\"\n            }\n        }\n    }\n\n    public static class Person implements Serializable {\n        String name\n        int age\n    }\n}\n```\n\n1\texecutes the ls command in an external process\n2\tfor each line of the input stream of the process\n3\tprint the line\n1. 在外部进程中执行ls命令\n2.\n\nIt is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input).\n\n\nRemember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write:\n\n```groovy\ndef process = \"dir\".execute()\nprintln \"${process.text}\"\n```\n\n接着你会收到一个异常`IOException`,异常信息为`Cannot run program \"dir\": CreateProcess error=2`,系统找不到指定的文件.\n\n这是因为`dir`是内建于`windows shell(cmd.ext)`, 想要使用那个命令,你要像下面这个样操作:\n```groovy\ndef process = \"cmd /c dir\".execute()\nprintln \"${process.text}\"\n```\n\n还有,因为上述的功能是在内部使用的`java.lang.Process`, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的:\n\n> Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock\nBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier.\n\n现在演示一下,如何输出进程里所有的输出(包括error stream).\n```groovy\ndef p = \"rm -f foo.tmp\".execute([], tmpDir)\np.consumeProcessOutput()\np.waitFor()\n```\n\n`consumeProcessOutput`仍然有很多对`StringBuffer`, `InputStream`, `OutputStream`等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 [GDK API for java.lang.Process](http://docs.groovy-lang.org/latest/html/groovy-jdk/java/lang/Process.html)\n\n另外, `pipeTo`命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例:\n\n```groovy\nproc1 = 'ls'.execute()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc1 | proc2 | proc3 | proc4\nproc4.waitFor()\nif (proc4.exitValue()) {\n    println proc4.err.text\n} else {\n    println proc4.text\n}\n```\nConsuming errors\n```groovy\ndef sout = new StringBuilder()\ndef serr = new StringBuilder()\nproc2 = 'tr -d o'.execute()\nproc3 = 'tr -d e'.execute()\nproc4 = 'tr -d i'.execute()\nproc4.consumeProcessOutput(sout, serr)\nproc2 | proc3 | proc4\n[proc2, proc3].each { it.consumeProcessErrorStream(serr) }\nproc2.withWriter { writer ->\n    writer << 'testfile.groovy'\n}\nproc4.waitForOrKill(1000)\nprintln \"Standard output: $sout\"\nprintln \"Standard error: $serr\"\n```\n\n# 集合\n\nGroovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法.\n## Lists\n\nGroovy使用了一种被`[]`括起来,值通过`,`分割的语法 定义list. Groovy list 采用的是 JDK里`java.util.List`的实现, 因为它自身并没有定义自己的集合类.\nGroovy list 的默认实现是`java.util.ArrayList`, 在后面我们可以看到其他形式的list\n\n```groovy\ndef numbers = [1, 2, 3]         (1)\n\nassert numbers instanceof List  (2)\nassert numbers.size() == 3      (3)\n```\n\n1. 我们定义了一个Number类型的List,然后将这个list分配给一个变量\n2. 判断list是 Java’s `java.util.List` interface 的实例\n3. list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素\n\n在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样：\n```groovy\ndef heterogeneous = [1, \"a\", true]  (1)\n```\n1. 我们定义了一个包含有number,string,boolean 三个类型的list\n\n在上面我们提到过, list实际上是`java.util.ArrayList`实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现\n```groovy\ndef arrayList = [1, 2, 3]\nassert arrayList instanceof java.util.ArrayList\n\ndef linkedList = [2, 3, 4] as LinkedList    (1)\nassert linkedList instanceof java.util.LinkedList\n\nLinkedList otherLinked = [3, 4, 5]          (2)\nassert otherLinked instanceof java.util.LinkedList\n```\n1. 我们使用操作符强制将类型显式地声明为`java.util.LinkedList`\n2. 我们使用显式声明方式, 将list声明为`java.util.LinkedList`\n\n我们可以通过`[]`下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用`<<`操作符向list里追加元素\n```groovy\ndef letters = ['a', 'b', 'c', 'd']\n\nassert letters[0] == 'a'     (1)\nassert letters[1] == 'b'\n\nassert letters[-1] == 'd'    (2)\nassert letters[-2] == 'c'\n\nletters[2] = 'C'             (3)\nassert letters[2] == 'C'\n\nletters << 'e'               (4)\nassert letters[ 4] == 'e'\nassert letters[-1] == 'e'\n\nassert letters[1, 3] == ['b', 'd']         (5)\nassert letters[2..4] == ['C', 'd', 'e']    (6)\n```\n\n1. 访问第一个元素(从这可以看出,list的下标是从0开始的)\n2. 通过-1 下标访问list中的最后一个元素.\n3. 使用下标对list中第三个元素重新赋值\n4. 使用`<<`向list尾部添加一个元素\n5. 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list\n6. 使用值域符来访问list中一定范围内的值.\n\n由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list\n```groovy\ndef multi = [[0, 1], [2, 3]]     (1)\nassert multi[1][0] == 2          (2)\n```\n\n1. 定义了一个包含Number类型list的list\n2. 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素)\n\n### List literals\n\n你可以像下面这样创建集合, 注意`[]`是空集合表达式.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.get(2) == 7\nassert list[2] == 7\nassert list instanceof java.util.List\n\ndef emptyList = []\nassert emptyList.size() == 0\nemptyList.add(5)\nassert emptyList.size() == 1\n```groovy\n\n每一个list表达式都是实现自`java.util.List`\n\n当然list也可以指定其具体的实现类型\n```groovy\ndef list1 = ['a', 'b', 'c']\n//construct a new list, seeded with the same items as in list1\ndef list2 = new ArrayList<String>(list1)\n\nassert list2 == list1 // == checks that each corresponding element is the same\n\n// clone() can also be called\ndef list3 = list1.clone()\nassert list3 == list1\n```\n\nlist本质上是一个有序的对象集合.\n```groovy\ndef list = [5, 6, 7, 8]\nassert list.size() == 4\nassert list.getClass() == ArrayList     // the specific kind of list being used\n\nassert list[2] == 7                     // indexing starts at 0\nassert list.getAt(2) == 7               // equivalent method to subscript operator []\nassert list.get(2) == 7                 // alternative method\n\nlist[2] = 9\nassert list == [5, 6, 9, 8,]           // trailing comma OK\n\nlist.putAt(2, 10)                       // equivalent method to [] when value being changed\nassert list == [5, 6, 10, 8]\nassert list.set(2, 11) == 10            // alternative method that returns old value\nassert list == [5, 6, 11, 8]\n\nassert ['a', 1, 'a', 'a', 2.5, 2.5f, 2.5d, 'hello', 7g, null, 9 as byte]\n//objects can be of different types; duplicates allowed\n\nassert [1, 2, 3, 4, 5][-1] == 5             // use negative indices to count from the end\nassert [1, 2, 3, 4, 5][-2] == 4\nassert [1, 2, 3, 4, 5].getAt(-2) == 4       // getAt() available with negative index...\ntry {\n    [1, 2, 3, 4, 5].get(-2)                 // but negative index not allowed with get()\n    assert false\n} catch (e) {\n    assert e instanceof ArrayIndexOutOfBoundsException\n}\n```\n\n### List as a boolean expression\n\nlist还可以计算出boolean表达式.\n```groovy\nassert ![]             // an empty list evaluates as false\n\n//all other lists, irrespective of contents, evaluate as true\nassert [1] && ['a'] && [0] && [0.0] && [false] && [null]\n```\n\n### Iterating on a list\n\n可以通过`each`, `eachWithIndex`遍历整个集合.\n```groovy\n[1, 2, 3].each {\n    println \"Item: $it\" // `it` is an implicit parameter corresponding to the current element\n}\n['a', 'b', 'c'].eachWithIndex { it, i -> // `it` is the current element, while `i` is the index\n    println \"$i: $it\"\n}\n```\n\n在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过`collect`方法实现.\n```groovy\nassert [1, 2, 3].collect { it * 2 } == [2, 4, 6]\n\n// shortcut syntax instead of collect\nassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect { it.multiply(2) }\n\ndef list = [0]\n// it is possible to give `collect` the list which collects the elements\nassert [1, 2, 3].collect(list) { it * 2 } == [0, 2, 4, 6]\nassert list == [0, 2, 4, 6]\n```\n\n### Manipulating lists\n\n#### Filtering and searching\n\n[Groovy development kit](http://www.groovy-lang.org/gdk.html)提供了许多强大有趣的方法用来强化标准集合:\n\n```groovy\nassert [1, 2, 3].find { it > 1 } == 2           // find 1st element matching criteria\nassert [1, 2, 3].findAll { it > 1 } == [2, 3]   // find all elements matching critieria\nassert ['a', 'b', 'c', 'd', 'e'].findIndexOf {      // find index of 1st element matching criteria\n    it in ['c', 'e', 'g']\n} == 2\n\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('c') == 2  // index returned\nassert ['a', 'b', 'c', 'd', 'c'].indexOf('z') == -1 // index -1 means value not in list\nassert ['a', 'b', 'c', 'd', 'c'].lastIndexOf('c') == 4\n\nassert [1, 2, 3].every { it < 5 }               // returns true if all elements match the predicate\nassert ![1, 2, 3].every { it < 3 }\nassert [1, 2, 3].any { it > 2 }                 // returns true if any element matches the predicate\nassert ![1, 2, 3].any { it > 3 }\n\nassert [1, 2, 3, 4, 5, 6].sum() == 21                // sum anything with a plus() method\nassert ['a', 'b', 'c', 'd', 'e'].sum {\n    it == 'a' ? 1 : it == 'b' ? 2 : it == 'c' ? 3 : it == 'd' ? 4 : it == 'e' ? 5 : 0\n    // custom value to use in sum\n} == 15\nassert ['a', 'b', 'c', 'd', 'e'].sum { ((char) it) - ((char) 'a') } == 10\nassert ['a', 'b', 'c', 'd', 'e'].sum() == 'abcde'\nassert [['a', 'b'], ['c', 'd']].sum() == ['a', 'b', 'c', 'd']\n\n// an initial value can be provided\nassert [].sum(1000) == 1000\nassert [1, 2, 3].sum(1000) == 1006\n\nassert [1, 2, 3].join('-') == '1-2-3'           // String joining\nassert [1, 2, 3].inject('counting: ') {\n    str, item -> str + item                     // reduce operation\n} == 'counting: 123'\nassert [1, 2, 3].inject(0) { count, item ->\n    count + item\n} == 6\n```\n\n下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子:\n```groovy\ndef list = [9, 4, 2, 10, 5]\nassert list.max() == 10\nassert list.min() == 2\n\n// we can also compare single characters, as anything comparable\nassert ['x', 'y', 'a', 'z'].min() == 'a'\n\n// we can use a closure to specify the sorting behaviour\ndef list2 = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list2.max { it.size() } == 'xyzuvw'\nassert list2.min { it.size() } == 'z'\n```\n\n在闭包里,你还可以自定义一个比较规则.\n```groovy\nComparator mc = { a, b -> a == b ? 0 : (a < b ? -1 : 1) }\n\ndef list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list.max(mc) == 11\nassert list.min(mc) == -13\n\nComparator mc2 = { a, b -> a == b ? 0 : (Math.abs(a) < Math.abs(b)) ? -1 : 1 }\n\n\nassert list.max(mc2) == -13\nassert list.min(mc2) == -1\n\nassert list.max { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -13\nassert list.min { a, b -> a.equals(b) ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } == -1\n```\n\n#### Adding or removing elements\n\n我们可以使用`[]`去声明一个新的空list, 然后使用`<<`向list追加元素\n```groovy\ndef list = []\nassert list.empty\n\nlist << 5\nassert list.size() == 1\n\nlist << 7 << 'i' << 11\nassert list == [5, 7, 'i', 11]\n\nlist << ['m', 'o']\nassert list == [5, 7, 'i', 11, ['m', 'o']]\n\n//first item in chain of << is target list\nassert ([1, 2] << 3 << [4, 5] << 6) == [1, 2, 3, [4, 5], 6]\n\n//using leftShift is equivalent to using <<\nassert ([1, 2, 3] << 4) == ([1, 2, 3].leftShift(4))\n```groovy\nWe can add to a list in many ways:\n```groovy\nassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]\n// equivalent to calling the `plus` method\nassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]\n\ndef a = [1, 2, 3]\na += 4      // creates a new list and assigns it to `a`\na += [5, 6]\nassert a == [1, 2, 3, 4, 5, 6]\n\nassert [1, *[222, 333], 456] == [1, 222, 333, 456]\nassert [*[1, 2, 3]] == [1, 2, 3]\nassert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\ndef list = [1, 2]\nlist.add(3)\nlist.addAll([5, 4])\nassert list == [1, 2, 3, 5, 4]\n\nlist = [1, 2]\nlist.add(1, 3) // add 3 just before index 1\nassert list == [1, 3, 2]\n\nlist.addAll(2, [5, 4]) //add [5,4] just before index 2\nassert list == [1, 3, 5, 4, 2]\n\nlist = ['a', 'b', 'z', 'e', 'u', 'v', 'g']\nlist[8] = 'x' // the [] operator is growing the list as needed\n// nulls inserted if required\nassert list == ['a', 'b', 'z', 'e', 'u', 'v', 'g', null, 'x']\n```\n\n在list中`+`的语义并没有发生变化,这是何等的重要啊~~~ 与`<<`相比, `+`会创建一个新的list,  但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题.\n\n`Groovy development kit`同样提供了很多便捷的方式从list里删除元素:\n```groovy\nassert ['a','b','c','b','b'] - 'c' == ['a','b','b','b']\nassert ['a','b','c','b','b'] - 'b' == ['a','c']\nassert ['a','b','c','b','b'] - ['b','c'] == ['a']\n\ndef list = [1,2,3,4,3,2,1]\nlist -= 3           // creates a new list by removing `3` from the original one\nassert list == [1,2,4,2,1]\nassert ( list -= [2,4] ) == [1,1]\n```\n同样,你也能通过索引的方式从list里删除元素.\n```groovy\ndef list = [1,2,3,4,5,6,2,2,1]\nassert list.remove(2) == 3          // remove the third element, and return it\nassert list == [1,2,4,5,6,2,2,1]\n```\n假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用`remove`方法.\n```groovy\ndef list= ['a','b','c','b','b']\nassert list.remove('c')             // remove 'c', and return true because element removed\nassert list.remove('b')             // remove first 'b', and return true because element removed\n\nassert ! list.remove('z')           // return false because no elements removed\nassert list == ['a','b','b']\n```\n如果你想要将list清空的话,只需要调用`clear`方法即可\n```groovy\ndef list= ['a',2,'c',4]\nlist.clear()\nassert list == []\n```\n\n#### Set operations\n\n`Groovy development kit`还包含很多逻辑运算的方法\n```groovy\nassert 'a' in ['a','b','c']             // returns true if an element belongs to the list\nassert ['a','b','c'].contains('a')      // equivalent to the `contains` method in Java\nassert [1,3,4].containsAll([1,4])       // `containsAll` will check that all elements are found\n\nassert [1,2,3,3,3,3,4,5].count(3) == 4  // count the number of elements which have some value\nassert [1,2,3,3,3,3,4,5].count {\n    it%2==0                             // count the number of elements which match the predicate\n} == 2\n\nassert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]\n\nassert [1,2,3].disjoint( [4,6,9] )\nassert ![1,2,3].disjoint( [2,4,6] )\n```\n\n#### Sorting\n\nGroovy还提供了很多使用闭包比较器的排序操作\n```groovy\nassert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]\n\ndef list = ['abc', 'z', 'xyzuvw', 'Hello', '321']\nassert list.sort {\n    it.size()\n} == ['z', 'abc', '321', 'Hello', 'xyzuvw']\n\ndef list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]\nassert list2.sort { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 } ==\n        [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\nComparator mc = { a, b -> a == b ? 0 : Math.abs(a) < Math.abs(b) ? -1 : 1 }\n\n// JDK 8+ only\n// list2.sort(mc)\n// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]\n\ndef list3 = [6, -3, 9, 2, -7, 1, 5]\n\nCollections.sort(list3)\nassert list3 == [-7, -3, 1, 2, 5, 6, 9]\n\nCollections.sort(list3, mc)\nassert list3 == [1, 2, -3, 5, 6, -7, 9]\n```\n\n#### Duplicating elements\n\n`roovy development kit`还通过重载操作符的方式, 内部提供了一些方法进行list元素复制.\n```groovy\nassert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]\nassert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]\nassert Collections.nCopies(3, 'b') == ['b', 'b', 'b']\n\n// nCopies from the JDK has different semantics than multiply for lists\nassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2]\n```\n\n## Arrays\n\nGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型\n```groovy\nString[] arrStr = ['Ananas', 'Banana', 'Kiwi']  (1)\n\nassert arrStr instanceof String[]    (2)\nassert !(arrStr instanceof List)\n\ndef numArr = [1, 2, 3] as int[]      (3)\n\nassert numArr instanceof int[]       (4)\nassert numArr.size() == 3\n```\n\n1. 使用显式变量类型定义了一个字符串数组\n2. 断言刚才创建的数组是否是string类型\n3. 使用操作符定义一个int数组\n4. 断言刚才创建的数组是否是int类型\n\n我们也可以创建出一个多维数组\n```groovy\ndef matrix3 = new Integer[3][3]         (1)\nassert matrix3.size() == 3\n\nInteger[][] matrix2                     (2)\nmatrix2 = [[1, 2], [3, 4]]\nassert matrix2 instanceof Integer[][]\n```\n1. 我们指定了新数组的边界\n2. 当然我们也可以不指定它的边界\n\n访问数组元素和访问list元素的方式相同\n```groovy\nString[] names = ['Cédric', 'Guillaume', 'Jochen', 'Paul']\nassert names[0] == 'Cédric'     (1)\n\nnames[2] = 'Blackdrag'          (2)\nassert names[2] == 'Blackdrag'\n```\n1\tRetrieve the first element of the array\n2\tSet the value of the third element of the array to a new value\n1. 检索数组中第一个元素\n2. 对数组中第三个元素重新赋值\n\nGroovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包\n\n## Maps\n有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被`[]`括起来, 通过`,`分割键值对, 键值通过`:`分割\n```groovy\ndef colors = [red: '#FF0000', green: '#00FF00', blue: '#0000FF']   (1)\n\nassert colors['red'] == '#FF0000'    (2)\nassert colors.green  == '#00FF00'    (3)\n\ncolors['pink'] = '#FF00FF'           (4)\ncolors.yellow  = '#FFFF00'           (5)\n\nassert colors.pink == '#FF00FF'\nassert colors['yellow'] == '#FFFF00'\n\nassert colors instanceof java.util.LinkedHashMap\n```\n\n1. 我们定义了一个string类型的代表颜色名字的数组,\n2. 然后使用下标来检索map中是否包含red这个key\n3. 我们还可以直接使用`.`来索引到某个key\n4. 我们可以使用下标向map中添加一个新的键值对\n5. 我们也可以使用`.`添加一个新的键值对\n\nGroovy创建的map类型默认的是`java.util.LinkedHashMap`\n\n当你想要访问一个不存在的key时：\n```groovy\nassert colors.unknown == null\n```\n你将检索出一个null的结果\n\n在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key：\n\n```groovy\ndef numbers = [1: 'one', 2: 'two']\n\nassert numbers[1] == 'one'\n```\n\n我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key：\n\n```groovy\ndef key = 'name'\ndef person = [key: 'Guillaume']      (1)\n\nassert !person.containsKey('name')   (2)\nassert person.containsKey('key')     (3)\n```\n1. 与`\\'Guillaume'` 关联的key实际上是`\"key\"`这个字符串, 而不是这个key的引用值`'name'`\n2. map中不包含`'name'`key\n3. 取而代之的是map中包含一个`\"key\"`的字符串\n\n你可以向map中传递一个引号字符串作为key,例如`[\"name\": \"Guillaume\"]`.\n\n```groovy\nperson = [(key): 'Guillaume']        (1)\n\nassert person.containsKey('name')    (2)\nassert !person.containsKey('key')    (3)\n```\n1\tThis time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key\n2\tThe map does contain the name key\n3\tBut the map doesn’t contain the key key as before\n1.\n2.\n3.\n\n### Map literals\n\n在Groovy中可以使用`[:]` 创建一个map.\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.get('name') == 'Gromit'\nassert map.get('id') == 1234\nassert map['name'] == 'Gromit'\nassert map['id'] == 1234\nassert map instanceof java.util.Map\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.put(\"foo\", 5)\nassert emptyMap.size() == 1\nassert emptyMap.get(\"foo\") == 5\n```\n\nMap的key默认是`string`, 例如`[a:1]`等同于`['a':1]`. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量a`put`进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用`()`key进行转义了.\n```groovy\ndef a = 'Bob'\ndef ages = [a: 43]\nassert ages['Bob'] == null // `Bob` is not found\nassert ages['a'] == 43     // because `a` is a literal!\n\nages = [(a): 43]            // now we escape `a` by using parenthesis\nassert ages['Bob'] == 43   // and the value is found!\n```\n\n通过下面的方式你可以轻松克隆一个map\n```groovy\ndef map = [\n        simple : 123,\n        complex: [a: 1, b: 2]\n]\ndef map2 = map.clone()\nassert map2.get('simple') == map.get('simple')\nassert map2.get('complex') == map.get('complex')\nmap2.get('complex').put('c', 3)\nassert map.get('complex').get('c') == 3\n```\n\n### Map property notation\n\nMaps和beans也是非常相像的, 所以你可以对map使用`get/set`操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key.\n\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.name == 'Gromit'     // can be used instead of map.get('Gromit')\nassert map.id == 1234\n\ndef emptyMap = [:]\nassert emptyMap.size() == 0\nemptyMap.foo = 5\nassert emptyMap.size() == 1\nassert emptyMap.foo == 5\n```\n\n注意:`map.foo`总是会在map中查找key`foo`. 这意味着,\n```groovy\ndef map = [name: 'Gromit', likes: 'cheese', id: 1234]\nassert map.class == null\nassert map.get('class') == null\nassert map.getClass() == LinkedHashMap // this is probably what you want\n\nmap = [1      : 'a',\n       (true) : 'p',\n       (false): 'q',\n       (null) : 'x',\n       'null' : 'z']\nassert map.containsKey(1) // 1 is not an identifier so used as is\nassert map.true == null\nassert map.false == null\nassert map.get(true) == 'p'\nassert map.get(false) == 'q'\nassert map.null == 'z'\nassert map.get(null) == 'x'\n```\n\n### Iterating on maps\n\n`Groovy development kit`还提供了`eachWithIndex`方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的.\n```groovy\ndef map = [\n        Bob  : 42,\n        Alice: 54,\n        Max  : 33\n]\n\n// `entry` is a map entry\nmap.each { entry ->\n    println \"Name: $entry.key Age: $entry.value\"\n}\n\n// `entry` is a map entry, `i` the index in the map\nmap.eachWithIndex { entry, i ->\n    println \"$i - Name: $entry.key Age: $entry.value\"\n}\n\n// Alternatively you can use key and value directly\nmap.each { key, value ->\n    println \"Name: $key Age: $value\"\n}\n\n// Key, value and i as the index in the map\nmap.eachWithIndex { key, value, i ->\n    println \"$i - Name: $key Age: $value\"\n}\n```\n\n### Manipulating maps\n\n#### Adding or removing elements\n\n向map中添加元素你可以使用`put`方法, `下标`, `putAll`方法.\n```groovy\ndef defaults = [1: 'a', 2: 'b', 3: 'c', 4: 'd']\ndef overrides = [2: 'z', 5: 'x', 13: 'x']\n\ndef result = new LinkedHashMap(defaults)\nresult.put(15, 't')\nresult[17] = 'u'\nresult.putAll(overrides)\nassert result == [1: 'a', 2: 'z', 3: 'c', 4: 'd', 5: 'x', 13: 'x', 15: 't', 17: 'u']\n```\n\n如果想要删除map中全部的元素,可以使用`clear`方法.\n```groovy\ndef m = [1:'a', 2:'b']\nassert m.get(1) == 'a'\nm.clear()\nassert m == [:]\n```\n\n通过map字面量标记创建的map会使用`object`的`equals`方法和`hashcode`方法.\n\n还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样.\n```groovy\ndef key = 'some key'\ndef map = [:]\ndef gstringKey = \"${key.toUpperCase()}\"\nmap.put(gstringKey,'value')\nassert map.get('SOME KEY') == null\n```\n\n#### Keys, values and entries\n\n我们可以在视图中inspect`keys, values, and entries`\n```groovy\ndef map = [1:'a', 2:'b', 3:'c']\n\ndef entries = map.entrySet()\nentries.each { entry ->\n  assert entry.key in [1,2,3]\n  assert entry.value in ['a','b','c']\n}\n\ndef keys = map.keySet()\nassert keys == [1,2,3] as Set\n```\n\nMutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values.\n\n\n#### Filtering and searching\n\nThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists:\n\n```groovy\ndef people = [\n    1: [name:'Bob', age: 32, gender: 'M'],\n    2: [name:'Johnny', age: 36, gender: 'M'],\n    3: [name:'Claire', age: 21, gender: 'F'],\n    4: [name:'Amy', age: 54, gender:'F']\n]\n\ndef bob = people.find { it.value.name == 'Bob' } // find a single entry\ndef females = people.findAll { it.value.gender == 'F' }\n\n// both return entries, but you can use collect to retrieve the ages for example\ndef ageOfBob = bob.value.age\ndef agesOfFemales = females.collect {\n    it.value.age\n}\n\nassert ageOfBob == 32\nassert agesOfFemales == [21,54]\n\n// but you could also use a key/pair value as the parameters of the closures\ndef agesOfMales = people.findAll { id, person ->\n    person.gender == 'M'\n}.collect { id, person ->\n    person.age\n}\nassert agesOfMales == [32, 36]\n\n// `every` returns true if all entries match the predicate\nassert people.every { id, person ->\n    person.age > 18\n}\n\n// `any` returns true if any entry matches the predicate\n\nassert people.any { id, person ->\n    person.age == 54\n}\n```\n\n#### Grouping\n\nWe can group a list into a map using some criteria:\n\n```groovy\nassert ['a', 7, 'b', [2, 3]].groupBy {\n    it.class\n} == [(String)   : ['a', 'b'],\n      (Integer)  : [7],\n      (ArrayList): [[2, 3]]\n]\n\nassert [\n        [name: 'Clark', city: 'London'], [name: 'Sharma', city: 'London'],\n        [name: 'Maradona', city: 'LA'], [name: 'Zhang', city: 'HK'],\n        [name: 'Ali', city: 'HK'], [name: 'Liu', city: 'HK'],\n].groupBy { it.city } == [\n        London: [[name: 'Clark', city: 'London'],\n                 [name: 'Sharma', city: 'London']],\n        LA    : [[name: 'Maradona', city: 'LA']],\n        HK    : [[name: 'Zhang', city: 'HK'],\n                 [name: 'Ali', city: 'HK'],\n                 [name: 'Liu', city: 'HK']],\n]\n```\n\n## Ranges\n\nRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List.\n\nRanges defined with the .. notation are inclusive (that is the list contains the from and to value).\n\nRanges defined with the ..< notation are half-open, they include the first value but not the last value.\n\n```groovy\n// an inclusive range\ndef range = 5..8\nassert range.size() == 4\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert range.contains(8)\n\n// lets use a half-open range\nrange = 5..<8\nassert range.size() == 3\nassert range.get(2) == 7\nassert range[2] == 7\nassert range instanceof java.util.List\nassert range.contains(5)\nassert !range.contains(8)\n\n//get the end points of the range without using indexes\nrange = 1..10\nassert range.from == 1\nassert range.to == 10\n```\n\nNote that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value.\n\nRanges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:\n\n# Parsing and producing JSON\n\nGroovy 原生支持Groovy对象和JSON之间的转换. `groovy.json`包内的类用于JSON的序列化和解析功能\n\n# JsonSlurper\n\n`JsonSlurper`用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如`maps</code>, `lists</code>, 或者其他原生基本类型 `Integer</code>, `Double</code>, `Boolean</code>, `String`。\n\n这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如`parseText</code>, `parseFile` 等.下面这个例子中我们使用了 `parseText` 方法, 它会解析一个JSON字符串, 然后递归地将它转换成`list</code>, `map`结构. 一些其他的`parse*</code> 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样.\n\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"name\": \"John Doe\" } /* some comment */')\n\nassert object instanceof Map\nassert object.name == 'John Doe'\n```\n\n需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. `JsonSlurper`根据[ECMA-404 JSON Interchange Standard](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf)定义来解析JSON, 同时支持JavaScript的注释和时间类型.\n\n除了支持maps之外, `JsonSlurper` 还支持将JSON数组解析成list的功能\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\nJSON标准上只支持下面这些原生数据类型：`string</code>, `number</code>, `object</code>, `true</code>, `false</code>, `null</code>. `JsonSlurper` 将那些JSON类型转换成Groovy类型.\n```groovy\ndef jsonSlurper = new JsonSlurper()\ndef object = jsonSlurper.parseText '''\n    { \"simple\": 123,\n      \"fraction\": 123.66,\n      \"exponential\": 123e12\n    }'''\n\nassert object instanceof Map\nassert object.simple.class == Integer\nassert object.fraction.class == BigDecimal\nassert object.exponential.class == BigDecimal\n```\n\n`JsonSlurper` 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上`JsonSlurper`的结果遵循`GPath`表达式. `GPath`是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如`XmlSlurper`支持`XML` 就是其中一个例子)\n\n如果想要了解更多的内容, 你可以直接去[GPath expressions](http://docs.groovy-lang.org/latest/html/documentation/core-semantics.html#gpath_expressions)看一看.\n下面给出了JSON类型与Groovy数据类型之间的对应关系.\n```groovy\nJSON\t\t\tGroovy\nstring\t\t\tjava.lang.String\nnumber\t\t\tjava.lang.BigDecimal or java.lang.Integer\nobject\t\t\tjava.util.LinkedHashMap\narray\t\t\tjava.util.ArrayList\ntrue\t\t\ttrue\nfalse\t\t\tfalse\nnull\t\t\tnull\ndate\t\t\tjava.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format\n```\n\n如果JSON中的一个值是`null</code>, `JsonSlurper`支持它转换成Groovy中的`null</code>.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。\n\n## Parser Variants\n\nGroovy 有多个`JsonSlurper` 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介:\n\n`JsonParserCharArray` 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as \"chopping\") and operates on them.\n\n\n* `JsonFastParser`解析器是`JsonParserCharArray`解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. `JsonFastParser`解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. `JsonFastParser`采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用`JsonFastParser</code>, 那么给你的建议是保持`JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制.\n\n* `JsonParserLax` 是`JsonFastParser`的一个变种实现. 它与`JsonFastParser` 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar</code>. 例如,在下面例子中它支持不带引号的字符串注释.\n\n`JsonParserUsingCharacterSource` 用于解析非常大的文件. 它使用一种称为<code>\"character windowing\"</code>的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定\n\n`JsonSlurper`的默认实现是 `JsonParserCharArray</code>.  `JsonParserType`包含了解析器种类的枚举类型:\n\n```groovy\nImplementation\t\t\t\t\tConstant\nJsonParserCharArray\t\t\t\tJsonParserType#CHAR_BUFFER\nJsonFastParser\t\t\t\t\tJsonParserType#INDEX_OVERLAY\nJsonParserLax\t\t\t\t\tJsonParserType#LAX\nJsonParserUsingCharacterSource\tJsonParserType#CHARACTER_SOURCE\n```\n\n如果想要改变解析器的实现也非常简单, 只需要通过调用`JsonSlurper#setType()</code>方法给`JsonParserType`设置上不同的值就可以了\n\n```groovy\ndef jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)\ndef object = jsonSlurper.parseText('{ \"myList\": [4, 8, 15, 16, 23, 42] }')\n\nassert object instanceof Map\nassert object.myList instanceof List\nassert object.myList == [4, 8, 15, 16, 23, 42]\n```\n\n## JsonOutput\n\n`JsonOutput`用于将Groovy对象序列化成JSON字符串. \n\n`JsonOutput` 重载了`toJson`静态方法. 每个不同的`toJson`方法都会接受一个不同的参数类型. \n\n`toJson`方法返回的是一个包含JSOn格式的字符串\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n```\n\n`JsonOutput`不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs</code>(一种比较老的Groovy对象)\n```groovy\nclass Person { String name }\n\ndef json = JsonOutput.toJson([ new Person(name: 'John'), new Person(name: 'Max') ])\n\nassert json == '[{\"name\":\"John\"},{\"name\":\"Max\"}]'\n```\n\n刚才那个例子中, JSON输出默认没有进行pretty输出. 因此`JsonSlurper`还提供了`prettyPrint`方法\n```groovy\ndef json = JsonOutput.toJson([name: 'John Doe', age: 42])\n\nassert json == '{\"name\":\"John Doe\",\"age\":42}'\n\nassert JsonOutput.prettyPrint(json) == '''\\\n{\n    \"name\": \"John Doe\",\n    \"age\": 42\n}'''.stripIndent()\n```\n\n`prettyPrint`方法只接受一个String类型的字符串, 它不能和`JsonOutput`里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances.\n\n在Groovy中还可以使用`JsonBuilder</code>, `StreamingJsonBuilder`方式创建JSON. 这俩个构建起都提供了一个`DSL</code>, 当构建器生成一个JSON的时候,可以制定一个对象图.\n\n\n```groovy\n// an inclusive range\ndef range = 'a'..'d'\nassert range.size() == 4\nassert range.get(2) == 'c'\nassert range[2] == 'c'\nassert range instanceof java.util.List\nassert range.contains('a')\nassert range.contains('d')\nassert !range.contains('e')\n```\n\nYou can iterate on a range using a classic for loop:\n\n```groovy\nfor (i in 1..10) {\n    println \"Hello ${i}\"\n}\n```\n\nbut alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method:\n\n```groovy\n(1..10).each { i ->\n    println \"Hello ${i}\"\n}\n```\n\nRanges can be also used in the switch statement:\n\n```\nswitch (years) {\n    case 1..10: interestRate = 0.076; break;\n    case 11..25: interestRate = 0.052; break;\n    default: interestRate = 0.037;\n}\n```\n\n# Syntax enhancements for collections\n\n## GPath support\n\nThanks to the support of property notation for both lists and maps, Groovy provides syntactic sugar making it really easy to deal with nested collections, as illustrated in the following examples:\n\n```groovy\ndef listOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22]]\nassert listOfMaps.a == [11, 21] //GPath notation\nassert listOfMaps*.a == [11, 21] //spread dot notation\n\nlistOfMaps = [['a': 11, 'b': 12], ['a': 21, 'b': 22], null]\nassert listOfMaps*.a == [11, 21, null] // caters for null values\nassert listOfMaps*.a == listOfMaps.collect { it?.a } //equivalent notation\n// But this will only collect non-null values\nassert listOfMaps.a == [11,21]\n```\n\n## Spread operator\n\nThe spread operator can be used to \"inline\" a collection into another. It is syntactic sugar which often avoids calls to putAll and facilitates the realization of one-liners:\n\n```groovy\nassert [ 'z': 900,\n         *: ['a': 100, 'b': 200], 'a': 300] == ['a': 300, 'b': 200, 'z': 900]\n//spread map notation in map definition\nassert [*: [3: 3, *: [5: 5]], 7: 7] == [3: 3, 5: 5, 7: 7]\n\ndef f = { [1: 'u', 2: 'v', 3: 'w'] }\nassert [*: f(), 10: 'zz'] == [1: 'u', 10: 'zz', 2: 'v', 3: 'w']\n//spread map notation in function arguments\nf = { map -> map.c }\nassert f(*: ['a': 10, 'b': 20, 'c': 30], 'e': 50) == 30\n\nf = { m, i, j, k -> [m, i, j, k] }\n//using spread map notation with mixed unnamed and named arguments\nassert f('e': 100, *[4, 5], *: ['a': 10, 'b': 20, 'c': 30], 6) ==\n        [[\"e\": 100, \"b\": 20, \"c\": 30, \"a\": 10], 4, 5, 6]\n```\n\n### 2.4.3. The star-dot `*.' operator\n\nThe \"star-dot\" operator is a shortcut operator allowing you to call a method or a property on all elements of a collection:\n\n```groovy\nassert [1, 3, 5] == ['a', 'few', 'words']*.size()\n\nclass Person {\n    String name\n    int age\n}\ndef persons = [new Person(name:'Hugo', age:17), new Person(name:'Sandra',age:19)]\nassert [17, 19] == persons*.age\n```\n\n## Slicing with the subscript operator\n\nYou can index into lists, arrays, maps using the subscript expression. It is interesting that strings are considered as special kinds of collections in that context:\n\n```groovy\ndef text = 'nice cheese gromit!'\ndef x = text[2]\n\nassert x == 'c'\nassert x.class == String\n\ndef sub = text[5..10]\nassert sub == 'cheese'\n\ndef list = [10, 11, 12, 13]\ndef answer = list[2,3]\nassert answer == [12,13]\n```\n\nNotice that you can use ranges to extract part of a collection:\n\n```groovy\nlist = 100..200\nsub = list[1, 3, 20..25, 33]\nassert sub == [101, 103, 120, 121, 122, 123, 124, 125, 133]\n```\n\nThe subscript operator can be used to update an existing collection (for collection type which are not immutable):\n\n```groovy\nlist = ['a','x','x','d']\nlist[1..2] = ['b','c']\nassert list == ['a','b','c','d']\n```\n\nIt is worth noting that negative indices are allowed, to extract more easily from the end of a collection:\n\nYou can use negative indices to count from the end of the List, array, String etc.\n\n```groovy\ntext = \"nice cheese gromit!\"\nx = text[-1]\nassert x == \"!\"\n\ndef name = text[-7..-2]\nassert name == \"gromit\"\n```\n\nEventually, if you use a backwards range (the starting index is greater than the end index), then the answer is reversed.\n\n```groovy\ntext = \"nice cheese gromit!\"\nname = text[3..1]\nassert name == \"eci\"\n```\n\n# Scripting Ant tasks\n\n虽然`Ant`只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用`build.xml`文件或者`Jelly`脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程.\n\nGroovy提供了一个辅助类`AntBuilder`帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们.\n\n`AntBuilder`通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息.\n```groovy\ndef ant = new AntBuilder()          \nant.echo('hello from Ant!')        \n```\n\n1. 创建一个`AntBuilder`实例\n2. 执行`AntBuilder`实例的echo task\n\n假设,现在你需要创建一个ZIP文件：\n```groovy\ndef ant = new AntBuilder()\nant.zip(destfile: 'sources.zip', basedir: 'src')\n```\n\n在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过`AntBuilder`拷贝一组文件.\n```groovy\n// lets just call one task\nant.echo(\"hello\")\n\n// here is an example of a block of Ant inside GroovyMarkup\nant.sequential {\n    echo(\"inside sequential\")\n    def myDir = \"target/AntTest/\"\n    mkdir(dir: myDir)\n    copy(todir: myDir) {\n        fileset(dir: \"src/test\") {\n            include(name: \"**/*.groovy\")\n        }\n    }\n    echo(\"done\")\n}\n\n// now lets do some normal Groovy again\ndef file = new File(ant.project.baseDir,\"target/AntTest/groovy/util/AntTest.groovy\")\nassert file.exists()\n```\n\n下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配.\n```groovy\n// lets create a scanner of filesets\ndef scanner = ant.fileScanner {\n    fileset(dir:\"src/test\") {\n        include(name:\"**/Ant*.groovy\")\n    }\n}\n\n// now lets iterate over\ndef found = false\nfor (f in scanner) {\n    println(\"Found file $f\")\n    found = true\n    assert f instanceof File\n    assert f.name.endsWith(\".groovy\")\n}\nassert found\n```\n\nOr execute a JUnit test:\n\n下面我们执行JUnit\n```groovy\n// lets create a scanner of filesets\nant.junit {\n    test(name:'groovy.util.SomethingThatDoesNotExist')\n}\n```\n\n现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件.\n```groovy\nant.echo(file:'Temp.java', '''\n    class Temp {\n        public static void main(String[] args) {\n            System.out.println(\"Hello\");\n        }\n    }\n''')\nant.javac(srcdir:'.', includes:'Temp.java', fork:'true')\nant.java(classpath:'.', classname:'Temp', fork:'true')\nant.echo('Done')\n```\n\n需要提及的是, `AntBuilder`是内嵌于`Gradle`中的. 你可以像在Groovy中那样, 在`Gradle`使用`AntBuilder`","slug":"groovy","published":1,"date":"2015-09-16T05:56:20.900Z","updated":"2015-09-16T05:55:44.388Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeb3001o74uft5kcaxkh"},{"title":"gitbook使用","_content":"# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n\n","source":"_posts/gitbook.md","raw":"title: gitbook使用\n---\n# 安装gitbook命令行\n\n1. 下载安装`npm`和`io.js`\n2. 安装`git`, `gitbook`需要依赖`git`.\n3. 将`git`的`bin`目录放到环境变量`Path`里\n4. 在windows下npm module一般都是安装到`C:\\Users\\Administrator\\AppData\\Roaming\\npm\\node_modules`这\n    里,所以为了我们能够使用安装好的module,我们将这个路径添加到环境变量`Path`里\n5. 然后使用`npm install gitbook-cli -g` 安装gitbook\n6. 最后验证一下gitbook是否安装成功： `gitbook -V` 我安装的是`0.3.3`, 所以在命令行里直接输出了`0.3.3`\n\n\n# gitbook + github简历博客\n我们假设下列所有操作都在`D:\\git`这个目录下操作\n1. 我们将github上创建的项目`demo`检出到`D:\\git`目录里,最好你也是用svn检出的，因为我是在svn检出的前提下写了个小工具\n2. 然后我们进入到`D:\\git\\demo`目录里,我们会看到`branches`和`trunk`俩个文件夹,`branches`用于存储博客的web文件,`trunk`用于存放博客的`markdown`源文件\n3. 接着我们进入到`D:\\git\\demo\\trunk`新建`blog`文件夹\n4. 进入到`D:\\git\\demo\\trunk\\blog`在这个目录里新建一个`build.bat`批处理脚本文件,同时创建一个`repository`\n5. `build.bat`批处理脚本文件内容为`gitbook build ./repository ../../branches/gh-pages`\n6. 我们使用gitbook客户端在`repository`文件夹内创建一个gitbook项目\n7. 双击运行`build.bat`\n8. 查看`D:\\git\\demo\\branches\\gh-pages`是否生成了一个web站点呢？这个就是我们的博客了\n9. 最后在`D:\\git\\demo`这个目录里上传所有的文件就好了\n\n","slug":"gitbook","published":1,"date":"2015-06-27T07:05:07.677Z","updated":"2015-06-15T04:48:10.862Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeb4001p74uf3kp4e3de"},{"title":"Dropwizard","_content":"\n# Setting Up Maven\n\n在MAVEN的dependency里添加`metrics-core`库\n```xml\n<dependencies>\n    <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics.version}</version>\n    </dependency>\n</dependencies>\n```\n注意，使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n# Meters\n\n`meter`表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, `meter`仍然会追踪`1-,5-,15-`分钟的移动平均数.\n```java\nprivate final Meter requests = metrics.meter(\"requests\");\n\npublic void handleRequest(Request request, Response response) {\n    requests.mark();\n    // etc\n}\n```\n上面的`meter`表示每秒请求数的比例。\n\n# Console Reporter\n\n`Console Reporter`正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次.\n```java\nConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n       .convertRatesTo(TimeUnit.SECONDS)\n       .convertDurationsTo(TimeUnit.MILLISECONDS)\n       .build();\n   reporter.start(1, TimeUnit.SECONDS);\n```\n\n# Complete getting started\n\n下面是一个完整的示例：\n```java\n  package sample;\n  import com.codahale.metrics.*;\n  import java.util.concurrent.TimeUnit;\n\n  public class GetStarted {\n    static final MetricRegistry metrics = new MetricRegistry();\n    public static void main(String args[]) {\n      startReport();\n      Meter requests = metrics.meter(\"requests\");\n      requests.mark();\n      wait5Seconds();\n    }\n\n  static void startReport() {\n      ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n          .convertRatesTo(TimeUnit.SECONDS)\n          .convertDurationsTo(TimeUnit.MILLISECONDS)\n          .build();\n      reporter.start(1, TimeUnit.SECONDS);\n  }\n\n  static void wait5Seconds() {\n      try {\n          Thread.sleep(5*1000);\n      }\n      catch(InterruptedException e) {}\n  }\n}\n```\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>somegroup</groupId>\n  <artifactId>sample</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <name>Example project for Metrics</name>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.dropwizard.metrics</groupId>\n      <artifactId>metrics-core</artifactId>\n      <version>${metrics.version}</version>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n注意：使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n```\nmvn package exec:java -Dexec.mainClass=sample.First\n```\n\n# The Registry\n\nMetrics的核心部分是`MetricRegistry`类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的`MetricRegistry`:\n```java\nfinal MetricRegistry metrics = new MetricRegistry();\n```\n如果你在应用程序中嵌入一个自己创建的`MetricRegistry`实例，你应该将这个属性置为静态的.\n\n# Gauges\n\n`gauge`表示的是一个瞬时值. 例如我们获取队列里待执行的任务数\n```xml\npublic class QueueManager {\n    private final Queue queue;\n\n    public QueueManager(MetricRegistry metrics, String name) {\n        this.queue = new Queue();\n        metrics.register(MetricRegistry.name(QueueManager.class, name, \"size\"),\n                         new Gauge<Integer>() {\n                             @Override\n                             public Integer getValue() {\n                                 return queue.size();\n                             }\n                         });\n    }\n}\n```\n当完成计算之后,它将会返回队列里的任务数。\n\n在`registry`里的每个`metric`都有一个唯一的名字,其命名规范为用`.`分割的字符串,例如`things.count`或者`com.example.Thing.latency`. `MetricRegistry`类提供了一个静态方法来构建这些名字.\n```xml\nMetricRegistry.name(QueueManager.class, \"jobs\", \"size\")\n```\n上面的调用会返回`com.example.QueueManager.jobs.size`。\n\n对于大多数队列或者类队列结构,你也许仅想要获得`queue.size()`这个值. 大多数`java.util`和`java.util.concurrent`包都实现了`size()`方法,它的复杂度是`O(n)`,这意味着你的`gauge`也许会很慢(也许还会持有锁)\n\n# Counters\n\n`counter`是一个内部采用`AtomicLong`计数器的`gauge`实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式:\n```xml\nprivate final Counter pendingJobs = metrics.counter(name(QueueManager.class, \"pending-jobs\"));\n\npublic void addJob(Job job) {\n    pendingJobs.inc();\n    queue.offer(job);\n}\n\npublic Job takeJob() {\n    pendingJobs.dec();\n    return queue.take();\n}\n```\n每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数.\n\n正如你看到的,counter的API是非常不同的是,`counter(String)`取代了`register(String, Metric)`，然而你可以仍然可以使用`register`方法创建你自己的`Counter`实例,实际上`counter(String)`在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用\n\n还需要说明一点,在上例中,我们静态引入了`MetricRegistry`的`name`方法.\n\n# Histograms\n\n`histogram`表示的是流中数据值的静态分布. 除了计算`minimum, maximum, mean, etc`等值,它还计算中间值或者`75th, 90th, 95th, 98th, 99th, 99.9th`等百分比.\n```xml\nprivate final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, \"response-sizes\"));\n\npublic void handleRequest(Request request, Response response) {\n    // etc\n    responseSizes.update(response.getContent().length);\n}\n```\n上面的`histogram`统计了响应中的字节数.\n\n# Timers\n`timer`可以计算某个代码段的调用比例,和调用期间的分布状况.\n```xml\nprivate final Timer responses = metrics.timer(name(RequestHandler.class, \"responses\"));\n\npublic String handleRequest(Request request, Response response) {\n    final Timer.Context context = responses.time();\n    try {\n        // etc;\n        return \"OK\";\n    } finally {\n        context.stop();\n    }\n}\n```\nThis timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second.\n\n\n# Health Checks\n\nMetrics还可以通过`metrics-healthchecks`模块集中检查你的服务的健康.\n\n首先创建一个新的`HealthCheckRegistry`实例\n```xml\nfinal HealthCheckRegistry healthChecks = new HealthCheckRegistry();\nSecond, implement a HealthCheck subclass:\n\npublic class DatabaseHealthCheck extends HealthCheck {\n    private final Database database;\n\n    public DatabaseHealthCheck(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public HealthCheck.Result check() throws Exception {\n        if (database.isConnected()) {\n            return HealthCheck.Result.healthy();\n        } else {\n            return HealthCheck.Result.unhealthy(\"Cannot connect to \" + database.getUrl());\n        }\n    }\n}\n```\n然后将Metrics注册到它身上：\n```xml\nhealthChecks.register(\"postgres\", new DatabaseHealthCheck(database));\n```\n接下来运行所有的health checks:\n```xml\nfinal Map<String, HealthCheck.Resultresults = healthChecks.runHealthChecks();\nfor (Entry<String, HealthCheck.Resultentry : results.entrySet()) {\n    if (entry.getValue().isHealthy()) {\n        System.out.println(entry.getKey() + \" is healthy\");\n    } else {\n        System.err.println(entry.getKey() + \" is UNHEALTHY: \" + entry.getValue().getMessage());\n        final Throwable e = entry.getValue().getError();\n        if (e != null) {\n            e.printStackTrace();\n        }\n    }\n}\n```\nMetrics内置了一种health check：`ThreadDeadlockHealthCheck`,它使用了java内置的线程死锁检测来查找死锁线程.\n\n# Reporting Via JMX\n\n通过`JMX`报告metrics：\n```xml\nfinal JmxReporter reporter = JmxReporter.forRegistry(registry).build();\nreporter.start();\n```\n一旦reporter启动了,registry中的所有的metrics都可以通过`JConsole`或者`VisualVM`看到.\n\nMetrics被包装成`JMX MBeans`,可以在`VisualVM's MBeans browser`查看`Metrics`.\n\n注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你.\n\n# Reporting Via HTTP\n\nMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告`health checks`,打印`thread dump`,或者提供一个负载均衡的简单响应. (它还提供了其他的`servlets–MetricsServlet`,例如`HealthCheckServlet, ThreadDumpServlet`或者`PingServlet`.)\n\n如果想要使用servlet你必须在pom文件中依赖`metrics-servlets`.\n```xml\n<dependency>\n    <groupId>io.dropwizard.metrics</groupId>\n    <artifactId>metrics-servlets</artifactId>\n    <version>${metrics.version}</version>\n</dependency>\n```\n\n# Other Reporting\n\n除了`JMX`和`HTTP`以外,Metrics还提供了下面的报告方式\n\n* `STDOUT`: 使用`metrics-core`的`ConsoleReporter`报告\n* `CSV files`, 使用`metrics-core`的`CsvReporter`报告\n* `SLF4J loggers`, 使用`metrics-core`的`Slf4jReporter`报告\n* `Ganglia`, 使用`metrics-ganglia`的`GangliaReporter`报告\n* `Graphite`, 使用`metrics-graphite`的`GraphiteReporter`报告 ","source":"_posts/dropwizard.md","raw":"title: Dropwizard\n---\n\n# Setting Up Maven\n\n在MAVEN的dependency里添加`metrics-core`库\n```xml\n<dependencies>\n    <dependency>\n        <groupId>io.dropwizard.metrics</groupId>\n        <artifactId>metrics-core</artifactId>\n        <version>${metrics.version}</version>\n    </dependency>\n</dependencies>\n```\n注意，使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n# Meters\n\n`meter`表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, `meter`仍然会追踪`1-,5-,15-`分钟的移动平均数.\n```java\nprivate final Meter requests = metrics.meter(\"requests\");\n\npublic void handleRequest(Request request, Response response) {\n    requests.mark();\n    // etc\n}\n```\n上面的`meter`表示每秒请求数的比例。\n\n# Console Reporter\n\n`Console Reporter`正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次.\n```java\nConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n       .convertRatesTo(TimeUnit.SECONDS)\n       .convertDurationsTo(TimeUnit.MILLISECONDS)\n       .build();\n   reporter.start(1, TimeUnit.SECONDS);\n```\n\n# Complete getting started\n\n下面是一个完整的示例：\n```java\n  package sample;\n  import com.codahale.metrics.*;\n  import java.util.concurrent.TimeUnit;\n\n  public class GetStarted {\n    static final MetricRegistry metrics = new MetricRegistry();\n    public static void main(String args[]) {\n      startReport();\n      Meter requests = metrics.meter(\"requests\");\n      requests.mark();\n      wait5Seconds();\n    }\n\n  static void startReport() {\n      ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics)\n          .convertRatesTo(TimeUnit.SECONDS)\n          .convertDurationsTo(TimeUnit.MILLISECONDS)\n          .build();\n      reporter.start(1, TimeUnit.SECONDS);\n  }\n\n  static void wait5Seconds() {\n      try {\n          Thread.sleep(5*1000);\n      }\n      catch(InterruptedException e) {}\n  }\n}\n```\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n\n  <groupId>somegroup</groupId>\n  <artifactId>sample</artifactId>\n  <version>0.0.1-SNAPSHOT</version>\n  <name>Example project for Metrics</name>\n\n  <dependencies>\n    <dependency>\n      <groupId>io.dropwizard.metrics</groupId>\n      <artifactId>metrics-core</artifactId>\n      <version>${metrics.version}</version>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n注意：使用上面依赖你需要在pom文件里声明了`metrics.version`属性,并且该属性值是`3.1.0`\n\n```\nmvn package exec:java -Dexec.mainClass=sample.First\n```\n\n# The Registry\n\nMetrics的核心部分是`MetricRegistry`类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的`MetricRegistry`:\n```java\nfinal MetricRegistry metrics = new MetricRegistry();\n```\n如果你在应用程序中嵌入一个自己创建的`MetricRegistry`实例，你应该将这个属性置为静态的.\n\n# Gauges\n\n`gauge`表示的是一个瞬时值. 例如我们获取队列里待执行的任务数\n```xml\npublic class QueueManager {\n    private final Queue queue;\n\n    public QueueManager(MetricRegistry metrics, String name) {\n        this.queue = new Queue();\n        metrics.register(MetricRegistry.name(QueueManager.class, name, \"size\"),\n                         new Gauge<Integer>() {\n                             @Override\n                             public Integer getValue() {\n                                 return queue.size();\n                             }\n                         });\n    }\n}\n```\n当完成计算之后,它将会返回队列里的任务数。\n\n在`registry`里的每个`metric`都有一个唯一的名字,其命名规范为用`.`分割的字符串,例如`things.count`或者`com.example.Thing.latency`. `MetricRegistry`类提供了一个静态方法来构建这些名字.\n```xml\nMetricRegistry.name(QueueManager.class, \"jobs\", \"size\")\n```\n上面的调用会返回`com.example.QueueManager.jobs.size`。\n\n对于大多数队列或者类队列结构,你也许仅想要获得`queue.size()`这个值. 大多数`java.util`和`java.util.concurrent`包都实现了`size()`方法,它的复杂度是`O(n)`,这意味着你的`gauge`也许会很慢(也许还会持有锁)\n\n# Counters\n\n`counter`是一个内部采用`AtomicLong`计数器的`gauge`实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式:\n```xml\nprivate final Counter pendingJobs = metrics.counter(name(QueueManager.class, \"pending-jobs\"));\n\npublic void addJob(Job job) {\n    pendingJobs.inc();\n    queue.offer(job);\n}\n\npublic Job takeJob() {\n    pendingJobs.dec();\n    return queue.take();\n}\n```\n每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数.\n\n正如你看到的,counter的API是非常不同的是,`counter(String)`取代了`register(String, Metric)`，然而你可以仍然可以使用`register`方法创建你自己的`Counter`实例,实际上`counter(String)`在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用\n\n还需要说明一点,在上例中,我们静态引入了`MetricRegistry`的`name`方法.\n\n# Histograms\n\n`histogram`表示的是流中数据值的静态分布. 除了计算`minimum, maximum, mean, etc`等值,它还计算中间值或者`75th, 90th, 95th, 98th, 99th, 99.9th`等百分比.\n```xml\nprivate final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, \"response-sizes\"));\n\npublic void handleRequest(Request request, Response response) {\n    // etc\n    responseSizes.update(response.getContent().length);\n}\n```\n上面的`histogram`统计了响应中的字节数.\n\n# Timers\n`timer`可以计算某个代码段的调用比例,和调用期间的分布状况.\n```xml\nprivate final Timer responses = metrics.timer(name(RequestHandler.class, \"responses\"));\n\npublic String handleRequest(Request request, Response response) {\n    final Timer.Context context = responses.time();\n    try {\n        // etc;\n        return \"OK\";\n    } finally {\n        context.stop();\n    }\n}\n```\nThis timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second.\n\n\n# Health Checks\n\nMetrics还可以通过`metrics-healthchecks`模块集中检查你的服务的健康.\n\n首先创建一个新的`HealthCheckRegistry`实例\n```xml\nfinal HealthCheckRegistry healthChecks = new HealthCheckRegistry();\nSecond, implement a HealthCheck subclass:\n\npublic class DatabaseHealthCheck extends HealthCheck {\n    private final Database database;\n\n    public DatabaseHealthCheck(Database database) {\n        this.database = database;\n    }\n\n    @Override\n    public HealthCheck.Result check() throws Exception {\n        if (database.isConnected()) {\n            return HealthCheck.Result.healthy();\n        } else {\n            return HealthCheck.Result.unhealthy(\"Cannot connect to \" + database.getUrl());\n        }\n    }\n}\n```\n然后将Metrics注册到它身上：\n```xml\nhealthChecks.register(\"postgres\", new DatabaseHealthCheck(database));\n```\n接下来运行所有的health checks:\n```xml\nfinal Map<String, HealthCheck.Resultresults = healthChecks.runHealthChecks();\nfor (Entry<String, HealthCheck.Resultentry : results.entrySet()) {\n    if (entry.getValue().isHealthy()) {\n        System.out.println(entry.getKey() + \" is healthy\");\n    } else {\n        System.err.println(entry.getKey() + \" is UNHEALTHY: \" + entry.getValue().getMessage());\n        final Throwable e = entry.getValue().getError();\n        if (e != null) {\n            e.printStackTrace();\n        }\n    }\n}\n```\nMetrics内置了一种health check：`ThreadDeadlockHealthCheck`,它使用了java内置的线程死锁检测来查找死锁线程.\n\n# Reporting Via JMX\n\n通过`JMX`报告metrics：\n```xml\nfinal JmxReporter reporter = JmxReporter.forRegistry(registry).build();\nreporter.start();\n```\n一旦reporter启动了,registry中的所有的metrics都可以通过`JConsole`或者`VisualVM`看到.\n\nMetrics被包装成`JMX MBeans`,可以在`VisualVM's MBeans browser`查看`Metrics`.\n\n注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你.\n\n# Reporting Via HTTP\n\nMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告`health checks`,打印`thread dump`,或者提供一个负载均衡的简单响应. (它还提供了其他的`servlets–MetricsServlet`,例如`HealthCheckServlet, ThreadDumpServlet`或者`PingServlet`.)\n\n如果想要使用servlet你必须在pom文件中依赖`metrics-servlets`.\n```xml\n<dependency>\n    <groupId>io.dropwizard.metrics</groupId>\n    <artifactId>metrics-servlets</artifactId>\n    <version>${metrics.version}</version>\n</dependency>\n```\n\n# Other Reporting\n\n除了`JMX`和`HTTP`以外,Metrics还提供了下面的报告方式\n\n* `STDOUT`: 使用`metrics-core`的`ConsoleReporter`报告\n* `CSV files`, 使用`metrics-core`的`CsvReporter`报告\n* `SLF4J loggers`, 使用`metrics-core`的`Slf4jReporter`报告\n* `Ganglia`, 使用`metrics-ganglia`的`GangliaReporter`报告\n* `Graphite`, 使用`metrics-graphite`的`GraphiteReporter`报告 ","slug":"dropwizard","published":1,"date":"2015-07-07T12:07:03.407Z","updated":"2015-07-07T12:05:12.217Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeb5001q74ufj61kdzpe"},{"title":"docker命令","_content":"## Docker命令\n#### `service docker start`  \n安装之后启动 Docker 服务.\n\n#### `docker pull` \n命令来从仓库获取所需要的镜像\n```\ndocker pull ubuntu12.04\n```\n\n#### `docker push` \n把自己创建的镜像上传到仓库中来共享\n```\ndocker push ouruser/sinatra\n```\n\n#### `docker images` \n显示本地已有的镜像.\n\n#### `docker commit` \n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n#### `docker build` \n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n#### `docker tag` \n命令来修改镜像的标签.\n```\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n#### `docker import` \n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n#### `docker save` \n导出镜像到本地文件\n```\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n#### `docker load` \n从导出的本地文件中再导入到本地镜像库 \n```\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n#### `docker rmi` \n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```\nsudo docker rmi training/sinatra\n```\n\n#### `docker run`  \n基于镜像新建一个容器并启动\n```\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n###### 映射所有接口地址\n使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n###### 此时默认会绑定本地所有接口上的所有地址。\n映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n##### 映射到指定地址的任意端口\n使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n#### `docker start` \n直接将一个已经终止的容器启动运行\n\n#### `docker stop` \n终止一个运行中的容器.\n\n#### `docker restart` \n将一个运行态的容器终止,然后再重新启动它.\n\n#### `docker attach` \n进入容器\n\n#### `docker export ` \n导出本地某个容器\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n#### `docker import` \n从容器快照文件中再导入为镜像\n```\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n#### `docker rm` \n移除容器.删除一个处于终止状态的容器\n```\ndocker rm  trusting_newton\n```\n\n#### `docker search` \n查找官方仓库中的镜像\n\n#### `docker ps` \n\n#### `docker logs` \n获取容器的输出信息\n```\ndocker logs insane_babbage\n```\n\n#### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile \n\nDockerfile中每一条指令都创建镜像的一层,例如\n```\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n##### 当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n##### `docker load` vs `docker import`\n用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n\n","source":"_posts/docker命令.md","raw":"title: docker命令\n---\n## Docker命令\n#### `service docker start`  \n安装之后启动 Docker 服务.\n\n#### `docker pull` \n命令来从仓库获取所需要的镜像\n```\ndocker pull ubuntu12.04\n```\n\n#### `docker push` \n把自己创建的镜像上传到仓库中来共享\n```\ndocker push ouruser/sinatra\n```\n\n#### `docker images` \n显示本地已有的镜像.\n\n#### `docker commit` \n使用 docker commit 命令来提交更新后的副本. 这个命令是用来将容器的改变提交到镜像身上.如果目标镜像不存在就创建一个.\n```\nsudo docker commit -m \"Added json gem\" -a \"Docker Newbee\" 0b2616b0e5a8 ouruser/sinatrav2\n```\n* `-m` : 来指定提交的说明信息，跟我们使用的版本控制工具一样；\n* `-a` : 可以指定更新的用户信息；\n* `0b2616b0e5a8` : 用来创建镜像的容器的 ID；\n* `ouruser/sinatrav2` : 指定目标镜像的仓库名和 tag 信息。\n\n\n#### `docker build` \n使用 docker build 来创建一个新的镜像.为此,首先需要创建一个 Dockerfile,包含一些如何创建镜像的指令.\n```\ndocker build -t=\"ouruser/sinatrav2\"\n```\n* -t 标记来添加 tag,指定新的镜像的用户信息\n\n#### `docker tag` \n命令来修改镜像的标签.\n```\ndocker tag 5db5f8471261 ouruser/sinatradevel\n```\n\n#### `docker import` \n从本地文件系统导入一个镜像,可以使用 openvz(容器虚拟化的先锋技术)的模板来创建 openvz 的模板下载地址为 templates .比如,先下载了一个 ubuntu-14.04 的镜像,之后使用以下命令导入\n```\ncat ubuntu-14.04-x86_64-minimal.tar.gz  |docker import - ubuntu14.04\n```\n\n#### `docker save` \n导出镜像到本地文件\n```\ndocker save -o ubuntu_14.04.tar ubuntu14.04\n```\n\n#### `docker load` \n从导出的本地文件中再导入到本地镜像库 \n```\ndocker load --input ubuntu_14.04.tar\ndocker load < ubuntu_14.04.tar\n```\n\n#### `docker rmi` \n移除本地的镜像. 注意在删除镜像之前要先用 docker rm 删掉依赖于这个镜像的所有容器.\n```\nsudo docker rmi training/sinatra\n```\n\n#### `docker run`  \n基于镜像新建一个容器并启动\n```\ndocker run ubuntu14.04\n\ndocker run -t -i ubuntu14.04 /bin/bash\n```\n* -t 选项让Docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上\n* -i 则让容器的标准输入保持打开.\n* -d 让 Docker 容器在后台以守护态(Daemonized)形式运行\n* -P 端口映射.当使用 -P 标记时，Docker 会随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n\n> -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 `ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort`   在`--net=host`模式下，可以时容器内的端口自动映射到宿主主机上\n\n\n###### 映射所有接口地址\n使用 `hostPort:containerPort` 格式本地的 `5000` 端口映射到容器的 `5000` 端口，可以执行\n```\n$ sudo docker run -d -p 5000:5000 training/webapp python app.py\n```\n\n###### 此时默认会绑定本地所有接口上的所有地址。\n映射到指定地址的指定端口\n\n可以使用 `ip:hostPort:containerPort` 格式指定映射使用一个特定地址，比如 `localhost` 地址 `127.0.0.1`\n```\n$ sudo docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py\n```\n\n##### 映射到指定地址的任意端口\n使用 `ip::containerPort` 绑定 `localhost` 的任意端口到容器的 `5000` 端口，本地主机会自动分配一个端口。\n```\n$ sudo docker run -d -p 127.0.0.1::5000 training/webapp python app.py\n```\n\n#### `docker start` \n直接将一个已经终止的容器启动运行\n\n#### `docker stop` \n终止一个运行中的容器.\n\n#### `docker restart` \n将一个运行态的容器终止,然后再重新启动它.\n\n#### `docker attach` \n进入容器\n\n#### `docker export ` \n导出本地某个容器\n```\ndocker export 7691a814370e > ubuntu.tar\n```\n\n#### `docker import` \n从容器快照文件中再导入为镜像\n```\ncat ubuntu.tar | sudo docker import - test/buntuv1.0\n\ndocker import http//example.com/exampleimage.tgz example/imagerepo\n```\n\n#### `docker rm` \n移除容器.删除一个处于终止状态的容器\n```\ndocker rm  trusting_newton\n```\n\n#### `docker search` \n查找官方仓库中的镜像\n\n#### `docker ps` \n\n#### `docker logs` \n获取容器的输出信息\n```\ndocker logs insane_babbage\n```\n\n#### `docker port`\n查看当前映射的端口配置，也可以查看到绑定的地址\n```\ndocker port nostalgic_morse 5000\n```\n\n\n## Dockerfile \n\nDockerfile中每一条指令都创建镜像的一层,例如\n```\n# This is a comment\nFROM ubuntu14.04\nMAINTAINER Docker Newbee <newbee@docker.com>\nRUN apt-get -qq update\nRUN apt-get -qqy install ruby ruby-dev\nRUN gem install sinatra\nDockerfile 基本的语法是\n```\n1. 使用`#`来注释\n2. `FROM` 指令告诉 `Docker` 使用哪个镜像作为基础\n3. 接着是维护者的信息\n4. `RUN`开头的指令会在创建中运行,比如安装一个软件包,在这里使用 `apt-get` 来安装了一些软件\n5. `ADD` 命令复制本地文件到镜像;\n6. `EXPOSE` 命令来向外部开放端口;\n7. `CMD` 命令来描述容器启动后运行的程序等\n\n\n##### 当利用 `docker run` 来创建容器时,`Docker` 在后台运行的标准操作包括\n1. 检查本地是否存在指定的镜像,不存在就从公有仓库下载\n2. 利用镜像创建并启动一个容器\n3. 分配一个文件系统,并在只读的镜像层外面挂载一层可读写层\n4. 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去\n5. 从地址池配置一个 ip 地址给容器\n6. 执行用户指定的应用程序\n7. 执行完毕后容器被终止\n\n\n##### `docker load` vs `docker import`\n用户既可以使用 `docker load` 来导入镜像存储文件到本地镜像库,也可以使用 `docker import `来导入一个容器快照到本地镜像库.这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息(即仅保存容器当时的快照状态),而镜像存储文件将保存完整记录,体积也要大.此外,从容器快照文件导入时可以重新指定标签等元数据信息.\n\n","slug":"docker命令","published":1,"date":"2015-06-27T07:05:07.520Z","updated":"2015-06-15T04:46:29.100Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeb6001r74uf2jreumyi"},{"title":"并发集合","_content":"java 提供了俩类用于并发的集合\n\n###### 基本上,Java提供两种在并发应用程序中使用的集合：\n* 阻塞式集合:这类集合包括添加和移除数据的方法.当集合已满或为空时,被调用的添加或者移除的方法就不能立即被执行,那么调用这个方法的线程将被阻塞,一直到该方法可以被执行.\n\t\t\t  这种集合包括添加和删除数据的操作.如果操作不能立即进行,是因为集合已满或者为空,该程序将被阻塞,直到操作可以进行.\n* 非阻塞式集合:这类集合也包括添加和移除数据的方法,如果方法不能被执行,则返回null或者抛出异常,但是调用这个方法的线程不会被阻塞.\n\t\t\t\t这种集合也包括添加和删除数据的操作.如果操作不能立即进行,这个操作将返回null值或抛出异常,但该线程将不会阻塞.\n\t\t\t  \n如果我们要实现一个线程安全的队列有两种实现方式：一种是使用阻塞算法,另一种是使用非阻塞算法.使用阻塞算法的队列可以用一个锁(入队和出队用同一把锁)或两个锁(入队和出队用不同的锁)等方式来实现,\n而非阻塞的实现方式则可以使用循环CAS的方式来实现,\n\n## 阻塞队列:\n\n###### 阻塞队列说明:\n> 它实质上就是一种带有一点扭曲的 FIFO 数据结构.它提供了可阻塞的put和take方法.如果Queue已经满了,put方法会被阻塞直到有空间可用;如果Queue是空的,那么take方法会被阻塞,直到有元素可用.offer方法如果数据项不能被添加到队列中,会返回一个失败的状态.Queue的长度可用有限,也可以无限;无限的Queue永远不会充满,所以它的put方法永远不会被阻塞.阻塞队列支持生产者-消费者设计模式.BlockingQueue可以使用任意数量的生产者和消费者,从而简化了生产者-消费者设计的实现.\n\n> Java6 新增了俩种新的容器类型 Deque和 BlockingDeque 分别对Queue 和BlockingQueue 进行了拓展Deque是一个双端队列,实现了在队列头和队列尾 > > > 高效的插入和移除.正如阻塞队列适用于生产者和消费者模式,双端队列适用于工作密取模式(工作密取模式非常适用于既是生产者又是消费者问题).\n\n> ArrayDeque：Deque是基于有首尾指针的数组(环形缓冲区)实现的.和LinkedList不同,这个类没有实现List接口.因此,如果没有首尾元素的话就不能取出任何元素.这个类比LinkedList要好一些,因为它产生的垃圾数量较少(在扩展的时候旧的数组会被丢弃).Stack：一种后进先出的队列.不要在生产代码中使用,使用别的Deque来代替(ArrayDeque比较好).PriorityQueue：一个基于优先级的队列.使用自然顺序或者制定的比较器来排序.他的主要属性——poll/peek/remove/element会返回一个队列的最小值.不仅如此,PriorityQueue还实现了Iterable接口,队列迭代时不进行排序(或者其他顺序).在需要排序的集合中,使用这个队列会比TreeSet等其他队列要方便.\n\n* `BlockingQueue`：简化了生产者-消费者实现过程,支持任意数量的生产者或者消费者.\n* `ArrayBlockingQueue`：一个由数组结构(ArrayList)组成的有界阻塞队列.比同步List拥有更高的并发性\n基于数组实现的一个有界阻塞队,大小不能重新定义.所以当你试图向一个满的队列添加元素的时候,\n就会受到阻塞,直到另一个方法从队列中取出元素.\n\n* `DelayQueue`：一个由优先级堆支持的、基于时间的调度队列.存储延迟元素的阻塞列表无界的保存Delayed元素的集合.元素只有在延时已经过期的时候才能被取出.队列的第一个元素延期最小\n(包含负值——延时已经过期).当你要实现一个延期任务的队列的时候使用(不要自己手动实现——使用ScheduledThreadPoolExecutor).\n\n* `LinkedBlockingDeque`: 一个由链表结构组成的双向阻塞队列.可选择有界或者无界基于链表的实现.在队列为空或者满的情况下使用ReentrantLock-s.LinkedBlockingQueue与此一样\n\n* `LinkedBlockingQueue`：一个由链表结构(LinkedList)组成的有界阻塞队列.比同步List拥有更高的并发性\n\n* `LinkedTransferQueue`: 一个由链表结构组成的无界阻塞队列.基于链表的无界队列.除了通常的队列操作,它还有一系列的transfer方法,可以让生产者直接给等待的消费者传递信息,这样就不用将元素存储到队列中了.这是一个基于CAS操作的无锁集合.\n\n* `PriorityBlockingQueue`：一个支持优先级排序的无界阻塞队列.PriorityQueue的无界的版本.\n\n* `SynchronousQueue`：一个不存储元素的阻塞队列.它维护一组线程,这些线程在等待着吧元素加入或移除队列.一个有界队列,其中没有任何内存容量.这就意味着任何插入操作必须等到响应的取出操作才能执行,反之亦反.如果不需要Queue接口的话,通过Exchanger类也能完成响应的功能.\n\n\n###### 非阻塞集合说明:\n\n这一部分将介绍java.util.concurrent包中线程安全的集合.这些集合的主要属性是一个不可分割的必须执行的方法.因为并发的操作,例如add或update或者check再update,都有一次以上的调用,必须同步.因为第一步从集合中组合操作查询到的信息在开始第二步操作时可能变为无效数据.多数的并发集合是在Java 1.5引入的.ConcurrentSkipListMap / ConcurrentSkipListSet 和 LinkedBlockingDeque\n是在Java 1.6新加入的.Java 1.7加入了最后的 ConcurrentLinkedDeque 和 LinkedTransferQueue\n\n\n## 非阻塞集合:\n\n* `ConcurrentHashMap`:  代替基于散列的Map,使用分段锁机制,任意数量的读取线程可以访问Map,读取线程和写入线程可以并发的访问Map, 一定数量的写入线程可以并发的修改Map.ConcurrentHashMap没有实现对Map加锁以提供独占访问 (Hashtable和synchronizedMap 都可以获得Map的锁以防止其他线程的访问).ConcurrentHashMap本身实现了很多原子复合操作,具体参考测试程序.\n\nget操作全并发访问,put操作可配置并发操作的哈希表.并发的级别可以通过构造函数中concurrencyLevel参数设置(默认级别16).该参数会在Map内部划分一些分区.在put操作的时候只有只有更新的分区是锁住的.\n这种Map不是代替HashMap的线程安全版本——任何 get-then-put的操作都需要在外部进行同步.\n\n* `ConcurrentLinkedDeque`: 非阻塞列表. 基于链表实现的无界队列,添加元素不会堵塞.但是这就要求这个集合的消费者工作速度至少要和生产这一样快,不然内存就会耗尽.严重依赖于CAS(compare-and-set)操作.\n\n* `ConcurrentLinkedQueue`: 一个传统的先进先出队列\n\n* `ConcurrentSkipListMap`: 作为同步的SortedMap.基于跳跃列表(Skip List)的ConcurrentNavigableMap实现.本质上这种集合可以当做一种TreeMap的线程安全版本来使用\n\n* `ConcurrentSkipListSet`: 作为同步的SortedSet.使用 ConcurrentSkipListMap来存储的线程安全的Set.\n\n* `CopyOnWriteArrayList`: list的实现每一次更新都会产生一个新的隐含数组副本,所以这个操作成本很高.通常用在遍历操作比更新操作多的集合,比如listeners/observers集合.最适合于读操作通常大大超过写操作的情况.代替遍历操作为主要操作的同步的List.如果写大于读的并发用什么?\n\n* `CopyOnWriteArraySet`: 最适合于读操作通常大大超过写操作的情况.使用CopyOnWriteArrayList来存储的线程安全的Set\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/concurrency/collection/简介.md","raw":"category: \n- collection\ntitle: 并发集合\n---\njava 提供了俩类用于并发的集合\n\n###### 基本上,Java提供两种在并发应用程序中使用的集合：\n* 阻塞式集合:这类集合包括添加和移除数据的方法.当集合已满或为空时,被调用的添加或者移除的方法就不能立即被执行,那么调用这个方法的线程将被阻塞,一直到该方法可以被执行.\n\t\t\t  这种集合包括添加和删除数据的操作.如果操作不能立即进行,是因为集合已满或者为空,该程序将被阻塞,直到操作可以进行.\n* 非阻塞式集合:这类集合也包括添加和移除数据的方法,如果方法不能被执行,则返回null或者抛出异常,但是调用这个方法的线程不会被阻塞.\n\t\t\t\t这种集合也包括添加和删除数据的操作.如果操作不能立即进行,这个操作将返回null值或抛出异常,但该线程将不会阻塞.\n\t\t\t  \n如果我们要实现一个线程安全的队列有两种实现方式：一种是使用阻塞算法,另一种是使用非阻塞算法.使用阻塞算法的队列可以用一个锁(入队和出队用同一把锁)或两个锁(入队和出队用不同的锁)等方式来实现,\n而非阻塞的实现方式则可以使用循环CAS的方式来实现,\n\n## 阻塞队列:\n\n###### 阻塞队列说明:\n> 它实质上就是一种带有一点扭曲的 FIFO 数据结构.它提供了可阻塞的put和take方法.如果Queue已经满了,put方法会被阻塞直到有空间可用;如果Queue是空的,那么take方法会被阻塞,直到有元素可用.offer方法如果数据项不能被添加到队列中,会返回一个失败的状态.Queue的长度可用有限,也可以无限;无限的Queue永远不会充满,所以它的put方法永远不会被阻塞.阻塞队列支持生产者-消费者设计模式.BlockingQueue可以使用任意数量的生产者和消费者,从而简化了生产者-消费者设计的实现.\n\n> Java6 新增了俩种新的容器类型 Deque和 BlockingDeque 分别对Queue 和BlockingQueue 进行了拓展Deque是一个双端队列,实现了在队列头和队列尾 > > > 高效的插入和移除.正如阻塞队列适用于生产者和消费者模式,双端队列适用于工作密取模式(工作密取模式非常适用于既是生产者又是消费者问题).\n\n> ArrayDeque：Deque是基于有首尾指针的数组(环形缓冲区)实现的.和LinkedList不同,这个类没有实现List接口.因此,如果没有首尾元素的话就不能取出任何元素.这个类比LinkedList要好一些,因为它产生的垃圾数量较少(在扩展的时候旧的数组会被丢弃).Stack：一种后进先出的队列.不要在生产代码中使用,使用别的Deque来代替(ArrayDeque比较好).PriorityQueue：一个基于优先级的队列.使用自然顺序或者制定的比较器来排序.他的主要属性——poll/peek/remove/element会返回一个队列的最小值.不仅如此,PriorityQueue还实现了Iterable接口,队列迭代时不进行排序(或者其他顺序).在需要排序的集合中,使用这个队列会比TreeSet等其他队列要方便.\n\n* `BlockingQueue`：简化了生产者-消费者实现过程,支持任意数量的生产者或者消费者.\n* `ArrayBlockingQueue`：一个由数组结构(ArrayList)组成的有界阻塞队列.比同步List拥有更高的并发性\n基于数组实现的一个有界阻塞队,大小不能重新定义.所以当你试图向一个满的队列添加元素的时候,\n就会受到阻塞,直到另一个方法从队列中取出元素.\n\n* `DelayQueue`：一个由优先级堆支持的、基于时间的调度队列.存储延迟元素的阻塞列表无界的保存Delayed元素的集合.元素只有在延时已经过期的时候才能被取出.队列的第一个元素延期最小\n(包含负值——延时已经过期).当你要实现一个延期任务的队列的时候使用(不要自己手动实现——使用ScheduledThreadPoolExecutor).\n\n* `LinkedBlockingDeque`: 一个由链表结构组成的双向阻塞队列.可选择有界或者无界基于链表的实现.在队列为空或者满的情况下使用ReentrantLock-s.LinkedBlockingQueue与此一样\n\n* `LinkedBlockingQueue`：一个由链表结构(LinkedList)组成的有界阻塞队列.比同步List拥有更高的并发性\n\n* `LinkedTransferQueue`: 一个由链表结构组成的无界阻塞队列.基于链表的无界队列.除了通常的队列操作,它还有一系列的transfer方法,可以让生产者直接给等待的消费者传递信息,这样就不用将元素存储到队列中了.这是一个基于CAS操作的无锁集合.\n\n* `PriorityBlockingQueue`：一个支持优先级排序的无界阻塞队列.PriorityQueue的无界的版本.\n\n* `SynchronousQueue`：一个不存储元素的阻塞队列.它维护一组线程,这些线程在等待着吧元素加入或移除队列.一个有界队列,其中没有任何内存容量.这就意味着任何插入操作必须等到响应的取出操作才能执行,反之亦反.如果不需要Queue接口的话,通过Exchanger类也能完成响应的功能.\n\n\n###### 非阻塞集合说明:\n\n这一部分将介绍java.util.concurrent包中线程安全的集合.这些集合的主要属性是一个不可分割的必须执行的方法.因为并发的操作,例如add或update或者check再update,都有一次以上的调用,必须同步.因为第一步从集合中组合操作查询到的信息在开始第二步操作时可能变为无效数据.多数的并发集合是在Java 1.5引入的.ConcurrentSkipListMap / ConcurrentSkipListSet 和 LinkedBlockingDeque\n是在Java 1.6新加入的.Java 1.7加入了最后的 ConcurrentLinkedDeque 和 LinkedTransferQueue\n\n\n## 非阻塞集合:\n\n* `ConcurrentHashMap`:  代替基于散列的Map,使用分段锁机制,任意数量的读取线程可以访问Map,读取线程和写入线程可以并发的访问Map, 一定数量的写入线程可以并发的修改Map.ConcurrentHashMap没有实现对Map加锁以提供独占访问 (Hashtable和synchronizedMap 都可以获得Map的锁以防止其他线程的访问).ConcurrentHashMap本身实现了很多原子复合操作,具体参考测试程序.\n\nget操作全并发访问,put操作可配置并发操作的哈希表.并发的级别可以通过构造函数中concurrencyLevel参数设置(默认级别16).该参数会在Map内部划分一些分区.在put操作的时候只有只有更新的分区是锁住的.\n这种Map不是代替HashMap的线程安全版本——任何 get-then-put的操作都需要在外部进行同步.\n\n* `ConcurrentLinkedDeque`: 非阻塞列表. 基于链表实现的无界队列,添加元素不会堵塞.但是这就要求这个集合的消费者工作速度至少要和生产这一样快,不然内存就会耗尽.严重依赖于CAS(compare-and-set)操作.\n\n* `ConcurrentLinkedQueue`: 一个传统的先进先出队列\n\n* `ConcurrentSkipListMap`: 作为同步的SortedMap.基于跳跃列表(Skip List)的ConcurrentNavigableMap实现.本质上这种集合可以当做一种TreeMap的线程安全版本来使用\n\n* `ConcurrentSkipListSet`: 作为同步的SortedSet.使用 ConcurrentSkipListMap来存储的线程安全的Set.\n\n* `CopyOnWriteArrayList`: list的实现每一次更新都会产生一个新的隐含数组副本,所以这个操作成本很高.通常用在遍历操作比更新操作多的集合,比如listeners/observers集合.最适合于读操作通常大大超过写操作的情况.代替遍历操作为主要操作的同步的List.如果写大于读的并发用什么?\n\n* `CopyOnWriteArraySet`: 最适合于读操作通常大大超过写操作的情况.使用CopyOnWriteArrayList来存储的线程安全的Set\n\n\n\n\n\n\n\n\n\n\n","slug":"concurrency/collection/简介","published":1,"date":"2015-09-18T08:39:47.211Z","updated":"2015-09-18T08:39:47.211Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeb7001s74uf533ov82x"},{"title":"���ɲ���������","_content":"ThreadLocalRandom 线程本地变量.每个生成随机数的线程都有一个不同的生成��?但都是在同一个类中被管理.\n","source":"_posts/concurrency/collection/生成并发随机数.md","raw":"category: \n- collection\ntitle: ���ɲ���������\n---\nThreadLocalRandom 线程本地变量.每个生成随机数的线程都有一个不同的生成��?但都是在同一个类中被管理.\n","slug":"concurrency/collection/生成并发随机数","published":1,"date":"2015-09-18T08:39:43.380Z","updated":"2015-09-18T08:39:43.380Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeba001v74ufzof5o6vs"},{"title":"ConcurrentLinkedDequeʹ�÷�����ʽ�̰߳�ȫ�б�","_content":"ConcurrentLinkedDeque 为非阻塞式并发列��?\n\n并发列表允许不同的线程在同一时间添加或移除列表中的元��?而不会造成数据不一��?\n\n* `list.pollFirst()`\t// 返回并移除列表中的第一个元��?列表为空返回null\n* `list.pollLast()`\t\t// 返回并移除列表中的最后一个元��?列表为空返回null\n* `list.remove()`\t\t// 返回并移除列表中的第一个元��?列表为空抛出NoSuchElementException\n* `list.removeFirst()`\t// 返回并移除列表中的第一个元��?列表为空抛出NoSuchElementException\n* `list.removeLast()`\t// 返回并移除列表中的最后一个元��?列表为空抛出NoSuchElementException\n\n* `list.getFirst()`\t\t// 返回列表中的第一个元素但不移��?列表为空抛出NoSuchElementException\n* `list.getLast()`\t\t// 返回列表中的最后一个元素但不移��?列表为空抛出NoSuchElementException\n* `list.peek()`\t\t\t// 返回列表中的第一个元素但不移��?列表为空返回null\n* `list.peekFirst()`\t    // 返回列表中的第一个元素但不移��?列表为空返回null\n* `list.peekLast()`\t\t// 返回列表中的最后一个元素但不移��?列表为空返回null\n\n`ConcurrentLinkedQueue`是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了`wait－free`算法来实现，该算法在Michael & Scott算法上进行了一些修��?\n","source":"_posts/concurrency/collection/使用非阻塞式线程安全列表.md","raw":"category: \n- collection\ntitle: ConcurrentLinkedDequeʹ�÷�����ʽ�̰߳�ȫ�б�\n---\nConcurrentLinkedDeque 为非阻塞式并发列��?\n\n并发列表允许不同的线程在同一时间添加或移除列表中的元��?而不会造成数据不一��?\n\n* `list.pollFirst()`\t// 返回并移除列表中的第一个元��?列表为空返回null\n* `list.pollLast()`\t\t// 返回并移除列表中的最后一个元��?列表为空返回null\n* `list.remove()`\t\t// 返回并移除列表中的第一个元��?列表为空抛出NoSuchElementException\n* `list.removeFirst()`\t// 返回并移除列表中的第一个元��?列表为空抛出NoSuchElementException\n* `list.removeLast()`\t// 返回并移除列表中的最后一个元��?列表为空抛出NoSuchElementException\n\n* `list.getFirst()`\t\t// 返回列表中的第一个元素但不移��?列表为空抛出NoSuchElementException\n* `list.getLast()`\t\t// 返回列表中的最后一个元素但不移��?列表为空抛出NoSuchElementException\n* `list.peek()`\t\t\t// 返回列表中的第一个元素但不移��?列表为空返回null\n* `list.peekFirst()`\t    // 返回列表中的第一个元素但不移��?列表为空返回null\n* `list.peekLast()`\t\t// 返回列表中的最后一个元素但不移��?列表为空返回null\n\n`ConcurrentLinkedQueue`是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了`wait－free`算法来实现，该算法在Michael & Scott算法上进行了一些修��?\n","slug":"concurrency/collection/使用非阻塞式线程安全列表","published":1,"date":"2015-09-18T08:40:22.887Z","updated":"2015-09-18T08:40:22.887Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebc001x74ufxec2fc7c"},{"title":"LinkedBlockingDequeʹ������ʽ�̰߳�ȫ�б�","_content":"# LinkedBlockingDeque 阻塞式并发列��?\n\nLinkedBlockingDeque是一个由链表结构组成的双向阻塞队��?所谓双向队列指的你可以从队列的两端插入和移出元��?\n双端队列因为多了一个操作队列的入口,在多线程同时入队��?也就减少了一半的竞争.相比其他的阻塞队��?LinkedBlockingDeque多了addFirst\n,addLast,offerFirst,offerLast,peekFirst,peekLast等方��?以First单词结尾的方��?表示插入,获取（peek）或移除双端队列的第一个元��?以Last单词结尾的方��?表示插入,获取或移除双端队列的最后一个元��?另外插入方法add等同于addLast,移除方法remove等效于removeFirst.但是take方法却等同于takeFirst ,不知道是不是Jdk的bug,使用时还是用带有First和Last后缀的方法更清楚.\n在初始化LinkedBlockingDeque时可以初始化队列的容��?,用来防止其再扩容时过渡膨胀.另外双向阻塞队列可以运用在“工作窃取”模式中.\n\n> 阻塞式并发列表与非阻塞式并发列表主要区别在于��?\n> 阻塞式并发列表在插入或者删除元素时,如果列表已满或者列表为��?操作不会立即被执��?而是将调用这个操作的线程阻塞队列直到操作可以执行成功.\n\n* takeFirst();\t// 返回并移除列表中的第一个元��?列表为空线程将阻��?\n* takeLast();\t// 返回并移除列表中的最后一个元��?列表为空线程将阻��?\n* pollFirst();\t// 返回并移除列表中的第一个元��?列表为空返回null\n* pollLast();  // 返回并移除列表中的最后一个元��?列表为空返回null\n\n* getFirst();\t// 返回列表中的第一个元素但不移��?列表为空抛出NoSuchElementException\n* getLast();\t// 返回列表中的最后一个元素但不移��?列表为空抛出NoSuchElementException\n* peek();\t\t// 返回列表中的第一个元素但不移��?列表为空返回null\n* peekFirst();\t// 返回列表中的第一个元素但不移��?列表为空返回null\n* peekLast();\t// 返回列表中的最后一个元素但不移��?列表为空返回null\n\n\nLinkedBlockingQueue是一个用链表实现的有界阻塞队��?此队列的默认和最大长度为Integer.MAX_VALUE.此队列按照先进先出的原则对元素进行排��?\n\n一种通过链表实现的阻塞队列，支持先进先出.队列的头部是队列中保持时间最长的元素，队列的尾部是保持时间最短的元素.新元素插入队列的尾部.\n可选的容量设置可以有效防止队列过于扩张造成系统资源的过多消耗，如果不指定队列容量，队列默认使用Integer.MAX_VALUE.LinkedBlockingQueue的特定是，支持无限（理论上）容量.\n\nLinkedBlockingQueue是一个基于已链接节点的、范围任意的blocking queue的实��?此队列按FIFO（先进先出）排序元素.队列的头��?是在队列中时间最长的元素.队列的尾��?是在队列中时间最短的元素.\n\n新元素插入到队列的尾��?并且队列检索操作会获得位于队列头部的元��?\n\n链接队列的吞吐量通常要高于基于数组的队列,\n\n但是在大多数并发应用程序��?其可预知的性能要低.可选的容量范围构造方法参数作为防止队列过度扩展的一种方��?如果未指定容��?则它等于Integer.MAX_VALUE.除非插入节点会使队列超出容量,否则每次插入后会动态地创建链接节点.\n\n1. 如果未指定容��?默认容量为Integer.MAX_VALUE ,容量范围可以在构造方法参数中指定作为防止队列过度扩展.\n2. 此对象是 线程阻塞-安全��?\n3. 不接��?null 元素\n4. 它实现了BlockingQueue接口.\n5. 实现��?Collection ��?Iterator 接口的所有可��?方法.\n\n","source":"_posts/concurrency/collection/使用阻塞式线程安全列表.md","raw":"category: \n- collection\ntitle: LinkedBlockingDequeʹ������ʽ�̰߳�ȫ�б�\n---\n# LinkedBlockingDeque 阻塞式并发列��?\n\nLinkedBlockingDeque是一个由链表结构组成的双向阻塞队��?所谓双向队列指的你可以从队列的两端插入和移出元��?\n双端队列因为多了一个操作队列的入口,在多线程同时入队��?也就减少了一半的竞争.相比其他的阻塞队��?LinkedBlockingDeque多了addFirst\n,addLast,offerFirst,offerLast,peekFirst,peekLast等方��?以First单词结尾的方��?表示插入,获取（peek）或移除双端队列的第一个元��?以Last单词结尾的方��?表示插入,获取或移除双端队列的最后一个元��?另外插入方法add等同于addLast,移除方法remove等效于removeFirst.但是take方法却等同于takeFirst ,不知道是不是Jdk的bug,使用时还是用带有First和Last后缀的方法更清楚.\n在初始化LinkedBlockingDeque时可以初始化队列的容��?,用来防止其再扩容时过渡膨胀.另外双向阻塞队列可以运用在“工作窃取”模式中.\n\n> 阻塞式并发列表与非阻塞式并发列表主要区别在于��?\n> 阻塞式并发列表在插入或者删除元素时,如果列表已满或者列表为��?操作不会立即被执��?而是将调用这个操作的线程阻塞队列直到操作可以执行成功.\n\n* takeFirst();\t// 返回并移除列表中的第一个元��?列表为空线程将阻��?\n* takeLast();\t// 返回并移除列表中的最后一个元��?列表为空线程将阻��?\n* pollFirst();\t// 返回并移除列表中的第一个元��?列表为空返回null\n* pollLast();  // 返回并移除列表中的最后一个元��?列表为空返回null\n\n* getFirst();\t// 返回列表中的第一个元素但不移��?列表为空抛出NoSuchElementException\n* getLast();\t// 返回列表中的最后一个元素但不移��?列表为空抛出NoSuchElementException\n* peek();\t\t// 返回列表中的第一个元素但不移��?列表为空返回null\n* peekFirst();\t// 返回列表中的第一个元素但不移��?列表为空返回null\n* peekLast();\t// 返回列表中的最后一个元素但不移��?列表为空返回null\n\n\nLinkedBlockingQueue是一个用链表实现的有界阻塞队��?此队列的默认和最大长度为Integer.MAX_VALUE.此队列按照先进先出的原则对元素进行排��?\n\n一种通过链表实现的阻塞队列，支持先进先出.队列的头部是队列中保持时间最长的元素，队列的尾部是保持时间最短的元素.新元素插入队列的尾部.\n可选的容量设置可以有效防止队列过于扩张造成系统资源的过多消耗，如果不指定队列容量，队列默认使用Integer.MAX_VALUE.LinkedBlockingQueue的特定是，支持无限（理论上）容量.\n\nLinkedBlockingQueue是一个基于已链接节点的、范围任意的blocking queue的实��?此队列按FIFO（先进先出）排序元素.队列的头��?是在队列中时间最长的元素.队列的尾��?是在队列中时间最短的元素.\n\n新元素插入到队列的尾��?并且队列检索操作会获得位于队列头部的元��?\n\n链接队列的吞吐量通常要高于基于数组的队列,\n\n但是在大多数并发应用程序��?其可预知的性能要低.可选的容量范围构造方法参数作为防止队列过度扩展的一种方��?如果未指定容��?则它等于Integer.MAX_VALUE.除非插入节点会使队列超出容量,否则每次插入后会动态地创建链接节点.\n\n1. 如果未指定容��?默认容量为Integer.MAX_VALUE ,容量范围可以在构造方法参数中指定作为防止队列过度扩展.\n2. 此对象是 线程阻塞-安全��?\n3. 不接��?null 元素\n4. 它实现了BlockingQueue接口.\n5. 实现��?Collection ��?Iterator 接口的所有可��?方法.\n\n","slug":"concurrency/collection/使用阻塞式线程安全列表","published":1,"date":"2015-09-18T08:40:15.588Z","updated":"2015-09-18T08:40:15.588Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebe001z74ufg9djq3ra"},{"title":"ConcurrentHashMapʹ���̰߳�ȫ�ɱ���ӳ��","_content":"concurrentHashMap与ConcurrentSkipListMap性能测试 ��?线程1.6万数据的条件下，ConcurrentHashMap存取速度是ConcurrentSkipListMap ��?倍左右��?\n\n但ConcurrentSkipListMap有几个ConcurrentHashMap 不能比拟的优点：\n1、ConcurrentSkipListMap 的key是有序的��?\n2、ConcurrentSkipListMap 支持更高的并发。ConcurrentSkipListMap的存取时间是log（N），和线程数几乎无关。也就是说在数据量一定的情况下，并发的线程越多，ConcurrentSkipListMap越能体现出他的优势��?\n\n> 使用建议 在非多线程的情况下，应当尽量使用TreeMap。此外对于并发性相对较低的并行程序可以使用Collections.synchronizedSortedMap将TreeMap进行包装，也可以提供较好的效率。对于高并发程序，应当使用ConcurrentSkipListMap，能够提供更高的并发度��?\n\n\n所以在多线程程序中，如果需要对Map的键值进行排序时，请尽量使用ConcurrentSkipListMap，可能得到更好的并发度。注意，调用ConcurrentSkipListMap的size时，由于多个线程可以同时对映射表进行操作，所以映射表需要遍历整个链表才能返回元素个数，这个操作是个O(log(n))的操作��?\n\nConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳表）结构实现，在理论上能够在O(log(n))时间内完成查找、插入、删除操作。注意，调用ConcurrentSkipListMap的size时，由于多个线程可以同时对映射表进行操作，所以映射表需要遍历整个链表才能返回元素个数，这个操作是个O(log(n))的操作��?\n\n\nConcurrentNavigableMap 接口以及其实现类 ConcurrentSkipListMap该接口与实现类有相同行为的非阻塞式列��?当插入元素时ConcurrentSkipListMap 使用键值排序插入元��?\n\n\n\n","source":"_posts/concurrency/collection/使用线程安全可遍历映射.md","raw":"category: \n- collection\ntitle: ConcurrentHashMapʹ���̰߳�ȫ�ɱ���ӳ��\n---\nconcurrentHashMap与ConcurrentSkipListMap性能测试 ��?线程1.6万数据的条件下，ConcurrentHashMap存取速度是ConcurrentSkipListMap ��?倍左右��?\n\n但ConcurrentSkipListMap有几个ConcurrentHashMap 不能比拟的优点：\n1、ConcurrentSkipListMap 的key是有序的��?\n2、ConcurrentSkipListMap 支持更高的并发。ConcurrentSkipListMap的存取时间是log（N），和线程数几乎无关。也就是说在数据量一定的情况下，并发的线程越多，ConcurrentSkipListMap越能体现出他的优势��?\n\n> 使用建议 在非多线程的情况下，应当尽量使用TreeMap。此外对于并发性相对较低的并行程序可以使用Collections.synchronizedSortedMap将TreeMap进行包装，也可以提供较好的效率。对于高并发程序，应当使用ConcurrentSkipListMap，能够提供更高的并发度��?\n\n\n所以在多线程程序中，如果需要对Map的键值进行排序时，请尽量使用ConcurrentSkipListMap，可能得到更好的并发度。注意，调用ConcurrentSkipListMap的size时，由于多个线程可以同时对映射表进行操作，所以映射表需要遍历整个链表才能返回元素个数，这个操作是个O(log(n))的操作��?\n\nConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳表）结构实现，在理论上能够在O(log(n))时间内完成查找、插入、删除操作。注意，调用ConcurrentSkipListMap的size时，由于多个线程可以同时对映射表进行操作，所以映射表需要遍历整个链表才能返回元素个数，这个操作是个O(log(n))的操作��?\n\n\nConcurrentNavigableMap 接口以及其实现类 ConcurrentSkipListMap该接口与实现类有相同行为的非阻塞式列��?当插入元素时ConcurrentSkipListMap 使用键值排序插入元��?\n\n\n\n","slug":"concurrency/collection/使用线程安全可遍历映射","published":1,"date":"2015-09-18T08:40:19.292Z","updated":"2015-09-18T08:40:19.292Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebi002174uf3poepbua"},{"title":"PriorityBlockingQueueʹ�ð����ȼ�����������ʽ�̰߳�ȫ�б�","_content":"# PriorityBlockingQueue\n\n`PriorityBlockingQueue`是一个支持优先级的无界队��?默认情况下元素采取自然顺序排��?也可以通过比较器`comparator`来指定元素的排序规则.元素按照升序排列,这与构造队列时,提供的参数有��?\n\n使用提取方法��?队列将返回头��?具有最高优先级(或最低优先级,这与排序规则有关)的元��?如果多个元素具有相同的优先级,则同等优先级间的元素获取次序无特殊说��?\n\n优先级队列使用的是一种可扩展的数组结��?一般可以认为这个队列是无界��?当需要新添加一个元素时,如果此时数组已经被填��?优先队列将会自动扩充当前数组.(一般认为是,先分配一个原数组一定倍数空间的数��?之后将原数组中的元素拷贝到新分配的数组中,释放原数组的空间).\n\n如果使用优先级队列的`iterator`变量队列��?不保证遍历次序按照优先级大小进行.因为优先级队列使用的是堆结构.如果需要按照次序遍历需要使用`Arrays.sort(pq.toArray())`.\n\n在`PriorityBlockingQueue`的实现过程中聚合了`PriorityQueue`的一个实��?并且优先队列的操作完全依赖与`PriorityQueue`的实��?在`PriorityQueue`中使用了一个一维数组来存储相关的元素信��?一维数组使用最小堆算法进行元素添加.`PriorityBlockingQueue` 按优先级排序的阻塞时线程安全列表\n\n与`LinkedBlockingDeque` 一��?它也是一个阻塞时并发列表\n","source":"_posts/concurrency/collection/使用按优先级排序的阻塞式线程安全列表.md","raw":"category: \n- collection\ntitle: PriorityBlockingQueueʹ�ð����ȼ�����������ʽ�̰߳�ȫ�б�\n---\n# PriorityBlockingQueue\n\n`PriorityBlockingQueue`是一个支持优先级的无界队��?默认情况下元素采取自然顺序排��?也可以通过比较器`comparator`来指定元素的排序规则.元素按照升序排列,这与构造队列时,提供的参数有��?\n\n使用提取方法��?队列将返回头��?具有最高优先级(或最低优先级,这与排序规则有关)的元��?如果多个元素具有相同的优先级,则同等优先级间的元素获取次序无特殊说��?\n\n优先级队列使用的是一种可扩展的数组结��?一般可以认为这个队列是无界��?当需要新添加一个元素时,如果此时数组已经被填��?优先队列将会自动扩充当前数组.(一般认为是,先分配一个原数组一定倍数空间的数��?之后将原数组中的元素拷贝到新分配的数组中,释放原数组的空间).\n\n如果使用优先级队列的`iterator`变量队列��?不保证遍历次序按照优先级大小进行.因为优先级队列使用的是堆结构.如果需要按照次序遍历需要使用`Arrays.sort(pq.toArray())`.\n\n在`PriorityBlockingQueue`的实现过程中聚合了`PriorityQueue`的一个实��?并且优先队列的操作完全依赖与`PriorityQueue`的实��?在`PriorityQueue`中使用了一个一维数组来存储相关的元素信��?一维数组使用最小堆算法进行元素添加.`PriorityBlockingQueue` 按优先级排序的阻塞时线程安全列表\n\n与`LinkedBlockingDeque` 一��?它也是一个阻塞时并发列表\n","slug":"concurrency/collection/使用按优先级排序的阻塞式线程安全列表","published":1,"date":"2015-09-18T08:39:39.019Z","updated":"2015-09-18T08:39:39.019Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebl002374uf3xqliye5"},{"title":"DelayQueueʹ�ô����ӳ�Ԫ�ص��̰߳�ȫ�б�","_content":"#DelayQueue\n\n`DelayQueue`是一个支持延时获取元素的无界阻塞队列。队列使用`PriorityQueue`来实现。队列中的元素必须实现Delayed接口,在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将`DelayQueue`运用在以下应用场景：\n\n缓存系统的设计：可以用`DelayQueue`保存缓存元素的有效期，使用一个线程循环查询`DelayQueue`，一旦能从`DelayQueue`中获取元素时，表示缓存有效期到了。定时任务调度。使用`DelayQueue`保存当天将会执行的任务和执行时间，一旦从`DelayQueue`中获取到任务就开始执行，从比如TimerQueue就是使用`DelayQueue`实现的。队列中的Delayed必须实现compareTo来指定元素的顺序。比如让延时时间最长的放在队列的末尾\n\n一个无界阻塞队列，只有在延时期满时才能从中提取元素。如果没有元素到达延时期，则没有头元素\n\n`DelayQueue`里存放的元素必须实现Delayed接口(该接口使对象称为延迟对象).\n\n实现`Delayed`接口的对象,到了指定日期将强制执行`compareTo(Delayed o),getDelay(TimeUnit unit)`这俩个方法\n","source":"_posts/concurrency/collection/使用带有延迟元素的线程安全列表.md","raw":"category: \n- collection\ntitle: DelayQueueʹ�ô����ӳ�Ԫ�ص��̰߳�ȫ�б�\n---\n#DelayQueue\n\n`DelayQueue`是一个支持延时获取元素的无界阻塞队列。队列使用`PriorityQueue`来实现。队列中的元素必须实现Delayed接口,在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将`DelayQueue`运用在以下应用场景：\n\n缓存系统的设计：可以用`DelayQueue`保存缓存元素的有效期，使用一个线程循环查询`DelayQueue`，一旦能从`DelayQueue`中获取元素时，表示缓存有效期到了。定时任务调度。使用`DelayQueue`保存当天将会执行的任务和执行时间，一旦从`DelayQueue`中获取到任务就开始执行，从比如TimerQueue就是使用`DelayQueue`实现的。队列中的Delayed必须实现compareTo来指定元素的顺序。比如让延时时间最长的放在队列的末尾\n\n一个无界阻塞队列，只有在延时期满时才能从中提取元素。如果没有元素到达延时期，则没有头元素\n\n`DelayQueue`里存放的元素必须实现Delayed接口(该接口使对象称为延迟对象).\n\n实现`Delayed`接口的对象,到了指定日期将强制执行`compareTo(Delayed o),getDelay(TimeUnit unit)`这俩个方法\n","slug":"concurrency/collection/使用带有延迟元素的线程安全列表","published":1,"date":"2015-09-18T08:40:26.309Z","updated":"2015-09-18T08:40:26.309Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebm002574ufr9dbuemx"},{"title":"SynchronousQueue","_content":"# SynchronousQueue\n\nSynchronousQueue是一个不存储元素的阻塞队列.每一个put操作必须等待一个take操作,否则不能继续添加元素.反之亦然.同步队列没有任何内部容量,甚至连一个队列的容量都没有.\n\nSynchronousQueue可以看成是一个传球手,负责把生产者线程处理的数据直接传递给消费者线程.队列本身并不存储任何元素,非常适合于传递性场景,比如在一个线程中使用的数据,\n\n传递给另外一个线程使用,SynchronousQueue的吞吐量高于LinkedBlockingQueue 和 ArrayBlockingQueue.\n\n\n不能在同步队列上进行 peek,因为仅在试图要取得元素时,该元素才存在;除非另一个线程试图移除某个元素,否则也不能(使用任何方法)添加元素;\n也不能迭代队列,因为其中没有元素可用于迭代.队列的头是尝试添加到队列中的首个已排队线程元素; 如果没有已排队线程,则不添加元素并且头为 null.\n\n对于其他 Collection 方法(例如 contains),SynchronousQueue 作为一个空集合.此队列不允许 null 元素.\n\n同步队列非常适合于传递性设计,在这种设计中,在一个线程中运行的对象要将某些信息,事件或任务传递给在另一个线程中运行的对象,它就必须与该对象同步.\n\n对于正在等待的生产者和使用者线程而言,此类支持可选的公平排序策略.\n\n默认情况下不保证这种排序. 但是,使用公平设置为 true 所构造的队列可保证线程以 FIFO 的顺序进行访问.公平通常会降低吞吐量,但是可以减小可变性并避免得不到服务.\n\n\nConcurrentSkipListSet（提供的功能类似于TreeSet，能够并发的访问有序的set。因为ConcurrentSkipListSet是基于“跳跃列表（skip list）”实现的，只要多个线程没有同时修改集合的同一个部分，那么在正常读、写集合的操作中不会出现竞争现象。\n\nConcurrentSkipListSet是线程安全的有序的集合，适用于高并发的场景。\nConcurrentSkipListSet和TreeSet，它们虽然都是有序的集合。但是，\n第一，它们的线程安全机制不同，TreeSet是非线程安全的，而ConcurrentSkipListSet是线程安全的。\n第二，ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，而TreeSet是通过TreeMap实现的。\n\nConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，它的接口基本上都是通过调用ConcurrentSkipListMap接口来实现的\n\n","source":"_posts/concurrency/collection/synchronousqueue.md","raw":"category: \n- collection\ntitle: SynchronousQueue\n---\n# SynchronousQueue\n\nSynchronousQueue是一个不存储元素的阻塞队列.每一个put操作必须等待一个take操作,否则不能继续添加元素.反之亦然.同步队列没有任何内部容量,甚至连一个队列的容量都没有.\n\nSynchronousQueue可以看成是一个传球手,负责把生产者线程处理的数据直接传递给消费者线程.队列本身并不存储任何元素,非常适合于传递性场景,比如在一个线程中使用的数据,\n\n传递给另外一个线程使用,SynchronousQueue的吞吐量高于LinkedBlockingQueue 和 ArrayBlockingQueue.\n\n\n不能在同步队列上进行 peek,因为仅在试图要取得元素时,该元素才存在;除非另一个线程试图移除某个元素,否则也不能(使用任何方法)添加元素;\n也不能迭代队列,因为其中没有元素可用于迭代.队列的头是尝试添加到队列中的首个已排队线程元素; 如果没有已排队线程,则不添加元素并且头为 null.\n\n对于其他 Collection 方法(例如 contains),SynchronousQueue 作为一个空集合.此队列不允许 null 元素.\n\n同步队列非常适合于传递性设计,在这种设计中,在一个线程中运行的对象要将某些信息,事件或任务传递给在另一个线程中运行的对象,它就必须与该对象同步.\n\n对于正在等待的生产者和使用者线程而言,此类支持可选的公平排序策略.\n\n默认情况下不保证这种排序. 但是,使用公平设置为 true 所构造的队列可保证线程以 FIFO 的顺序进行访问.公平通常会降低吞吐量,但是可以减小可变性并避免得不到服务.\n\n\nConcurrentSkipListSet（提供的功能类似于TreeSet，能够并发的访问有序的set。因为ConcurrentSkipListSet是基于“跳跃列表（skip list）”实现的，只要多个线程没有同时修改集合的同一个部分，那么在正常读、写集合的操作中不会出现竞争现象。\n\nConcurrentSkipListSet是线程安全的有序的集合，适用于高并发的场景。\nConcurrentSkipListSet和TreeSet，它们虽然都是有序的集合。但是，\n第一，它们的线程安全机制不同，TreeSet是非线程安全的，而ConcurrentSkipListSet是线程安全的。\n第二，ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，而TreeSet是通过TreeMap实现的。\n\nConcurrentSkipListSet是通过ConcurrentSkipListMap实现的，它的接口基本上都是通过调用ConcurrentSkipListMap接口来实现的\n\n","slug":"concurrency/collection/synchronousqueue","published":1,"date":"2015-09-18T08:39:51.973Z","updated":"2015-09-18T08:39:51.973Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebo002774uf9dpqqi0m"},{"title":"java2.0的同步方式","_content":"# synchronize2.0\n\n##### 2.0\n同步的集合包装器 synchronizedMap 和 synchronizedList ,有时也被称作 有条件地线程安全――所有单个的操作都是线程安全的,但是多个操作组成的操作序列却可能导致数据争用,\n因为在操作序列中控制流取决于前面操作的结果.例如对于这样的功能put-if-absent语句块――如果一个条目不在Map 中,那么添加这个条目.该功能通过containsKey() 方法和 put() 方法组合起来.\n要保证原子性操作,就需要对该语句块加上同步锁.\n而且同步容器是对每个操作都进行同步,当大数据量或者多个线程下,会造成严重的并发性能下降\n通过将基本的功能从线程安全性中分离开来,Collections.synchronizedMap 允许需要同步的用户可以拥有同步,而不需要同步的用户则不必为同步付出代价.\n\n###### 第一组方法主要返回集合的各种数据：\n* 检查要添加的元素的类型并返回结果.任何尝试添加非法类型的变量都会抛出一个ClassCastException异常.这个功能可以防止在运行的时候出错.\n```\nCollections.checkedCollection\nCollections.checkedList\nCollections.checkedMap\nCollections.checkedSet\nCollections.checkedSortedMap\nCollections.checkedSortedSet：\n```\n* 返回一个固定的空集合,不能添加任何元素.\n```\nCollections.emptyList\nCollections.emptyMap\nCollections.emptySet ：\n```\n* 返回一个只有一个入口的 set/list/map 集合.\n```\nCollections.singleton\nCollections.singletonList\nCollections.singletonMap：\n```\n* 获得集合的线程安全版本(多线程操作时开销低但不高效,而且不支持类似put或update这样的复合操作)\n```\nCollections.synchronizedCollection\nCollections.synchronizedList\nCollections.synchronizedMap\nCollections.synchronizedSet\nCollections.synchronizedSortedMap\nCollections.synchronizedSortedSet：\n```\n* 返回一个不可变的集合.当一个不可变对象中包含集合的时候,可以使用此方法.\n```\nCollections.unmodifiableCollection\nCollections.unmodifiableList\nCollections.unmodifiableMap\nCollections.unmodifiableSet\nCollections.unmodifiableSortedMap\nCollections.unmodifiableSortedSet：\n```\n\n###### 第二组方法中,其中有一些方法因为某些原因没有加入到集合中：\n* Collections.addAll：添加一些元素或者一个数组的内容到集合中.\n* Collections.binarySearch：和数组的Arrays.binarySearch功能相同.\n* Collections.disjoint：检查两个集合是不是没有相同的元素.\n* Collections.fill：用一个指定的值代替集合中的所有元素.\n* Collections.frequency：集合中有多少元素是和给定元素相同的.\n* Collections.indexOfSubList / lastIndexOfSubList：和String.indexOf(String) / lastIndexOf(String)方法类似——找出给定的List中第一个出现或者最后一个出现的子表.\n* Collections.max / min：找出基于自然顺序或者比较器排序的集合中,最大的或者最小的元素.\n* Collections.replaceAll：将集合中的某一元素替换成另一个元素.\n* Collections.reverse：颠倒排列元素在集合中的顺序.如果你要在排序之后使用这个方法的话,在列表排序时,最好使用Collections.reverseOrder比较器.\n* Collections.rotate：根据给定的距离旋转元素.\n* Collections.shuffle：随机排放List集合中的节点,可以给定你自己的生成器——例如 java.util.Random / java.util.ThreadLocalRandom or java.security.SecureRandom.\n* Collections.sort：将集合按照自然顺序或者给定的顺序排序.\n* Collections.swap：交换集合中两个元素的位置(多数开发者都是自己实现这个操作的).","source":"_posts/concurrency/collection/synchronize20.md","raw":"category: \n- collection\ntitle: java2.0的同步方式\n---\n# synchronize2.0\n\n##### 2.0\n同步的集合包装器 synchronizedMap 和 synchronizedList ,有时也被称作 有条件地线程安全――所有单个的操作都是线程安全的,但是多个操作组成的操作序列却可能导致数据争用,\n因为在操作序列中控制流取决于前面操作的结果.例如对于这样的功能put-if-absent语句块――如果一个条目不在Map 中,那么添加这个条目.该功能通过containsKey() 方法和 put() 方法组合起来.\n要保证原子性操作,就需要对该语句块加上同步锁.\n而且同步容器是对每个操作都进行同步,当大数据量或者多个线程下,会造成严重的并发性能下降\n通过将基本的功能从线程安全性中分离开来,Collections.synchronizedMap 允许需要同步的用户可以拥有同步,而不需要同步的用户则不必为同步付出代价.\n\n###### 第一组方法主要返回集合的各种数据：\n* 检查要添加的元素的类型并返回结果.任何尝试添加非法类型的变量都会抛出一个ClassCastException异常.这个功能可以防止在运行的时候出错.\n```\nCollections.checkedCollection\nCollections.checkedList\nCollections.checkedMap\nCollections.checkedSet\nCollections.checkedSortedMap\nCollections.checkedSortedSet：\n```\n* 返回一个固定的空集合,不能添加任何元素.\n```\nCollections.emptyList\nCollections.emptyMap\nCollections.emptySet ：\n```\n* 返回一个只有一个入口的 set/list/map 集合.\n```\nCollections.singleton\nCollections.singletonList\nCollections.singletonMap：\n```\n* 获得集合的线程安全版本(多线程操作时开销低但不高效,而且不支持类似put或update这样的复合操作)\n```\nCollections.synchronizedCollection\nCollections.synchronizedList\nCollections.synchronizedMap\nCollections.synchronizedSet\nCollections.synchronizedSortedMap\nCollections.synchronizedSortedSet：\n```\n* 返回一个不可变的集合.当一个不可变对象中包含集合的时候,可以使用此方法.\n```\nCollections.unmodifiableCollection\nCollections.unmodifiableList\nCollections.unmodifiableMap\nCollections.unmodifiableSet\nCollections.unmodifiableSortedMap\nCollections.unmodifiableSortedSet：\n```\n\n###### 第二组方法中,其中有一些方法因为某些原因没有加入到集合中：\n* Collections.addAll：添加一些元素或者一个数组的内容到集合中.\n* Collections.binarySearch：和数组的Arrays.binarySearch功能相同.\n* Collections.disjoint：检查两个集合是不是没有相同的元素.\n* Collections.fill：用一个指定的值代替集合中的所有元素.\n* Collections.frequency：集合中有多少元素是和给定元素相同的.\n* Collections.indexOfSubList / lastIndexOfSubList：和String.indexOf(String) / lastIndexOf(String)方法类似——找出给定的List中第一个出现或者最后一个出现的子表.\n* Collections.max / min：找出基于自然顺序或者比较器排序的集合中,最大的或者最小的元素.\n* Collections.replaceAll：将集合中的某一元素替换成另一个元素.\n* Collections.reverse：颠倒排列元素在集合中的顺序.如果你要在排序之后使用这个方法的话,在列表排序时,最好使用Collections.reverseOrder比较器.\n* Collections.rotate：根据给定的距离旋转元素.\n* Collections.shuffle：随机排放List集合中的节点,可以给定你自己的生成器——例如 java.util.Random / java.util.ThreadLocalRandom or java.security.SecureRandom.\n* Collections.sort：将集合按照自然顺序或者给定的顺序排序.\n* Collections.swap：交换集合中两个元素的位置(多数开发者都是自己实现这个操作的).","slug":"concurrency/collection/synchronize20","published":1,"date":"2015-09-18T08:39:56.204Z","updated":"2015-09-18T08:39:56.204Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebq002974ufbkvcr2tl"},{"title":"Skip list","_content":"# Skip list\n\nSkip list(跳表)说明\n\n> 是一种可以代替平衡树的数据结构,默认是按照Key值升序的.Skip list让已排序的数据分布在多层链表中,以0-1随机数决定一个数据的向上攀升与否,\n通过“空间来换取时间”的一个算法,在每个节点中增加了向前的指针,在插入、删除、查找时可以忽略\n一些不可能涉及到的结点,从而提高了效率.\n\n从概率上保持数据结构的平衡比显示的保持数据结构平衡要简单的多.对于大多数应用,\n用Skip list要比用树算法相对简单.由于Skip list比较简单,实现起来会比较容易,\n虽然和平衡树有着相同的时间复杂度(O(logn)),但是skip list的常数项会相对小很多.\nSkip list在空间上也比较节省.一个节点平均只需要1.333个指针(甚至更少).\n\nSkip list的性质\n(1) 由很多层结构组成,level是通过一定的概率随机产生的.\n(2) 每一层都是一个有序的链表,默认是升序,也可以根据创建映射时所提供的Comparator进行排序,\n    具体取决于使用的构造方法.\n(3) 最底层(Level 1)的链表包含所有元素.\n(4) 如果一个元素出现在Level i 的链表中,则它在Level i 之下的链表也都会出现.\n(5) 每个节点包含两个指针,一个指向同一链表中的下一个元素,一个指向下面一层的元素.","source":"_posts/concurrency/collection/skip_list.md","raw":"category: \n- collection\ntitle: Skip list\n---\n# Skip list\n\nSkip list(跳表)说明\n\n> 是一种可以代替平衡树的数据结构,默认是按照Key值升序的.Skip list让已排序的数据分布在多层链表中,以0-1随机数决定一个数据的向上攀升与否,\n通过“空间来换取时间”的一个算法,在每个节点中增加了向前的指针,在插入、删除、查找时可以忽略\n一些不可能涉及到的结点,从而提高了效率.\n\n从概率上保持数据结构的平衡比显示的保持数据结构平衡要简单的多.对于大多数应用,\n用Skip list要比用树算法相对简单.由于Skip list比较简单,实现起来会比较容易,\n虽然和平衡树有着相同的时间复杂度(O(logn)),但是skip list的常数项会相对小很多.\nSkip list在空间上也比较节省.一个节点平均只需要1.333个指针(甚至更少).\n\nSkip list的性质\n(1) 由很多层结构组成,level是通过一定的概率随机产生的.\n(2) 每一层都是一个有序的链表,默认是升序,也可以根据创建映射时所提供的Comparator进行排序,\n    具体取决于使用的构造方法.\n(3) 最底层(Level 1)的链表包含所有元素.\n(4) 如果一个元素出现在Level i 的链表中,则它在Level i 之下的链表也都会出现.\n(5) 每个节点包含两个指针,一个指向同一链表中的下一个元素,一个指向下面一层的元素.","slug":"concurrency/collection/skip_list","published":1,"date":"2015-09-18T08:40:00.670Z","updated":"2015-09-18T08:40:00.670Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebr002b74uf45rflssn"},{"title":"LinkedTransferQueue","_content":"# LinkedTransferQueue\n\nLinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列LinkedTransferQueue多了tryTransfer和transfer方法。\n\n\ntransfer方法。如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer\n （传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。transfer方法的关键代码如下：\n```\n  Node pred = tryAppend(s, haveData);\n  return awaitMatch(s, pred, e, (how == TIMED), nanos);\n```\n第一行代码是试图把存放当前元素的s节点作为tail节点。第二行代码是让CPU自旋等待消费者消费元素。因为自旋会消耗CPU，所以自旋一定的次数后使用Thread.yield()方法来暂停当前正在执行的线程，并执行其他线程。\n\ntryTransfer方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。\n\n对于带有时间限制的tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。","source":"_posts/concurrency/collection/linkedtransferqueue.md","raw":"category: \n- collection\ntitle: LinkedTransferQueue\n---\n# LinkedTransferQueue\n\nLinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列LinkedTransferQueue多了tryTransfer和transfer方法。\n\n\ntransfer方法。如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer\n （传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。transfer方法的关键代码如下：\n```\n  Node pred = tryAppend(s, haveData);\n  return awaitMatch(s, pred, e, (how == TIMED), nanos);\n```\n第一行代码是试图把存放当前元素的s节点作为tail节点。第二行代码是让CPU自旋等待消费者消费元素。因为自旋会消耗CPU，所以自旋一定的次数后使用Thread.yield()方法来暂停当前正在执行的线程，并执行其他线程。\n\ntryTransfer方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。\n\n对于带有时间限制的tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。","slug":"concurrency/collection/linkedtransferqueue","published":1,"date":"2015-09-18T08:40:05.134Z","updated":"2015-09-18T08:40:05.134Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebs002d74ufiu16ut28"},{"title":"CopyOnWriteArrayList","_content":"# CopyOnWriteArrayList\n\n1. CopyOnWriteArrayList（写数组的拷贝）是ArrayList的一个线程安全的变体,CopyOnWriteArrayList和CopyOnWriteSet都是线程安全的集合,其中所有可变操作（add、set等等）都是通过对底层数组进行一次新的复制来实现的。\n\n2. 它绝对不会抛出ConcurrentModificationException的异常。因为该列表（CopyOnWriteArrayList）在遍历时将不会被做任何的修改。\n\n3. CopyOnWriteArrayList适合用在“读多,写少”的“并发”应用中,换句话说,它适合使用在读操作远远大于写操作的场景里,比如缓存。它不存在“扩容”的概念,每次写操作（add or remove）都要copy一个副本,在副本的基础上修改后改变array引用,所以称为“CopyOnWrite”,因此在写操作是加锁,并且对整个list的copy操作时相当耗时的,过多的写操作不推荐使用该存储结构。\n\n4. CopyOnWriteArrayList的功能是是创建一个列表,有三种构造方法：\n   >（1）CopyOnWriteArrayList ()创建一个空列表。\n   >（2）CopyOnWriteArrayList (Collection<? extendsE> c) 创建一个按 collection的迭代器返回元素的顺序包含指定 collection元素的列表。\n   >（3）CopyOnWriteArrayList（E[] toCopyIn） 创建一个保存给定数组的副本的列表。\n\n\n它是线程安全的无序的集合，可以将它理解成线程安全的HashSet。有意思的是，CopyOnWriteArraySet和HashSet虽然都继承于共同的父类AbstractSet\n；但是，HashSet是通过“散列表(HashMap)”实现的，而CopyOnWriteArraySet则是通过“动态数组(CopyOnWriteArrayList)”实现的，并不是散列表。\n和CopyOnWriteArrayList类似，CopyOnWriteArraySet具有以下特性： \n1. 它最适合于具有以下特征的应用程序：Set大小通常保持很小，只读操作远多于可变操作，需要在遍历期间防止线程间的冲突。 \n2. 它是线程安全的。 \n3. 因为通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove() 等等）的开销很大。 \n4. 迭代器支持hasNext(),next()等不可变操作，但不支持可变 remove()等 操作。 \n5. 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。\n\n","source":"_posts/concurrency/collection/copyonwritearraylist.md","raw":"category: \n- 并发集合\ntitle: CopyOnWriteArrayList\n---\n# CopyOnWriteArrayList\n\n1. CopyOnWriteArrayList（写数组的拷贝）是ArrayList的一个线程安全的变体,CopyOnWriteArrayList和CopyOnWriteSet都是线程安全的集合,其中所有可变操作（add、set等等）都是通过对底层数组进行一次新的复制来实现的。\n\n2. 它绝对不会抛出ConcurrentModificationException的异常。因为该列表（CopyOnWriteArrayList）在遍历时将不会被做任何的修改。\n\n3. CopyOnWriteArrayList适合用在“读多,写少”的“并发”应用中,换句话说,它适合使用在读操作远远大于写操作的场景里,比如缓存。它不存在“扩容”的概念,每次写操作（add or remove）都要copy一个副本,在副本的基础上修改后改变array引用,所以称为“CopyOnWrite”,因此在写操作是加锁,并且对整个list的copy操作时相当耗时的,过多的写操作不推荐使用该存储结构。\n\n4. CopyOnWriteArrayList的功能是是创建一个列表,有三种构造方法：\n   >（1）CopyOnWriteArrayList ()创建一个空列表。\n   >（2）CopyOnWriteArrayList (Collection<? extendsE> c) 创建一个按 collection的迭代器返回元素的顺序包含指定 collection元素的列表。\n   >（3）CopyOnWriteArrayList（E[] toCopyIn） 创建一个保存给定数组的副本的列表。\n\n\n它是线程安全的无序的集合，可以将它理解成线程安全的HashSet。有意思的是，CopyOnWriteArraySet和HashSet虽然都继承于共同的父类AbstractSet\n；但是，HashSet是通过“散列表(HashMap)”实现的，而CopyOnWriteArraySet则是通过“动态数组(CopyOnWriteArrayList)”实现的，并不是散列表。\n和CopyOnWriteArrayList类似，CopyOnWriteArraySet具有以下特性： \n1. 它最适合于具有以下特征的应用程序：Set大小通常保持很小，只读操作远多于可变操作，需要在遍历期间防止线程间的冲突。 \n2. 它是线程安全的。 \n3. 因为通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove() 等等）的开销很大。 \n4. 迭代器支持hasNext(),next()等不可变操作，但不支持可变 remove()等 操作。 \n5. 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。\n\n","slug":"concurrency/collection/copyonwritearraylist","published":1,"date":"2015-09-18T09:11:43.217Z","updated":"2015-09-18T09:11:43.217Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebu002f74ufs5no58fc"},{"title":"简介","_content":"java 提供了俩类用于并发的集合\n\n###### 基本上,Java提供两种在并发应用程序中使用的集合：\n* 阻塞式集合:这类集合包括添加和移除数据的方法.当集合已满或为空时,被调用的添加或者移除的方法就不能立即被执行,那么调用这个方法的线程将被阻塞,一直到该方法可以被执行.\n\t\t\t  这种集合包括添加和删除数据的操作.如果操作不能立即进行,是因为集合已满或者为空,该程序将被阻塞,直到操作可以进行.\n* 非阻塞式集合:这类集合也包括添加和移除数据的方法,如果方法不能被执行,则返回null或者抛出异常,但是调用这个方法的线程不会被阻塞.\n\t\t\t\t这种集合也包括添加和删除数据的操作.如果操作不能立即进行,这个操作将返回null值或抛出异常,但该线程将不会阻塞.\n\t\t\t  \n如果我们要实现一个线程安全的队列有两种实现方式：一种是使用阻塞算法,另一种是使用非阻塞算法.使用阻塞算法的队列可以用一个锁(入队和出队用同一把锁)或两个锁(入队和出队用不同的锁)等方式来实现,\n而非阻塞的实现方式则可以使用循环CAS的方式来实现,\n\n## 阻塞队列:\n\n###### 阻塞队列说明:\n> 它实质上就是一种带有一点扭曲的 FIFO 数据结构.它提供了可阻塞的put和take方法.如果Queue已经满了,put方法会被阻塞直到有空间可用;如果Queue是空的,那么take方法会被阻塞,直到有元素可用.offer方法如果数据项不能被添加到队列中,会返回一个失败的状态.Queue的长度可用有限,也可以无限;无限的Queue永远不会充满,所以它的put方法永远不会被阻塞.阻塞队列支持生产者-消费者设计模式.BlockingQueue可以使用任意数量的生产者和消费者,从而简化了生产者-消费者设计的实现.\n\n> Java6 新增了俩种新的容器类型 Deque和 BlockingDeque 分别对Queue 和BlockingQueue 进行了拓展Deque是一个双端队列,实现了在队列头和队列尾 > > > 高效的插入和移除.正如阻塞队列适用于生产者和消费者模式,双端队列适用于工作密取模式(工作密取模式非常适用于既是生产者又是消费者问题).\n\n> ArrayDeque：Deque是基于有首尾指针的数组(环形缓冲区)实现的.和LinkedList不同,这个类没有实现List接口.因此,如果没有首尾元素的话就不能取出任何元素.这个类比LinkedList要好一些,因为它产生的垃圾数量较少(在扩展的时候旧的数组会被丢弃).Stack：一种后进先出的队列.不要在生产代码中使用,使用别的Deque来代替(ArrayDeque比较好).PriorityQueue：一个基于优先级的队列.使用自然顺序或者制定的比较器来排序.他的主要属性——poll/peek/remove/element会返回一个队列的最小值.不仅如此,PriorityQueue还实现了Iterable接口,队列迭代时不进行排序(或者其他顺序).在需要排序的集合中,使用这个队列会比TreeSet等其他队列要方便.\n\n* `BlockingQueue`：简化了生产者-消费者实现过程,支持任意数量的生产者或者消费者.\n* `ArrayBlockingQueue`：一个由数组结构(ArrayList)组成的有界阻塞队列.比同步List拥有更高的并发性\n基于数组实现的一个有界阻塞队,大小不能重新定义.所以当你试图向一个满的队列添加元素的时候,\n就会受到阻塞,直到另一个方法从队列中取出元素.\n\n* `DelayQueue`：一个由优先级堆支持的、基于时间的调度队列.存储延迟元素的阻塞列表无界的保存Delayed元素的集合.元素只有在延时已经过期的时候才能被取出.队列的第一个元素延期最小\n(包含负值——延时已经过期).当你要实现一个延期任务的队列的时候使用(不要自己手动实现——使用ScheduledThreadPoolExecutor).\n\n* `LinkedBlockingDeque`: 一个由链表结构组成的双向阻塞队列.可选择有界或者无界基于链表的实现.在队列为空或者满的情况下使用ReentrantLock-s.LinkedBlockingQueue与此一样\n\n* `LinkedBlockingQueue`：一个由链表结构(LinkedList)组成的有界阻塞队列.比同步List拥有更高的并发性\n\n* `LinkedTransferQueue`: 一个由链表结构组成的无界阻塞队列.基于链表的无界队列.除了通常的队列操作,它还有一系列的transfer方法,可以让生产者直接给等待的消费者传递信息,这样就不用将元素存储到队列中了.这是一个基于CAS操作的无锁集合.\n\n* `PriorityBlockingQueue`：一个支持优先级排序的无界阻塞队列.PriorityQueue的无界的版本.\n\n* `SynchronousQueue`：一个不存储元素的阻塞队列.它维护一组线程,这些线程在等待着吧元素加入或移除队列.一个有界队列,其中没有任何内存容量.这就意味着任何插入操作必须等到响应的取出操作才能执行,反之亦反.如果不需要Queue接口的话,通过Exchanger类也能完成响应的功能.\n\n\n###### 非阻塞集合说明:\n\n这一部分将介绍java.util.concurrent包中线程安全的集合.这些集合的主要属性是一个不可分割的必须执行的方法.因为并发的操作,例如add或update或者check再update,都有一次以上的调用,必须同步.因为第一步从集合中组合操作查询到的信息在开始第二步操作时可能变为无效数据.多数的并发集合是在Java 1.5引入的.ConcurrentSkipListMap / ConcurrentSkipListSet 和 LinkedBlockingDeque\n是在Java 1.6新加入的.Java 1.7加入了最后的 ConcurrentLinkedDeque 和 LinkedTransferQueue\n\n\n## 非阻塞集合:\n\n* `ConcurrentHashMap`:  代替基于散列的Map,使用分段锁机制,任意数量的读取线程可以访问Map,读取线程和写入线程可以并发的访问Map, 一定数量的写入线程可以并发的修改Map.ConcurrentHashMap没有实现对Map加锁以提供独占访问 (Hashtable和synchronizedMap 都可以获得Map的锁以防止其他线程的访问).ConcurrentHashMap本身实现了很多原子复合操作,具体参考测试程序.\n\nget操作全并发访问,put操作可配置并发操作的哈希表.并发的级别可以通过构造函数中concurrencyLevel参数设置(默认级别16).该参数会在Map内部划分一些分区.在put操作的时候只有只有更新的分区是锁住的.\n这种Map不是代替HashMap的线程安全版本——任何 get-then-put的操作都需要在外部进行同步.\n\n* `ConcurrentLinkedDeque`: 非阻塞列表. 基于链表实现的无界队列,添加元素不会堵塞.但是这就要求这个集合的消费者工作速度至少要和生产这一样快,不然内存就会耗尽.严重依赖于CAS(compare-and-set)操作.\n\n* `ConcurrentLinkedQueue`: 一个传统的先进先出队列\n\n* `ConcurrentSkipListMap`: 作为同步的SortedMap.基于跳跃列表(Skip List)的ConcurrentNavigableMap实现.本质上这种集合可以当做一种TreeMap的线程安全版本来使用\n\n* `ConcurrentSkipListSet`: 作为同步的SortedSet.使用 ConcurrentSkipListMap来存储的线程安全的Set.\n\n* `CopyOnWriteArrayList`: list的实现每一次更新都会产生一个新的隐含数组副本,所以这个操作成本很高.通常用在遍历操作比更新操作多的集合,比如listeners/observers集合.最适合于读操作通常大大超过写操作的情况.代替遍历操作为主要操作的同步的List.如果写大于读的并发用什么?\n\n* `CopyOnWriteArraySet`: 最适合于读操作通常大大超过写操作的情况.使用CopyOnWriteArrayList来存储的线程安全的Set\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/concurrency/collection/collection.md","raw":"category: \n- collection\ntitle: 简介\n---\njava 提供了俩类用于并发的集合\n\n###### 基本上,Java提供两种在并发应用程序中使用的集合：\n* 阻塞式集合:这类集合包括添加和移除数据的方法.当集合已满或为空时,被调用的添加或者移除的方法就不能立即被执行,那么调用这个方法的线程将被阻塞,一直到该方法可以被执行.\n\t\t\t  这种集合包括添加和删除数据的操作.如果操作不能立即进行,是因为集合已满或者为空,该程序将被阻塞,直到操作可以进行.\n* 非阻塞式集合:这类集合也包括添加和移除数据的方法,如果方法不能被执行,则返回null或者抛出异常,但是调用这个方法的线程不会被阻塞.\n\t\t\t\t这种集合也包括添加和删除数据的操作.如果操作不能立即进行,这个操作将返回null值或抛出异常,但该线程将不会阻塞.\n\t\t\t  \n如果我们要实现一个线程安全的队列有两种实现方式：一种是使用阻塞算法,另一种是使用非阻塞算法.使用阻塞算法的队列可以用一个锁(入队和出队用同一把锁)或两个锁(入队和出队用不同的锁)等方式来实现,\n而非阻塞的实现方式则可以使用循环CAS的方式来实现,\n\n## 阻塞队列:\n\n###### 阻塞队列说明:\n> 它实质上就是一种带有一点扭曲的 FIFO 数据结构.它提供了可阻塞的put和take方法.如果Queue已经满了,put方法会被阻塞直到有空间可用;如果Queue是空的,那么take方法会被阻塞,直到有元素可用.offer方法如果数据项不能被添加到队列中,会返回一个失败的状态.Queue的长度可用有限,也可以无限;无限的Queue永远不会充满,所以它的put方法永远不会被阻塞.阻塞队列支持生产者-消费者设计模式.BlockingQueue可以使用任意数量的生产者和消费者,从而简化了生产者-消费者设计的实现.\n\n> Java6 新增了俩种新的容器类型 Deque和 BlockingDeque 分别对Queue 和BlockingQueue 进行了拓展Deque是一个双端队列,实现了在队列头和队列尾 > > > 高效的插入和移除.正如阻塞队列适用于生产者和消费者模式,双端队列适用于工作密取模式(工作密取模式非常适用于既是生产者又是消费者问题).\n\n> ArrayDeque：Deque是基于有首尾指针的数组(环形缓冲区)实现的.和LinkedList不同,这个类没有实现List接口.因此,如果没有首尾元素的话就不能取出任何元素.这个类比LinkedList要好一些,因为它产生的垃圾数量较少(在扩展的时候旧的数组会被丢弃).Stack：一种后进先出的队列.不要在生产代码中使用,使用别的Deque来代替(ArrayDeque比较好).PriorityQueue：一个基于优先级的队列.使用自然顺序或者制定的比较器来排序.他的主要属性——poll/peek/remove/element会返回一个队列的最小值.不仅如此,PriorityQueue还实现了Iterable接口,队列迭代时不进行排序(或者其他顺序).在需要排序的集合中,使用这个队列会比TreeSet等其他队列要方便.\n\n* `BlockingQueue`：简化了生产者-消费者实现过程,支持任意数量的生产者或者消费者.\n* `ArrayBlockingQueue`：一个由数组结构(ArrayList)组成的有界阻塞队列.比同步List拥有更高的并发性\n基于数组实现的一个有界阻塞队,大小不能重新定义.所以当你试图向一个满的队列添加元素的时候,\n就会受到阻塞,直到另一个方法从队列中取出元素.\n\n* `DelayQueue`：一个由优先级堆支持的、基于时间的调度队列.存储延迟元素的阻塞列表无界的保存Delayed元素的集合.元素只有在延时已经过期的时候才能被取出.队列的第一个元素延期最小\n(包含负值——延时已经过期).当你要实现一个延期任务的队列的时候使用(不要自己手动实现——使用ScheduledThreadPoolExecutor).\n\n* `LinkedBlockingDeque`: 一个由链表结构组成的双向阻塞队列.可选择有界或者无界基于链表的实现.在队列为空或者满的情况下使用ReentrantLock-s.LinkedBlockingQueue与此一样\n\n* `LinkedBlockingQueue`：一个由链表结构(LinkedList)组成的有界阻塞队列.比同步List拥有更高的并发性\n\n* `LinkedTransferQueue`: 一个由链表结构组成的无界阻塞队列.基于链表的无界队列.除了通常的队列操作,它还有一系列的transfer方法,可以让生产者直接给等待的消费者传递信息,这样就不用将元素存储到队列中了.这是一个基于CAS操作的无锁集合.\n\n* `PriorityBlockingQueue`：一个支持优先级排序的无界阻塞队列.PriorityQueue的无界的版本.\n\n* `SynchronousQueue`：一个不存储元素的阻塞队列.它维护一组线程,这些线程在等待着吧元素加入或移除队列.一个有界队列,其中没有任何内存容量.这就意味着任何插入操作必须等到响应的取出操作才能执行,反之亦反.如果不需要Queue接口的话,通过Exchanger类也能完成响应的功能.\n\n\n###### 非阻塞集合说明:\n\n这一部分将介绍java.util.concurrent包中线程安全的集合.这些集合的主要属性是一个不可分割的必须执行的方法.因为并发的操作,例如add或update或者check再update,都有一次以上的调用,必须同步.因为第一步从集合中组合操作查询到的信息在开始第二步操作时可能变为无效数据.多数的并发集合是在Java 1.5引入的.ConcurrentSkipListMap / ConcurrentSkipListSet 和 LinkedBlockingDeque\n是在Java 1.6新加入的.Java 1.7加入了最后的 ConcurrentLinkedDeque 和 LinkedTransferQueue\n\n\n## 非阻塞集合:\n\n* `ConcurrentHashMap`:  代替基于散列的Map,使用分段锁机制,任意数量的读取线程可以访问Map,读取线程和写入线程可以并发的访问Map, 一定数量的写入线程可以并发的修改Map.ConcurrentHashMap没有实现对Map加锁以提供独占访问 (Hashtable和synchronizedMap 都可以获得Map的锁以防止其他线程的访问).ConcurrentHashMap本身实现了很多原子复合操作,具体参考测试程序.\n\nget操作全并发访问,put操作可配置并发操作的哈希表.并发的级别可以通过构造函数中concurrencyLevel参数设置(默认级别16).该参数会在Map内部划分一些分区.在put操作的时候只有只有更新的分区是锁住的.\n这种Map不是代替HashMap的线程安全版本——任何 get-then-put的操作都需要在外部进行同步.\n\n* `ConcurrentLinkedDeque`: 非阻塞列表. 基于链表实现的无界队列,添加元素不会堵塞.但是这就要求这个集合的消费者工作速度至少要和生产这一样快,不然内存就会耗尽.严重依赖于CAS(compare-and-set)操作.\n\n* `ConcurrentLinkedQueue`: 一个传统的先进先出队列\n\n* `ConcurrentSkipListMap`: 作为同步的SortedMap.基于跳跃列表(Skip List)的ConcurrentNavigableMap实现.本质上这种集合可以当做一种TreeMap的线程安全版本来使用\n\n* `ConcurrentSkipListSet`: 作为同步的SortedSet.使用 ConcurrentSkipListMap来存储的线程安全的Set.\n\n* `CopyOnWriteArrayList`: list的实现每一次更新都会产生一个新的隐含数组副本,所以这个操作成本很高.通常用在遍历操作比更新操作多的集合,比如listeners/observers集合.最适合于读操作通常大大超过写操作的情况.代替遍历操作为主要操作的同步的List.如果写大于读的并发用什么?\n\n* `CopyOnWriteArraySet`: 最适合于读操作通常大大超过写操作的情况.使用CopyOnWriteArrayList来存储的线程安全的Set\n\n\n\n\n\n\n\n\n\n\n","slug":"concurrency/collection/collection","published":1,"date":"2015-09-18T08:39:24.444Z","updated":"2015-09-18T08:39:24.444Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebw002i74ufxiayd1bl"},{"title":"MongoDB","_content":"# Run MongoDB\n\n## Run MongoDB On Windows\n\n```\n\t如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见.\n```\n\n### 设置MOngoDB环境\n\n###### 设置环境变量\n```\n\t在环境变量里添加环境变量 D:\\Program Files\\MongoDB\\Server\\3.0\\\n\t然后在Path里添加： %MONGODB_HOME%\\bin\n```\n\n###### data directory\n```\n\tMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是\\data\\db, \n\t所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: D:\\mongodb\\data\\db.\n\n\t你可以通过--dbpath选项给mongod.exe设置另一个data directory.\n\tmongod.exe --dbpath D:\\mongodb\\data\\db\n\n\t如果你的data directory包含空格的话,那么就需要使用\"\"将他们包含起来：\n\tmongod.exe --dbpath \"d:\\test\\mongo db data\"\n```\n\n## 启动MongoDB\n\n###### 使用mongod.exe命令启动mongoDB\n```\n\tmongod.exe\n```\n\n###### 启动日志\n```\n\t最后我们在启动日志里看到\n\twaiting for connections on port 27017\n```\n\n#### 命令行方式启动\n\nMongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017.\n```\n\tmongod --dbpath=/data/db\n```\n\n#### 配置文件方式启动\nMongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下:\n```\n\tcat /etc/mongodb.cnf\n```\n启动时加上”-f”参数,并指向配置文件即可:\n```\n\tmongod -f /etc/mongodb.cnf\n```\n\n#### Daemon 方式启动\nMongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” --fork”参数即可,,但如果用到了 ” --fork”参数就必须也启用 ”--logpath”参数,这是强制的\n\n```\n\tmongod --dbpath=/data/db --logpath=/data/log/r3.log --fork\n```\n\n#### mongod 参数说明\nmongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数\n\nmongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,\nmmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经\n有了一定程度的改善.\n\n###### mongod 的主要参数有：\n* dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中.\n* logpath —— 错误日志文件\n* logappend —— 错误日志采用追加模式（默认是覆写模式）\n* bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定\n* port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000\n* fork —— 以后台 Daemon 形式运行服务\n* journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数.\n* syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒.\n* directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似\n* maxConns —— 最大连接数\n* repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作.\n\n## 停止数据库\n\n#### Control-C\n#### shutdownServer()指令\n```\n\tmongo --port 28013\n\tuse admin\n\tdb.shutdownServer()\n```\n\n## 常用工具集\nMongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上\n的方便。\n* bsondump: 将 bson 格式的文件转储为 json 格式的数据\n* mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法\n* mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行\n* mongodump/ mongorestore: 数据库备份和恢复工具\n* mongoexport/ mongoimport: 数据导出和导入工具\n* mongofiles: GridFS 管理工具,可实现二制文件的存取\n* mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod\n* mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出\n* mongostat: 实时性能监控工具\n\n## 部署 Replica Sets\n* 创建数据文件存储路径\n```\n\tmkdir E:/mongoData/data/r0\n\tmkdir E:/mongoData/data/r1\n\tmkdir E:/mongoData/data/r2\n```\n* 创建日志文件路径\n```\n\tmkdir E:/mongoData/log\n```\n* 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。\n```\n\tmkdir E:/mongoData/key\n\techo \"this is rs1 super secret key\" > E:/mongoData/key/r0\n\techo \"this is rs1 super secret key\" > E:/mongoData/key/r1\n\techo \"this is rs1 super secret key\" > E:/mongoData/key/r2\n```\n* 启动 3 个实例\n```\n\tmongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappend\n\tmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappend\n\tmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend\n```\n* 配置及初始化 Replica Sets\n```\n\tmongo -port 28010\n\t\n```\n\n\n# Introduction\n\n## A Quick Tour\n\n使用java 驱动开发是非常简单的,首先你要确保你的`classpath`中包含`mongo.jar`\n\n### Making a Connection\n\n为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库\n\n另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地`mydb`数据库的方式\n```java\nimport com.mongodb.BasicDBObject;\nimport com.mongodb.BulkWriteOperation;\nimport com.mongodb.BulkWriteResult;\nimport com.mongodb.Cursor;\nimport com.mongodb.DB;\nimport com.mongodb.DBCollection;\nimport com.mongodb.DBCursor;\nimport com.mongodb.DBObject;\nimport com.mongodb.MongoClient;\nimport com.mongodb.ParallelScanOptions;\nimport com.mongodb.ServerAddress;\n\nimport java.util.List;\nimport java.util.Set;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\n// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even\n// if it's a member of a replica set:\nMongoClient mongoClient = new MongoClient();\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" );\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" , 27017 );\n// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of members\nMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(\"localhost\", 27017),\n                                      new ServerAddress(\"localhost\", 27018),\n                                      new ServerAddress(\"localhost\", 27019)));\n\nDB db = mongoClient.getDB( \"mydb\" );\n```\n\n在这个例子中`db`对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作\n\n> Note:\n>\n> `MongoClient`实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个`MongoClient`实例, 参考[concurrency doc page]()\n\n\n`MongoClient`被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个`MongoClient`实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个`MongoClient`实例,那么你需要注意下面俩点：\n\n* all resource usage limits (max connections, etc) apply per MongoClient instance\n* 当关闭一个实例时,你必须确保你调用了`MongoClient.close()`清理掉了全部的资源\n\nNew in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead.\n\n### Authentication (Optional)\n\nMongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建`MongoClient`实例时提供一下证书.\n```java\nMongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);\nMongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential));\n```\n\nMongoDB支持不同的认证机制,具体参考[the access control tutorials]()\n\n### Getting a Collection\n\n如果想要使用一个collection,那么你仅仅需要调用`getCollection(String collectionName)`方法,然后指定该collection名称就好\n\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\n```\n\n一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了\n\n### Setting Write Concern\n\n在2.10.0这个版本里,默认的write concern是`WriteConcern.ACKNOWLEDGED`不过你可以通过下面的方法轻松改变它\n```java\nmongoClient.setWriteConcern(WriteConcern.JOURNALED);\n```\n\n对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载.\n\nChanged in version 2.10.0: Prior to version 2.10.0, the default write concern is WriteConcern.NORMAL. Under normal circumstances, clients will typically change this to ensure they are notified of problems writing to the database.\n\n\n### Inserting a Document\n\n一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档\n```json\n{\n   \"name\" : \"MongoDB\",\n   \"type\" : \"database\",\n   \"count\" : 1,\n   \"info\" : {\n               x : 203,\n               y : 102\n             }\n}\n```\n\n注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用`BasicDBObject`类来实现：\n```java\nBasicDBObject doc = new BasicDBObject(\"name\", \"MongoDB\")\n        .append(\"type\", \"database\")\n        .append(\"count\", 1)\n        .append(\"info\", new BasicDBObject(\"x\", 203).append(\"y\", 102));\ncoll.insert(doc);\n```\n\n\n### Finding the First Document in a Collection Using findOne()\n\n如果想要查看刚才插入的文档,我们可以简单地调用`findOne()`,这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而`find()`会返回一个`DBCursor`对象),当collection中只有一个文档的时候,这是非常有用的.\n```java\nDBObject myDoc = coll.findOne();\nSystem.out.println(myDoc);\n```\n结果如下：\n```json\n{ \"_id\" : \"49902cde5162504500b45c2c\" ,\n  \"name\" : \"MongoDB\" ,\n  \"type\" : \"database\" ,\n  \"count\" : 1 ,\n  \"info\" : { \"x\" : 203 , \"y\" : 102}}\n\n```\n\n>Note:\n>\n> `_id`元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称\n\n### Adding Multiple Documents\n\n当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中.\n```json\n{\n   \"i\" : value\n}\n```\n\n我们可以在一个循环中不断地插入数据\n```java\nfor (int i=0; i < 100; i++) {\n    coll.insert(new BasicDBObject(\"i\", i));\n}\n```\n\n注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为`schema-free`\n\n### Counting Documents in A Collection\n\n通过以上的操作我们已经插入了101个文档,我们通过`getCount()`方法来检查一下.\n```java\nSystem.out.println(coll.getCount());\n```\n\n### Using a Cursor to Get All the Documents\n\n如果想要获得collection中的全部文档,我们可以使用`find()`方法. `find()`返回一个`DBCursor`对象,我们可以通过遍历该对象获取所有匹配我们需求的文档.\n```java\nDBCursor cursor = coll.find();\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n### Getting A Single Document with A Query\n\n我们可以向`find()`方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档.\n```java\nBasicDBObject query = new BasicDBObject(\"i\", 71);\n\ncursor = coll.find(query);\n\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n该代码只会输出一个文档\n```json\n{ \"_id\" : \"49903677516250c1008d624e\" , \"i\" : 71 }\n```\n\n你也可以从其他的实例和文档中查看`$`操作符的用法：\n```java\ndb.things.find({j: {$ne: 3}, k: {$gt: 10} });\n```\n\n使用内嵌的`DBObject`,`$`可以看作是正则表达式字串\n``` java\nquery = new BasicDBObject(\"j\", new BasicDBObject(\"$ne\", 3))\n        .append(\"k\", new BasicDBObject(\"$gt\", 10));\n\ncursor = coll.find(query);\n\ntry {\n    while(cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### Getting A Set of Documents With a Query\n\n我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i > 50的文档\n```java\n// find all where i > 50\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 50));\n\ncursor = coll.find(query);\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n我们还可以获得一个区间(20 < i <= 30)文档集合\n```java\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 20).append(\"$lte\", 30));\ncursor = coll.find(query);\n\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### MaxTime\n\nMongoDB2.6 添加查询超时的能力\n\n```java\ncoll.find().maxTime(1, SECONDS).count();\n```\n\n在上面的例子中将`maxTime`设置为1s,当时间到后查询将被打断\n\n### Bulk operations\n\nUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations:\n\n1. Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出\n2. Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行\n\n下面展示了上面所说的俩个示例\n```java\n// 1. Ordered bulk operation\nBulkWriteOperation builder = coll.initializeOrderedBulkOperation();\nbuilder.insert(new BasicDBObject(\"_id\", 1));\nbuilder.insert(new BasicDBObject(\"_id\", 2));\nbuilder.insert(new BasicDBObject(\"_id\", 3));\n\nbuilder.find(new BasicDBObject(\"_id\", 1)).updateOne(new BasicDBObject(\"$set\", new BasicDBObject(\"x\", 2)));\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 3)).replaceOne(new BasicDBObject(\"_id\", 3).append(\"x\", 4));\n\nBulkWriteResult result = builder.execute();\n\n// 2. Unordered bulk operation - no guarantee of order of operation\nbuilder = coll.initializeUnorderedBulkOperation();\nbuilder.find(new BasicDBObject(\"_id\", 1)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\n\nresult = builder.execute();\n```\n\n\n> Note:\n> \nFor servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers.\n\n\n### parallelScan\n\nMongoDB 2.6 增加了`parallelCollectionScan`命令, 该命令通过使用多个游标读取整个collection.\n```java\nParallelScanOptions parallelScanOptions = ParallelScanOptions\n        .builder()\n        .numCursors(3)\n        .batchSize(300)\n        .build();\n\nList<Cursor> cursors = coll.parallelScan(parallelScanOptions);\nfor (Cursor pCursor: cursors) {\n    while (pCursor.hasNext()) {\n        System.out.println((pCursor.next()));\n    }\n}\n```\n\n其对collection进行IO吞吐量的优化.\n\n> Note:\n>\n> `ParallelScan`不能通过`mongos`运行\n\n## Quick Tour of the Administrative Functions\n\n### Getting A List of Databases\n\n通过下面的代码你可以获取一个可用数据库列表\n```java\nMongoClient mongoClient = new MongoClient();\n\nfor (String s : mongoClient.getDatabaseNames()) {\n   System.out.println(s);\n}\n```\n\n调用`mongoClient.getDB()`并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档.\n\n### Dropping A Database\n\n通过`MongoClient`实例你也可以`drop`掉一个数据库\n```java\nMongoClient mongoClient = new MongoClient();\nmongoClient.dropDatabase(\"databaseToBeDropped\");\n```\n\n### Creating A Collection\n\n有俩种方式创建collection：\n1. 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来\n2. 或者直接调用`createCollection`命令\n\n下面的例子展示了创建1M大小的collection\n```java\ndb = mongoClient.getDB(\"mydb\");\ndb.createCollection(\"testCollection\", new BasicDBObject(\"capped\", true)\n        .append(\"size\", 1048576));\n```\n\n### Getting A List of Collections\n\n你可以通过下面的方式获得一个数据库当中可用collection列表\n```java\nfor (String s : db.getCollectionNames()) {\n   System.out.println(s);\n}\n```\n\n上面的例子会输出：\n```\nsystem.indexes\ntestCollection\n```\n\n>Note:\n>\n> `system.indexes` collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它\n\n### Dropping A Collection\n\n你可以通过`drop()`方法直接drop掉一个collection\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\ncoll.drop();\nSystem.out.println(db.getCollectionNames());\n```\n\n### Getting a List of Indexes on a Collection\n\n下例展示了如何获得一个collection中索引的列表\n```java\nList<DBObject> list = coll.getIndexInfo();\n\nfor (DBObject o : list) {\n   System.out.println(o.get(\"key\"));\n}\n```\n\n上面的实例会进行下面的输出：\n```json\n{ \"v\" : 1 , \"key\" : { \"_id\" : 1} , \"name\" : \"_id_\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"i\" : 1} , \"name\" : \"i_1\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"loc\" : \"2dsphere\"} , \"name\" : \"loc_2dsphere\" , ... }\n{ \"v\" : 1 , \"key\" : { \"_fts\" : \"text\" , \"_ftsx\" : 1} , \"name\" : \"content_text\" , ... }\n```\n\n\n### Creating An Index\n\nMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1).\n```java\ncoll.createIndex(new BasicDBObject(\"i\", 1));  // create index on \"i\", ascending\n```\n\n\n### Geo indexes\n\nMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个`2dsphere`索引, 我们可以通过标准`GeoJson`标记进行查询. 想要创建一个`2dsphere`索引,我们需要在索引文档中指定`2dsphere`这个字面量.\n```java\ncoll.createIndex(new BasicDBObject(\"loc\", \"2dsphere\"));\n```\n\n有不同的方式去查询`2dsphere`索引,下面的例子中找到了500m以内的位置.\n```java\nBasicDBList coordinates = new BasicDBList();\ncoordinates.put(0, -73.97);\ncoordinates.put(1, 40.77);\ncoll.insert(new BasicDBObject(\"name\", \"Central Park\")\n                .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n                .append(\"category\", \"Parks\"));\n\ncoordinates.put(0, -73.88);\ncoordinates.put(1, 40.78);\ncoll.insert(new BasicDBObject(\"name\", \"La Guardia Airport\")\n        .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n        .append(\"category\", \"Airport\"));\n\n\n// Find whats within 500m of my location\nBasicDBList myLocation = new BasicDBList();\nmyLocation.put(0, -73.965);\nmyLocation.put(1, 40.769);\nmyDoc = coll.findOne(\n            new BasicDBObject(\"loc\",\n                new BasicDBObject(\"$near\",\n                        new BasicDBObject(\"$geometry\",\n                                new BasicDBObject(\"type\", \"Point\")\n                                    .append(\"coordinates\", myLocation))\n                             .append(\"$maxDistance\",  500)\n                        )\n                )\n            );\nSystem.out.println(myDoc.get(\"name\"));\n```\n\n更多参考[geospatial]()文档\n\n### Text indexes\n\nMongoDB还支持`text`索引,该索引用来支持从String中搜索文本. `text`索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个`text`索引,只需要在索引文档中指定`text`字面量.\n```java\n// create a text index on the \"content\" field\ncoll.createIndex(new BasicDBObject(\"content\", \"text\"));\n```\n\nMongoDB2.6 以后`text`索引融进了主要的查询语言中,并且成为了一种默认的方式.\n```java\n// Insert some documents\ncoll.insert(new BasicDBObject(\"_id\", 0).append(\"content\", \"textual content\"));\ncoll.insert(new BasicDBObject(\"_id\", 1).append(\"content\", \"additional content\"));\ncoll.insert(new BasicDBObject(\"_id\", 2).append(\"content\", \"irrelevant content\"));\n\n// Find using the text index\nBasicDBObject search = new BasicDBObject(\"$search\", \"textual content -irrelevant\");\nBasicDBObject textSearch = new BasicDBObject(\"$text\", search);\nint matchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches: \"+ matchCount);\n\n// Find using the $language operator\ntextSearch = new BasicDBObject(\"$text\", search.append(\"$language\", \"english\"));\nmatchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches (english): \"+ matchCount);\n\n// Find the highest scoring match\nBasicDBObject projection = new BasicDBObject(\"score\", new BasicDBObject(\"$meta\", \"textScore\"));\nmyDoc = coll.findOne(textSearch, projection);\nSystem.out.println(\"Highest scoring document: \"+ myDoc);\n```\n\n上面的代码应该输出：\n```java\nText search matches: 2\nText search matches (english): 2\nHighest scoring document: { \"_id\" : 1 , \"content\" : \"additional content\" , \"score\" : 0.75}\n```\n\n更多关于text search,参考[text index and $text query operator]()\n\n# Replica\n# Deploy a Replica Set\n\n这篇教程讲述的是如何基于正在运行的不进行控制访问的`mongod`创建三个`replica set`.\n\n如果想要创建带有控制访问功能的`replica set`,参考[Deploy Replica Set and Configure Authentication and Authorization](http://docs.mongodb.org/manual/tutorial/deploy-replica-set-with-auth/). 如果你想要在一个单独的MongoDB上部署`replica set`, 可以参考[Convert a Standalone to a Replica Set](http://docs.mongodb.org/manual/tutorial/convert-standalone-to-replica-set/). 关于更多的`replica set`部署信息,参考[Replication](http://docs.mongodb.org/manual/replication/)和[Replica Set Deployment Architectures](http://docs.mongodb.org/manual/core/replica-set-architectures/)\n\n## Overview\n\n带有三个成员的`replica sets`就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. `Replica sets`应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的[elections](http://docs.mongodb.org/manual/core/replica-set-elections/). 更多关于对`replica sets`的设计,参考[Replication overview](http://docs.mongodb.org/manual/core/replication-introduction/)\n\n基本的步骤是: 首先启动要成为`replica set`成员的`mongod`, 然后配置`replica set`, 最后将`mongod`添加到`replica set`上.\n\n## Requirements\n\nFor production deployments, you should maintain as much separation between members as possible by hosting the mongod instances on separate machines. When using virtual machines for production deployments, you should place each mongod instance on a separate host server serviced by redundant power circuits and redundant network paths.\n\n在生产部署阶段, 你应该尽量在不同的主机上部署代理`mongod`的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个'mongod'.\n\n在你创建`replica set`之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的`replica set`部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考[Test Connections Between all Members](http://docs.mongodb.org/manual/tutorial/troubleshoot-replica-sets/#replica-set-troubleshooting-check-connection)\n\n## Considerations When Deploying a Replica Set\n\n### Architecture\n\n在生产阶段, 将`replica set`和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用`bind_ip`选项确保MongoDB会根据配置好的地址监听来自应用程序的连接.\n\n如果`replica set`在不同的机房内部署, 那么应该确保大多数的`mongod`实例部署在第一站点上.参考[Replica Set Deployment Architectures]()\n\n### Connectivity\n\n确保网络中所有的`replica set`成员和客户端的流量能够安全和高效地传输:\n\n* 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量.\n* 配置访问控制能够阻止未知的客户端连接到 `replica set`上\n* 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上.\n\n最终确保`replica set`中每个成员都可以通过可解析的`DNS`或者`hostname`访问到. 你应该恰当地设置上`DNS`名称或者通过`/etc/hosts`文件来映射这个配置\n\n### Configuration\nSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB.\n\nFor more information about the run time options used above and other configuration options, see Configuration File Options.\n\n## Procedure\n\n下面的步骤概括了在`access control`失效的情况下如何部署replica set\n\n###### 1. Start each member of the replica set with the appropriate options.\n\n\n启动`mongod`然后通过`replSet`选项设定`replica set`名字, 向`replica set`中添加一个成员. 如果想要配置其他特有参数,参考[Replication Options]()\n\n如果你的应用程序连接了多个`replica set`, 每一个`replica set`都应该有一个独立的名字. 某些驱动会根据`replica set`名称将`replica set`连接进行分组.\n\n下面是一个示例：\n```\n\tmongod --replSet \"rs0\"\n```\n\n你也通过配置文件设置`replica set`名字. 如果想要通过配置文件启动`mongod`, 那么你需要`--config`选项指定配置文件\n```\nmongod --config $HOME/.mongodb/config\n```\n在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围.\n\n> 注意:\n>\n> 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样. \n>\n> 那么你就需要在命令上加上 --dbpath 选项了\n\n###### 2. Connect a mongo shell to a replica set member.\n\n下例展示了如何连接到在`localhost:27017`上运行的`mongod`:\n```\nmongo\n```\n\n###### 3. Initiate the replica set.\n\n接着这`mongo`shell里使用`rs.initiate()`设置成员.\n```\nrs.initiate()\n```\nMongoDB使用`replica set`默认配置启动了一个包含当前成员的`replica set`\n\n> 注意:\n>\n> 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下.\n\n###### 4. Verify the initial replica set configuration.\n\n在`mongo`shell中使用`rs.conf()`输出`replica set`配置:\n```\nrs.conf()\n```\n\n输出的`replica set`配置类似于下面的结构\n```json\n{\n   \"_id\" : \"rs0\",\n   \"version\" : 1,\n   \"members\" : [\n      {\n         \"_id\" : 1,\n         \"host\" : \"mongodb0.example.net:27017\"\n      }\n   ]\n}\n```\n\n###### 5. Add the remaining members to the replica set.\n\n在`mongo`shell中使用`rs.add()`方法添加俩个成员:\n```\nrs.add(\"mongodb1.example.net\")\nrs.add(\"mongodb2.example.net\")\n```\n\n完成这一步之后,你就获得了一个拥有完整功能的`replica set`. 新的`replica set`会选出一个主要的来.\n\n###### 6. Check the status of the replica set.\n\n在`mongo`shell中使用`rs.status()`方法查看`replica set`状态.\n```\nrs.status()\n```\n\n## Replication Introduction\n\n`Replication` 是用于多台服务器间数据同步的一个进程.\n\n## Purpose of Replication\n\nReplication provides redundancy and increases data availability. With multiple copies of data on different database servers, replication protects a database from the loss of a single server. Replication also allows you to recover from hardware failure and service interruptions. With additional copies of the data, you can dedicate one to disaster recovery, reporting, or backup.\n\nIn some cases, you can use replication to increase read capacity. Clients have the ability to send read and write operations to different servers. You can also maintain copies in different data centers to increase the locality and availability of data for distributed applications.\n\n`Replication`提供了减少和提高数据的可用性. \n\n在某些情况下, 通过`replication`可以提高读数据的能力. \n\n## Replication in MongoDB\n\nA replica set is a group of mongod instances that host the same data set. One mongod, the primary, receives all write operations. All other instances, secondaries, apply operations from the primary so that they have the same data set.\n\nThe primary accepts all write operations from clients. Replica set can have only one primary. Because only one member can accept write operations, replica sets provide strict consistency for all reads from the primary. To support replication, the primary logs all changes to its data sets in its oplog. See primary for more information.\n\n![replica-set-read-write-operations-primary](/images/mongodb/replica-set-read-write-operations-primary.png)\n\nDiagram of default routing of reads and writes to the primary.\n\nThe secondaries replicate the primary’s oplog and apply the operations to their data sets. Secondaries’ data sets reflect the primary’s data set. If the primary is unavailable, the replica set will elect a secondary to be primary. By default, clients read from the primary, however, clients can specify a read preferences to send read operations to secondaries. Reads from secondaries may return data that does not reflect the state of the primary. See secondaries for more information.\n\n![replica-set-primary-with-two-secondaries](/images/mongodb/replica-set-primary-with-two-secondaries.png)\n\nDiagram of a 3 member replica set that consists of a primary and two secondaries.\nYou may add an extra mongod instance to a replica set as an arbiter. Arbiters do not maintain a data set. Arbiters only exist to vote in elections. If your replica set has an even number of members, add an arbiter to obtain a majority of votes in an election for primary. Arbiters do not require dedicated hardware. See arbiter for more information.\n\nDiagram of a replica set that consists of a primary, a secondary, and an arbiter.\n\n![replica-set-primary-with-secondary-and-arbiter](/images/mongodb/replica-set-primary-with-secondary-and-arbiter.png)\n\nAn arbiter will always be an arbiter. A primary may step down and become a secondary. A secondary may become the primary during an election.\n\n## Asynchronous Replication\n\nSecondaries apply operations from the primary asynchronously. By applying operations after the primary, sets can continue to function without some members. However, as a result secondaries may not return the most current data to clients.\n\nSee Replica Set Oplog and Replica Set Data Synchronization for more information. See Read Preference for more on read operations and secondaries.\n\n## Automatic Failover\n\nWhen a primary does not communicate with the other members of the set for more than 10 seconds, the replica set will attempt to select another member to become the new primary. The first secondary that receives a majority of the votes becomes primary.\n\n![replica-set-trigger-election](/images/mongodb/replica-set-trigger-election.png)\n\nDiagram of an election of a new primary. In a three member replica set with two secondaries, the primary becomes unreachable. The loss of a primary triggers an election where one of the secondaries becomes the new primary\nSee Replica Set Elections and Rollbacks During Replica Set Failover for more information.\n\n## Additional Features\n\nReplica sets provide a number of options to support application needs. For example, you may deploy a replica set with members in multiple data centers, or control the outcome of elections by adjusting the priority of some members. Replica sets also support dedicated members for reporting, disaster recovery, or backup functions.\n\nSee Priority 0 Replica Set Members, Hidden Replica Set Members and Delayed Replica Set Members for more information.\n\n\n# Shard\n","source":"_posts/MongoDB.md","raw":"title: MongoDB\n---\n# Run MongoDB\n\n## Run MongoDB On Windows\n\n```\n\t如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见.\n```\n\n### 设置MOngoDB环境\n\n###### 设置环境变量\n```\n\t在环境变量里添加环境变量 D:\\Program Files\\MongoDB\\Server\\3.0\\\n\t然后在Path里添加： %MONGODB_HOME%\\bin\n```\n\n###### data directory\n```\n\tMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是\\data\\db, \n\t所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: D:\\mongodb\\data\\db.\n\n\t你可以通过--dbpath选项给mongod.exe设置另一个data directory.\n\tmongod.exe --dbpath D:\\mongodb\\data\\db\n\n\t如果你的data directory包含空格的话,那么就需要使用\"\"将他们包含起来：\n\tmongod.exe --dbpath \"d:\\test\\mongo db data\"\n```\n\n## 启动MongoDB\n\n###### 使用mongod.exe命令启动mongoDB\n```\n\tmongod.exe\n```\n\n###### 启动日志\n```\n\t最后我们在启动日志里看到\n\twaiting for connections on port 27017\n```\n\n#### 命令行方式启动\n\nMongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017.\n```\n\tmongod --dbpath=/data/db\n```\n\n#### 配置文件方式启动\nMongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下:\n```\n\tcat /etc/mongodb.cnf\n```\n启动时加上”-f”参数,并指向配置文件即可:\n```\n\tmongod -f /etc/mongodb.cnf\n```\n\n#### Daemon 方式启动\nMongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” --fork”参数即可,,但如果用到了 ” --fork”参数就必须也启用 ”--logpath”参数,这是强制的\n\n```\n\tmongod --dbpath=/data/db --logpath=/data/log/r3.log --fork\n```\n\n#### mongod 参数说明\nmongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数\n\nmongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,\nmmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经\n有了一定程度的改善.\n\n###### mongod 的主要参数有：\n* dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中.\n* logpath —— 错误日志文件\n* logappend —— 错误日志采用追加模式（默认是覆写模式）\n* bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定\n* port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000\n* fork —— 以后台 Daemon 形式运行服务\n* journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数.\n* syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒.\n* directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似\n* maxConns —— 最大连接数\n* repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作.\n\n## 停止数据库\n\n#### Control-C\n#### shutdownServer()指令\n```\n\tmongo --port 28013\n\tuse admin\n\tdb.shutdownServer()\n```\n\n## 常用工具集\nMongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上\n的方便。\n* bsondump: 将 bson 格式的文件转储为 json 格式的数据\n* mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法\n* mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行\n* mongodump/ mongorestore: 数据库备份和恢复工具\n* mongoexport/ mongoimport: 数据导出和导入工具\n* mongofiles: GridFS 管理工具,可实现二制文件的存取\n* mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod\n* mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出\n* mongostat: 实时性能监控工具\n\n## 部署 Replica Sets\n* 创建数据文件存储路径\n```\n\tmkdir E:/mongoData/data/r0\n\tmkdir E:/mongoData/data/r1\n\tmkdir E:/mongoData/data/r2\n```\n* 创建日志文件路径\n```\n\tmkdir E:/mongoData/log\n```\n* 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。\n```\n\tmkdir E:/mongoData/key\n\techo \"this is rs1 super secret key\" > E:/mongoData/key/r0\n\techo \"this is rs1 super secret key\" > E:/mongoData/key/r1\n\techo \"this is rs1 super secret key\" > E:/mongoData/key/r2\n```\n* 启动 3 个实例\n```\n\tmongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappend\n\tmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappend\n\tmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend\n```\n* 配置及初始化 Replica Sets\n```\n\tmongo -port 28010\n\t\n```\n\n\n# Introduction\n\n## A Quick Tour\n\n使用java 驱动开发是非常简单的,首先你要确保你的`classpath`中包含`mongo.jar`\n\n### Making a Connection\n\n为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库\n\n另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地`mydb`数据库的方式\n```java\nimport com.mongodb.BasicDBObject;\nimport com.mongodb.BulkWriteOperation;\nimport com.mongodb.BulkWriteResult;\nimport com.mongodb.Cursor;\nimport com.mongodb.DB;\nimport com.mongodb.DBCollection;\nimport com.mongodb.DBCursor;\nimport com.mongodb.DBObject;\nimport com.mongodb.MongoClient;\nimport com.mongodb.ParallelScanOptions;\nimport com.mongodb.ServerAddress;\n\nimport java.util.List;\nimport java.util.Set;\n\nimport static java.util.concurrent.TimeUnit.SECONDS;\n\n// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even\n// if it's a member of a replica set:\nMongoClient mongoClient = new MongoClient();\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" );\n// or\nMongoClient mongoClient = new MongoClient( \"localhost\" , 27017 );\n// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of members\nMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(\"localhost\", 27017),\n                                      new ServerAddress(\"localhost\", 27018),\n                                      new ServerAddress(\"localhost\", 27019)));\n\nDB db = mongoClient.getDB( \"mydb\" );\n```\n\n在这个例子中`db`对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作\n\n> Note:\n>\n> `MongoClient`实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个`MongoClient`实例, 参考[concurrency doc page]()\n\n\n`MongoClient`被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个`MongoClient`实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个`MongoClient`实例,那么你需要注意下面俩点：\n\n* all resource usage limits (max connections, etc) apply per MongoClient instance\n* 当关闭一个实例时,你必须确保你调用了`MongoClient.close()`清理掉了全部的资源\n\nNew in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead.\n\n### Authentication (Optional)\n\nMongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建`MongoClient`实例时提供一下证书.\n```java\nMongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);\nMongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential));\n```\n\nMongoDB支持不同的认证机制,具体参考[the access control tutorials]()\n\n### Getting a Collection\n\n如果想要使用一个collection,那么你仅仅需要调用`getCollection(String collectionName)`方法,然后指定该collection名称就好\n\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\n```\n\n一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了\n\n### Setting Write Concern\n\n在2.10.0这个版本里,默认的write concern是`WriteConcern.ACKNOWLEDGED`不过你可以通过下面的方法轻松改变它\n```java\nmongoClient.setWriteConcern(WriteConcern.JOURNALED);\n```\n\n对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载.\n\nChanged in version 2.10.0: Prior to version 2.10.0, the default write concern is WriteConcern.NORMAL. Under normal circumstances, clients will typically change this to ensure they are notified of problems writing to the database.\n\n\n### Inserting a Document\n\n一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档\n```json\n{\n   \"name\" : \"MongoDB\",\n   \"type\" : \"database\",\n   \"count\" : 1,\n   \"info\" : {\n               x : 203,\n               y : 102\n             }\n}\n```\n\n注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用`BasicDBObject`类来实现：\n```java\nBasicDBObject doc = new BasicDBObject(\"name\", \"MongoDB\")\n        .append(\"type\", \"database\")\n        .append(\"count\", 1)\n        .append(\"info\", new BasicDBObject(\"x\", 203).append(\"y\", 102));\ncoll.insert(doc);\n```\n\n\n### Finding the First Document in a Collection Using findOne()\n\n如果想要查看刚才插入的文档,我们可以简单地调用`findOne()`,这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而`find()`会返回一个`DBCursor`对象),当collection中只有一个文档的时候,这是非常有用的.\n```java\nDBObject myDoc = coll.findOne();\nSystem.out.println(myDoc);\n```\n结果如下：\n```json\n{ \"_id\" : \"49902cde5162504500b45c2c\" ,\n  \"name\" : \"MongoDB\" ,\n  \"type\" : \"database\" ,\n  \"count\" : 1 ,\n  \"info\" : { \"x\" : 203 , \"y\" : 102}}\n\n```\n\n>Note:\n>\n> `_id`元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称\n\n### Adding Multiple Documents\n\n当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中.\n```json\n{\n   \"i\" : value\n}\n```\n\n我们可以在一个循环中不断地插入数据\n```java\nfor (int i=0; i < 100; i++) {\n    coll.insert(new BasicDBObject(\"i\", i));\n}\n```\n\n注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为`schema-free`\n\n### Counting Documents in A Collection\n\n通过以上的操作我们已经插入了101个文档,我们通过`getCount()`方法来检查一下.\n```java\nSystem.out.println(coll.getCount());\n```\n\n### Using a Cursor to Get All the Documents\n\n如果想要获得collection中的全部文档,我们可以使用`find()`方法. `find()`返回一个`DBCursor`对象,我们可以通过遍历该对象获取所有匹配我们需求的文档.\n```java\nDBCursor cursor = coll.find();\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n### Getting A Single Document with A Query\n\n我们可以向`find()`方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档.\n```java\nBasicDBObject query = new BasicDBObject(\"i\", 71);\n\ncursor = coll.find(query);\n\ntry {\n   while(cursor.hasNext()) {\n       System.out.println(cursor.next());\n   }\n} finally {\n   cursor.close();\n}\n```\n\n该代码只会输出一个文档\n```json\n{ \"_id\" : \"49903677516250c1008d624e\" , \"i\" : 71 }\n```\n\n你也可以从其他的实例和文档中查看`$`操作符的用法：\n```java\ndb.things.find({j: {$ne: 3}, k: {$gt: 10} });\n```\n\n使用内嵌的`DBObject`,`$`可以看作是正则表达式字串\n``` java\nquery = new BasicDBObject(\"j\", new BasicDBObject(\"$ne\", 3))\n        .append(\"k\", new BasicDBObject(\"$gt\", 10));\n\ncursor = coll.find(query);\n\ntry {\n    while(cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### Getting A Set of Documents With a Query\n\n我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i > 50的文档\n```java\n// find all where i > 50\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 50));\n\ncursor = coll.find(query);\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n我们还可以获得一个区间(20 < i <= 30)文档集合\n```java\nquery = new BasicDBObject(\"i\", new BasicDBObject(\"$gt\", 20).append(\"$lte\", 30));\ncursor = coll.find(query);\n\ntry {\n    while (cursor.hasNext()) {\n        System.out.println(cursor.next());\n    }\n} finally {\n    cursor.close();\n}\n```\n\n\n### MaxTime\n\nMongoDB2.6 添加查询超时的能力\n\n```java\ncoll.find().maxTime(1, SECONDS).count();\n```\n\n在上面的例子中将`maxTime`设置为1s,当时间到后查询将被打断\n\n### Bulk operations\n\nUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations:\n\n1. Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出\n2. Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行\n\n下面展示了上面所说的俩个示例\n```java\n// 1. Ordered bulk operation\nBulkWriteOperation builder = coll.initializeOrderedBulkOperation();\nbuilder.insert(new BasicDBObject(\"_id\", 1));\nbuilder.insert(new BasicDBObject(\"_id\", 2));\nbuilder.insert(new BasicDBObject(\"_id\", 3));\n\nbuilder.find(new BasicDBObject(\"_id\", 1)).updateOne(new BasicDBObject(\"$set\", new BasicDBObject(\"x\", 2)));\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 3)).replaceOne(new BasicDBObject(\"_id\", 3).append(\"x\", 4));\n\nBulkWriteResult result = builder.execute();\n\n// 2. Unordered bulk operation - no guarantee of order of operation\nbuilder = coll.initializeUnorderedBulkOperation();\nbuilder.find(new BasicDBObject(\"_id\", 1)).removeOne();\nbuilder.find(new BasicDBObject(\"_id\", 2)).removeOne();\n\nresult = builder.execute();\n```\n\n\n> Note:\n> \nFor servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers.\n\n\n### parallelScan\n\nMongoDB 2.6 增加了`parallelCollectionScan`命令, 该命令通过使用多个游标读取整个collection.\n```java\nParallelScanOptions parallelScanOptions = ParallelScanOptions\n        .builder()\n        .numCursors(3)\n        .batchSize(300)\n        .build();\n\nList<Cursor> cursors = coll.parallelScan(parallelScanOptions);\nfor (Cursor pCursor: cursors) {\n    while (pCursor.hasNext()) {\n        System.out.println((pCursor.next()));\n    }\n}\n```\n\n其对collection进行IO吞吐量的优化.\n\n> Note:\n>\n> `ParallelScan`不能通过`mongos`运行\n\n## Quick Tour of the Administrative Functions\n\n### Getting A List of Databases\n\n通过下面的代码你可以获取一个可用数据库列表\n```java\nMongoClient mongoClient = new MongoClient();\n\nfor (String s : mongoClient.getDatabaseNames()) {\n   System.out.println(s);\n}\n```\n\n调用`mongoClient.getDB()`并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档.\n\n### Dropping A Database\n\n通过`MongoClient`实例你也可以`drop`掉一个数据库\n```java\nMongoClient mongoClient = new MongoClient();\nmongoClient.dropDatabase(\"databaseToBeDropped\");\n```\n\n### Creating A Collection\n\n有俩种方式创建collection：\n1. 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来\n2. 或者直接调用`createCollection`命令\n\n下面的例子展示了创建1M大小的collection\n```java\ndb = mongoClient.getDB(\"mydb\");\ndb.createCollection(\"testCollection\", new BasicDBObject(\"capped\", true)\n        .append(\"size\", 1048576));\n```\n\n### Getting A List of Collections\n\n你可以通过下面的方式获得一个数据库当中可用collection列表\n```java\nfor (String s : db.getCollectionNames()) {\n   System.out.println(s);\n}\n```\n\n上面的例子会输出：\n```\nsystem.indexes\ntestCollection\n```\n\n>Note:\n>\n> `system.indexes` collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它\n\n### Dropping A Collection\n\n你可以通过`drop()`方法直接drop掉一个collection\n```java\nDBCollection coll = db.getCollection(\"testCollection\");\ncoll.drop();\nSystem.out.println(db.getCollectionNames());\n```\n\n### Getting a List of Indexes on a Collection\n\n下例展示了如何获得一个collection中索引的列表\n```java\nList<DBObject> list = coll.getIndexInfo();\n\nfor (DBObject o : list) {\n   System.out.println(o.get(\"key\"));\n}\n```\n\n上面的实例会进行下面的输出：\n```json\n{ \"v\" : 1 , \"key\" : { \"_id\" : 1} , \"name\" : \"_id_\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"i\" : 1} , \"name\" : \"i_1\" , \"ns\" : \"mydb.testCollection\"}\n{ \"v\" : 1 , \"key\" : { \"loc\" : \"2dsphere\"} , \"name\" : \"loc_2dsphere\" , ... }\n{ \"v\" : 1 , \"key\" : { \"_fts\" : \"text\" , \"_ftsx\" : 1} , \"name\" : \"content_text\" , ... }\n```\n\n\n### Creating An Index\n\nMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1).\n```java\ncoll.createIndex(new BasicDBObject(\"i\", 1));  // create index on \"i\", ascending\n```\n\n\n### Geo indexes\n\nMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个`2dsphere`索引, 我们可以通过标准`GeoJson`标记进行查询. 想要创建一个`2dsphere`索引,我们需要在索引文档中指定`2dsphere`这个字面量.\n```java\ncoll.createIndex(new BasicDBObject(\"loc\", \"2dsphere\"));\n```\n\n有不同的方式去查询`2dsphere`索引,下面的例子中找到了500m以内的位置.\n```java\nBasicDBList coordinates = new BasicDBList();\ncoordinates.put(0, -73.97);\ncoordinates.put(1, 40.77);\ncoll.insert(new BasicDBObject(\"name\", \"Central Park\")\n                .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n                .append(\"category\", \"Parks\"));\n\ncoordinates.put(0, -73.88);\ncoordinates.put(1, 40.78);\ncoll.insert(new BasicDBObject(\"name\", \"La Guardia Airport\")\n        .append(\"loc\", new BasicDBObject(\"type\", \"Point\").append(\"coordinates\", coordinates))\n        .append(\"category\", \"Airport\"));\n\n\n// Find whats within 500m of my location\nBasicDBList myLocation = new BasicDBList();\nmyLocation.put(0, -73.965);\nmyLocation.put(1, 40.769);\nmyDoc = coll.findOne(\n            new BasicDBObject(\"loc\",\n                new BasicDBObject(\"$near\",\n                        new BasicDBObject(\"$geometry\",\n                                new BasicDBObject(\"type\", \"Point\")\n                                    .append(\"coordinates\", myLocation))\n                             .append(\"$maxDistance\",  500)\n                        )\n                )\n            );\nSystem.out.println(myDoc.get(\"name\"));\n```\n\n更多参考[geospatial]()文档\n\n### Text indexes\n\nMongoDB还支持`text`索引,该索引用来支持从String中搜索文本. `text`索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个`text`索引,只需要在索引文档中指定`text`字面量.\n```java\n// create a text index on the \"content\" field\ncoll.createIndex(new BasicDBObject(\"content\", \"text\"));\n```\n\nMongoDB2.6 以后`text`索引融进了主要的查询语言中,并且成为了一种默认的方式.\n```java\n// Insert some documents\ncoll.insert(new BasicDBObject(\"_id\", 0).append(\"content\", \"textual content\"));\ncoll.insert(new BasicDBObject(\"_id\", 1).append(\"content\", \"additional content\"));\ncoll.insert(new BasicDBObject(\"_id\", 2).append(\"content\", \"irrelevant content\"));\n\n// Find using the text index\nBasicDBObject search = new BasicDBObject(\"$search\", \"textual content -irrelevant\");\nBasicDBObject textSearch = new BasicDBObject(\"$text\", search);\nint matchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches: \"+ matchCount);\n\n// Find using the $language operator\ntextSearch = new BasicDBObject(\"$text\", search.append(\"$language\", \"english\"));\nmatchCount = coll.find(textSearch).count();\nSystem.out.println(\"Text search matches (english): \"+ matchCount);\n\n// Find the highest scoring match\nBasicDBObject projection = new BasicDBObject(\"score\", new BasicDBObject(\"$meta\", \"textScore\"));\nmyDoc = coll.findOne(textSearch, projection);\nSystem.out.println(\"Highest scoring document: \"+ myDoc);\n```\n\n上面的代码应该输出：\n```java\nText search matches: 2\nText search matches (english): 2\nHighest scoring document: { \"_id\" : 1 , \"content\" : \"additional content\" , \"score\" : 0.75}\n```\n\n更多关于text search,参考[text index and $text query operator]()\n\n# Replica\n# Deploy a Replica Set\n\n这篇教程讲述的是如何基于正在运行的不进行控制访问的`mongod`创建三个`replica set`.\n\n如果想要创建带有控制访问功能的`replica set`,参考[Deploy Replica Set and Configure Authentication and Authorization](http://docs.mongodb.org/manual/tutorial/deploy-replica-set-with-auth/). 如果你想要在一个单独的MongoDB上部署`replica set`, 可以参考[Convert a Standalone to a Replica Set](http://docs.mongodb.org/manual/tutorial/convert-standalone-to-replica-set/). 关于更多的`replica set`部署信息,参考[Replication](http://docs.mongodb.org/manual/replication/)和[Replica Set Deployment Architectures](http://docs.mongodb.org/manual/core/replica-set-architectures/)\n\n## Overview\n\n带有三个成员的`replica sets`就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. `Replica sets`应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的[elections](http://docs.mongodb.org/manual/core/replica-set-elections/). 更多关于对`replica sets`的设计,参考[Replication overview](http://docs.mongodb.org/manual/core/replication-introduction/)\n\n基本的步骤是: 首先启动要成为`replica set`成员的`mongod`, 然后配置`replica set`, 最后将`mongod`添加到`replica set`上.\n\n## Requirements\n\nFor production deployments, you should maintain as much separation between members as possible by hosting the mongod instances on separate machines. When using virtual machines for production deployments, you should place each mongod instance on a separate host server serviced by redundant power circuits and redundant network paths.\n\n在生产部署阶段, 你应该尽量在不同的主机上部署代理`mongod`的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个'mongod'.\n\n在你创建`replica set`之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的`replica set`部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考[Test Connections Between all Members](http://docs.mongodb.org/manual/tutorial/troubleshoot-replica-sets/#replica-set-troubleshooting-check-connection)\n\n## Considerations When Deploying a Replica Set\n\n### Architecture\n\n在生产阶段, 将`replica set`和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用`bind_ip`选项确保MongoDB会根据配置好的地址监听来自应用程序的连接.\n\n如果`replica set`在不同的机房内部署, 那么应该确保大多数的`mongod`实例部署在第一站点上.参考[Replica Set Deployment Architectures]()\n\n### Connectivity\n\n确保网络中所有的`replica set`成员和客户端的流量能够安全和高效地传输:\n\n* 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量.\n* 配置访问控制能够阻止未知的客户端连接到 `replica set`上\n* 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上.\n\n最终确保`replica set`中每个成员都可以通过可解析的`DNS`或者`hostname`访问到. 你应该恰当地设置上`DNS`名称或者通过`/etc/hosts`文件来映射这个配置\n\n### Configuration\nSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB.\n\nFor more information about the run time options used above and other configuration options, see Configuration File Options.\n\n## Procedure\n\n下面的步骤概括了在`access control`失效的情况下如何部署replica set\n\n###### 1. Start each member of the replica set with the appropriate options.\n\n\n启动`mongod`然后通过`replSet`选项设定`replica set`名字, 向`replica set`中添加一个成员. 如果想要配置其他特有参数,参考[Replication Options]()\n\n如果你的应用程序连接了多个`replica set`, 每一个`replica set`都应该有一个独立的名字. 某些驱动会根据`replica set`名称将`replica set`连接进行分组.\n\n下面是一个示例：\n```\n\tmongod --replSet \"rs0\"\n```\n\n你也通过配置文件设置`replica set`名字. 如果想要通过配置文件启动`mongod`, 那么你需要`--config`选项指定配置文件\n```\nmongod --config $HOME/.mongodb/config\n```\n在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围.\n\n> 注意:\n>\n> 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样. \n>\n> 那么你就需要在命令上加上 --dbpath 选项了\n\n###### 2. Connect a mongo shell to a replica set member.\n\n下例展示了如何连接到在`localhost:27017`上运行的`mongod`:\n```\nmongo\n```\n\n###### 3. Initiate the replica set.\n\n接着这`mongo`shell里使用`rs.initiate()`设置成员.\n```\nrs.initiate()\n```\nMongoDB使用`replica set`默认配置启动了一个包含当前成员的`replica set`\n\n> 注意:\n>\n> 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下.\n\n###### 4. Verify the initial replica set configuration.\n\n在`mongo`shell中使用`rs.conf()`输出`replica set`配置:\n```\nrs.conf()\n```\n\n输出的`replica set`配置类似于下面的结构\n```json\n{\n   \"_id\" : \"rs0\",\n   \"version\" : 1,\n   \"members\" : [\n      {\n         \"_id\" : 1,\n         \"host\" : \"mongodb0.example.net:27017\"\n      }\n   ]\n}\n```\n\n###### 5. Add the remaining members to the replica set.\n\n在`mongo`shell中使用`rs.add()`方法添加俩个成员:\n```\nrs.add(\"mongodb1.example.net\")\nrs.add(\"mongodb2.example.net\")\n```\n\n完成这一步之后,你就获得了一个拥有完整功能的`replica set`. 新的`replica set`会选出一个主要的来.\n\n###### 6. Check the status of the replica set.\n\n在`mongo`shell中使用`rs.status()`方法查看`replica set`状态.\n```\nrs.status()\n```\n\n## Replication Introduction\n\n`Replication` 是用于多台服务器间数据同步的一个进程.\n\n## Purpose of Replication\n\nReplication provides redundancy and increases data availability. With multiple copies of data on different database servers, replication protects a database from the loss of a single server. Replication also allows you to recover from hardware failure and service interruptions. With additional copies of the data, you can dedicate one to disaster recovery, reporting, or backup.\n\nIn some cases, you can use replication to increase read capacity. Clients have the ability to send read and write operations to different servers. You can also maintain copies in different data centers to increase the locality and availability of data for distributed applications.\n\n`Replication`提供了减少和提高数据的可用性. \n\n在某些情况下, 通过`replication`可以提高读数据的能力. \n\n## Replication in MongoDB\n\nA replica set is a group of mongod instances that host the same data set. One mongod, the primary, receives all write operations. All other instances, secondaries, apply operations from the primary so that they have the same data set.\n\nThe primary accepts all write operations from clients. Replica set can have only one primary. Because only one member can accept write operations, replica sets provide strict consistency for all reads from the primary. To support replication, the primary logs all changes to its data sets in its oplog. See primary for more information.\n\n![replica-set-read-write-operations-primary](/images/mongodb/replica-set-read-write-operations-primary.png)\n\nDiagram of default routing of reads and writes to the primary.\n\nThe secondaries replicate the primary’s oplog and apply the operations to their data sets. Secondaries’ data sets reflect the primary’s data set. If the primary is unavailable, the replica set will elect a secondary to be primary. By default, clients read from the primary, however, clients can specify a read preferences to send read operations to secondaries. Reads from secondaries may return data that does not reflect the state of the primary. See secondaries for more information.\n\n![replica-set-primary-with-two-secondaries](/images/mongodb/replica-set-primary-with-two-secondaries.png)\n\nDiagram of a 3 member replica set that consists of a primary and two secondaries.\nYou may add an extra mongod instance to a replica set as an arbiter. Arbiters do not maintain a data set. Arbiters only exist to vote in elections. If your replica set has an even number of members, add an arbiter to obtain a majority of votes in an election for primary. Arbiters do not require dedicated hardware. See arbiter for more information.\n\nDiagram of a replica set that consists of a primary, a secondary, and an arbiter.\n\n![replica-set-primary-with-secondary-and-arbiter](/images/mongodb/replica-set-primary-with-secondary-and-arbiter.png)\n\nAn arbiter will always be an arbiter. A primary may step down and become a secondary. A secondary may become the primary during an election.\n\n## Asynchronous Replication\n\nSecondaries apply operations from the primary asynchronously. By applying operations after the primary, sets can continue to function without some members. However, as a result secondaries may not return the most current data to clients.\n\nSee Replica Set Oplog and Replica Set Data Synchronization for more information. See Read Preference for more on read operations and secondaries.\n\n## Automatic Failover\n\nWhen a primary does not communicate with the other members of the set for more than 10 seconds, the replica set will attempt to select another member to become the new primary. The first secondary that receives a majority of the votes becomes primary.\n\n![replica-set-trigger-election](/images/mongodb/replica-set-trigger-election.png)\n\nDiagram of an election of a new primary. In a three member replica set with two secondaries, the primary becomes unreachable. The loss of a primary triggers an election where one of the secondaries becomes the new primary\nSee Replica Set Elections and Rollbacks During Replica Set Failover for more information.\n\n## Additional Features\n\nReplica sets provide a number of options to support application needs. For example, you may deploy a replica set with members in multiple data centers, or control the outcome of elections by adjusting the priority of some members. Replica sets also support dedicated members for reporting, disaster recovery, or backup functions.\n\nSee Priority 0 Replica Set Members, Hidden Replica Set Members and Delayed Replica Set Members for more information.\n\n\n# Shard\n","slug":"MongoDB","published":1,"date":"2015-09-18T02:01:56.832Z","updated":"2015-09-18T01:06:55.596Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjeby002k74ufdr2n6l8q"},{"title":"Flick Ticket Server","_content":"## 为什么采用Ticket Server\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外Flicker Mysql是基于`主-主`复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n## 考虑GUID \n\nGUID是非常大的,但是他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会建立索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n## 一致性哈希 \n像Amazon Dynamo等项目提出了在数据存储顶部采用`一致性哈希环`,来解决`GUID/sharding`问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然而MYSQL针对快速随机读进行了优化\n\n\n## 集中自动增量\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n## 替换(重新插入) \n\n大概十多年前,mysql对`ANSI SQL`实现了一个非标准化的拓展-`REPLACE INTO`. 随后`INSERT ON DUPLICATE KEY UPDATE`做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是`REPLACE INTO` 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的`PRIMARY KEY`或者 `UNIQUE index`重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n## 组装 \n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n\n#### 下面展示了一下Ticket64 schema\n\n```\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n#### 当我需要一个新的64位ID时,我执行面貌这个sql\n\n```\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n#### SPOF(单点故障) \n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n\n#### 我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n###### 在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n\n","source":"_posts/Flick Ticket Server.md","raw":"title: Flick Ticket Server\n---\n## 为什么采用Ticket Server\nFlickr采用分库分表的方式来拓展数据库. 有时候需要合并不同数据库之间的数据,那么就需要保证全局唯一的key.另外Flicker Mysql是基于`主-主`复制的。 这就意味着我们在分库分表时必须确保唯一性,以避免主键的重复.虽然使用MYSQL的自增长主键是极好的,但是它却不能确保无论是在物理主机还是逻辑主机上的唯一性.\n\n\n## 考虑GUID \n\nGUID是非常大的,但是他们在MYSQL索引时性能比较差.我们使用MYSQL查询非常快的一个原因就是,我们对想要查询的东西都会建立索引,那么在查询的时候,我们只需要查询这些索引就好了. 所以索引的大小是一个关键性的选择.另外TickerServer内含了序列性,这对于报告或者debug是很有好处的.\n\n\n## 一致性哈希 \n像Amazon Dynamo等项目提出了在数据存储顶部采用`一致性哈希环`,来解决`GUID/sharding`问题.这种解决方案更适合write-cheap(大量写操作)这种场景,然而MYSQL针对快速随机读进行了优化\n\n\n## 集中自动增量\n如果不能让mysql在多个数据库中实现自动增长的话,那么为什么不仅仅只是更新一个数据库呢？如果我们每次只是在一个数据库中插入一行数据, 那么某人在上传一张照片时 我们可以只使用从那个表中生成的主键ID.\n\n当然如果每秒钟上传60张照片的话,这个表会变得非常大. 那我们可以将这张照片的图像数据去掉, 在中心数据库中只保留ID. 可即便那样, 这个表有可能仍然会变得非常大. 而且还会产生评论,分组,标记等等其他信息, 这些数据都需要ID\n\n\n## 替换(重新插入) \n\n大概十多年前,mysql对`ANSI SQL`实现了一个非标准化的拓展-`REPLACE INTO`. 随后`INSERT ON DUPLICATE KEY UPDATE`做为一个新的语法出现了, 它的出现更好的解决了那个初始问题. 但是`REPLACE INTO` 仍然被支持着.\n\nREPLACE 的操作极像 INSERT, 如果新插入的一行和原有行中的`PRIMARY KEY`或者 `UNIQUE index`重复的话,那么会先将原来的整行删掉,然后再插入新的一行.\n\n\n## 组装 \n\nFlicker ticket server 专用于database服务器, 该服务器上有且仅有一个数据库. 在该数据库内有一些表,像表示32位ID的Tickets32, 或者表示64位ID的 Tickets64.\n\n\n#### 下面展示了一下Ticket64 schema\n\n```\nCREATE TABLE Tickets64 (\nid bigint(20) unsigned NOT NULL auto_increment,\nstub char(1) NOT NULL default ' ' ,\nPRIMARY KEY ( id ) ,\nUNIQUE KEY  stub ( stub )\n) ENGINE=MyISAM\n\n```\n\n* 当我们执行sql:`SELECT * from Tickets64` 返回下面一个结果\n\n```\n+-------------------+------+\n| id \t\t\t\t|stub  |\n+-------------------+------+\n| 72157623227190423 | a    |\n+-------------------+------+\n```\n\n#### 当我需要一个新的64位ID时,我执行面貌这个sql\n\n```\nREPLACE INTO Tickets64 (stub) VALUES (' a' ) ;\nSELECT LAST_INSERT_ID() ;\n```\n\n#### SPOF(单点故障) \n\n你无法预料到准备好给你的ID会产生单点故障. 故我们同事运行俩台ticket server来达到高可用. 同时在不同的数据库中大量的发生写/更新操作也会产生问题, 如果加锁的话就会使服务器白白丧失掉大量的性能.\n我们的解决办法是通过拆分ID空间 在不同的数据库间进行责任拆分, 如下所示：\n\n```\nTicketServer1:\nauto-increment-increment = 2\nauto-increment-offset = 1\n\nTicketServer2:\nauto-increment-increment = 2\nauto-increment-offset = 2\n\n```\n\n#### 我们通过在不同的服务器间循环操作来达到负载均衡以及减少运行时间.\n\n###### 在Ticket server我们不单单只有Tickets32 and Tickets64 这俩张表,我们还有更多的表. 例如针对照片, 账号, 离线任务等等 其他的表.\n\n","slug":"Flick Ticket Server","published":1,"date":"2015-09-16T04:04:20.599Z","updated":"2015-09-16T01:04:31.106Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjebz002l74ufvl67jd20"},{"title":"Archiva","_content":"\n## 安装步骤\n1. 从[Archiva官网]()下载Archiva后解压到`D:\\archiva`里\n2. 运行`bin\\archiva.bat install`, archiva就启动成功了\n3. 在浏览器运行`http://localhost:8080/`就可以进入archiva本地主页了\n4. 当进入之后我们需要创建一个账号：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/0.jpg)\n5. 接着我们创建一个私有的仓库![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/1.jpg)\n6. 我们创建一个最简单的私有仓库：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/2.jpg)\n7. 创建一个连接器![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/3.jpg)\n8. 同样我们只选用必须的![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/4.jpg)\n9. 接着如图操作![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/5.jpg)\n10. 然后我们修改项目中的`pom.xml`文件!\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>testMaven</groupId>\n    <artifactId>testDeply</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <distributionManagement>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </distributionManagement>\n</project>\n```\n11. 修改本地仓库中的`setting.xml`文件(我的目录`C:\\Users\\Administrator\\.m2`),我们添加私有仓库的用户名和密码!\n```xml\n<settings xmlns=\"http://maven.apache.org/settings/1.0.0\" \n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n   \n\t<servers>\n        <server>\n            <id>ID2015_09_17</id>\n            <username>admin</username>\n            <password>admin1</password>\n        </server>\n    </servers>\n  \n </settings>\n ```\n\n\n","source":"_posts/Archiva.md","raw":"title: Archiva\n---\n\n## 安装步骤\n1. 从[Archiva官网]()下载Archiva后解压到`D:\\archiva`里\n2. 运行`bin\\archiva.bat install`, archiva就启动成功了\n3. 在浏览器运行`http://localhost:8080/`就可以进入archiva本地主页了\n4. 当进入之后我们需要创建一个账号：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/0.jpg)\n5. 接着我们创建一个私有的仓库![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/1.jpg)\n6. 我们创建一个最简单的私有仓库：![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/2.jpg)\n7. 创建一个连接器![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/3.jpg)\n8. 同样我们只选用必须的![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/4.jpg)\n9. 接着如图操作![](https://raw.githubusercontent.com/wanggnim/website/images/Archiva/5.jpg)\n10. 然后我们修改项目中的`pom.xml`文件!\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>testMaven</groupId>\n    <artifactId>testDeply</artifactId>\n    <version>1.0-SNAPSHOT</version>\n\n    <repositories>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <distributionManagement>\n        <repository>\n            <id>ID2015_09_17</id>\n            <name>NAME2015_09_17</name>\n            <url>http://localhost:8080/repository/ID2015_09_17</url>\n        </repository>\n    </distributionManagement>\n</project>\n```\n11. 修改本地仓库中的`setting.xml`文件(我的目录`C:\\Users\\Administrator\\.m2`),我们添加私有仓库的用户名和密码!\n```xml\n<settings xmlns=\"http://maven.apache.org/settings/1.0.0\" \n          xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n          xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n   \n\t<servers>\n        <server>\n            <id>ID2015_09_17</id>\n            <username>admin</username>\n            <password>admin1</password>\n        </server>\n    </servers>\n  \n </settings>\n ```\n\n\n","slug":"Archiva","published":1,"date":"2015-09-18T02:01:56.830Z","updated":"2015-09-17T10:22:01.653Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciepfjec0002m74uf878qplsx"}],"PostAsset":[],"PostCategory":[{"post_id":"ciepfje99000674ufqfk4jhb4","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9c000874ufa4uk9urd"},{"post_id":"ciepfje9d000974ufwdvc4wyv","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9e000a74uf5zzpcogb"},{"post_id":"ciepfje9f000b74ufkvfmuhnb","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9g000c74ufa2cl4isd"},{"post_id":"ciepfje9h000d74uf2rwuniga","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9i000e74ufiofl12b8"},{"post_id":"ciepfje9j000f74uf85iub86g","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9j000g74ufnxwpcg37"},{"post_id":"ciepfje9k000h74ufry2ezbgx","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9l000i74uf7228bndg"},{"post_id":"ciepfje9m000j74ufsk3bl1q5","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9n000k74ufmw565alw"},{"post_id":"ciepfje9o000l74ufhc5wa25u","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9q000m74uf8h755zph"},{"post_id":"ciepfje9r000n74uf73v7gwd5","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9s000o74ufih513bo8"},{"post_id":"ciepfje9u000q74uf1fpxbx6y","category_id":"ciepfje9a000774uf4uyrwljj","_id":"ciepfje9v000r74ufbpgcdwmi"},{"post_id":"ciepfjea0000u74uf0o5ytdnn","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjea2000w74ufl9lxuse2"},{"post_id":"ciepfjea3000x74ufomgeso8c","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjea5000y74ufyjb15mtn"},{"post_id":"ciepfjea6000z74ufvuvb5jr2","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjea7001074ufn9ttz16c"},{"post_id":"ciepfjea8001174uf6670uv36","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjea9001274ufrkojcyi4"},{"post_id":"ciepfjeaa001374ufo222wu5i","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeac001474ufzwmjkps5"},{"post_id":"ciepfjead001574ufa721erce","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeae001674ufinnat47t"},{"post_id":"ciepfjeaf001774ufhc6cqqmr","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeaf001874ufpzfi4sc3"},{"post_id":"ciepfjeah001974ufvei5k63c","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeah001a74ufjfkhjssm"},{"post_id":"ciepfjeai001b74uf2sdo6mzl","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeak001c74uflvrua0tg"},{"post_id":"ciepfjeal001d74ufb6mvxix5","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeam001e74ufzgruypea"},{"post_id":"ciepfjeam001f74uf34kwc13g","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjeao001g74uf9li4faf9"},{"post_id":"ciepfjeap001h74ufktvs4a39","category_id":"ciepfjea2000v74ufcabnoi50","_id":"ciepfjear001i74ufr8tbuy95"},{"post_id":"ciepfjeb7001s74uf533ov82x","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjeb9001u74uf7ssy83pz"},{"post_id":"ciepfjeba001v74ufzof5o6vs","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebb001w74uf4d0crpue"},{"post_id":"ciepfjebc001x74ufxec2fc7c","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebd001y74ufuut1xlp7"},{"post_id":"ciepfjebe001z74ufg9djq3ra","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebf002074uf441wh6w8"},{"post_id":"ciepfjebi002174uf3poepbua","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebj002274ufbftopayw"},{"post_id":"ciepfjebl002374uf3xqliye5","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebm002474ufel3pr8id"},{"post_id":"ciepfjebm002574ufr9dbuemx","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebn002674ufy4e8xq0g"},{"post_id":"ciepfjebo002774uf9dpqqi0m","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebp002874uf3cgjirna"},{"post_id":"ciepfjebq002974ufbkvcr2tl","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebq002a74uffkqw9d1e"},{"post_id":"ciepfjebr002b74uf45rflssn","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebs002c74uf5n88d24h"},{"post_id":"ciepfjebs002d74ufiu16ut28","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebt002e74uf5850ou56"},{"post_id":"ciepfjebu002f74ufs5no58fc","category_id":"ciepfjebv002g74ufunvqzkfn","_id":"ciepfjebw002h74ufivgodty1"},{"post_id":"ciepfjebw002i74ufxiayd1bl","category_id":"ciepfjeb8001t74ufy0hfqhsr","_id":"ciepfjebx002j74ufb24uds31"}],"PostTag":[],"Tag":[]}}